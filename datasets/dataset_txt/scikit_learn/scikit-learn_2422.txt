ppallesen commented on Feb 8, 2017 â€¢
edited by jnothman
I'm missing a learning curver method for the random_forest classifier. I have made one by hand. It does not seem efficient. Surgestions for improvements or will some admin impliment something simular:
----code below--
from types import MethodType
from sklearn.ensemble import RandomForestClassifier
import numpy as np
import scipy
import matplotlib.pyplot as plt

#Learning curve function to be appended to the RandomForestClassifier class
def learning_curve_binary_classify(self,x_train,y_train,x_valid,y_valid,plot_curves=True):
    learning_curve_dict={'train_error':[],'valid_error':[]}
    preds_train=np.zeros(y_train.shape)
    preds_valid=np.zeros(y_valid.shape)
    for i in range(self.n_estimators):
        preds_train+=self.estimators_[i].predict(x_train)
        preds_valid+=self.estimators_[i].predict(x_valid)
        learning_curve_dict['train_error']+=[1-np.mean(np.equal((preds_train>i/2.0),y_train))]
        learning_curve_dict['valid_error']+=[1-np.mean(np.equal((preds_valid>i/2.0),y_valid))]
    if plot_curves:
        plt.plot(learning_curve_dict['train_error'])
        plt.plot(learning_curve_dict['valid_error'])
        plt.show()
    return learning_curve_dict

#Make dummy data
n=1000
idx=np.random.permutation(n)
train_idx=idx[:n*0.7]
test_idx=idx[n*0.7:]
X=np.random.normal(size=(n,16))
Y=np.random.binomial(1,scipy.stats.norm.cdf(np.sum(X,axis=1)))

#Fit data
RFC=RandomForestClassifier(n_estimators=200,max_features=int(np.sqrt(X.shape[1])),n_jobs=-1)
RFC.fit(X[train_idx],Y[train_idx])
preds=RFC.predict(X[test_idx])

#Attach method to class
RFC.learning_curve_binary_classify = MethodType(learning_curve_binary_classify, RFC, RandomForestClassifier)
#Print out learning curve
learning_curve_dict=RFC.learning_curve_binary_classify(X[train_idx],Y[train_idx],X[test_idx],Y[test_idx])
lamin3 commented on Jan 20, 2019 â€¢
edited
Hello,
I have a dataset of 13600 of PE executables samples, and I want to make some clustering on them. These samples have different nature of features, in which I can't apply directly the same distance metric on them all together, it doesn't make sense for me, since the nature of these features is totally different.
Basically, I have two different nature of features:
Category_1 : Represents opcodes/mnemonics sequences of a binary software. Example: ["push", "pop","mov", "ret", ....].
Category_2 : Represents some numbers and ratios, like the number of sections of a PE executable ...etc.
So, as you can see, I can't apply directly euclidean distance on them all, even if a scale them on the same unit.
What I want to do is: to apply leveinshtein distance on the first category and euclidean distance on the second category, then join them with some operator (summation or other relation) and finally apply DBSCAN on them.
My questions, or points of discussion, are the following:
1 - Do you have a suggestion on how it could done efficiently ? Should I perhaps compute the pairwise dissimilarity matrix for the first category with leveinshtein distance metric (and this step is already done), and compute a second pairwise dissimilarity matrix for the second category with euclidean distance metric, then make the sum of them and give as input the final dissimilarity matrix in DBSCAN with metric="precomputed" ?
2- Do you have a suggestion on how can I guess the kind of operator I should use to join the two dissimilarity matrix ? I'm really confused about this. My idea was to give a weight on the category I consider more important, them add them up. But of course, this summation relation is not necessarily true. Do you have a suggestion on how I can guess the right operator I should use to join the two distances.
Thanks in advance for your answers/discussion
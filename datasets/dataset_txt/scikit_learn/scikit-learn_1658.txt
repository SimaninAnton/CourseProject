CsStudent5678 commented on Dec 26, 2017 â€¢
edited
(x post from this usage question)
Is there any current way, or desire to add in the future,the ability to do a voting classifier with heterogeneous features, as per this situation:
My data is stored in my_df, a DataFrame object that has a bunch of sparse categorical feature columns that have been binaraized, text_data (a text feature column) and abinary_outcome column.
I want to use a voting ensemble with one classifier for the categorical features, and another for the text features:
categorical_col_names=['foo','bar','jar','tar','boo','car']

#Construct a classifier for use on categorical features...
categorical_clf = Pipeline([('selector', 
SelectPercentile(f_classif, percentile=20)), ('sgd', SGDClassifier())])

#"X" is a new data frame object formed from just the categorical columns of my_df and "Y" is a binary outcome... 
categorical_clf.fit(df[[col for category in categorical_col_names for col in my_df.columns if category in col]], binary_outcome)

#Construct a classifier for use on the text_data column 
text_clf = Pipeline([('vect', TfidfVectorizer()),  ('mnb', MultinomialNB())])

# "X" is my text column; "Y" is a binary outcome. 
text_clf.fit(my_df['text_data'], binary_outcome)
I would normally fit a voting ensemble classifier, but I can't do this because both of my classifiers take different features. For instance:
voting_clf = VotingClassifier(estimators=[('text', text_clf), ('categorical', categorical_clf)],voting='soft')
can only be fitted with wth a single X but each classifier takes a different X.
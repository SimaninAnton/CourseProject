Member
larsmans commented on Apr 30, 2012
SelectKBest doesn't do tie breaking and may return feature vectors that are larger than requested. Observe:
>>> from sklearn.feature_selection import SelectKBest, chi2
>>> import numpy as np
>>> X = np.array([[1, 0, 0], [0, 1, 1]])
>>> X.shape
(2, 3)
>>> SelectKBest(chi2, k=2).fit_transform(X, [0, 1]).shape
(2, 3)
>>> SelectKBest(chi2, k=1).fit_transform(X, [0, 1]).shape
(2, 3)
This turns out to be quite surprising for users. The problem is in SelectKBest._get_support_mask:
alpha = np.sort(self.pvalues_)[k - 1]
return (self.pvalues_ <= alpha)
We should either change the documentation to reflect the current behavior, or fix the implementation to actually select k features instead of some number between k and n_features. I'm in favor of the latter.
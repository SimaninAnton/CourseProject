Contributor
mheilman commented on Jul 17, 2014
It appears that the raw_coef_ variable in LIBLINEAR models is only used when training to set the final model parameters (coef_ and intercept_). It seems like this doesn't need to be kept around as a member variable. Keeping it essentially causes the parameters to be saved twice when writing to disk using joblib (see code below).
I noticed this after removing columns of zeros from a logistic regression fit with an L1 penalty. Even though I'd removed all but 5% of the features, the model on disk ended up still being about 50% of the size because raw_coef_ was still large.
See
scikit-learn/sklearn/svm/base.py
Line 697 in 9c51bc9
 self.raw_coef_ = liblinear.train_wrap(X, y_ind, 
).
import numpy as np
from sklearn.externals import joblib
from sklearn import linear_model, datasets

iris = datasets.load_iris()
X = iris.data[:, :2]  # we only take the first two features.
Y = iris.target
logreg = linear_model.LogisticRegression(C=1e5)
logreg.fit(X, Y)
joblib.dump(logreg, 'original_model.pkl') 

logreg.raw_coef_ = None
joblib.dump(logreg, 'smaller_model.pkl')
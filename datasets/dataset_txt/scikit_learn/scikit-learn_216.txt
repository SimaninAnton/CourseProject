TimotheeMathieu commented on Oct 7, 2019
Hello,
I hope that I am posting at the right place.
I am currently working on Robust Machine learning and I want to try and add something to scikit-learn on this subject. I want to know if some of you are interested in it and if it would be interesting to implement this new feature.
The project
The idea is to have a correct classification even when there are outliers and we want to be able to control (with an hyperparameter) how much robust the estimator is (this hyperparameter is then often tuned by cross-validation on specific examples).
What I achieved
The algorithms are robust to outliers in the feature as well as in the label (which is not the case of HuberRegressor), it can do robust non-linear regression/classification. The idea is that I use incremental algorithms like SGDRegressor/SGDClassifier or MLPRegressor/MLPClassifier that feature a partial_fit function, and then at each iteration I give to the algorithm a sample_weight argument that down-weight outliers according to whether its loss (robust estimation of loss function) is big or not, and the "inliers" with low loss function are not down-weighted. This is the basic idea, if you want more details feel free to ask me.
Ref
The algorithms are based on ideas from the following articles: https://arxiv.org/abs/1906.04280 and https://arxiv.org/abs/1808.03106 .
To conclude, my main question is : is someone interested in this ? In that case, if possible I want to implement this feature but as I am very new to contributing and the likes I may need help and some time to achieve something viable to put into sklearn.
PS : for the code & example, you can look at https://github.com/TimotheeMathieu/scikit-learn/blob/RobustIterativeWeighting/ and https://github.com/TimotheeMathieu/scikit-learn/blob/RobustIterativeWeighting/Illustration_Robust.ipynb it is not documented yet but I hope that the notebook speaks for itself.
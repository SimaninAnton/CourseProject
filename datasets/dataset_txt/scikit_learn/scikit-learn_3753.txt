Member
ogrisel commented on Jun 25, 2015
Since we released the GIL in most of the Cython coordinate descent solver (#3102), we could now sparse encode in parallel efficiently with threads when using that solver.
Making this change in the code of sparse_encode should be straightforward and the tests should stay the same but accepting a PR for that will require running some benchmarks to check that switching to the threading backend improves memory usage, reduces scheduling overhead and therefore should slightly improve overall sparse encoding speed.
Note: Using threading for the LARS solver might not be efficiently parallelizable with threads. The LARS solver is primarily written in Python / NumPy although we should check as numpy releases the GIL often.
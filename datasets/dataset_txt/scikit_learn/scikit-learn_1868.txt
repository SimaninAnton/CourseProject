Member
qinhanmin2014 commented on Sep 25, 2017 ‚Ä¢
edited
Wrap up the discussions in #9828 #9567 along with some opinions from myself
sklearn/metrics/tests/test_common might need some improvements
(1) Move roc_auc scores out of METRIC_UNDEFINED_BINARY (Fixed in #9786)
(2) Move average_precision scores out of METRIC_UNDEFINED_BINARY
(3) Get rid of the awkward list here (See #9828)
(4) In order to achieve (1) and (3), fully support binary y_true for roc_auc scores (See #9828)
(5) In order to achieve (2) and (3), fully support binary y_true for average_precision scores
(6) Remove some unnecessary metrics (e.g., roc_auc_score/macro_roc_auc, average_precision_score/macro_average_precision_score are actually the same)
(7) This comment ("and label") may be inappropriate currently. Possibly related to the TODO here
cc @jnothman Feel free to edit it :)
üëç 2
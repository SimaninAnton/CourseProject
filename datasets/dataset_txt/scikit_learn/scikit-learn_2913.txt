Dandandan commented on Jul 15, 2016 ‚Ä¢
edited
Description
When trying to use the MLPClassifier for out of core learning, the code crashed. It crashes when computing the loss function for the current minibatch when using partial_fit.
I added a small example below to reproduce this issue.
Steps/Code to Reproduce
Example:
from sklearn.neural_network import MLPClassifier

clf = MLPClassifier()

clf.partial_fit([[1],[2],[3]],["a", "b", "c"], classes=["a", "b", "c", "d"])

clf.partial_fit([[4]],["d"])
Expected Results
Code runs without crash.
Actual Results
Traceback (most recent call last):
  File "fail.py", line 7, in <module>
    clf.partial_fit([[4]],["d"])
  File "/usr/local/lib/python3.4/dist-packages/sklearn/neural_network/multilayer_perceptron.py", line 989, in _partial_fit
    super(MLPClassifier, self)._partial_fit(X, y)
  File "/usr/local/lib/python3.4/dist-packages/sklearn/neural_network/multilayer_perceptron.py", line 640, in _partial_fit
    return self._fit(X, y, incremental=True)
  File "/usr/local/lib/python3.4/dist-packages/sklearn/neural_network/multilayer_perceptron.py", line 375, in _fit
    intercept_grads, layer_units, incremental)
  File "/usr/local/lib/python3.4/dist-packages/sklearn/neural_network/multilayer_perceptron.py", line 512, in _fit_stochastic
    coef_grads, intercept_grads)
  File "/usr/local/lib/python3.4/dist-packages/sklearn/neural_network/multilayer_perceptron.py", line 225, in _backprop
    loss = LOSS_FUNCTIONS[self.loss](y, activations[-1])
  File "/usr/local/lib/python3.4/dist-packages/sklearn/neural_network/_base.py", line 208, in log_loss
    return -np.sum(y_true * np.log(y_prob)) / y_prob.shape[0]
ValueError: operands could not be broadcast together with shapes (1,2) (1,3) 
Versions
Latest development version as of July 15.
üëç 1
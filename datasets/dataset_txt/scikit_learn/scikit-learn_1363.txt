cheng-w-liu commented on May 26, 2018
Description
For the kernels in gaussian_process.kernels, the gradient of a compound kernel is not correct.
As the following example shows:
Steps/Code to Reproduce
Example:
import numpy as np
from sklearn.gaussian_process.kernels import RBF

X = np.array([[1,2], [3, 4], [5,6]])

kernel1 = RBF(1.0)
kernel2 = 1.0 * RBF(1.0)

kernel1_grad = kernel1(X, eval_gradient=True)[1][:, :, 0]
kernel2_grad = kernel2(X, eval_gradient=True)[1][:, :, 0]
Expected Results
kernel1_grad = 
array([[  0.00000000e+00,   1.46525111e-01,   3.60112559e-06],
       [  1.46525111e-01,   0.00000000e+00,   1.46525111e-01],
       [  3.60112559e-06,   1.46525111e-01,   0.00000000e+00]])
And kernel2_grad should be the same as kernel1_grad
Actual Results
kernel2_grad = 
array([[  1.00000000e+00,   1.83156389e-02,   1.12535175e-07],
       [  1.83156389e-02,   1.00000000e+00,   1.83156389e-02],
       [  1.12535175e-07,   1.83156389e-02,   1.00000000e+00]])
The diagonal elements of kernel2_grad are not 0.
It seems that the issues is caused by the hyper-parameters of the first component of the compound kernel being non-fixed:
kernel2.hyperparameters
Out[16]: 
[Hyperparameter(name='k1__constant_value', value_type='numeric', bounds=array([[  1.00000000e-05,   1.00000000e+05]]), n_elements=1, fixed=False),
 Hyperparameter(name='k2__length_scale', value_type='numeric', bounds=array([[  1.00000000e-05,   1.00000000e+05]]), n_elements=1, fixed=False)]
Is this a design decision or it's unexpected?
Versions
Darwin-14.5.0-x86_64-i386-64bit
Python 3.6.3 (default, Oct 8 2017, 15:07:13)
[GCC 4.2.1 Compatible Apple LLVM 7.0.0 (clang-700.0.72)]
NumPy 1.13.3
SciPy 0.19.1
Scikit-Learn 0.19.0
EmreAtes commented on Jan 9, 2018
Description
The default AdaBoostClassifier algorithm has a DecisionTreeClassifier as the default base classifier. This results in the AdaBoost only training one decision tree, since the default decision tree has no limit on the number of leaves, and always fits the training set perfectly.
In the examples with AdaBoost, a custom decision tree is used, except for this one which just uses AdaBoost(), and the normal AdaBoost behavior is significantly different from what's shown in the example (closer to the random forest one).
I think either the default decision tree instance for AdaBoost should have a max_depth not None, or there should be a warning in the AdaBoost page.
Versions
>>> import platform; print(platform.platform())
Linux-4.13.16-041316-generic-x86_64-with-Ubuntu-17.10-artful
>>> import sys; print("Python", sys.version)
Python 3.6.3 (default, Oct  3 2017, 21:45:48) 
[GCC 7.2.0]
>>> import numpy; print("NumPy", numpy.__version__)
NumPy 1.13.3
>>> import scipy; print("SciPy", scipy.__version__)
SciPy 1.0.0
>>> import sklearn; print("Scikit-Learn", sklearn.__version__)
Scikit-Learn 0.19.1
phdowling commented on Aug 28, 2015
Not sure if this is really a bug, but it seems to be a tricky detail in the implementation of the SGDClassifier (possibly also others, haven't checked).
Calling fit on an SGDClassifier internally calls self._partial_fit with n_iter=5. When calling partial_fit straight away, n_iter is set to 1 on the internal self._partial_fit call (as one would expect). This leads to significantly worse performance (~5% in one of my experiments) when calling partial_fit compared to fit, using the exact same training data. This can be fixed by simply feeding the data to partial_fit 5 times, but that seems like a strange way to do it and one that might not occur to most users.
So, is this desired behavior? Is there a better way to do this?
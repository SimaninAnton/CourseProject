Member
amueller commented on Mar 9, 2015
This has come up in #4347.
Changing all sample weights by a constant factor changes the output of the trees.
I thought it should not change the math, and this seems pretty substantial for floating point issues:
from sklearn.tree import DecisionTreeClassifier
from sklearn.datasets import fetch_mldata
mnist = fetch_mldata("MNIST original")
tree = DecisionTreeClassifier(max_depth=10, random_state=1).fit(mnist.data, mnist.target)
tree3 = DecisionTreeClassifier(max_depth=10, random_state=1).fit(mnist.data, mnist.target, sample_weight=1.1 * np.ones(len(mnist.target)))
np.sum(tree.predict(mnist.data) != tree3.predict(mnist.data))
72
Contributor
alexitkes commented on Jul 26, 2019
Possibly a naive idea, but I think it may be interesting.
GridSearchCV normally finds the parameter combination giving maximum mean score over the train/validation splits, but the mean value is notalways the most relevant aggregated value. If some values are considerably greater/less than most values, median value may be more valueable than mean. On may prefer a model with higher probability of achieving a relatively good score at cost of lower probability of getting a very good score, in that case 25% quantile may be useful instead of mean value.
For example, I tried to fit a GradientBoostingClassifier on Titanic dataset using GridSearchCV with 20 splits and discovered that the accuracy distribution over splits is far from normal. Furthermore, the parameters giving best 25% quantile of test score lead to better score on public leaderboard that the normal best_estimator_ giving best mean test score (however both scores are rather low because I didn't use engineered features to conserver time, so some future investigation may be needed). Surprisingly the parameter combination maximizing the minimal test score over splits appeared to be even better.
So, why not let GridSearchCV return the best_estimator_ providing best 25% quantile, best median, or even best minimum of the test score over the train/test splits instead of mean test score if requested? I want to try it in my own fork anyway, but can such feature be worth adding to mainline?
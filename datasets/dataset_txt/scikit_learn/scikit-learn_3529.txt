sytham commented on Oct 20, 2015
The current default behaviour of the f1_score metric and similarly the 'f1' score string for model selection in binary classification is to take the f1 score of the class labeled 1.
This is a bad idea. This means a classifier that predicts all 1s can get a pretty decent score (e.g. 2/3 on perfectly balanced classes).
I suggest that either
a) the documentation should be adjusted to make this very clear (for example, the model selection docs just say that "'f1' is the string to use for binary classification", tempting a naive user to just blindly use this score)
b) the default behaviour should be changed to either "micro" or "weighted"
Where option b would have my preference.
Contributor
jstriebel commented on Nov 3, 2016 â€¢
edited
Currently kernel-based estimators (SVR, SVC, ...) accept a descriptive string, a callable or a matrix as kernels (where the latter is given as X).
For advanced usage of those (positive-(semi-)definite) kernels I propose to introduce a PSDKernel base class (or e.g. HilbertKernel, Positive(Semi)DefiniteKernel, ...), similar to sklearn.gaussian_process.kernels.Kernel. Then it should be possible to use subclasses of this with all kernel-based Estimators (SVMs, KernelPCA, ...).
The PSDKernel class could also implement the estimator interface and simply be used pipelined before a kernel-based estimator. This would also benefit the performance of multivariate SVMs (see #7817). As an alternative SVR and such classes could accept instances of this class directly as the initialization's kernel-attribute, e.g. by simply making this callable.
Based on this also combinations of kernels like for sklearn.gaussian_process are possible for SVMs, etc.
Changes in this context:
new class PSDKernel (either in the style of sklearn.gaussian_process.kernels.Kernel, or as an estimator), maybe callable
integrating this with sklearn.gaussian_process.kernels, as there is some overlap (not sure yet how to do this nicely)
maybe: integrating this with kernel-based estimators (SVMs, KernelPCA, ...) (this is not necessary if it is meant to be pipelined or is callable, or both)
(Thanks for reading my thoughts on this, any feedback appreciated.)
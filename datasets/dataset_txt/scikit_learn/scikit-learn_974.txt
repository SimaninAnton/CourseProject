Contributor
tuliocasagrande commented on Oct 24, 2018
Hello!
I apologize if this was discussed previously, but I couldn't find anything related.
I understand that scale is equivalent to StandardScaler without the estimator API, but they have different implementations. Shouldn't scale use StandardScaler.fit_transform() under the hood, such as power_transform:
scikit-learn/sklearn/preprocessing/data.py
Lines 2468 to 2477 in ebe77d6
 n = QuantileTransformer(n_quantiles=n_quantiles, 
                         output_distribution=output_distribution, 
                         subsample=subsample, 
                         ignore_implicit_zeros=ignore_implicit_zeros, 
                         random_state=random_state, 
                         copy=copy) 
 if axis == 0: 
     return n.fit_transform(X) 
 elif axis == 1: 
     return n.fit_transform(X.T).T 
or minmax_scale:
scikit-learn/sklearn/preprocessing/data.py
Lines 468 to 472 in ebe77d6
 s = MinMaxScaler(feature_range=feature_range, copy=copy) 
 if axis == 0: 
     X = s.fit_transform(X) 
 else: 
     X = s.fit_transform(X.T).T 
Thanks for reviewing this!
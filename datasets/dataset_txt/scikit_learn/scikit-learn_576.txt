Contributor
notmatthancock commented on Apr 22, 2019
In _parallel_build_trees, if the bootstrap option is selected, then a bootstrap sample the size of the training set X is produced and used.
In the situation where X is quite big and a large number of estimators are to be fit, I would find it useful to limit the size of the bootstrap subsample to be less than the number of examples, having the loose expectation that the random subsamples chosen over all the estimators generally "cover" the training dataset.
This seems like it could be implemented as a keyword argument bootstrap_subsample_fraction to the appropriate classes, taking the range of values (0, 1].
If this seems like a useful feature more broadly, I could take a whack at it.
pukhlyakova commented on Jun 12, 2018
Hello. I think I found a mistake in brier_score_loss.
When you have a target = 1 and a prediction = 1 too, brier_score_loss should be 0 (best result), but it gives 1. Why is it happening? Because _check_binary_probabilistic_predictions gets target with only one class and convert it to 0. And metric calculates for target = 0 and prediction = 1. The same problem for target = 1 and prediction = 0. brier_score_loss is 0 (the best result), but it should be 1.
Examples:
Approx = [0, 0, 0, 0]
Target = [1, 1, 1, 1]
Weight = [1, 1, 1, 1]
brier_score_loss(Target, Approx, sample_weight=Weight)
result is 0
Approx = [1, 1, 1, 1]
Target = [1, 1, 1, 1]
Weight = [1, 1, 1, 1]
brier_score_loss(Target, Approx, sample_weight=Weight)
result is 1
Maybe we should fix it? Thank you.
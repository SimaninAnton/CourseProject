Contributor
bwhite commented on Apr 26, 2013
Here is a gist illustrating the problem
https://gist.github.com/bwhite/5463217
Here are two lines of the output (run the script to make 100 of these)
Example 1
true_label[0] predictions: svm.predict[1] svm2.predict[1] svm2.dec >= intercept[1] manual[1] decision_functions: svm.decision_function[nan] svm2.decision_function[0.305067] manual[-0.472692]
Example 2
true_label[0] predictions: svm.predict[0] svm2.predict[0] svm2.dec >= intercept[1] manual[0] decision_functions: svm.decision_function[nan] svm2.decision_function[-0.112419] manual[-0.0552063]
We'd expect all prediction and decision function methods to agree, but the predictions are all the same (expect for the one that I derive from svm2's decision_function) but all decision_functions disagree. The reason I show the prediction derived from svm2's decision_function is because it shows that it is almost certainly wrong because it doesn't agree with it's own prediction function. However, my own custom predictor and decision_function (derived from the raw model parameters) are all consistent with the true predictions.
In summary, I think the following are problematic
svm and svm2 disagree at all, since there shouldn't be a difference between computing the gram matrix manually vs letting sklearn do it
svm's decision function (the one where we let sklearn compute the gram matrix) is basically infinite, so that is really wrong.
svm2's seems more reasonable but still wrong since using it's intercept as a threshold disagrees with it's own prediction
my handmade predictor/decision_function agree in prediction with svm/svm2 but the decision_function is way off
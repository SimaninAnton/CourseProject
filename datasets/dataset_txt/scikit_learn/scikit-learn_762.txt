Mn-Saleh commented on Jan 31, 2019
Could someone please help me with a problem, when I run this code
reg = fit_model(X_train, y_train)
print("Parameter 'max_depth' is {} for the optimal model.".format(reg.get_params()['max_depth']))
this came up
C:\Users\Mona Saleh\Anaconda3\lib\site-packages\sklearn\model_selection_validation.py:542: FutureWarning: From version 0.22, errors during fit will result in a cross validation score of NaN by default. Use error_score='raise' if you want an exception raised or error_score=np.nan to adopt the behavior from version 0.22.
ValueError Traceback (most recent call last)
in
1 # Fit the training data to the model using grid search
----> 2 reg = fit_model(X_train, y_train)
3
4 # Produce the value for 'max_depth'
5 print("Parameter 'max_depth' is {} for the optimal model.".format(reg.get_params()['max_depth']))
in fit_model(X, y)
28
29 # Fit the grid search object to the data to compute the optimal model
---> 30 grid = grid.fit(X, y)
31
32 # Return the optimal model after fitting the data
~\Anaconda3\lib\site-packages\sklearn\model_selection_search.py in fit(self, X, y, groups, **fit_params)
720 return results_container[0]
721
--> 722 self._run_search(evaluate_candidates)
723
724 results = results_container[0]
~\Anaconda3\lib\site-packages\sklearn\model_selection_search.py in _run_search(self, evaluate_candidates)
1189 def _run_search(self, evaluate_candidates):
1190 """Search all candidates in param_grid"""
-> 1191 evaluate_candidates(ParameterGrid(self.param_grid))
1192
1193
~\Anaconda3\lib\site-packages\sklearn\model_selection_search.py in evaluate_candidates(candidate_params)
709 for parameters, (train, test)
710 in product(candidate_params,
--> 711 cv.split(X, y, groups)))
712
713 all_candidate_params.extend(candidate_params)
~\Anaconda3\lib\site-packages\sklearn\externals\joblib\parallel.py in call(self, iterable)
915 # remaining jobs.
916 self._iterating = False
--> 917 if self.dispatch_one_batch(iterator):
918 self._iterating = self._original_iterator is not None
919
~\Anaconda3\lib\site-packages\sklearn\externals\joblib\parallel.py in dispatch_one_batch(self, iterator)
757 return False
758 else:
--> 759 self._dispatch(tasks)
760 return True
761
~\Anaconda3\lib\site-packages\sklearn\externals\joblib\parallel.py in _dispatch(self, batch)
714 with self._lock:
715 job_idx = len(self._jobs)
--> 716 job = self._backend.apply_async(batch, callback=cb)
717 # A job can complete so quickly than its callback is
718 # called before we get here, causing self._jobs to
~\Anaconda3\lib\site-packages\sklearn\externals\joblib_parallel_backends.py in apply_async(self, func, callback)
180 def apply_async(self, func, callback=None):
181 """Schedule a func to be run"""
--> 182 result = ImmediateResult(func)
183 if callback:
184 callback(result)
~\Anaconda3\lib\site-packages\sklearn\externals\joblib_parallel_backends.py in init(self, batch)
547 # Don't delay the application, to avoid keeping the input
548 # arguments in memory
--> 549 self.results = batch()
550
551 def get(self):
~\Anaconda3\lib\site-packages\sklearn\externals\joblib\parallel.py in call(self)
223 with parallel_backend(self._backend, n_jobs=self._n_jobs):
224 return [func(*args, **kwargs)
--> 225 for func, args, kwargs in self.items]
226
227 def len(self):
~\Anaconda3\lib\site-packages\sklearn\externals\joblib\parallel.py in (.0)
223 with parallel_backend(self._backend, n_jobs=self._n_jobs):
224 return [func(*args, **kwargs)
--> 225 for func, args, kwargs in self.items]
226
227 def len(self):
~\Anaconda3\lib\site-packages\sklearn\model_selection_validation.py in _fit_and_score(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)
526 estimator.fit(X_train, **fit_params)
527 else:
--> 528 estimator.fit(X_train, y_train, **fit_params)
529
530 except Exception as e:
~\Anaconda3\lib\site-packages\sklearn\tree\tree.py in fit(self, X, y, sample_weight, check_input, X_idx_sorted)
1140 sample_weight=sample_weight,
1141 check_input=check_input,
-> 1142 X_idx_sorted=X_idx_sorted)
1143 return self
1144
~\Anaconda3\lib\site-packages\sklearn\tree\tree.py in fit(self, X, y, sample_weight, check_input, X_idx_sorted)
114 random_state = check_random_state(self.random_state)
115 if check_input:
--> 116 X = check_array(X, dtype=DTYPE, accept_sparse="csc")
117 y = check_array(y, ensure_2d=False, dtype=None)
118 if issparse(X):
~\Anaconda3\lib\site-packages\sklearn\utils\validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)
550 "Reshape your data either using array.reshape(-1, 1) if "
551 "your data has a single feature or array.reshape(1, -1) "
--> 552 "if it contains a single sample.".format(array))
553
554 # in the future np.flexible dtypes will be handled like object dtypes
ValueError: Expected 2D array, got 1D array instead:
array=[ 409500. 357000. 764400. 525000. 732900. 220500. 405300. 632100.
602700. 184800. 697200. 478800. 214200. 277200. 672000. 478800.
369600. 426300. 1014300. 426300. 405300. 472500. 453600. 443100.
417900. 407400. 495600. 281400. 501900. 384300. 760200. 636300.
783300. 485100. 319200. 491400. 396900. 611100. 499800. 405300.
529200. 701400. 327600. 386400. 462000. 312900. 485100. 466200.
476700. 789600. 487200. 525000. 281400. 401100. 680400. 279300.
592200. 422100. 487200. 411600. 485100. 401100. 953400. 455700.
445200. 512400. 487200. 151200. 266700. 795900. 525000. 474600.
422100. 760200. 596400. 178500. 510300. 512400. 361200. 382200.
396900. 451500. 174300. 296100. 176400. 554400. 432600. 732900.
1024800. 812700. 516600. 365400. 726600. 415800. 495600. 501900.
409500. 350700. 417900. 174300. 428400. 359100. 228900. 170100.
220500. 558600. 373800. 554400. 338100. 525000. 436800. 485100.
363300. 155400. 262500. 510300. 474600. 361200. 237300. 273000.
407400. 432600. 487200. 468300. 558600. 176400. 468300. 399000.
701400. 449400. 281400. 413700. 378000. 508200. 924000. 441000.
266700. 459900. 424200. 478800. 403200. 577500. 436800. 300300.
455700. 514500. 835800. 241500. 445200. 315000. 682500. 644700.
117600. 105000. 531300. 480900. 340200. 336000. 422100. 506100.
661500. 556500. 338100. 663600. 457800. 409500. 315000. 462000.
758100. 709800. 501900. 373800. 291900. 430500. 445200. 405300.
405300. 609000. 443100. 275100. 245700. 329700. 525000. 462000.
289800. 646800. 627900. 466200. 424200. 499800. 245700. 493500.
249900. 451500. 518700. 602700. 342300. 289800. 319200. 919800.
560700. 323400. 695100. 520800. 434700. 506100. 266700. 430500.
411600. 476700. 665700. 228900. 285600. 449400. 218400. 462000.
728700. 695100. 338100. 201600. 392700. 298200. 294000. 777000.
399000. 525000. 401100. 693000. 449400. 596400. 203700. 415800.
739200. 455700. 386400. 306600. 348600. 151200. 527100. 289800.
365400. 411600. 1018500. 312900. 480900. 504000. 686700. 327600.
432600. 105000. 178500. 151200. 365400. 388500. 457800. 609000.
380100. 478800. 520800. 279300. 373800. 407400. 434700. 319200.
420000. 913500. 352800. 506100. 348600. 422100. 327600. 655200.
598500. 558600. 388500. 390600. 672000. 577500. 157500. 420000.
499800. 441000. 485100. 462000. 304500. 264600. 625800. 350700.
310800. 621600. 147000. 382200. 466200. 438900. 732900. 663600.
510300. 497700. 766500. 367500. 588000. 432600. 485100. 483000.
384300. 417900. 489300. 676200. 254100. 394800. 312900. 483000.].
Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.
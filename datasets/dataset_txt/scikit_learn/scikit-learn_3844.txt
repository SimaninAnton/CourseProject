therriault commented on May 5, 2015
I have a pickled CalibratedClassifierCV object that I'm trying to change the n_jobs parameter on, and while it appears to work, it doesn't actually adjust the parameter at prediction time. I'm pretty sure this is a product of the base estimator's parameters not being carried over to the calibrated classifiers when they change. See the example below---I've tried to make this as simple as possible.
First, I load the object and adjust the n_jobs parameter of the base estimator from 24 to 6 (ignore the nonsequential numbering---it took a few tries to correctly convert the pieces to a minimal reproducible example):
Next, I confirm that the parameter change has been implemented, and it is. But when I go to predict, you can see that it parallelizes at n_jobs=24:
I looked to see if the individual classifiers have mutable parameters, but couldn't find my way around in there, and in any case it would seem that the action above should work (as it does when using a single classifier). Without knowing too much about the underlying mechanics, perhaps the individual classifiers should be pulling the parameter from the base estimator but are currently looking for it somewhere else instead?
Update: Just dug into it more, and it seems the individual classifiers are indeed storing their parameters deep down in the model.calibrated_classifiers_[0].base_estimator part of the individual classifers, rather than in the base_estimator for the object itself. So it's not a bug per se, but it's an awkward setup to not be able to adjust the parameters as one would normally do. Would be preferable to either have the overall set_params() change the underlying values, or else have the individual classifiers point to the main set of parameters rather than their own.
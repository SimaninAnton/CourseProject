eyal6699 commented on May 10, 2018 â€¢
edited by jnothman
Description
Argument normalize=True in LinearRegression() doesn't affect the coefficients, they still calculated for non normalize values. So, when the model is used for RFE as an estimator, it gets different result from real normalized values.
Steps/Code to Reproduce
import numpy as np
from sklearn.linear_model import LinearRegression
X = np.array([[1.],[2.],[3.],[4.]])
Y = np.array([1.5, 2, 2.5, 2])

model_normed = LinearRegression(normalize=True)
model_normed.fit(X,Y)
print(model_normed.coef_)
Expected Results
0.6
Can be calculated by
from sklearn.preprocessing import MinMaxScaler

X_normed = MinMaxScaler().fit(X).transform(X)
model_real_normed = LinearRegression(normalize=False)
model_real_normed.fit(X_normed,Y)
print(model_real_normed.coef_)
Actual Results
0.2, the same results when normalize=False.
Versions
Linux-4.16.5-200.fc27.x86_64-x86_64-with-fedora-27-Twenty_Seven
Python 3.6.4 |Anaconda custom (64-bit)| (default, Mar 13 2018, 01:15:57)
[GCC 7.2.0]
NumPy 1.14.0
SciPy 1.0.0
Scikit-Learn 0.19.1
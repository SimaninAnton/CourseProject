Contributor
pratapvardhan commented on Dec 11, 2014
Using this piece of code below decision tree is generated.
dot_data = StringIO() 
iris = load_iris()
clf = tree.DecisionTreeClassifier()
clf = clf.fit(iris.data, iris.target)
tree.export_graphviz(clf, out_file=dot_data) 
graph = pydot.graph_from_dot_data(dot_data.getvalue()) 
graph.write_pdf("iris.pdf") 
The node values are
clf.tree_.value
array([[[  0.,   0.,   0.]],
       [[ 50.,   0.,   0.]],
       [[  0.,   0.,   0.]],
       [[  0.,   0.,   0.]],
       [[  0.,   0.,   0.]],
       [[  0.,  47.,   0.]],
       [[  0.,   0.,   1.]],
       [[  0.,   0.,   0.]],
       [[  0.,   0.,   3.]],
       [[  0.,   0.,   0.]],
       [[  0.,   2.,   0.]],
       [[  0.,   0.,   1.]],
       [[  0.,   0.,   0.]],
       [[  0.,   0.,   0.]],
       [[  0.,   1.,   0.]],
       [[  0.,   0.,   2.]],
       [[  0.,   0.,  43.]]])
Which seems incorrect? Shouldn't the node values be the sum of child nodes?
Something like the documented image
Is there a way to extract accurate node values? And, why is there a difference between generated image and the documentation image on the docs for same piece of code?
sklearn.__version__ '0.15.2'
Yanjiayork commented on Jan 22, 2019
Description
I expect that when the training set and test set are the same and the features are binary, I should get the same probability from BernoulliNB and MultinomialNB, as MultinomialNB is a more generalised version than BernoulliNB. But when the features are binary, they should both give the same result and probability. I also calculate the probability of this example by hand, which confirms that the probability from BernoulliNB is correct, but I am sure how MultinomialNB get the result [[0.3631348 0.6368652]]. It seems quite wrong to me. Please shed some light on this. Thank you very much.
Steps/Code to Reproduce
import numpy as np
from sklearn.naive_bayes import BernoulliNB
train_x = np.array([(1,1,1,0,0),(0,1,1,0,1),(1,0,0,1,1),(0,0,0,1,1),(1,0,0,1,0),(0,1,0,0,0),
(1,1,0,0,1),(1,0,0,1,1),(0,1,1,1,1),(0,1,0,1,1),(1,1,0,1,1),(0,1,1,0,1),
(0,0,1,0,1)])
train_y = np.array([0,0,0,0,0,0,1,1,1,1,1,1,1])
test_x = np.array([(0,1,1,0,1)])
clf = BernoulliNB(alpha=1.0e-10, class_prior=None, fit_prior=True)
clf.fit(train_x, train_y)
print(clf.predict(test_x))
print (clf.predict_proba(test_x))
from sklearn.naive_bayes import MultinomialNB
cl = MultinomialNB(alpha=1.0e-10, class_prior=None, fit_prior=True)
cl.fit(train_x, train_y)
print(cl.predict(test_x))
print (cl.predict_proba(test_x))
Expected Results
[1]
[[0.19237241 0.80762759]]
[1]
[[0.19237241 0.80762759]]
Actual Results
[1]
[[0.19237241 0.80762759]]
[1]
[[0.3631348 0.6368652]]
Versions
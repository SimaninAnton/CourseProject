Contributor
ClimbsRocks commented on Jan 8, 2016
The MLP has so many hyperparameters that can be tuned that it's a bit overwhelming at times.
I've been running RandomizedSearchCV with the MLP on a couple different datasets, with inconsistent results. Sometimes it finds a good combination of hyperparameters and gets great results; other times the chosen values appear to sabotage each other, leading to unimpressive results.
Having an example of which parameters are most useful to tune would go a long way towards making this more accurate for the average engineer putting it to use.
I'm happy to create the example doc if someone else has some insights into effective hyperparameters to work with.
Thanks for building such a robust implementation into scikit-learn! I've been hoping for this for a long time, so it's exciting to see it available.
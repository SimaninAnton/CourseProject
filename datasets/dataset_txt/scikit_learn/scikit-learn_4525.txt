twiecki commented on Feb 4, 2014
This is probably just a result of an misunderstanding of mine but anyway. I expect that if I pass in scaled data, setting scale=True or scale=False on CCA should have no effect. While that's true for the first component, it's not true for the second component.
>>> from sklearn.cross_decomposition import CCA
>>> X = np.array([[0., 0., 1.], [1.,0.,0.], [2.,2.,2.], [3.,5.,4.]])
>>> Y = np.array([[0.1, -0.2], [0.9, 1.1], [6.2, 5.9], [11.9, 12.3]])
>>> cca_scale = CCA(n_components=2, scale=True)
>>> X_c_scale_orig, Y_c_scale_orig = cca_scale.fit_transform(X, Y)
>>> X_scaled = (X - X.mean(axis=0)) / X.std(axis=0, ddof=1)
>>> Y_scaled = (Y - Y.mean(axis=0)) / Y.std(axis=0, ddof=1)
>>> cca = CCA(n_components=2, scale=False)
>>> X_c_no_scale, Y_c_no_scale = cca.fit_transform(X_scaled, Y_scaled)
>>> cca_scale = CCA(n_components=2, scale=True)
>>> X_c_scale, Y_c_scale = cca_scale.fit_transform(X_scaled, Y_scaled)
>>> print X_c_scale_orig
>>> print X_c_no_scale
>>> print X_c_scale
>>> print Y_c_scale_orig
>>> print Y_c_no_scale
>>> print Y_c_scale
[[-1.3373174  -0.04167927]
 [-1.10847164  0.09813184]
 [ 0.40763151 -0.10309382]
 [ 2.03815753  0.04664126]]
[[-1.3373174  -0.04162312]
 [-1.10847164  0.09808313]
 [ 0.40763151 -0.10311608]
 [ 2.03815753  0.04665606]]
[[ -1.33731740e+00  -3.67012265e-16]
 [ -1.10847164e+00   5.49218284e-16]
 [  4.07631507e-01  -4.10164420e-16]
 [  2.03815753e+00   2.27958401e-16]]
[[ -8.55115369e-01  -6.80017977e-13]
 [ -7.08785466e-01   1.60025100e-12]
 [  2.60650139e-01  -1.68065559e-12]
 [  1.30325070e+00   7.60422569e-13]]
[[ -8.55115369e-01  -5.05140039e-14]
 [ -7.08785466e-01   1.19382664e-13]
 [  2.60650139e-01  -1.25290257e-13]
 [  1.30325070e+00   5.64215966e-14]]
[[ -8.55115369e-01  -7.35441933e-17]
 [ -7.08785466e-01   5.19310197e-16]
 [  2.60650139e-01  -4.83848720e-16]
 [  1.30325070e+00   3.80827163e-17]]
Contributor
nelson-liu commented on Jul 28, 2016 â€¢
edited
Description
The last commit to master, 376aa50 (from #6954) is failing tests on travisCI (although the PR passed all tests). The reason it's doing so is because of a phenomenon that people who work with the tree module are quite familiar with --- for some reason, it isn't recythonizing all of the dependencies and thus throws an ImportError.
This behavior has been reported several times, e.g. at:
#4899 (comment)
Steps/Code to Reproduce
see: https://travis-ci.org/scikit-learn/scikit-learn/jobs/147795508 line 2226
Expected Results
Tests pass
Actual Results
Tests fail
======================================================================
ERROR: Failure: ValueError (sklearn.tree._tree.TreeBuilder has the wrong size, try recompiling. Expected 72, got 64)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/travis/build/scikit-learn/scikit-learn/testvenv/local/lib/python2.7/site-packages/nose/loader.py", line 418, in loadTestsFromName
    addr.filename, addr.module)
  File "/home/travis/build/scikit-learn/scikit-learn/testvenv/local/lib/python2.7/site-packages/nose/importer.py", line 47, in importFromPath
    return self.importFromDir(dir_path, fqname)
  File "/home/travis/build/scikit-learn/scikit-learn/testvenv/local/lib/python2.7/site-packages/nose/importer.py", line 94, in importFromDir
    mod = load_module(part_fqname, fh, filename, desc)
  File "/home/travis/sklearn_build_ubuntu/scikit-learn/sklearn/ensemble/__init__.py", line 17, in <module>
    from .gradient_boosting import GradientBoostingClassifier
  File "/home/travis/sklearn_build_ubuntu/scikit-learn/sklearn/ensemble/gradient_boosting.py", line 36, in <module>
    from ._gradient_boosting import predict_stages
  File "sklearn/tree/_tree.pxd", line 84, in init sklearn.ensemble._gradient_boosting (sklearn/ensemble/_gradient_boosting.c:19325)
ValueError: sklearn.tree._tree.TreeBuilder has the wrong size, try recompiling. Expected 72, got 64
Misc Comments
I've been using hacky methods to get around this for awhile (e.g. manually adding a change to the file that isn't being recythonized), but it also seems to work if someone clears the travis cache. However, these are annoying "solutions" -- is there anyway we can fix the behavior? Namely, it seems that _gradient_boosting.pyx isn't being recythonized when things change in the tree module.
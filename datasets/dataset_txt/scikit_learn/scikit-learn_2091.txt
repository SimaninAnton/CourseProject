MarenMa commented on Jun 27, 2017 â€¢
edited
Description
I would like to train a network on a dataset and then continue training on further data, i.e., to adjust the weights of my model with the help of some data and then use these weights for further training on more data.
I thought that this would be possible with the warm_start parameter in a network model.
Steps/Code to Reproduce
from sklearn.datasets import load_boston
from sklearn import linear_model

X, y = load_boston(return_X_y=True)

X_1, X_2, y_1, y_2 = X[:len(X)/2], X[len(X)/2:], y[:len(y)/2], y[len(y)/2:]

model_1 = linear_model.ElasticNet(alpha = 0.01, warm_start=True)
in_weights = model_1.coef_
print 'Initialization : \nin_weights', in_weights
model_1.fit(X_1, y_1)
weights_1 = model_1.coef_
print '\nFirst fit:\n in_weights', in_weights, '\n \nweights_1 \n', weights_1
model_1.fit(X_2, y_2)
weights_2 = model_1.coef_
print '\n Second Fit: \nin_weights \n', in_weights, '\n \nweights_1 \n', weights_1, '\n \nweights_2 \n', weights_2
Expected Results
I expected the warm start parameter to set the weights to zero with every initialization and in case of several calls to fit use the weights of the previous fit call as starting point for the next fit if the warm_start parameter is set to True.
Actual Results
However, comparing the two options (warm_start = True/False) in practice (try in code above) yields identical results for weights and consequently for predictions. The only difference seems to be, that weights are updated retrospectively if assigned to variables in between if warm_start = True.
The following code illustrates this with a simple scikit-learn dataset and the ElasticNet as model. weights_1 changes values after the second fit such that weights_1 == weights_2 for warm_start = True (as described above), whereas weights_1 keeps the values of the first fit in case of warm_start = False (set warm_start to False in a second run for comparison).
So apparently the warm_start option is not the right approach to solve my problem. What possibilities are there then to pass coefficients, learned from a first fit to a model and continue the training with the passed coefficients as starting point?
The models I want to use this with are the MLPRegressor and the ElastcNet.
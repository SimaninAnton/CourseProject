tlikhomanenko commented on Jan 26, 2016
Hi!
If I add zero columns in the dataset then Naive Bayes rule changes (this is true for BernoulliNB, MultinomialNB). Below is minimal example:
from sklearn.datasets import make_blobs
from sklearn.metrics import log_loss
from sklearn.naive_bayes import MultinomialNB

X, y = make_blobs(centers=2, n_features=5, center_box=(5, 10), random_state=43)
X += 4
# setting first column to zero!
X[:, 0] = 0
X = X.astype(int).clip(0)

clf1 = MultinomialNB()
clf1.fit(X, y)
log_loss(y, clf1.predict_proba(X)[:, 1])
>>> 0.56291595820692908

clf1.coef_
>>> array([[-7.69938941, -1.32777756, -1.36788756, -1.59907045, -1.28102447]])

clf2 = MultinomialNB()
clf2.fit(X[:, 1:], y)
log_loss(y, clf2.predict_proba(X[:, 1:])[:, 1])
>>> 0.56293665017616201

clf2.coef_
>>> array([[-1.32732435, -1.36743435, -1.59861725, -1.28057126]])
Note: two values of logloss are different.
What is the reason? From theory the predictions should be identical (as far as I understand).
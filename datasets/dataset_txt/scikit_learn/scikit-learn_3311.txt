phdowling commented on Dec 16, 2015
I'm trying to cluster a fairly large number of high-dimensional data points using TruncatedSVD for dimensional reduction and DBSCAN for clustering. I'm able to use LSHForest to efficiently prepare a graph of nearest neighbors, however this graph is a sparse CSR matrix, where a value close to 1 indicates semantic closeness, rather than distance (which would be close to 0 in the same case).
First problem: DBSCAN crashes on sparse input:
>>> DBSCAN(metric="precomputed").fit(res)  # res is a sparse N x N matrix
/usr/local/lib/python2.7/site-packages/scipy/sparse/base.py:180: RuntimeWarning: tp_compare didn't return -1 or -2 for exception
  if self.shape == (1, 1):
Traceback (most recent call last):
  File "/Users/dowling/Development/mmds/mmds-project/backend/pipeline.py", line 306, in <module>
    print dbscan.fit_predict(res)
  File "/Users/dowling/Library/Python/2.7/lib/python/site-packages/sklearn/cluster/dbscan_.py", line 267, in fit_predict
    self.fit(X, sample_weight=sample_weight)
  File "/Users/dowling/Library/Python/2.7/lib/python/site-packages/sklearn/cluster/dbscan_.py", line 237, in fit
    clust = dbscan(X, sample_weight=sample_weight, **self.get_params())
  File "/Users/dowling/Library/Python/2.7/lib/python/site-packages/sklearn/cluster/dbscan_.py", line 121, in dbscan
    neighborhoods[:] = [np.where(x <= eps)[0] for x in D]
  File "/usr/local/lib/python2.7/site-packages/scipy/sparse/base.py", line 120, in __iter__
    for r in xrange(self.shape[0]):
  File "/usr/local/lib/python2.7/site-packages/scipy/sparse/base.py", line 180, in __bool__
    if self.shape == (1, 1):
  File "/usr/local/lib/python2.7/site-packages/scipy/sparse/base.py", line 183, in __bool__
    raise ValueError("The truth value of an array with more than one "
ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all().
Second problem: Even if sparse input was okay, DBSCAN wants a distance matrix, not closeness, and there is not really a way to represent that sparsely.
Is there any way I can still use DBSCAN for this task and avoid materializing a huge dense matrix?
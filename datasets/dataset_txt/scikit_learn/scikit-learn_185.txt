kwunlyou commented on Oct 28, 2019
Steps/Code to Reproduce
import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import RandomForestClassifier, VotingClassifier

X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])
y = np.array([1, 1, 1, 2, 2, 2])

clf1 = LogisticRegression(solver='lbfgs', multi_class='multinomial', random_state=1)
clf2 = RandomForestClassifier(n_estimators=50, random_state=1)
clf3 = GaussianNB()

eclf1 = VotingClassifier(estimators=[('lr', clf1), ('rf', None), ('gnb', clf3)], voting='hard')

eclf = eclf1.fit(X, y)
print(eclf.named_estimators_)
Expected Results
{'lr': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='multinomial', n_jobs=None, penalty='l2',
                   random_state=1, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'gnb: GaussianNB(priors=None, var_smoothing=1e-09)}
Actual Results
{'lr': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='multinomial', n_jobs=None, penalty='l2',
                   random_state=1, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), 'rf': GaussianNB(priors=None, var_smoothing=1e-09)}
Versions
System:
python: 3.6.8 (default, Oct 7 2019, 12:59:55) [GCC 8.3.0]
executable: /usr/local/bin/python
machine: Linux-4.15.0-1039-aws-x86_64-with-Ubuntu-18.04-bionic
Python deps:
pip: 19.3.1
setuptools: 41.5.0
sklearn: 0.21.3
numpy: 1.17.3
scipy: 1.3.1
Cython: None
pandas: 0.25.2
akshatshreemali commented on Feb 21, 2019
I ran a logistic regression model and computer the auc using roc_auc_score(sklearn).
i got it as 0.54
However, when I try to visualize my actuals with the probability numbers of the positive class, it appeared to be more than that.
Upon investigating further, I tried to run just the output numbers through R and calculated the auc using pROC library.
There I got an AUC of 0.66, which is a huge difference compared to sklearn.
I also tried computing the auc using alternate metric code (https://github.com/IraKorshunova/metrics_test/blob/master/sklearn_alternative_auc.py)
but got the same results.
Due to security reasons, I won't be able to upload the output data.
Code: roc_auc_score(y_test,(result.predict_proba(X_test)[:,1]))
If I run the same values in R and compute the AUC, it's 0.66
Any idea what could be the reason?
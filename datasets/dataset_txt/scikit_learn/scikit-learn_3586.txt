afshinrahimi commented on Sep 30, 2015
When using SGDClassifier, setting alpha=0 throws division by zero warnings and underflow/overflow exceptions. This happens ignoring what the penalty term is set to.
If penalty is 'none', I think SGDClassifier should accept alpha=0.
The problem is that, when I set the penalty to 'none' and set different numbers for alpha, I get different results (shuffle is False) which I don't expect because I don't have any regularization any more. So I think something other than regularization is using the alpha parameter.
Reproduction:
The problem is reproducible by setting alpha=0 in one of 20newsgroup SGDClassifiers.
SGDClassifier(alpha=0, average=False, class_weight=None, epsilon=0.1,
       eta0=0.0, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='hinge', n_iter=50, n_jobs=1,
       penalty='none', power_t=0.5, random_state=None, shuffle=False,
       verbose=0, warm_start=False)
Errors:
/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/stochastic_gradient.py:292: RuntimeWarning: divide by zero encountered in double_scalars
  est.power_t, est.t_, intercept_decay)
/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/stochastic_gradient.py:292: RuntimeWarning: invalid value encountered in double_scalars
  est.power_t, est.t_, intercept_decay)

File "sklearn/linear_model/sgd_fast.pyx", line 404, in sklearn.linear_model.sgd_fast.plain_sgd (sklearn/linear_model/sgd_fast.c:4873)
  File "sklearn/linear_model/sgd_fast.pyx", line 697, in sklearn.linear_model.sgd_fast._plain_sgd (sklearn/linear_model/sgd_fast.c:7523)
ValueError: Floating-point under-/overflow occurred at epoch #1. Scaling input data with StandardScaler or MinMaxScaler might help.
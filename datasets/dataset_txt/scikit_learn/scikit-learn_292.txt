12ycli commented on Aug 29, 2019 â€¢
edited
The normal proccess of using DecisionTreeClassifier is to calculate all the features for all samples and then put all the data to DecisionTreeClassifier . However, we know that sometimes we don't necessary need all the features for specific sample. For example, one sample is classified in the following path in which only two features are necessarily used. However, we may calculate other thousands of unnecessary features for this sample. This wastes lots of computation resource.
Can DecisionTreeClassifier add this feature to avoid calculating unnecesary features for specific sample?
I did this by the following proccess:
Train DecisionTreeClassifier as usual.
Draw the tree.
While testing for specified sample, I calculated the features and determined the classify proccess according to the tree. Unneccesary features thus won't be calculate. We can extract the decision rules from scikit-learn decision-tree using code from this
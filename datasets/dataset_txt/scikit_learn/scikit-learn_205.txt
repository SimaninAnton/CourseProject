Contributor
datajanko commented on Oct 15, 2019 â€¢
edited
I haven't found this issue before, so I hope this is not known.
Description
When reducing the number of columns to 1 in the usage examples we still get the Jaccard similarity for two columns(?) instead of 1.
From my interpretation, in the multilevel average=None case, we compute the Jaccard similarity per column of data, i.e. we compute the average of matching labels per column
Steps/Code to Reproduce
from sklearn.metrics import jaccard_score
import numpy as np
jaccard_score(np.asarray([[0], [0], [0]]),np.asarray([[1], [1], [0]]), average=None)
Expected Results
array([0.33333333])
Actual Results
array([0.33333333, 0. ])
Versions
 System:
    python: 3.6.7 | packaged by conda-forge | (default, Jul  2 2019, 02:07:37)  [GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]
executable: //miniconda3/envs/dataset-creation/bin/python
   machine: Darwin-18.7.0-x86_64-i386-64bit

BLAS:
    macros: NO_ATLAS_INFO=3, HAVE_CBLAS=None
  lib_dirs: 
cblas_libs: cblas

Python deps:
       pip: 19.2.3
setuptools: 41.2.0
   sklearn: 0.21.2
     numpy: 1.16.4
     scipy: 1.3.1
    Cython: 0.29.13
    pandas: 0.25.1
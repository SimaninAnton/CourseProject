Contributor
justhalf commented on Nov 7, 2014
I've been using sklearn.externals.joblib.Parallel for some time when I realized that the typical use of Parallel with delayed actually copies the arguments, even though they will never be written (and so based on Copy-on-Write it should not be copied). This causes it more difficult to include shared information to the worker, especially if the shared information is huge.
Typical use of Parallel with delayed is as follows:
shared = create_huge_shared_data()
result = Parallel(n_jobs=4)(delayed(_worker_function)(arg, shared) for arg in list_of_args)
I'm expecting shared to just be passed around without copying, but my measurement shows that it's copied on each job, causing it to spend unnecessary time in copying the shared data.
Is this intentional? Is there any idiomatic way to give huge shared information to the workers?
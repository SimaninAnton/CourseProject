Contributor
GuillemGSubies commented on Aug 26, 2019
The default token_pattern for tokenizer for the vectorizers in sklearn.feature_extraction.text is ’(?u)\b\w\w+\b’. I don't understand why there is this extra \w if we already have \w+.
If it is actually redundant I could make a PR
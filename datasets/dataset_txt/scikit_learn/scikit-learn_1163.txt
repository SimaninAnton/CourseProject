cibic89 commented on Aug 15, 2018 â€¢
edited
Description
Not all cores are utilised on a 1.3 million row x 3000 tfid-idf featured dataset. In fact only 1-2 cores are used and also this was reported before here.
Steps/Code to Reproduce
from sklearn.feature_extraction.text import CountVectorizer
import random
import string

def generate_str():
    return "".join([random.choice(string.ascii_lowercase) for i in range(10)]) # generates lowercase words

docs = [(generate_str()+' ')*10 for j in range(10**6)] # 10 words each row seperated by space

vectorizer = CountVectorizer(input=docs, analyzer='word') # initialise word counter
lda_features = vectorizer.fit_transform(docs) # word counts

lda_model = LatentDirichletAllocation( # lda config
    n_components=4
    ,learning_method='online'
    ,learning_decay=0.5
    ,max_iter=5
    ,batch_size=10240
    ,n_jobs=15
)
model = lda_model.fit_transform(lda_features) # fit and transform
Expected Results
No error but I was expecting all cores to be used
Actual Results
1-2 core usage
Versions
Windows-10-10.0.14393-SP0
Python 3.6.6 |Anaconda custom (64-bit)| (default, Jun 28 2018, 11:27:44) [MSC v.1900 64 bit (AMD64)]
NumPy 1.15.0
SciPy 1.1.0
Scikit-Learn 0.19.1
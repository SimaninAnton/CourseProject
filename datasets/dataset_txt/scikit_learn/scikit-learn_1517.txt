RingWong commented on Mar 6, 2018
Description
CountVectorizer can't remain stop words in Chinese
I want to remain all the words in sentence, but some stop words always dislodged.
Steps/Code to Reproduce
from sklearn.feature_extraction.text import CountVectorizer
import jieba

text = ['今天是个阴天。', '为什么会这样子...']
text_list = []
for t in text:
    text_list.append(' '.join(jieba.cut(t, HMM=False)))
print(text_list)
vectorizer = CountVectorizer(ngram_range=(1, 1), stop_words=None)
word_count = vectorizer.fit_transform(text_list)
word = vectorizer.get_feature_names()
word_count_array = word_count.toarray()
print(word)
print(word_count_array)
Expected Results
text_list:
['今天 是 个 阴天 。', '为什么 会 这 样子 . . .']
word:
['为什么', '今天', '样子', '阴天', '是’, '个', '会', '这']
Actual Results
text_list:
['今天 是 个 阴天 。', '为什么 会 这 样子 . . .']
word:
['为什么', '今天', '样子', '阴天']
word_count_array:
[[0 1 0 1]
[1 0 1 0]]
Versions
platform: Windows-10-10.0.14393-SP0
sys: Python 3.6.1 |Anaconda 4.4.0 (64-bit)| (default, May 11 2017, 13:25:24) [MSC v.1900 64 bit (AMD64)]
numpy: 1.13.3
scipy: 0.19.0
Scikit-Learn: 0.18.1
bbirand commented on Sep 25, 2016 ‚Ä¢
edited
Description
I'm working on a classification problem using RanfomForestClassifier. Essentially, I get really good scores when I run cross_val_score using the roc_auc metric. But when I try to replicate these scores manually, either by using train_test_split or using the folds, I get dramatically worse results.
Inconsistency with train_test_split and cross_val_score
These two code blocks should be doing exactly the same thing, and return mostly similar results:
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)

cfc = RandomForestClassifier(n_estimators=50)
cfc.fit(X_train, y_train)

roc_auc_score(y_test, cfc.predict(X_test))
# Ouputs: 0.57986051894527035
cfc = RandomForestClassifier(n_estimators=50)

scores = cross_val_score(cfc, X, y, 
                         cv = ShuffleSplit(len(X), 1, test_size = 0.25), 
                         scoring = 'roc_auc')
print(scores)
# Outputs: 0.89
Inconsistency with cross_val_score and manually slicing using folds
Again, these two snippets should return exactly the same result:
# STEP 1: Prepare the fold to be used in both snippets
a_fold = KFold(len(X), 4, shuffle=True)
# STEP 2a: Using cross_val_score
cfc_2 = RandomForestClassifier(n_estimators=50)
scores = cross_val_score(cfc_2, X, y, 
                         cv = a_fold, 
                         scoring = 'roc_auc',
                         n_jobs = -1)

print(scores)
# Outputs: [ 0.89  0.88  0.89  0.89]
# STEP 2b: Manually slicing
train, test = next(iter(a_fold))

X_train = X.iloc[train,:]
y_train = y.iloc[train]

X_test = X.iloc[test,:]
y_test = y.iloc[test]

# Manual fitting
cfc = RandomForestClassifier(n_estimators=50)
cfc.fit(X_train, y_train)
roc_auc_score(y_test, cfc.predict(X_test))

# Outputs:  0.57438316349046625
Conclusion
When I try to use the low-level roc_auc_score function I always get a much lower result. But somehow cross_val_score returns a higher score, and I am not sure where that number comes from.
Any thoughts?
NOTES: I can't share the dataset, but I'm happy to test things out on it.
üëç 1
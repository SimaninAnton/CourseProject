esterwang1181 commented on Oct 13, 2018
I am using GridSearchCV (and BayeSearchCV) to tune my hyper-parameters. My train and validation sets are predefined, and I do NOT need folds. According to the documentation: I set the index for training set as "-1" and validation set as "0". However, on a toy example, GridSearchCV does not work properly (attached program output below).
from sklearn.model_selection import PredefinedSplit
# This is my training data (train+validation): X_train
# This is the corresponding y: y_train

estimator = lgb.LGBMRegressor(random_state=1000, 
objective='quantile',alpha=q*0.01)

# enforeced training set " -1"
my_test_fold = -np.ones(len(X_train), dtype=int)
# validation set "0"
my_test_fold[-100:-50]=0  

pcv = PredefinedSplit(test_fold=my_test_fold)
lgbm_cv = GridSearchCV(estimator, param_grid,cv=pcv)                        
lgbm_cv.fit(X_train, y_train)
When I set "my_test_fold[-100:-50]=0", then cv_results_ does NOT have "mean_test_score".
When I set "my_test_fold[0:50]=0", then cv_results_ DOES have "mean_test_score". Program output: my_test_fold[0:50]=0
It seems to me that somehow, CV may or may NOT recognize the validation set, depending on which data is set as validation? This seems like a bug to me. Any thoughts?
zym1010 commented on Oct 16, 2016 â€¢
edited
It seems that the normalizing factor for std error of difference between class mean and total mean is 1/n_k + 1/n, as shown in https://github.com/scikit-learn/scikit-learn/blob/412996f/sklearn/neighbors/nearest_centroid.py#L148. This is what's said in the original PNAS paper (Diagnosis of multiple cancer types by shrunken centroids of gene expression), but I think actually the equation in the paper has a typo, as their own implementation (pp. 29 of https://cran.r-project.org/web/packages/pamr/pamr.pdf, se.scale), as well as various papers on this topic, and the textbook The Elements of Statistical Learning all use 1/n_k - 1/n.
While I personally spent some time deriving these myself without much success, 1/n_k - 1/n looks more correct to me, as since we use sample total mean instead of the actual one, the variance should be larger than when using actual one, so - 1/n tries to enlarge the estimated error.
Update. I just derived it myself and I believe 1/n_k - 1/n is correct.
dr2p commented on Apr 4, 2018 â€¢
edited
Description
The AUC provided by roc_auc_score is giving the wrong value. Given the data attached ('Labels_predictions.xlsx'), the AUC is 0.6788 according to GraphPad Prism and R (pROC package) but sklearn's roc_auc_score provides an AUC of 0.3212 which is 1 - AUC of other programs.
I'm assuming that there's an issue with determining the positive class since the proper AUC is obtained by roc_auc_score when the labels are switched (labels = 1 - labels). Properly labeling the positive class is necessary when dealing with data with imbalanced classes.
I don't see a way to specify the positive class using roc_auc_score so this is an issue.
Steps/Code to Reproduce
Labels_predictions.xlsx
In attached file, labels = 0 for healthy patients and 1 for unhealthy patients
import pandas as pd
from sklearn.metrics import roc_auc_score
data = pd.read_excel('Labels_predictions.xlsx')
predictions = data['Predictions']
labels = data['Labels']
auc_score = roc_auc_score( y_true = labels, y_score = predictions )
Expected Results
auc_score = 0.6788
Actual Results
auc_score = 0.3212
Versions
Windows-8.1-6.3.9600-SP0
Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)]
NumPy 1.13.3
SciPy 0.19.1
Scikit-Learn 0.19.1
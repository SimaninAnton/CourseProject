Member
amueller commented on Mar 7, 2016
For many people, loading the model from disk for each prediction is a major bottleneck, and keeping the model in memory is not always possible.
One of the main pain-points there is working with CountVectorizer, which needs to load the whole vocabulary, even though each data point probably only needs very few features.
The problem can be solved by using hashing vectorizer, but then we lose interpretability of the coefficients, which is bad.
I was wondering if there are ideas to persist CountVectorizer in a way that is more geared towards single point predictions.
Maybe using a cuckoo hashing might help? I had someone telling me that they replaced the dictionary with a database call, but that doesn't seem feasible to do inside scikit-learn.
üëç 1
matalab commented on Oct 10, 2016
Why there is no BIC and AIC attributes for BayessianGaussianMixture? There were BIC and AIC available for VBGMM and DPGMM...
Is "weight_concentration_prior" parameter in BayessianGaussianMixture the same thing as "alpha" parameter in VBGMM and DPGMM? If not, how are they related?
I used to exploit formula alpha = 2/math.log(len(transformed_features)) for automatic inferring alpha parameter value for DPGMM and VBGMM and it worked OK. How can I determine optimum value for "weight_concentration_prior" parameter?
Are VBGMM and DPGMM going to stay in future scikit-learn versions or they will be completely removed in favor of BayessianGaussianMixture?
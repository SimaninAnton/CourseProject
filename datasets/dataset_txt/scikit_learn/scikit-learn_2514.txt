Member
amueller commented on Dec 18, 2016
I like to use nearest neighbors as a first example for explaining machine learning.
However with our API the training set score for n_neighbors=1 is always 1, which is a bit idiosyncratic. (Also, for all n_neighbors>1 we still have a weird bias by including the point itself).
Detecting that predict and score get the training set is a bit magic, and so we might not want to do that (we might want to warn though?) If we get a diagonal graph for 1-nn that's kinda suspicious.
What would be easily doable, though, is to extend the neighbors interface to have knn.predict(X=None) and knn.score(X=None), simliar to the graph interface.
That would basically be a "free" leave-one-out" score.
Wdyt?
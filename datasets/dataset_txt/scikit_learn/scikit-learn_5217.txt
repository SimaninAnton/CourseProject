mhlr commented on Sep 17, 2012
I am running scikit from trunk, and I am synced.
The following code crasshes for me on python 2.7.2 under Ubuntu:
from sklearn import datasets, decomposition
from sklearn.feature_extraction import text
from sklearn.pipeline import Pipeline
pipe = Pipeline([
        ('vect',
         text.TfidfVectorizer(analyzer='word', ngram_range=(1,1), max_features=500, sublinear_tf=True, norm=None)
         ),
        ('extract',
         decomposition.ProjectedGradientNMF(10, init='nndsvd', sparseness='data')
         )
        ])
train_corpus = datasets.fetch_20newsgroups(subset='train')
train_data=pipe.fit_transform(train_corpus.data, train_corpus.target)
the error is:
>>> train_data=pipe.fit_transform(train_corpus.data, train_corpus.target)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "sklearn/pipeline.py", line 137, in fit_transform
    return self.steps[-1][-1].fit_transform(Xt, y, **fit_params)
  File "sklearn/decomposition/nmf.py", line 475, in fit_transform
    W, gradW, iterW = self._update_W(X, H, W, tolW)
  File "sklearn/decomposition/nmf.py", line 398, in _update_W
    np.r_[X.T, np.zeros((1, n_samples))],
  File "/usr/lib/pymodules/python2.7/numpy/lib/index_tricks.py", line 383, in __getitem__
    res = _nx.concatenate(tuple(objs),axis=self.axis)
ValueError: 0-d arrays can't be concatenated
There is no error if the sparseness parameter to NMF is omitted
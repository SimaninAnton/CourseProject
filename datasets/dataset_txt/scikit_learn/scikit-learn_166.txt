Contributor
mfeurer commented on Nov 8, 2019
My goal: use RandomizedSearchCV to set both the number of layers and the size of each layer of the MLPClassifier (similar to Section 5 of Random Search for Hyper-Parameter Optimization). So far I've come to the conclusion that this is possible, but can be simplified. The code which I expected to work:
import scipy.stats
from sklearn.datasets import fetch_openml
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import RandomizedSearchCV

param_dist_1 = {
    'hidden_layer_sizes': (scipy.stats.randint(low=2**5, high=2**11+1), ),
}
param_dist_2 = {
    'hidden_layer_sizes': (
        scipy.stats.randint(low=2**5, high=2**11+1),
        scipy.stats.randint(low=2**5, high=2**11+1),
    )
}
param_dist = [param_dist_1, param_dist_2]
mlp = MLPClassifier()
random_search = RandomizedSearchCV(
    estimator=mlp,
    param_distributions=param_dist,
)
X, y = fetch_openml(data_id=61, return_X_y=True)
random_search.fit(X, y)
fails to recognize that the tuple for hidden_layer_sizes contains distributions, too. Thanks to #14549 it would be possible to do the following:
import scipy.stats
from sklearn.datasets import fetch_openml
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import RandomizedSearchCV

param_dist = [
    {'hidden_layer_sizes': [(scipy.stats.randint(low=2**5, high=2**11+1).rvs(), )]}
    for _ in range(100)] + [
    {'hidden_layer_sizes': (
            scipy.stats.randint(low=2 ** 5, high=2 ** 11 + 1).rvs(),
            scipy.stats.randint(low=2 ** 5, high=2 ** 11 + 1).rvs(),
    )} for i in range(100)
]
print(param_dist)
mlp = MLPClassifier()
random_search = RandomizedSearchCV(
    estimator=mlp,
    param_distributions=param_dist,
)
X, y = fetch_openml(data_id=61, return_X_y=True)
random_search.fit(X, y)
however, other libraries which serialize this object might have a problem with the size of the parameter distribution, while this also limits the number of random search runs based on the parameter distribution.
Therefore, I was wondering if it would be possible to add a recursive component into the parameter sampler to allow for the upper, simpler syntax.
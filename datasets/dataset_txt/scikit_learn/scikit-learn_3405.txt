jachymb commented on Nov 13, 2015
If I train a classifier on a dataset with y_train[i] = 1 for each i, I get different Exceptions for different classifiers.
For example:
AdaBoost raises ZeroDivisionError
RandomForest does not raise an exception
SVC raises ValueError.
I'd be better if the error would be the same, so they don't have to be caught separately, if one is trying different classifiers for a given task.
Alternatively, the classifier functions predict, predict_proba, decision_function could become degenerate to constant function, if it's consistent with theory.
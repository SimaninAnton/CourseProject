pemistahl commented on Feb 24, 2013
In scikit-learn 0.13.0, I'm trying to use the class sklearn.preprocessing.StandardScaler to scale my data for being used in an SVM classifier of class sklearn.svm.LinearSVC. The essential parts of my code are the following:
vectorizer = CountVectorizer(...)

X_train = vectorizer.fit_transform(my_training_data_here)
y_train = np.array(my_labels_here)
X_test = vectorizer.transform(my_test_data_here)

scaler = StandardScaler(with_mean=False)
X_train_scaled = scaler.fit_transform(X=X_train)
X_test_scaled = scaler.transform(X=X_test)

linear_svm_classifier = LinearSVC()
linear_svm_classifier.fit(X=X_train_scaled, y=y_train)
predictions = linear_svm_classifier.predict(X=X_test_scaled)
Unfortunately, an exception is raised by the line X_train_scaled = scaler.fit_transform(X=X_train). This is the relevant part of the stacktrace:
/[...]/sklearn/utils/validation.py:230: UserWarning: StandardScaler assumes floating point values as input, got int64
"got %s" % (estimator, X.dtype))
Traceback (most recent call last):
[...]
X_train_scaled = scaler.fit_transform(X=X_train)
  File "/[...]/sklearn/base.py", line 361, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File "/[...]/sklearn/preprocessing.py", line 302, in fit
    var = mean_variance_axis0(X)[1]
  File "sparsefuncs.pyx", line 272, in sklearn.utils.sparsefuncs.mean_variance_axis0 (sklearn/utils/sparsefuncs.c:3551)
  File "sparsefuncs.pyx", line 41, in sklearn.utils.sparsefuncs.csr_mean_variance_axis0 (sklearn/utils/sparsefuncs.c:1416)
ValueError: Buffer dtype mismatch, expected 'DOUBLE' but got 'long long'
Do I have to change the dtype myself? If so, how do I do that? Thank youl
martin-hunt commented on Sep 9, 2014
The maximum likelihood extimate for theta sometimes produces results that look very unreasonable.
Even trying to fit a very simple, smooth curve it fails sometimes. For example,
x* sin(x/divisor) where x is in [0,10000], changing the divisor from 636.06767 to 636.06768 changes the MLE for theta from 8 to 632.
Here is the code to reproduce this
import numpy as np
import sklearn
from sklearn.gaussian_process import GaussianProcess
def compute_fit(divisor):
x = np.linspace(0, 10000, 11)
y = x * np.sin(x/divisor)
x = np.atleast_2d(x).T

gp = GaussianProcess(theta0=2,
                     thetaL=.0001,
                     thetaU=1000)
gp.fit(x, y)
theta = gp.theta_[0][0]
return theta, gp.reduced_likelihood_function_value_
print "sklearn version:", sklearn.version
for n in [500, 636, 636.06767, 636.06768, 637, 1000]:
theta, like = compute_fit(n)
print '%s:\ttheta=%s, likelihood=%s' % (n, theta, like)
python prob.py
sklearn version: 0.15.2
500: theta=632.455532034, likelihood=-1.0
636: theta=632.455532034, likelihood=-1.0
636.06767: theta=632.455532034, likelihood=-1.0
636.06768: theta=8.47584723676, likelihood=-0.983409372837
637: theta=8.18740741469, likelihood=-0.976101646893
1000: theta=0.873105480722, likelihood=-0.0844448086551
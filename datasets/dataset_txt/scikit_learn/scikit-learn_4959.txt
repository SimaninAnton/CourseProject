chie4live commented on Feb 24, 2013
I get this eror each time i run Nosetests using the command ">>nosetests sklearn --exe".
I guess the nosetests has to pass before i continue using scikit-learn?
clf.fit(X, y)
File "c:\python33\lib\site-packages\sklearn\grid_search.py", line 372, in fit
for clf_params in grid for train, test in cv)
File "c:\python33\lib\site-packages\sklearn\externals\joblib\parallel.py", line 513, in call
for function, args, kwargs in iterable:
File "c:\python33\lib\site-packages\sklearn\grid_search.py", line 372, in
for clf_params in grid for train, test in cv)
File "c:\python33\lib\site-packages\sklearn\cross_validation.py", line 284, in iter
for i in xrange(n_folds):
NameError: global name 'xrange' is not defined
ERROR: Pass X as list in GridSearchCV
Traceback (most recent call last):
File "c:\python33\lib\site-packages\nose\case.py", line 198, in runTest
self.test(*self.arg)
File "c:\python33\lib\site-packages\sklearn\tests\test_grid_search.py", line 277, in test_X_as_list
grid_search.fit(X.tolist(), y).score(X, y)
File "c:\python33\lib\site-packages\sklearn\grid_search.py", line 372, in fit
for clf_params in grid for train, test in cv)
File "c:\python33\lib\site-packages\sklearn\externals\joblib\parallel.py", line 513, in call
for function, args, kwargs in iterable:
File "c:\python33\lib\site-packages\sklearn\grid_search.py", line 372, in
for clf_params in grid for train, test in cv)
File "c:\python33\lib\site-packages\sklearn\cross_validation.py", line 284, in iter
for i in xrange(n_folds):
NameError: global name 'xrange' is not defined
ERROR: sklearn.tests.test_grid_search.test_unsupervised_grid_search
Traceback (most recent call last):
File "c:\python33\lib\site-packages\nose\case.py", line 198, in runTest
self.test(*self.arg)
File "c:\python33\lib\site-packages\sklearn\tests\test_grid_search.py", line 286, in test_unsupervised_grid_search
grid_search.fit(X)
File "c:\python33\lib\site-packages\sklearn\grid_search.py", line 372, in fit
for clf_params in grid for train, test in cv)
File "c:\python33\lib\site-packages\sklearn\externals\joblib\parallel.py", line 513, in call
for function, args, kwargs in iterable:
File "c:\python33\lib\site-packages\sklearn\grid_search.py", line 372, in
for clf_params in grid for train, test in cv)
File "c:\python33\lib\site-packages\sklearn\cross_validation.py", line 284, in iter
for i in xrange(n_folds):
NameError: global name 'xrange' is not defined
ERROR: sklearn.tests.test_multiclass.test_ovr_gridsearch
Traceback (most recent call last):
File "c:\python33\lib\site-packages\nose\case.py", line 198, in runTest
self.test(*self.arg)
File "c:\python33\lib\site-packages\sklearn\tests\test_multiclass.py", line 200, in test_ovr_gridsearch
cv.fit(iris.data, iris.target)
File "c:\python33\lib\site-packages\sklearn\grid_search.py", line 372, in fit
for clf_params in grid for train, test in cv)
File "c:\python33\lib\site-packages\sklearn\externals\joblib\parallel.py", line 513, in call
for function, args, kwargs in iterable:
File "c:\python33\lib\site-packages\sklearn\grid_search.py", line 372, in
for clf_params in grid for train, test in cv)
File "c:\python33\lib\site-packages\sklearn\cross_validation.py", line 379, in iter
for i in xrange(n_folds):
NameError: global name 'xrange' is not defined
ERROR: sklearn.tests.test_multiclass.test_ovo_gridsearch
Traceback (most recent call last):
File "c:\python33\lib\site-packages\nose\case.py", line 198, in runTest
self.test(*self.arg)
File "c:\python33\lib\site-packages\sklearn\tests\test_multiclass.py", line 258, in test_ovo_gridsearch
cv.fit(iris.data, iris.target)
File "c:\python33\lib\site-packages\sklearn\grid_search.py", line 372, in fit
for clf_params in grid for train, test in cv)
File "c:\python33\lib\site-packages\sklearn\externals\joblib\parallel.py", line 513, in call
for function, args, kwargs in iterable:
File "c:\python33\lib\site-packages\sklearn\grid_search.py", line 372, in
for clf_params in grid for train, test in cv)
File "c:\python33\lib\site-packages\sklearn\cross_validation.py", line 379, in iter
for i in xrange(n_folds):
NameError: global name 'xrange' is not defined
ERROR: sklearn.tests.test_multiclass.test_ecoc_gridsearch
Traceback (most recent call last):
File "c:\python33\lib\site-packages\nose\case.py", line 198, in runTest
self.test(*self.arg)
File "c:\python33\lib\site-packages\sklearn\tests\test_multiclass.py", line 286, in test_ecoc_gridsearch
cv.fit(iris.data, iris.target)
File "c:\python33\lib\site-packages\sklearn\grid_search.py", line 372, in fit
for clf_params in grid for train, test in cv)
File "c:\python33\lib\site-packages\sklearn\externals\joblib\parallel.py", line 513, in call
for function, args, kwargs in iterable:
File "c:\python33\lib\site-packages\sklearn\grid_search.py", line 372, in
for clf_params in grid for train, test in cv)
File "c:\python33\lib\site-packages\sklearn\cross_validation.py", line 379, in iter
for i in xrange(n_folds):
NameError: global name 'xrange' is not defined
FAIL: Test Area under Receiver Operating Characteristic (ROC) curve
Traceback (most recent call last):
File "c:\python33\lib\site-packages\nose\case.py", line 198, in runTest
self.test(*self.arg)
File "c:\python33\lib\site-packages\sklearn\metrics\tests\test_metrics.py", line 92, in test_roc_curve
assert_array_almost_equal(roc_auc, 0.80, decimal=2)
File "c:\python33\lib\site-packages\numpy\testing\utils.py", line 812, in assert_array_almost_equal
header=('Arrays are not almost equal to %d decimals' % decimal))
File "c:\python33\lib\site-packages\numpy\testing\utils.py", line 645, in assert_array_compare
raise AssertionError(msg)
AssertionError:
Arrays are not almost equal to 2 decimals
(mismatch 100.0%)
x: array(0.8932676518883417)
y: array(0.8)
FAIL: roc_curve for confidence scores
Traceback (most recent call last):
File "c:\python33\lib\site-packages\nose\case.py", line 198, in runTest
self.test(*self.arg)
File "c:\python33\lib\site-packages\sklearn\metrics\tests\test_metrics.py", line 126, in test_roc_curve_confidence
assert_array_almost_equal(roc_auc, 0.80, decimal=2)
File "c:\python33\lib\site-packages\numpy\testing\utils.py", line 812, in assert_array_almost_equal
header=('Arrays are not almost equal to %d decimals' % decimal))
File "c:\python33\lib\site-packages\numpy\testing\utils.py", line 645, in assert_array_compare
raise AssertionError(msg)
AssertionError:
Arrays are not almost equal to 2 decimals
(mismatch 100.0%)
x: array(0.8932676518883417)
y: array(0.8)
FAIL: roc_curve for hard decisions
Traceback (most recent call last):
File "c:\python33\lib\site-packages\nose\case.py", line 198, in runTest
self.test(*self.arg)
File "c:\python33\lib\site-packages\sklearn\metrics\tests\test_metrics.py", line 148, in test_roc_curve_hard
assert_array_almost_equal(roc_auc, 0.74, decimal=2)
File "c:\python33\lib\site-packages\numpy\testing\utils.py", line 812, in assert_array_almost_equal
header=('Arrays are not almost equal to %d decimals' % decimal))
File "c:\python33\lib\site-packages\numpy\testing\utils.py", line 645, in assert_array_compare
raise AssertionError(msg)
AssertionError:
Arrays are not almost equal to 2 decimals
(mismatch 100.0%)
x: array(0.7627257799671592)
y: array(0.74)
FAIL: Test Precision Recall and F1 Score for binary classification task
Traceback (most recent call last):
File "c:\python33\lib\site-packages\nose\case.py", line 198, in runTest
self.test(*self.arg)
File "c:\python33\lib\site-packages\sklearn\metrics\tests\test_metrics.py", line 194, in test_precision_recall_f1_score_binary
assert_array_almost_equal(p, [0.73, 0.75], 2)
File "c:\python33\lib\site-packages\numpy\testing\utils.py", line 812, in assert_array_almost_equal
header=('Arrays are not almost equal to %d decimals' % decimal))
File "c:\python33\lib\site-packages\numpy\testing\utils.py", line 645, in assert_array_compare
raise AssertionError(msg)
AssertionError:
Arrays are not almost equal to 2 decimals
(mismatch 100.0%)
x: array([ 0.63333333, 0.9 ])
y: array([ 0.73, 0.75])
FAIL: Test confusion matrix - binary classification case
Traceback (most recent call last):
File "c:\python33\lib\site-packages\nose\case.py", line 198, in runTest
self.test(*self.arg)
File "c:\python33\lib\site-packages\sklearn\metrics\tests\test_metrics.py", line 257, in test_confusion_matrix_binary
assert_array_equal(cm, [[19, 6], [7, 18]])
File "c:\python33\lib\site-packages\numpy\testing\utils.py", line 719, in assert_array_equal
verbose=verbose, header='Arrays are not equal')
File "c:\python33\lib\site-packages\numpy\testing\utils.py", line 645, in assert_array_compare
raise AssertionError(msg)
AssertionError:
Arrays are not equal
(mismatch 50.0%)
x: array([[19, 2],
[11, 18]])
y: array([[19, 6],
[ 7, 18]])
FAIL: Test Precision Recall and F1 Score for multiclass classification task
Traceback (most recent call last):
File "c:\python33\lib\site-packages\nose\case.py", line 198, in runTest
self.test(*self.arg)
File "c:\python33\lib\site-packages\sklearn\metrics\tests\test_metrics.py", line 286, in test_precision_recall_f1_score_multiclass
assert_array_almost_equal(p, [0.82, 0.55, 0.47], 2)
File "c:\python33\lib\site-packages\numpy\testing\utils.py", line 812, in assert_array_almost_equal
header=('Arrays are not almost equal to %d decimals' % decimal))
File "c:\python33\lib\site-packages\numpy\testing\utils.py", line 645, in assert_array_compare
raise AssertionError(msg)
AssertionError:
Arrays are not almost equal to 2 decimals
(mismatch 100.0%)
x: array([ 0.79166667, 0.48148148, 0.625 ])
y: array([ 0.82, 0.55, 0.47])
FAIL: Test confusion matrix - multi-class case
Traceback (most recent call last):
File "c:\python33\lib\site-packages\nose\case.py", line 198, in runTest
self.test(*self.arg)
File "c:\python33\lib\site-packages\sklearn\metrics\tests\test_metrics.py", line 371, in test_confusion_matrix_multiclass
[0, 2, 18]])
File "c:\python33\lib\site-packages\numpy\testing\utils.py", line 719, in assert_array_equal
verbose=verbose, header='Arrays are not equal')
File "c:\python33\lib\site-packages\numpy\testing\utils.py", line 645, in assert_array_compare
raise AssertionError(msg)
AssertionError:
Arrays are not equal
(mismatch 77.77777777777777%)
x: array([[19, 4, 1],
[ 5, 13, 8],
[ 0, 10, 15]])
y: array([[23, 2, 0],
[ 5, 5, 20],
[ 0, 2, 18]])
FAIL: Test confusion matrix - multi-class case with subset of labels
Traceback (most recent call last):
File "c:\python33\lib\site-packages\nose\case.py", line 198, in runTest
self.test(*self.arg)
File "c:\python33\lib\site-packages\sklearn\metrics\tests\test_metrics.py", line 387, in test_confusion_matrix_multiclass_subset_labels
[5, 5]])
File "c:\python33\lib\site-packages\numpy\testing\utils.py", line 719, in assert_array_equal
verbose=verbose, header='Arrays are not equal')
File "c:\python33\lib\site-packages\numpy\testing\utils.py", line 645, in assert_array_compare
raise AssertionError(msg)
AssertionError:
Arrays are not equal
(mismatch 75.0%)
x: array([[19, 4],
[ 5, 13]])
y: array([[23, 2],
[ 5, 5]])
FAIL: Test performance report
Traceback (most recent call last):
File "c:\python33\lib\site-packages\nose\case.py", line 198, in runTest
self.test(*self.arg)
File "c:\python33\lib\site-packages\sklearn\metrics\tests\test_metrics.py", line 414, in test_classification_report
assert_equal(report, expected_report)
AssertionError: ' precision recall f1-score support\n\n setosa 0.79 [truncated]... != ' precision recall
f1-score support\n\n setosa 0.82 [truncated]...
Diff is 701 characters long. Set self.maxDiff to None to see it.
FAIL: sklearn.metrics.tests.test_metrics.test_precision_recall_curve
Traceback (most recent call last):
File "c:\python33\lib\site-packages\nose\case.py", line 198, in runTest
self.test(*self.arg)
File "c:\python33\lib\site-packages\sklearn\metrics\tests\test_metrics.py", line 432, in test_precision_recall_curve
_test_precision_recall_curve(y_true, probas_pred)
File "c:\python33\lib\site-packages\sklearn\metrics\tests\test_metrics.py", line 452, in _test_precision_recall_curve
assert_array_almost_equal(precision_recall_auc, 0.82, 2)
File "c:\python33\lib\site-packages\numpy\testing\utils.py", line 812, in assert_array_almost_equal
header=('Arrays are not almost equal to %d decimals' % decimal))
File "c:\python33\lib\site-packages\numpy\testing\utils.py", line 645, in assert_array_compare
raise AssertionError(msg)
AssertionError:
Arrays are not almost equal to 2 decimals
(mismatch 100.0%)
x: array(0.9315492337212434)
y: array(0.82)
Ran 1328 tests in 258.019s
FAILED (SKIP=15, errors=77, failures=10)
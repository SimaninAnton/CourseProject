FritzPeleke commented on Sep 10, 2019 â€¢
edited by amueller
#Early Stopping
np.random.seed(42)
m = 100
X = 6 * np.random.rand(m, 1) - 3
y = 2 + X + 0.5 * X**2 + np.random.randn(m, 1)

X_train,X_val,y_train,y_val = train_test_split(X,y.ravel(),test_size=0.2,random_state=10)

poly_scaler = Pipeline([('poly feat', PolynomialFeatures(degree=90,include_bias=False)),
                        ('scaler', StandardScaler())])

x_train_poly_scaled = poly_scaler.fit_transform(X_train)
x_val_poly_scaled = poly_scaler.transform(X_val)

sgd_reg = SGDRegressor(max_iter=1, tol=-np.infty, warm_start=True, penalty=None,
                       learning_rate="constant", eta0=0.0005, random_state=42)

minimum_val_error = float("inf")
best_epoch = None
best_model = None
for epoch in range(1000):
    sgd_reg.fit(x_train_poly_scaled, y_train)  # continues where it left off
    y_val_predict = sgd_reg.predict(x_val_poly_scaled)
    val_error = mean_squared_error(y_val, y_val_predict)
    if val_error < minimum_val_error:
        minimum_val_error = val_error
        best_epoch = epoch
        best_model = clone(sgd_reg)
print(best_epoch,minimum_val_error,best_model)

#early stopping using hyperparameters
s_reg = SGDRegressor(penalty=None,max_iter=1000,tol=-np.infty,random_state=42,
                     learning_rate="constant",eta0=0.0005,warm_start=True,
                     early_stopping=True,validation_fraction=0.2,n_iter_no_change=3)
s_reg.fit(x_train_poly_scaled,y_train)
pred = s_reg.predict(x_val_poly_scaled)
print(s_reg.n_iter_,mean_squared_error(y_val,pred))
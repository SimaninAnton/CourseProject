Contributor
erg commented on Jun 25, 2013
In [86]: from sklearn.metrics import f1_score

In [87]: f1_score([1,-1],[1,-1]) 
Out[87]: 1.0

In [88]: f1_score([2,-2],[2,-2])
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-88-4c4d2deb31e4> in <module>()
----> 1 f1_score([2,-2],[2,-2])

/home/erg/python/scikit-learn/sklearn/metrics/metrics.pyc in f1_score(y_true, y_pred, labels, pos_label, average)
   1210     """
   1211     return fbeta_score(y_true, y_pred, 1, labels=labels,
-> 1212                        pos_label=pos_label, average=average)
   1213 
   1214 

/home/erg/python/scikit-learn/sklearn/metrics/metrics.pyc in fbeta_score(y_true, y_pred, beta, labels, pos_label, average)
   1357                                                  labels=labels,
   1358                                                  pos_label=pos_label,
-> 1359                                                  average=average)
   1360     return f
   1361 

/home/erg/python/scikit-learn/sklearn/metrics/metrics.pyc in precision_recall_fscore_support(y_true, y_pred, beta, labels, pos_label, average)
   1719                 return (0., 0., 0., 0)
   1720             raise ValueError("pos_label=%d is not a valid label: %r" %
-> 1721                              (pos_label, labels))
   1722         pos_label_idx = list(labels).index(pos_label)
   1723         return (precision[pos_label_idx], recall[pos_label_idx],

ValueError: pos_label=1 is not a valid label: array([-2,  2])
Related to #1990.
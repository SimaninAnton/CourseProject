pratyushsharma commented on Feb 9, 2016
Python 3.5.1
~/D/Python data analysis> ipython news_classification.py
Automatically created module for IPython interactive environment
Loading 20 newsgroups training set...
20 newsgroups dataset for document classification (http://people.csail.mit.edu/jrennie/20Newsgroups)
13180 documents
20 categories
Extracting features from the dataset using a sparse vectorizer
UnicodeDecodeError Traceback (most recent call last)
/Users/bhawnasharma/Downloads/Python data analysis/news_classification.py in ()
37 vectorizer = TfidfVectorizer(encoding='latin1', stop_words='english')
38 X_train = vectorizer.fit_transform((open(f).read()
---> 39 for f in news_train.filenames))
40 print("done in %fs" % (time() - t0))
41 print("n_samples: %d, n_features: %d" % X_train.shape)
/usr/local/lib/python3.5/site-packages/sklearn/feature_extraction/text.py in fit_transform(self, raw_documents, y)
1303 Tf-idf-weighted document-term matrix.
1304 """
-> 1305 X = super(TfidfVectorizer, self).fit_transform(raw_documents)
1306 self._tfidf.fit(X)
1307 # X is already a transformed view of raw_documents so
/usr/local/lib/python3.5/site-packages/sklearn/feature_extraction/text.py in fit_transform(self, raw_documents, y)
815
816 vocabulary, X = self.count_vocab(raw_documents,
--> 817 self.fixed_vocabulary)
818
819 if self.binary:
/usr/local/lib/python3.5/site-packages/sklearn/feature_extraction/text.py in _count_vocab(self, raw_documents, fixed_vocab)
749 indptr = _make_int_array()
750 indptr.append(0)
--> 751 for doc in raw_documents:
752 for feature in analyze(doc):
753 try:
/Users/bhawnasharma/Downloads/Python data analysis/news_classification.py in (.0)
37 vectorizer = TfidfVectorizer(encoding='latin1', stop_words='english')
38 X_train = vectorizer.fit_transform((open(f).read()
---> 39 for f in news_train.filenames))
40 print("done in %fs" % (time() - t0))
41 print("n_samples: %d, n_features: %d" % X_train.shape)
/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/codecs.py in decode(self, input, final)
319 # decode input (taking the buffer into account)
320 data = self.buffer + input
--> 321 (result, consumed) = self._buffer_decode(data, self.errors, final)
322 # keep undecoded input until the next call
323 self.buffer = data[consumed:]
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xb9 in position 740: invalid start byte
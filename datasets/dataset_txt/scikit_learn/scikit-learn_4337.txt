Member
kastnerkyle commented on Jul 9, 2014
HashingVectorizer gives a pretty foul error message if np.nan is passed as part of a list or dict (or Pandas dataframe...). Since this can happen fairly often in Pandas, I would like to clean up the error message somehow, and ideally spit back the passed in value which causes the problem. The position in the document iterator would be useful information as well, so that people can clean up the problem in their data without having to search for it i.e. feed values one at a time.
A sample traceback is:
Traceback (most recent call last):
  File "unhelpful.py", line 6, in <module>
    hv.transform(s)
  File "/home/kkastner/src/scikit-learn/sklearn/feature_extraction/text.py", line 441, in transform
    X = self._get_hasher().transform(analyzer(doc) for doc in X)
  File "/home/kkastner/src/scikit-learn/sklearn/feature_extraction/hashing.py", line 129, in transform
    _hashing.transform(raw_X, self.n_features, self.dtype)
  File "_hashing.pyx", line 44, in sklearn.feature_extraction._hashing.transform (sklearn/feature_extraction/_hashing.c:1649)
  File "/home/kkastner/src/scikit-learn/sklearn/feature_extraction/hashing.py", line 127, in <genexpr>
    raw_X = (((f, 1) for f in x) for x in raw_X)
  File "/home/kkastner/src/scikit-learn/sklearn/feature_extraction/text.py", line 441, in <genexpr>
    X = self._get_hasher().transform(analyzer(doc) for doc in X)
  File "/home/kkastner/src/scikit-learn/sklearn/feature_extraction/text.py", line 229, in <lambda>
    tokenize(preprocess(self.decode(doc))), stop_words)
  File "/home/kkastner/src/scikit-learn/sklearn/feature_extraction/text.py", line 195, in <lambda>
    return lambda x: strip_accents(x.lower())
AttributeError: 'float' object has no attribute 'lower'
Minimal reproducing example:
from sklearn.feature_extraction.text import HashingVectorizer
import numpy as np

s = [np.nan, "HELLO WORLD"]
hv = HashingVectorizer()
hv.transform(s)
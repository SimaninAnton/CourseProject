Member
pprett commented on Dec 2, 2012
Random Forest is a popular classification technique; recent benchmarks [1][2] have shown that performance of sklearn's RandomForestClassifier is inferior to competing software implementations.
The performance penalty most likely stems from the underlying tree building procedure, however, changes here require considerable effort. These changes include:
Better representations for data set partitions (currently we use a bit mask)
Some low-hanging fruits may be found in the forest module itself:
Sampling w/ replacement requires memory copies and re-computation of X_argsorted -> this can be mitigated by introducing sample weights (see #522)
[1] http://continuum.io/blog/wiserf-use-cases-and-benchmarks
[2] http://wise.io/wiserf.html
Chriskamphuis commented on Mar 29, 2018
Description
I was comparing different types of regression algorithms: Ridge, Lasso and ElasticNet. I used the default parameters for all these techniques. I found that Lasso and ElasticNet gave the same results while I would expect them to be different as Lasso only uses a L1 penalty while ElasticNet uses both L1 and L2.
Steps/Code to Reproduce
from sklearn.linear_model import Ridge, Lasso, ElasticNet as Elastic  
from sklearn.model_selection import KFold

classifiers = [Ridge, Lasso, Elastic]

kf = KFold(n_splits=5)

for classifier in classifiers:
    name = classifier.__name__    
    splits = kf.split(x_bow)
    
    for i, (train_idx, test_idx) in enumerate(splits):
        clf = classifier()
        
        x_train_split = x_bow[train_idx,:]
        y_train_split = y_np[train_idx,:]
        x_test_split = x_bow[test_idx,:]
        y_test_split = y_np[test_idx,:]
        
        clf.fit(x_train_split, y_train_split)
        prediction = clf.predict(x_test_split)
        mae = np.mean(np.abs(prediction - y_test_split), axis=1)
        print(f'{name} - split {i+1} - points mae {mae[0]:.2f} price mae {mae[1]:.2f}')
Expected Results
I would expect the ElasticNet results and the Lasso results to be different.
Actual Results
Ridge - split 1 - points mae 0.32 price mae 0.51
Ridge - split 2 - points mae 0.21 price mae 0.42
Ridge - split 3 - points mae 0.68 price mae 0.63
Ridge - split 4 - points mae 0.36 price mae 0.61
Ridge - split 5 - points mae 0.19 price mae 0.48

Lasso - split 1 - points mae 1.08 price mae 0.51
Lasso - split 2 - points mae 0.46 price mae 0.06
Lasso - split 3 - points mae 0.99 price mae 1.23
Lasso - split 4 - points mae 0.66 price mae 0.66
Lasso - split 5 - points mae 0.56 price mae 0.46

ElasticNet - split 1 - points mae 1.08 price mae 0.51
ElasticNet - split 2 - points mae 0.46 price mae 0.06
ElasticNet - split 3 - points mae 0.99 price mae 1.23
ElasticNet - split 4 - points mae 0.66 price mae 0.66
ElasticNet - split 5 - points mae 0.56 price mae 0.46
A second problem occurs when I force the l1_ratio to be 0, then I get the following warning:
/home/chris/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:470: UserWarning: Coordinate descent with alpha=0 may lead to unexpected results and is discouraged.
  positive)
This is also weird as the alpha is set to 1 by default.
Versions
Linux-4.9.0-6-amd64-x86_64-with-debian-9.4
Python 3.6.1 |Continuum Analytics, Inc.| (default, May 11 2017, 13:09:58)
[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]
NumPy 1.12.1
SciPy 0.19.1
Scikit-Learn 0.18.2
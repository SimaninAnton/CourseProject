mpg85 commented on Oct 20, 2016 â€¢
edited
Sometimes when using grid search or randomized search one has the necessity to enable or disable some preprocessing steps. For example, I might decide to see whether my model performs better if I scale my features or not.
I think a simple way to obtain that would be to add a bypass argument to the transformers.
As an example, think of a setup where a LogisticRegression model is selected through grid search:
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler

# assuming X for feature matrix, y for label vector

pipe = Pipeline([("ss", StandardScaler()), ("lr", LogisticRegression())])

grid = {
    "ss__bypass": [True, False],
    "ss__with_std": [True, False],
    "lr__C": [0.1, 0.5, 1.0]
}

gs = GridSearchCV(pipe, grid)
gs.fit(X, y)
Given this setup, whenever the combination of parameters containsbypass=True, the scaling is ignored, regardless of the value of the other parameter with_std. I also think this is pretty easy to implement. For example, StandardScaler could be extended by just changing its __init__ and fit methods like this:
def __init__(self, copy=True, with_mean=True, with_std=True,  bypass=False, ):
    self.bypass = bypass
    super(StandardScaler, self).__init__(copy=copy, with_mean=with_mean, with_std=with_std)

def fit(self, X, y=None, **params):
    if self.bypass is False:
        return X
    return super(StandardScaler, self).fit(X, y, **params)
Not totally sure if I'm being clear with this request, if you don't understand I can provide a working example, since I've implemented it for my own personal use.
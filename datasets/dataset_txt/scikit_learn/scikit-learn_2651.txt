DonBeo commented on Oct 20, 2016 â€¢
edited by lesteve
This is the copy of a question available on stackoverflow http://stackoverflow.com/questions/40157165/sklearn-countvectorizer-vocabulary-is-not-complete?noredirect=1#comment67585058_40157165 .
I do not understand if I am doing something wrong or if there is a bug in the library.
This is my code:
all_docs = ['ETH0x0000 0017A4779C04 09002B000005 0 PortA Unknown 755 0 45300 FirstHourDay21 LastHourDay23 duration6911 ThreatScorenan ThreatCategorynan False AnomalyFalse',
            'ETH0x0000 0017A4779C04 09002B000005 2 PortC Unknown 774 0 46440 FirstHourDay21 LastHourDay23 duration6911 ThreatScorenan ThreatCategorynan False AnomalyFalse',
            'ETH0x0000 0017A4779C0A 09002B000005 0 PortA Unknown 752 0 45120 FirstHourDay21 LastHourDay23 duration6913 ThreatScorenan ThreatCategorynan False AnomalyFalse',
            'ICMP 10.6.224.1 71.6.165.200 0 PortA 192 IP-ICMP 1 1 70 FirstHourDay22 LastHourDay22 duration0 ThreatScore122,127 ThreatCategory21,23 True AnomalyTrue',
            'ICMP 10.6.224.1 71.6.165.200 2 PortC 192 IP-ICMP 1 1 70 FirstHourDay22 LastHourDay22 duration0 ThreatScore122,127 ThreatCategory21,23 True AnomalyTrue',
            'ICMP 10.6.224.1 185.93.185.239 0 PortA 192 IP-ICMP 1 1 70 FirstHourDay22 LastHourDay22 duration0 ThreatScore127 ThreatCategory23 True AnomalyTrue']

tf_vectorizer = CountVectorizer(max_df=1, min_df=0,
                                max_features=None,
                                stop_words=None,
                                token_pattern=r"(?u)\b\w\w+\b")
tf_v = tf_vectorizer.fit(all_docs)



print(tf_v.vocabulary_)
Output:
{'752': 6, '45120': 3, 'threatscore127': 12, '93': 9, '774': 8, '239': 2, 'duration6913': 10, '46440': 5, '0017a4779c0a': 0, '45300': 4, '185': 1, '755': 7, 'threatcategory23': 11}
I was expecting to obtain a different word for each spaced element in my strings. Instead some of them do not appear as for example AnomalyTrue
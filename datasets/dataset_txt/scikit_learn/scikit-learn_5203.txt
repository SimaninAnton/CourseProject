Emmanuel000 commented on Oct 1, 2012
Hi,
I'm using mixtures.GMM. With a full covaiance, everything is fine, but with a diagonal one, I get a division by zero if one of the features is constant.
Here is an example:
from sklearn import mixture
obs=[[0,1.3],[0,1.2],[0,1.1],[0,1.33],[0,1.5]]
g=mixture.GMM(n_components=2,cvtype='diag',min_covar=1E-2)
g.fit(obs)
So, yes it is stupid to do some learning on a constant feature. But still, I guess some people would like to correct this, by using min_covars value in the initialization of the diagonal covariance...
Thanks very much
Emmanuel
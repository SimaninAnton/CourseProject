ghost commented on Nov 13, 2016 â€¢
edited by amueller
I've tried feeding the Support vector regression (using a rbf kernel) a function with ~12 features and 1 continous labels and the results were quite disastrous.
However, after experimenting a bit it seems that either:
a)I'm messing something up
b)The docs are quite unclear about using SVR
c)There's a bug with SVR
What I'm basically doing it feeding the SVR a function of the form f(y) = y and the "accuracy" of the predictions are rather horrible, like, missing by hundred's of precentages horrible.
Here's the code I have for testing:
Y = []
X = []

Arr = np.random.rand(15000)
for val in Arr:
    X.append(
    [val]
    )
    Y.append(val)

length = len(X)

Xlearn = np.array(X[0:round(length*9/10)])
Ylearn = np.array(Y[0:round(length*9/10)])
Xtest = np.array(X[round(length*9/10):(length - 1)])
Ytest = np.array(Y[round(length*9/10):(length - 1)])

svr_rbf = svm.SVR(kernel='rbf', C=1e4, gamma=0.01)
svr_rbf.fit(Xlearn, Ylearn)
y_rbf = svr_rbf.predict(Xtest)


precentages = []
for ind, val in enumerate(Ytest):
    accuracy = abs((val - y_rbf[ind])/val)
    #print("real: ", val)
    #print("predicted", y_rbf[ind])
    precentages.append(accuracy*100)
    print(accuracy*100)
    #print(abs(v/val)*100)
print("accuracy mean(lower is better): ", np.mean(precentages))
print("accuracy std(lower is better): ", np.std(precentages))
Is my code written badly or am I not understanding SVR's usage correctly ?
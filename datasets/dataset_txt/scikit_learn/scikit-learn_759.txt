Contributor
srcole commented on Feb 4, 2019
Description
I was using sklearn.calibration.calibration_curve, and it currently accepts an n_bins parameter to specify the number of bins to evenly partition the probability space between 0 and 1.
However, I am using this in combination with a gradient boosting model in which the probabilities are very uncalibrated, and most of the predictions are close to 0. When I use the calibrated classifier, the result is very noisy because there are many data points in some bins and few, if any, in others (see example below).
In the code below, I made a work-around to do what I want and show a plot of my output (in semilog space because of the skewed distribution). I haven't contributed to a large open-source project before, but if there's agreement this would be a useful feature, I would be happy to try to draft up a PR.
My work-around
import numpy as np

def my_calibration_curve(y_true, y_prob, my_bins):
    prob_true = []
    prob_pred = []
    for i in range(len(my_bins) - 1):
        idx_use = np.logical_and(y_prob < my_bins[i+1], y_prob >= my_bins[i])
        prob_true.append(y_true[idx_use].mean())
        prob_pred.append(y_pred[idx_use].mean())
    return prob_true, prob_pred

# example bins:
# my_bins = np.concatenate([[0], np.logspace(-3, 0, 10)])
Results comparison
Notice the large disparity in results between the different bins chosen. For this reason, I think the user should be able to choose the bin edges, as in numpy's or matplotlib's histogram functions.
Versions
Darwin-18.0.0-x86_64-i386-64bit
Python 3.6.4 |Anaconda custom (x86_64)| (default, Jan 16 2018, 12:04:33) 
[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]
NumPy 1.15.1
SciPy 1.1.0
Scikit-Learn 0.19.1
gabrielelanaro commented on Jul 25, 2015
Hi, I've been running DBSCAN using a precomputed metric. I am using the option min_samples=6.
model = DBSCAN(eps=0.4, min_samples=6, metric='precomputed')
model.fit(D)
However if I group by label I obtain clusters as low as size 3 (actually as low as size 1, but I have to confirm that).
From what I understand a "core point" is defined when he has 6 points within eps. Assuming we find a core-point it means that he can reach at least other 5 points, shouldn't the minimum cluster size be 6?
This is the code I use to gather the clusters:
labels = model.labels_
from collections import defaultdict
d = defaultdict(set)
for i, l in enumerate(labels):
    if l == -1:
        continue
    else:
        d[l].add(i)
min([len(c) for c in d.values()])
MateuszKonopelski commented on Feb 22, 2019
Hi,
I've got very imbalanced set:
Class 0: 120,0549
Class 1: 1,005
For purpose od parapmeter tuning I'm using imbalanced learn library and techniques like: SMOTE and NearMiss to resample this set to be:
Class 0: 8,000
Class 1: 2,000
The algorithm I chose was Random Forrest (which I optimize using GridSearchCV). How should I build dictionary for class_weight parameter so I will put emphasize that original set is very imbalanced?
Is class_weight correct place to do it?
My procedure looks like it now:
cv_choice = StratifiedKFold(n_splits=10)

param_grid = {'n_estimators': np.arange(100, 1100, 100)
              ,'max_features': np.arange(10, db.shape[1], 10),
              'max_depth': np.arange(1,50, 2),
              'bootstrap': [True, False],
              'criterion': ['gini', 'entropy'],
              'class_weight': [None, 'balanced', {0: , 1: }]
              }

alg = RandomForestClassifier(n_jobs=-1)
clf = GridSearchCV(estimator=alg, 
                   param_grid =param_grid, 
                   cv=cv_choice, 
                   scoring='f1', 
                   n_jobs=-1,
                   verbose=50
                   )

clf.fit(db, labels)
Thank for the help!
Celelibi commented on Feb 6, 2018 â€¢
edited
Description
When using linear_model.LogisticRegression with warm_start=True and solver='saga', calling fit twice with the same input restart the computation from scratch.
My use-case is that my dataset is a bit large and convergence is slow. Therefore, I would like to perform a first fit on a small subset of the data before fitting on the whole data.
Looking at the code, I think the sag solver needs as input the whole warm_start_mem dict as returned by the function sag_solver. Not just the coef part.
Steps/Code to Reproduce
import numpy as np
from sklearn import linear_model as lin
X = np.random.random((100, 3))
y = np.random.randint(2, size=100)
reg = lin.LogisticRegression(solver='saga', verbose=4, warm_start=True, max_iter=10)
reg.fit(X, y)
reg.fit(X, y)
Expected Results
Improve the last result.
Actual Results
Restart the computation from scratch.
>>> reg.fit(X, y)
Epoch 1, change: 1.00000000
Epoch 2, change: 0.78532255
Epoch 3, change: 0.77354579
Epoch 4, change: 0.32331806
Epoch 5, change: 0.19534453
Epoch 6, change: 0.07763687
Epoch 7, change: 0.07397804
Epoch 8, change: 0.02722130
Epoch 9, change: 0.01970866
Epoch 10, change: 0.01451695
max_iter reached after 0 seconds
/usr/lib/python3/dist-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  "the coef_ did not converge", ConvergenceWarning)
[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s
[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished
LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=10, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='saga', tol=0.0001,
          verbose=4, warm_start=True)
>>> reg.fit(X, y)
Epoch 1, change: 1.00000000
Epoch 2, change: 1.16300535
Epoch 3, change: 0.16047612
Epoch 4, change: 0.13252828
Epoch 5, change: 0.13191930
Epoch 6, change: 0.07695475
Epoch 7, change: 0.02934466
Epoch 8, change: 0.02572194
Epoch 9, change: 0.03662578
Epoch 10, change: 0.01097797
max_iter reached after 0 seconds
/usr/lib/python3/dist-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  "the coef_ did not converge", ConvergenceWarning)
[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s
[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished
LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=10, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='saga', tol=0.0001,
          verbose=4, warm_start=True)
Versions
>>> import platform; print(platform.platform())
Linux-4.14.0-3-amd64-x86_64-with-debian-buster-sid
>>> import sys; print("Python", sys.version)
Python 3.6.4 (default, Jan  5 2018, 02:13:53) 
[GCC 7.2.0]
>>> import numpy; print("NumPy", numpy.__version__)
NumPy 1.14.0
>>> import scipy; print("SciPy", scipy.__version__)
SciPy 0.19.1
>>> import sklearn; print("Scikit-Learn", sklearn.__version__)
Scikit-Learn 0.19.1
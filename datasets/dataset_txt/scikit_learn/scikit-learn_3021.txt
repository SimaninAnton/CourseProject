ayanamirei00 commented on May 2, 2016
Description
The output of the thresholds of sklearn.metrics.precision_recall_curve is different than expected (also it is different from that of roc curve, where all probs are used). In the following example, only 3 thresholds are returned, why 0,1 is not used ?
I am unsure if it is a usage question.
Steps/Code to Reproduce
following the example here :
import numpy as np
from sklearn.metrics import precision_recall_curve
y_true = np.array([0, 0, 1, 1])
y_scores = np.array([0.1, 0.4, 0.35, 0.8])
precision, recall, thresholds = precision_recall_curve(
... y_true, y_scores)
precision
array([ 0.66..., 0.5 , 1. , 1. ])
recall
array([ 1. , 0.5, 0.5, 0. ])
thresholds
array([ 0.35, 0.4 , 0.8 ])
Expected Results
thresholds
array([ 0.1, 0.35, 0.4 , 0.8 ])
Actual Results
thresholds
array([ 0.35, 0.4 , 0.8 ])
Versions
Windows-XP-5.1.2600-SP3
('Python', '2.7.11 |Anaconda 4.0.0 (32-bit)| (default, Mar 4 2016, 15:18:41) [MSC v.1500 32 bit (Intel)]')
('NumPy', '1.10.4')
('SciPy', '0.17.0')
('Scikit-Learn', '0.17.1')
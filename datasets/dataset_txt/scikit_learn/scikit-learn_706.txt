tanayag commented on Feb 25, 2019 â€¢
edited
In this article: https://scikit-learn.org/stable/auto_examples/feature_selection/plot_f_test_vs_mi.html
we can see the difference between the scores of both f test and mutual info, and where each of them perform better.
So, I was thinking would it not be a good approach to consider both the scores while selecting our features.
So, I took intersection based on both the scores, and only considered the features where these f score and mutual info score both are high, and actually got good results while feature selection,
So, I was doing something like this:
def feature_selector_classification(x, y, k_f=10, k_mi=10, nn_mi=3):
    def my_mutual_info(x, y):
        return mutual_info_classif(x, y, n_neighbors=nn_mi)

    score_func = [f_classif, mutual_info_classif]
    fscore = SelectKBest(score_func=score_func[0], k=k_f)
    fscore.fit(x, y)
    idx_fscore = list(fscore.get_support(indices=False))
    miscore = SelectKBest(score_func=my_mutual_info, k=k_mi)
    miscore.fit(x, y)
    idx_miscore = list(miscore.get_support(indices=False))
    #idx_union = list(set(idx_miscore) & set(idx_fscore))
    idx_union = list()
    for i in range(len(idx_miscore)):
        if idx_miscore[i] and idx_fscore[i]:
            idx_union.append(i)
    try:
        new_x = x.ix[:, idx_union[0]]
    except:
        return np.array([])

    for i in idx_union[1:]:
        new_x = np.c_[new_x, x.ix[:, i]]

    return new_x
And then, k_f, k_mi, nn_mi can be tuned as per need.
this was the basic idea,
I also extended the class to use it in my work to use all the functionalities of feature selection in general,
def weighted_custom_selector(X, y,k_f=10,k_mi=10,nn_mi=3):

    def my_mutual_info(X, y):
        return mutual_info_regression(X, y, n_neighbors=nn_mi)

    real_mutual_info_score = my_mutual_info(X,y)
    real_f_regressor_score = f_regression(X,y)[0]


    scaled_mutual = (real_mutual_info_score - np.min(real_mutual_info_score))/(np.max(real_mutual_info_score)-np.min(real_mutual_info_score))
    scaled_regressor = (real_f_regressor_score - np.min(real_f_regressor_score)) / (np.max(real_f_regressor_score) - np.min(real_f_regressor_score))

    total_score = scaled_mutual + scaled_regressor




    sorted_mutual_info = np.argsort(real_mutual_info_score,)
    sorted_f_regressor = np.argsort(real_f_regressor_score)

    sorted_mutual_info = sorted_mutual_info[:k_mi]
    sorted_f_regressor = sorted_f_regressor[:k_f]

    idx_union = list(set(sorted_mutual_info) & set(sorted_f_regressor))

    for i in range(len(total_score)):
        if i not in idx_union:
            total_score[i] = 0


    return total_score





from sklearn.feature_selection.univariate_selection import _BaseFilter

class CustomWeightedFeatureSelector(_BaseFilter):

    def __init__(self,k_f=10,k_mi=10,nn_mi=3):
        super(CustomWeightedFeatureSelector,self).__init__(score_func=weighted_custom_selector)
        self.k = np.min([k_f,k_mi])
        self.exclusive_k = self.k
        self.k_f = k_f
        self.k_mi = k_mi
        self.nn_mi = nn_mi



    def _check_params(self, X, y):
        if not (self.k == "all" or 0 <= self.k <= X.shape[1]):
            raise ValueError("k should be >=0, <= n_features = %d; got %r. "
                             "Use k='all' to return all features."
                             % (X.shape[1], self.k))

    def _get_support_mask(self):
        check_is_fitted(self, 'scores_')

        if self.k == 'all':
            return np.ones(self.scores_.shape, dtype=bool)
        elif self.exclusive_k == 0:
            return np.zeros(self.scores_.shape, dtype=bool)
        else:
            scores = _clean_nans(self.scores_)
            mask = np.zeros(scores.shape, dtype=bool)

            # Request a stable sort. Mergesort takes more memory (~40MB per
            # megafeature on x86-64).
            mask[np.argsort(scores, kind="mergesort")[-self.exclusive_k:]] = 1
            return mask

    def fit(self, X, y):
        """Run score function on (X, y) and get the appropriate features.
               Parameters
               ----------
               X : array-like, shape = [n_samples, n_features]
                   The training input samples.
               y : array-like, shape = [n_samples]
                   The target values (class labels in classification, real numbers in
                   regression).
               Returns
               -------
               self : object
               """
        X, y = check_X_y(X, y, ['csr', 'csc'], multi_output=True)

        if not callable(self.score_func):
            raise TypeError("The score function should be a callable, %s (%s) "
                            "was passed."
                            % (self.score_func, type(self.score_func)))

        self._check_params(X, y)
        score_func_ret = self.score_func(X, y,self.k_f,self.k_mi,self.nn_mi)
        if isinstance(score_func_ret, (list, tuple)):
            self.scores_, self.pvalues_ = score_func_ret
            self.pvalues_ = np.asarray(self.pvalues_)
        else:
            self.scores_ = score_func_ret
            self.pvalues_ = None

        self.scores_ = np.asarray(self.scores_)

        return self
        self.exclusive_k = np.count_nonzero(self.scores_)
Is this something that can be useful?
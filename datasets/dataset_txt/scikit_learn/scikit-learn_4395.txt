Contributor
t-pfaff commented on May 22, 2014
I'm not sure if this is intended, but I was confused that the score function after grid search uses a different scorer than the scorer defined in GridSearchCV.
Example:
from sklearn import datasets
from sklearn.linear_model import LinearRegression
from sklearn.grid_search import GridSearchCV
from sklearn.cross_validation import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score

digits = datasets.load_digits()
X = digits.data
y = digits.target
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)

hyperparams = [{'fit_intercept':[True, False]}]
algo = LinearRegression()

grid = GridSearchCV(algo, hyperparams, cv=5, scoring='mean_squared_error')
grid.fit(X_train, y_train)
print grid.score(X_test, y_test)
print mean_squared_error(y_test, grid.best_estimator_.predict(X_test))
print r2_score(y_test, grid.best_estimator_.predict(X_test))
I expected that grid.score() would use the mean_squared_error because this was previously defined in the scoring option. It took me some time to find out that the number is actually the r2_score which seems to be the score function of LinearRegression.
The documentation of score() in BaseSearchCV says:
The score function of the best estimator is used, or the scoring parameter where unavailable.
Maybe the documentation of score() in BaseSearchCV could be adapted to make it clear that the calculated score is not necessarily the same as the one defined in the scoring parameter of GridSearchCV.
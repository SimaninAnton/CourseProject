ginward commented on Jul 12, 2018 â€¢
edited
Description
I did a PCA on Identity Matrix with sklearn. As you might know, an Identity Matrix has a eigenvalue as 1 and infinitely number of eigenvectors. The covariance of an identity matrix is:
1/4  0 
0    1/4
The eigenvalue of the covariance matrix should be 1/4 and the eigenvector should be orthogonal set of eigenvectors.
However, sklearn returned me two eigenvalues: 1.00000000e+00, 2.81351049e-34, and a weird set of eigenvectors.
Steps/Code to Reproduce
from sklearn.decomposition import PCA #PCA Package
ls=[[1,0],[0,1]]
pca=PCA()
res=pca.fit(ls)
res.explained_variance_
pca.explained_variance_ratio_
pca.components_
Expected Results
Eigenvalues of 1/4s and any orthogonal set of eigenvectors.
Actual Results
>>> from sklearn.decomposition import PCA #PCA Package
>>> ls=[[1,0],[0,1]]
>>> pca=PCA()
>>> res=pca.fit(ls)
>>> res.explained_variance_
array([  1.00000000e+00,   2.81351049e-34])
>>> pca.explained_variance_ratio_
array([  1.00000000e+00,   2.81351049e-34])
>>> pca.components_ 
array([[-0.70710678,  0.70710678],
       [-0.70710678, -0.70710678]])
Versions
>>> import platform; print(platform.platform())
Darwin-17.6.0-x86_64-i386-64bit
>>> import sys; print("Python", sys.version)
('Python', '2.7.10 (default, Oct  6 2017, 22:29:07) \n[GCC 4.2.1 Compatible Apple LLVM 9.0.0 (clang-900.0.31)]')
>>> import numpy; print("NumPy", numpy.__version__)
('NumPy', '1.8.0rc1')
>>> import scipy; print("SciPy", scipy.__version__)
('SciPy', '0.13.0b1')
>>> import sklearn; print("Scikit-Learn", sklearn.__version__)
('Scikit-Learn', '0.19.1')
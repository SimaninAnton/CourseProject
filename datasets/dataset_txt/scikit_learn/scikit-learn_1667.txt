hym1120 commented on Dec 21, 2017 â€¢
edited by lesteve
Description
When I do logistic regression with explicitly passed sample weights, I would expect result does not change if I scale all weights up and down. But I do get different result as shown below. Please advise.
Steps/Code to Reproduce
from sklearn.linear_model import LogisticRegression
from sklearn import datasets
import numpy as np
n = 1000
X, y = datasets.make_classification(n_samples=n, n_features=10,
                                    n_informative=5, n_redundant=0,
                                    random_state=42)
sample_weight1 = np.ones(n)
sample_weight2 = sample_weight1 / 1000.0
model1 = LogisticRegression()
model2 = LogisticRegression()
model1.fit(X,y,sample_weight1)
model2.fit(X,y,sample_weight2)
print('%.6f' % model1.score(X,y,sample_weight1))
print('%.6f' % model1.score(X,y,sample_weight2))
print('%.6f' % model2.score(X,y,sample_weight1))
print('%.6f' % model2.score(X,y,sample_weight2))
Expected Results
0.744000
0.744000
0.744000
0.744000
Actual Results
0.744000
0.744000
0.714000
0.714000
Versions
In [1]: import platform; print(platform.platform())
Linux-2.6.32-573.35.2.el6.x86_64-x86_64-with-redhat-6.7-Santiago

In [2]: import sys; print("Python", sys.version)
('Python', '2.7.12 |Anaconda 2.3.0 (64-bit)| (default, Jul  2 2016, 17:42:40) \n[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]')

In [3]: import numpy; print("NumPy", numpy.__version__)
('NumPy', '1.11.2')

In [4]: import scipy; print("SciPy", scipy.__version__)
('SciPy', '0.18.1')

In [5]: import sklearn; print("Scikit-Learn", sklearn.__version__)
('Scikit-Learn', '0.18')
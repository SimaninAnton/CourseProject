mattphotonman commented on Aug 12, 2014
In some cases the labels don't stay clamped in LabelPropagation. For example:
from sklearn.semi_supervised import LabelPropagation
import numpy as np
lp = LabelPropagation(kernel = 'knn', n_neighbors = 2)
X = np.array([[1.,1.],[1.,0.],[0.,1.]])
y = np.array([1.,0.,-1.])
lp.fit(X,y)
print lp
print y
print lp.transduction_

# Produces:

LabelPropagation(alpha=1, gamma=20, kernel='knn', max_iter=30, n_neighbors=2,
         tol=0.001)
[ 1.  0. -1.]
[ 0.  0.  1.]
I think the problem occurs in label_propagation.py at line 235 and line 249. When alpha is equal to 1, y_static is set to 0 in line 235, and then line 249 doesn't change self.label_distributions_, whereas it should clamp the values of the labelled data points.
My understanding from the documentation is that for LabelPropagation it is always supposed to do hard clamping, and thus it should be completely independent of alpha. I'm not actually sure what the intention was here since the same fit method is used for LabelSpreading.
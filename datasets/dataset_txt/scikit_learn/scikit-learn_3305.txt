vsaase commented on Dec 18, 2015
Hi,
is this a bug in the Huber loss?
In the example x = y so I would expect a perfect fit of the regression with slope=1.
The slope changes with epsilon.
import numpy as np
from sklearn.linear_model import SGDRegressor
import matplotlib.pyplot as plt


n=100
y=np.random.normal(n*[0])
X = np.zeros([n,1])
X[:,0]=y

r = SGDRegressor(loss='huber', penalty='none', epsilon=.1)
r.fit(X,y)
yp = r.predict(X)


plt.scatter(y,yp)
plt.plot([-3,3],[-3,3])
chiatungkuo commented on Jul 7, 2015
Below is something I found troublesome but not exactly a bug.
When setting init='random', NMF draws initial W, H from standard normal distribution and then take absolute values while the default init='nndsvd' takes values from results of randomized SVD (with small manipulations). The magnitudes of the initial W and H from the former (i.e. random) are irrespective of the data (entry-wise, but linear to size of X, of course) whereas the latter (nndsvd) tends to give initial W and H whose magnitudes are highly dependent on the data X.
Since the termination criterion during fitting is set based on the norms of the initial W and H, this often requires the user to supply very different values of 'tol' when using 'nndsvd' and 'random' to initialize. My experience was that using the default tol=0.0001 and init='random' while fitting a row-normalized X of size 10000x1000 results in immediate termination since the effective tolerance during the update step in fit() is too large.
Accordingly I suggest the author add a normalization step when init='random' such that the initial W and H have norms comparable to that of data X (or similar to what would result from nndsvd).
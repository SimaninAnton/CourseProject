Member
jnothman commented on Mar 16, 2017 ‚Ä¢
edited
One of the most frequent concerns from users is the size (in memory or on disk) of random forests and decision trees. Often this is because users have used the default parameters, which is inclined towards giving each distinct sample a distinct leaf (where that is necessary to obtain purity of target value at the leaf).
I think there should be a prominent Note in the docstring of DecisionTreeClassifier/Regressor and RandomForestClassifier/Regressor that the defaults are very memory consumptive, and likely to overfit the training data; parameters should be used to control model size (limiting depth or branching) and to regularise the model.
I am sure we had discussion about similar recently, and perhaps there is an open issue/PR, but I can't find it immediately.
üëç 1
Contributor
themrmax commented on Sep 15, 2016
Description
Looking into this question on stackoverflow, I found that pandas is getting much better performance using a hash table rather than then sorted search that we are currently using. Even using a dict would give us a big improvement on performance.
Steps/Code to Reproduce
import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder

df = pd.DataFrame({'ID_0':np.random.randint(0,1000,1000000), 
                   'ID_1':np.random.randint(0,1000,1000000)}).astype(str)

le = LabelEncoder()
le.fit(df.values.flat)

%time r = df.apply(le.transform)
# CPU times: user 6.28 s, sys: 48.9 ms, total: 6.33 s
# Wall time: 6.37 s

%time r = df.apply(lambda x: x.astype('category').cat.codes)
# CPU times: user 301 ms, sys: 28.6 ms, total: 330 ms
# Wall time: 331 ms

hashtable = {c:i for i,c in enumerate(df.values.reshape(-1))}
%time vs = df.applymap(lambda x: hashtable[x])
# CPU times: user 1.35 s, sys: 58 ms, total: 1.41 s
# Wall time: 1.42 s
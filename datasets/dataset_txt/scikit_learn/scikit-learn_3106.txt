Contributor
rhiever commented on Mar 15, 2016
I think it would be valuable to have a feature preprocessor that explicitly models feature-feature interactions. Currently, PolynomialFeatures is about the closest that comes to this, but in many cases some information is lost when you model the interaction as only the multiplication of the two features.
Here's an explicit example of what I'm talking about: Say you have two features and want to model their interactions. The features can take on the values 0, 1, and 2. With PolynomialFeatures, the possible mappings into feature-feature interaction space are:
0 * 0 = 0
0 * 1 = 0
0 * 2 = 0
1 * 0 = 0
1 * 1 = 1
1 * 2 = 2
2 * 0 = 0
2 * 1 = 2
2 * 2 = 4
So even though there's technically 9 different ways that the features could interact, multiplying them only maps them into 1 of 4 interaction "states." There is considerable research showing that how you model feature-feature interactions can have a huge impact on their efficacy.
I think there would be incredible value in adding a feature preprocessing that instead maps each feature interaction as a separate value, e.g. with the same example as above:
0 * 0 = 0
0 * 1 = 1
0 * 2 = 2
1 * 0 = 3
1 * 1 = 4
1 * 2 = 5
2 * 0 = 6
2 * 1 = 7
2 * 2 = 8
I don't think this would be too hard to implement. Is this something that you would add to sklearn?
ghost commented on Jun 27, 2012
This seems odd to me... Try running the below code.
import numpy as np
from sklearn.ensemble import GradientBoostingRegressor
np.random.seed(20)
y_train = np.random.randn(100)
x_train = np.random.randn(100, 6)
y_test = np.random.randn(20)
x_test = np.random.randn(20, 6)
clf = GradientBoostingRegressor(learn_rate = 0.01, subsample = 0.5, max_depth = 6, loss = 'lad', n_estimators = 50)
clf.fit(x_train, y_train)
u1 = clf.predict(x_test[0:2, np.arange(6)])
u2 = clf.predict(x_test[0:3, np.arange(6)])
u3 = clf.predict(x_test[0:4, np.arange(6)])
u4 = clf.predict(x_test[0:5, np.arange(6)])
None of these three values will be the same!
print "According to u1, the prediction for x_test[1] is " + str(u1[1]) # Outputs -0.195578574899
print "According to u2, the prediction for x_test[1] is " + str(u2[1]) # Outputs 0.0135114732991
print "According to u3, the prediction for x_test[1] is " + str(u3[1]) # Outputs 0.0181026272625
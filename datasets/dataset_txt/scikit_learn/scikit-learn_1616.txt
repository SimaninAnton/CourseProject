dreizehnutters commented on Jan 15, 2018
Description
The dimensions (TP, FP, FN, TN) of the confusion_matrix are lost, in case of a perfect/worst unbalanced classification result (anomaly detection).
Actual Results
from sklearn.metrics import confusion_matrix

#binary classification  
y_true = [1, 1, 1, 1, 1, 1]
y_pred = [1, 1, 1, 1, 1, 1]
confusion_matrix(y_true, y_pred)
>> array([[6]])

#same as 
y_true = [-1, -1, -1, -1, -1, -1]
y_pred = [-1, -1, -1, -1, -1, -1]
confusion_matrix(y_true, y_pred)
>> array([[6]])
Expected Results
from sklearn.metrics import confusion_matrix

#binary classification  
y_true = [1, 1, 1, 1, 1, 1]
y_pred = [1, 1, 1, 1, 1, 1]
confusion_matrix(y_true, y_pred)
>> array([[0],[0]],[[0],[6]])

#same as 
y_true = [-1, -1, -1, -1, -1, -1]
y_pred = [-1, -1, -1, -1, -1, -1]
confusion_matrix(y_true, y_pred)
>> array([[6],[0]],[0],[0])
Versions
Scikit-Learn 0.19.1
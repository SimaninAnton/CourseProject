Contributor
raamana commented on Oct 24, 2017
Description
Hi All, I am running into similar issues (as in #8210 ) when I try to parallelize a loop containing GridSearchCV in each iteration (think of repeated shufflesplit, with large num of repetitions like 250, and each repetition contains a grid search on the training set). I tried to parallelize outer loop using the builtin multiprocessing library.
Full issue (with lots of details) is documented here:
https://stackoverflow.com/q/46762533/4693562
I am starting to suspect the lack of speedup expected from the outer loop parallelization may something to do with bad interaction of joblib with multiprocessing, as suggested some maintainers here in other issues. For my use cases, parallelization in outer loop is much more important than that within GridSearchCV, so here is my question: is there a way to completely disable any form of parallelization within scikit-learn, to rule out such possibility of bad interactions between multiple parallel computing libraries?
Or do you see any better alternatives for my issue I am facing?
Thanks.
Steps/Code to Reproduce
Will try to post a more concise example soon. Want to rule out the possibility of making any obvious errors.
Versions
Mac:
Darwin-17.0.0-x86_64-i386-64bit
Python 3.6.2 |Continuum Analytics, Inc.| (default, Jul 20 2017, 13:14:59)
[GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)]
NumPy 1.13.3
SciPy 0.19.1
Scikit-Learn 0.19.0
Centos:
Linux-2.6.32-696.10.1.el6.x86_64-x86_64-with-centos-6.9-Final
Python 3.6.2 |Continuum Analytics, Inc.| (default, Jul 20 2017, 13:51:32)
[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]
NumPy 1.13.1
SciPy 0.19.1
Scikit-Learn 0.19.0
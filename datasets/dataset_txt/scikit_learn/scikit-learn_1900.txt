Contributor
raamana commented on Sep 13, 2017
Following up on discussion in #5115 , I am unable to use GridSearchCV as it hangs there without throwing an error or warning.
Min code to reproduce:
from os.path import join as pjoin
import sys
import timeit

import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV, ShuffleSplit

rf = RandomForestClassifier(max_features=10, n_estimators=10, oob_score=True)
param_grid = {'min_samples_leaf': range(1, 5, 2),
              'max_features': range(1, 6, 2),
              'n_estimators': range(50, 250, 50)}

inner_cv = ShuffleSplit(n_splits=25, train_size=0.5)
gs = GridSearchCV(estimator=rf, param_grid=param_grid, cv=inner_cv)

cur_dir = '.'
train_data_mat = np.loadtxt(pjoin(cur_dir, 'JS_sklearn_test.csv'))
train_labels = np.genfromtxt(pjoin(cur_dir, 'labels_sklearn_test.txt'), dtype='int')

print(gs)

start = timeit.default_timer()
print(start)

try:
    gs.fit(train_data_mat, train_labels)
except:
    stop = timeit.default_timer()
    print(stop-start)
    sys.exit(1)

print(gs.best_score_)
print(gs.best_params_)
Quick run of the above script, with results and software config:
$ 19:03:59 miner min_example_gs >>  python test.py 
GridSearchCV(cv=ShuffleSplit(n_splits=25, random_state=None, test_size=0.1, train_size=0.5),
       error_score='raise',
       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features=10, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=10, n_jobs=1, oob_score=True, random_state=None,
            verbose=0, warm_start=False),
       fit_params={}, iid=True, n_jobs=1,
       param_grid={'min_samples_leaf': range(1, 5, 2), 'max_features': range(1, 6, 2), 'n_estimators': range(50, 250, 50)},
       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,
       scoring=None, verbose=0)
5818976.563907812
^C151.3223996711895
$ 19:07:05 miner min_example_gs >>  python --version
Python 3.6.1 :: Anaconda 4.4.0 (64-bit)
$ 19:07:09 miner min_example_gs >>  ipython
Python 3.6.1 |Anaconda 4.4.0 (64-bit)| (default, May 11 2017, 13:09:58) 

IPython 5.3.0 -- An enhanced Interactive Python.

In [2]: import numpy

In [3]: numpy.__config__.show()
blas_mkl_info:
  NOT AVAILABLE
blis_info:
  NOT AVAILABLE
openblas_info:
    libraries = ['openblas', 'openblas']
    library_dirs = ['/usr/local/lib']
    language = c
    define_macros = [('HAVE_CBLAS', None)]
blas_opt_info:
    libraries = ['openblas', 'openblas']
    library_dirs = ['/usr/local/lib']
    language = c
    define_macros = [('HAVE_CBLAS', None)]
lapack_mkl_info:
  NOT AVAILABLE
openblas_lapack_info:
    libraries = ['openblas', 'openblas']
    library_dirs = ['/usr/local/lib']
    language = c
    define_macros = [('HAVE_CBLAS', None)]
lapack_opt_info:
    libraries = ['openblas', 'openblas']
    library_dirs = ['/usr/local/lib']
    language = c
    define_macros = [('HAVE_CBLAS', None)]

In [4]: import sklearn

In [5]: sklearn.__version__
Out[5]: '0.18.1'
I am unable to upload my files for some reason (bigger than 10MB - 412 samples with dimensions 64620). I don' think size is a causing the hangup as I let it run overnight, and it didn't even finish one GridSearchCV.fit call.
I will upload it else where and post a link here soon, or try working on subset of it, to reduce its size.
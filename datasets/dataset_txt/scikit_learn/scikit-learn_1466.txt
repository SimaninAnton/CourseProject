oliverangelil commented on Mar 25, 2018 â€¢
edited by TomDLT
Description
I've run LogisticRegressionCV on the Wisconsin Breast Cancer data, and the output of clf.n_iter_ was 100 for all but 1 of the variables. The default of 100 iterations was probably not sufficient in this case. Should there not be some kind of warning? I have done some tests and ~3000 iterations was probably a better choice for max_iter...
Steps/Code to Reproduce
from sklearn.datasets import load_breast_cancer
from sklearn.linear_model import LogisticRegressionCV

data = load_breast_cancer()
y = data.target
X = data.data

clf = LogisticRegressionCV()
clf.fit(X, y)
print(clf.n_iter_)
Expected Results
Some kind of error to be shown. E.g: "result did not converge, try increasing the maximum number of iterations (max_iter)"
Versions
import platform; print(platform.platform())
Darwin-16.7.0-x86_64-i386-64bit
import sys; print("Python", sys.version)
('Python', '2.7.14 |Anaconda, Inc.| (default, Oct 5 2017, 02:28:52) \n[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]')
import numpy; print("NumPy", numpy.version)
('NumPy', '1.13.3')
import scipy; print("SciPy", scipy.version)
('SciPy', '1.0.0')
import sklearn; print("Scikit-Learn", sklearn.version)
('Scikit-Learn', '0.19.1')
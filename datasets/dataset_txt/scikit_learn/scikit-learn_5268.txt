Contributor
conradlee commented on Aug 23, 2012
I'm trying to use the ExtraTreesRegressor to perform feature selection on a somewhat large dataset, which has 37241 rows 9492 and columns. My machine has 32 cores, so I'm trying to take advantage of that by setting n_jobs to be high.
However, this seems to run very slowly and it does not utilize all of the cores. Although 20 python processes are created, most of time are idle most of the time (sometimes a few are active, sometimes none of them are active.
Here's how you can re-create my problem. Download and extract that data in question here.
In python, run:
from scipy import io
from sklearn.ensemble import ExtraTreesRegressor

matlab_dict = io.loadmat("ACT1_competition_training.mat")
data = matlab_dict["data"]
data = data.toarray()
labels = data[:,1]
train_features = data[:,1:]
forest = ExtraTreesRegressor(n_estimators=1000, compute_importances=True, n_jobs=20)
forest.fit(train_features, labels)
Can anyone else confirm the problem? Anyone have any possible explanations? Could something be blocking, or could it be due to the large amount of memory taken up by the data? Note that my system has plenty of RAM free. I've tried this both with the latest dev version and with the stable 0.11 version.
rmsouza01 commented on Aug 25, 2015
Hi,
I am running a Random Forest script using sklearn. In version 0.14.1 I run my code and I get ~0.85 accuracy, but after I updated to v0.16.1 I obtained ~0.37 of accuracy.
I didn't alter the code, and I have no idea why I get such drastic change in the results.
Here is the code:
import numpy as np
from scipy.io import loadmat,savemat
from sklearn import cross_validation
from sklearn.grid_search import GridSearchCV
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.tree import DecisionTreeClassifier    
from sklearn.ensemble import RandomForestClassifier


#Loading the AP and EP
profiles = loadmat('./rome_ap.mat')#_rome

AP = profiles['ap']

#Loading labels
rome = loadmat('./rome_dataset.mat')
rome_gt = rome['GT']

H,W,Z = AP.shape
feats = np.zeros((H*W,Z))

for i in xrange(H):
    for j in xrange(W):
        feats[i*W+j,:] = AP[i,j,:]



labels = rome_gt.ravel().astype(int)
valid = labels!=0
labels = labels[valid]
feats = feats[valid,:]



skf = cross_validation.StratifiedKFold(labels, n_folds=10)
for train_index, test_index in skf:
    break   


X_test, X_train = feats[train_index,:], feats[test_index,:]
y_test, y_train = labels[train_index], labels[test_index]


rf = RandomForestClassifier(random_state=0,min_samples_split=1)


n_estimators= [90,80,70,60,50]
max_depth =[10,15,20,25] 

tuned_parameters = dict(n_estimators = n_estimators, max_depth = max_depth)

# Set the parameters by cross-validation
clf = GridSearchCV(rf, tuned_parameters, cv=3, scoring = 'accuracy') 
clf.fit(X_train, y_train)

for params, mean_score, scores in clf.grid_scores_:
    print("%0.3f (+/-%0.03f) for %r" % (mean_score, scores.std() * 2, params))

clf = clf.best_estimator_



#clf = RandomForestClassifier(n_estimators=25, max_depth=25,min_samples_split=1, random_state=0)
#clf.fit(X_train, y_train)

#X_test2 = pca.transform(X_test)

y_pred = clf.predict(X_test)
cm = confusion_matrix(y_pred,y_test)
print  accuracy_score(y_pred,y_test)
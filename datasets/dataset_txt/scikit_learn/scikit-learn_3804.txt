guigarfr commented on May 26, 2015
I have some feature array, consisting in a featureUnion of different features. Some of them, come from TfidfVectorizers. when I set the parameter tokenizer=LemmaTokenizer(lang='somelang'), GridSearchCV gives a segment violation.
If i just train and test the same features, it works fine. The problem is just using GridSearchCV.
This is the tokenizer I set:

import re
import Stemmer
class LemmaTokenizer(object):
def __init__(self, *args, **kwargs):
    self._lang = kwargs.get('lang',None)
    if self._lang is not None:
        self._stemmer = Stemmer.Stemmer(self._lang)
    else:
        self._stemmer = Stemmer.Stemmer('english')

def __call__(self, doc):
    return self.stemDoc(doc)

def stemWord(self, word):
    return self._stemmer.stemWord(word)

def stemDoc(self, doc):
    # [word.strip(string.punctuation) for word in re.split('\W+', doc) if word]
    return [self.stemWord(word)
            for word in re.split('[\s\.!"\\\&()%#@^$\'*+/,-:;<=>?\[\]`{|}~_]+',
                                 doc, flags=re.UNICODE) if word]
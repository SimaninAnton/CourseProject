Contributor
hannawallach commented on Feb 19, 2015
Hi,
I found a small bug in the _update_feature_log_prob() method of the BernoulliNB class (https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/naive_bayes.py). Line 706 currently reads
smoothed_cc = self.class_count_ + self.alpha * n_classes
but should instead read
smoothed_cc = self.class_count_ + self.alpha * 2 
To see why this is the case, check out line 8 in the TrainBernoulli() method on this page: http://nlp.stanford.edu/IR-book/html/htmledition/the-bernoulli-model-1.html (Basically, because features take on the value of 0/1 (presence/absence), the class-conditional probability of the presence/absence of a feature must sum to one over 0/1. Since the numerator is (# data points in class c containing feature + alpha) for 1 and (# data points in class c not containing feature + alpha) for 0, the denominator must contain alpha * 2. Happy to explain more, if that would be useful.)
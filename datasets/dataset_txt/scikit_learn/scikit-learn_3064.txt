ericmjl commented on Apr 8, 2016
Hi guys,
I recently ran into this interesting observation.
If I do:
from sklearn.preprocessing import MultiLabelBinarizer
import numpy as np

labels = np.array([('Doom', 'Metal'), ('hey', 'world')])
labels

terms_list = np.array([['Doom'], ['Metal'], ['hey'], ['world']])
terms = np.array(['Doom', 'Metal', 'hey', 'world'])

mlb = MultiLabelBinarizer()
mlb.fit(terms_list)
mlb.transform(labels)
Then I get the binarization done as expected.
    array([[1, 1, 0, 0],
       [0, 0, 1, 1]])
However, I found it more intuitive to do:
> mlb.fit(terms)
> mlb.transform(labels)
In which the output is:
> mlb.classes_
array(['D', 'M', 'a', 'd', 'e', 'h', 'l', 'm', 'o', 'r', 't', 'w', 'y'], dtype=object)
Is there a reason why the API was designed to use iterable of iterables, rather than a single iterable? No biggie, just curious about this design choice.
tobigue commented on Sep 5, 2012
When performing a cross_validation on a classifier trained with the best parameters found by a GridSearchCV the results differ, despite using the same random seed, folds and evaluation metric. So maybe one of them is not working correctly?!
Code to reproduce this issue can be found here: https://gist.github.com/3188762
GRID SEARCH:
Best f1_score: 0.556
Best parameters set:
    alpha: 0.0001
    loss: 'log'
    penalty: 'l1'
    seed: 0

CROSS VALIDATION:
Best f1_score: 0.521 (+/- 0.05)
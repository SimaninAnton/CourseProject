balancap commented on 9 Dec 2016
I noticed a small difference between the architecture described in https://arxiv.org/pdf/1610.02357v2.pdf and the Keras implementation. In the latter, the output of the Entry Flow has dimension 19x19x728 instead of 18x18x728.
One can easily observe it on the summary of the Xception model:
from keras.applications import xception
model = xception.Xception(include_top=True, weights='imagenet', input_tensor=None)
print(model.summary())
which gives for the output of the entry flow:
merge_15 (Merge)                 (None, 19, 19, 728)   0           block4_pool[0][0]            batchnormalization_7[0][0]  
The accuracy on ImageNet with the pre-trained weights is then a bit lower than the results obtained in the paper.
I tensorflow/core/kernels/logging_ops.cc:79] eval/Recall@5[0.94097668]
I tensorflow/core/kernels/logging_ops.cc:79] eval/Accuracy[0.77963156]
I guess we could obtained the optimal results by either fine-tuning with this model, and fixing some padding in the first layers?
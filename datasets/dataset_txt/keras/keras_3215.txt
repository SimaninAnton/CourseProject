yangqinj commented on 14 Feb 2017
I want to ask a really basic problem. In the code model.add(Embedding(max_features, 128, input_length=maxlen)), I know 128 represents the dimension of each word embedding, input_length means each document has maxlen words (or the first layer has maxlen units), but what's the max_features mean? there are max_features hidden units in LSTM? Thanks.
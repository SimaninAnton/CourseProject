Contributor
anayebi commented on 4 May 2016 â€¢
edited
I have an input sequence (because it is variable length, used the Keras pad_sequences function to zero pad it), and I wanted to basically average the outputs of my RNN and concatenate it with its prediction at the last timestep, which would then be the model's prediction.
Here is my code to better visualize what I mean (I'm using the Keras 1.0 Model class):
input_sentences = Input(shape=(max_sen_length,), dtype='int32')
x = Embedding(input_dim=vocab_size, output_dim=vocab_dim, input_length=max_sen_length, mask_zero=True)(input_sentences)
lstm_out = LSTM(150, return_sequences=True)(x)
attention = TimeDistributedDense(32, activation='softmax')(lstm_out)
context = Lambda(avg_timesteps, output_shape=avg_timesteps_output_shape)(attention)
last_lstm_out = Lambda(last_timestep, output_shape=last_timestep_output_shape)(lstm_out)
concat = Merge([last_lstm_out, context], mode='concat')
Note that avg_timesteps and last_timestep were custom functions I wrote to work with the Lambda layers (I won't include them here for brevity).
The issue I am running into is that Lambda layers do not support masking, so I was not able to get the above code to work. Is there a way to essentially implement my context layer (which is the average of the outputs of the TimeDistributedDense layer)?
I am aware of the various Keras threads about implementing neural attention, but this is a relatively simple version of that (since my model's overall prediction is based on the last timestep, so I'm just averaging the predictions up to then and concatenating them with the RNN's last output, last_lstm_out), based on Section 3.1 of this paper. I figure this is probably doable, so I'd be happy to hear anyone's thoughts on this. Thanks!
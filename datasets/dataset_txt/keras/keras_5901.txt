AriChow commented on 22 Feb 2016
Hi,
First of all, I would like to commend you on building a great toolbox for deep learning.
I am using the Image data generator in my code as follows:
datagen = ImageDataGenerator(
featurewise_center=True, # set input mean to 0 over the dataset
samplewise_center=True, # set each sample mean to 0
featurewise_std_normalization=True, # divide inputs by std of the dataset
samplewise_std_normalization=True, # divide each input by its std
zca_whitening=False, # apply ZCA whitening
rotation_range=20, # randomly rotate images in the range (degrees, 0 to 180)
width_shift_range=0.2, # randomly shift images horizontally (fraction of total width)
height_shift_range=0.2, # randomly shift images vertically (fraction of total height)
horizontal_flip=True, # randomly flip images
vertical_flip=False) # randomly flip images
X_sample,_=load_data(batch_size=300,names_file=image_files,labels_file=image_labels,stain_number=stain_no)
datagen.fit(X_sample)
After training the model using image augmentation, I would like to extract the hidden representations of the model on the training and testing data.
However, I understand that I would have to do the transformations included in the data generator like feature wise_centre and sample wise_center.
Is there a way to access the parameters of the data generator to transform the images or would I have to do them manually?
Thanks again,
Aritra
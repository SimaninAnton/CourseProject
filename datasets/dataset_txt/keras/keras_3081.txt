silentsnooc commented on 3 Mar 2017 â€¢
edited
I am evaluating my model after each epoch end but for some reason I am getting always the exact same predictions even though the training error is going down over time. The predictions do not change at all.
This is the EvaluationCallback I wrote:
class EvaluationCallback(Callback):

def __init__(self, batches, nb_batches, y_labels, target_max_values):
    super().__init__()
    self.target_max_values = target_max_values
    self.batches = batches
    self.nb_batches = nb_batches
    self.y_labels = y_labels

def on_epoch_end(self, epoch, logs=None):

    print('\nEvaluation ..')
    avg_mse = 0.0
    sample_count = 0.0

    for sample_idx in range(self.nb_batches):

        x, y = next(self.batches)
        y_pred = self.model.predict(x)

        y_pred = denormalize(y_pred,
                             min_values=np.zeros(len(self.target_max_values)),
                             max_values=self.target_max_values)

        for i in range(len(y)):
            mse = 1./len(y[i]) * (y[i] - y_pred[i])**2.
            avg_mse += mse
            sample_count += 1.

    avg_mse = avg_mse / sample_count

    print('  MSE per parameter on denormalized target:')
    for lbl, mse in zip(self.y_labels, avg_mse):
        print('    {:.4f} for {:s}'.format(mse, lbl))
Any idea why I always see the same values? (one can answer also on stackoverflow)
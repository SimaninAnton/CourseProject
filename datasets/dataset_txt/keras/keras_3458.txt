YazhiGao commented on 16 Jan 2017
attention mechanism , here the implementation in the MemN2N seem to mean the merge sum mode is a weighted sum of the weight and memory output vector to form a response. Why is it not a dot mode here or as other attention implementation use a multiplication then a timedistributedmerge ?
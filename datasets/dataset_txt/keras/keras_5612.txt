fluency03 commented on 31 Mar 2016
In this example lstm_text_generation.py, the following code:
preds = model.predict(x, verbose=0)[0]
gives a list of probabilities with length of len(chars), where the most probable next char is having the highest probability among them.
Question 1: what will this model.predict(x, verbose=0) return, without the [0] behind?
The above case is one-to-one mapping, where we use Dense(), i.e., the output (or each of y_train) is just one next char. However, when we change Dense() to TimeDistributedDense(), the output will be the next sequence, i.e., the each of y_train is sentence. In this case, the mapping is many-to-many.
Question 2: in this case, what will preds = model.predict(x, verbose=0)[0] or preds = model.predict(x, verbose=0) return?
Is that still the probability distribution of only the next single char among all char classes, or it will be the probability distribution of every char among all char classes in the output sentence?
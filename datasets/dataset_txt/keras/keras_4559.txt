MAGPC commented on 19 Aug 2016
I have been working using the functional API to design a convolutional neural network which is perfectly working with a normal ReLU activation.
Nevertheless, whenever I define an advanced activation layer it outputs the following error
layer = Act()(layer)
TypeError: call() takes at least 2 arguments (1 given)
The layer is defined as:
Act = advanced_activations.PReLU(init='zero', weights=None)
and just added as a layer after each convolution layer which I chose to have such an activation, for example
layer = convolutional.Convolution2D(32,3,3,init='glorot_normal')(layer)
layer = Act()(layer)
Is there some solution I can implement?
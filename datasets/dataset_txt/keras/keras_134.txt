AyaLahlou commented on 8 Jul 2019
I'm working with a dataset of different array shapes (e.i 499902x16, 328942x16, 289301x16)
I'm training it on the following model :
`
model.add(LSTM((64),input_shape=(None,16),return_sequences=True))
model.add(LSTM((64),return_sequences=False))
    model.add(Dense(64))
    model.add(Activation('relu'))
    model.add(Dropout(0.5))
    model.add(Dense(1))
    model.add(Activation('sigmoid'))

    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
    model=build_model()
    model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, shuffle=False)`
But I get the following error:
Error when checking input: expected lstm_1_input to have 3 dimensions, but got array with shape (321, 1)
The shape of my training data is supposed to be (321, None, 16) but when I display it I get X_train.shape is (321, )
Also, I can't zero pad the sequences as I used one hot encoding to generate the arrays.
What can I do in this case?
Thank you!
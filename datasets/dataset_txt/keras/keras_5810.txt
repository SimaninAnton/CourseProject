Imorton-zd commented on 7 Mar 2016
def train_single_model(train,unlabel,test,train_label,test_label):

    # input shape: (nb_samples, 32)
    encoder = containers.Sequential([Dense(16, input_dim=32), Dense(8)])
    decoder = containers.Sequential([Dense(16, input_dim=8), Dense(32)])

    autoencoder = AutoEncoder(encoder=encoder, decoder=decoder, output_reconstruction=True)
    model = models.Sequential()
    model.add(autoencoder)

    # training the autoencoder:
    model.compile(optimizer='sgd', loss='mse')
    model.fit(train+unlabel, train+unlabel, nb_epoch=10)

    # predicting compressed representations of inputs:
    autoencoder.output_reconstruction = False  # the model has to be recompiled after modifying this property
    model.compile(optimizer='sgd', loss='mse')
    representations = model.predict(test)

    return representations

data = create_data('electronics','10_00')
rep = train_single_model(data[0],data[1],data[2],data[3],data[4])
print rep[0]


ValueError: dimension mismatch in args to gemm (128,120)x(32,16)->(128,16)
Apply node that caused the error: GpuDot22(GpuFromHost.0, <CudaNdarrayType(float32, matrix)>)
Toposort index: 11
Inputs types: [CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)]
Inputs shapes: [(128, 120), (32, 16)]
Inputs strides: [(120, 1), (16, 1)]
Inputs values: ['not shown', 'not shown']
Outputs clients: [[GpuElemwise{Add}[(0, 0)](GpuDot22.0, GpuDimShuffle{x,0}.0)]]
The main part of my model is above. I have omitted the part of loading data. Would some one give me some suggestions?
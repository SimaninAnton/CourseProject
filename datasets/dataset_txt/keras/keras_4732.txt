Contributor
bojone commented on 22 Jul 2016 â€¢
edited
I want to train a model to identify the keyword of a sentences (assumpt just one keyword in a sentence).
My oringal thought is:
train word vectors using word2vec
train a lstm network using keras. Its input is the matrix (whose row is the word2vec vector of the words of sentence) of sentence, and the target is the word2vec vector of the keyword. Loss is mse or cosine_proximity.
if we want to identify the keyword of a new sentences, just rank the cos of the result and every word vector of sentence's words.
This way need to pretrain word vectors. But I know keras provide a embedding layer. Can we only use keras to realize my goal? In other word, Can we use take the result of embedding layer as target? Because in my way, the target is the result of the embedding layer?
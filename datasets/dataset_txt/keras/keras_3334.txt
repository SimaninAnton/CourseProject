GioJS commented on 30 Jan 2017 â€¢
edited
I'm looking for a way to use Embedding layers that take trees in penn tree notation and give a vector(its distributed representation).
Because in keras the input must be numerical, I use an array of indices as input to select a tree, and this is the Embedding layer implemented:
class EmbeddingDT(Layer):
input_ndim = 2

def __init__(self,dt, trees, limit, input_dim, output_dim,
              input_length=None
             , **kwargs):
    self.input_dim = input_dim
    self.dt = dt
    self.output_dim = output_dim
    self.input_length = input_dim
    self.cache = []
    self.trees = trees
    self.limit = limit

    kwargs['input_shape'] = (self.input_length,)
    kwargs['trainable'] = False
    super(EmbeddingDT, self).__init__(**kwargs)

def build(self, input_shape):

    super(EmbeddingDT, self).build(input_shape)

def get_output_shape_for(self, input_shape):
   return (1,self.output_dim)

def call(self, x, mask=None):

    if K.is_keras_tensor(x):
        return K.zeros((self.output_dim,))

    if x-1 < len(self.cache):
        return self.cache[x-1]

    if len(self.cache) < self.limit:
        self.cache.append(self.dt.dt(self.trees[x]))
        return self.cache[-1]

    return self.dt.dt(self.trees[x])
The call method checks if x is not a scalar because this method is called when the layer is added to the model with a tensor, I'm not sure this is right, in fact if a Dense layer(or other layers) is added to the model gives:
Exception: Input 0 is incompatible with layer dense_1: expected ndim=2, found ndim=1
Maybe this is not the right way, is there a way to do what I want in keras?
chunyangx commented on 2 Nov 2015
Hello,
I am learning to use Graph as it seems more powerful so I implemented one of my previous model which uses Sequential. Here is the model using sequential (number of dimension set in random):
def build_generation_embedding_model(self, dim):
    print "Build model ..."
    input_model = Sequential()
    input_model.add(TimeDistributedDense(dim, input_shape=(10,10)))
    input_model.add(LSTM(dim, return_sequences=False))
    input_model.add(Dense(dim))
    canonical_model = Sequential()
    canonical_model.add(TimeDistributedDense(dim, input_shape=(15,15)))
    canonical_model.add(LSTM(dim, return_sequences=False))
    canonical_model.add(Dense(dim))
    self.model = Sequential()
    self.model.add(Merge([input_model, canonical_model], mode='concat'))
    self.model.add(Dense(15))
    self.model.add(Activation('softmax'))
    self.model.compile(loss='categorical_crossentropy', optimizer='rmsprop')
The model works fine and below is my reimplementation using Graph:
def build_generation_embedding_model_graph(self, dim):
    self.model = Graph()
    self.model.add_input(name='input1', input_shape=(10,10))
    self.model.add_input(name='canonical', input_shape=(15,15))
    self.model.add_node(TimeDistributedDense(dim), name='Embed_input1', input='input1')
    self.model.add_node(TimeDistributedDense(dim), name='Embed_canonical', input='canonical')
    self.model.add_node(LSTM(dim, return_sequences=False), name='Hidden_input1', input='Embed_input1')
    self.model.add_node(LSTM(dim, return_sequences=False), name='Hidden_canonical', input='Embed_canonical')
    self.model.add_node(Dense(15), name='merge', inputs=['Hidden_input1','Hidden_canonical'], merge_mode='concat')
    self.model.add_node(Activation('softmax'), name='activation', input='merge')
    self.model.add_output(name='output', input='merge')
    self.model.compile('rmsprop', {'output':'categorical_crossentropy'})
My impression is that they are exactly the same model (grateful if somebody spotted something wrong there). But the model based on Graph gives a loss of 3.6 while the loss for the other one is around 0.002.
Is there a reason for this please ?
Thank you for your help
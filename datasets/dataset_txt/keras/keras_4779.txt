Yingyingzhang15 commented on 14 Jul 2016
Hi. I want to use two stacked LSTM layers to implement a encoder-decoder as in #1401.
The size of input sequence is (1000,1), where 1000 is the sequence length and 1 is the sequence dim.I hope to reconstruct the same sequence as output.
The code is just like follows:
model = Sequential()
model.add(LSTM(5, input_dim=1, return_sequences=True))
model.add(LSTM(1, return_sequences=True))
model.compile(loss='mean_squared_error', optimizer='Adam')
How does the code calculate the loss?
If the expected output of network is y_true(1000,1), the actual output is y_predict, just calculate the
sum((y_predict(1:1000,1)-y_true(1:1000,1) ).^2)
or the loss is only
(y_predict(1000,1)-y_true(1000,1)).^2
?
Actually, I obtained two different weights with same loss, but the results of
sum((y_predict(1:1000,1)-y_true(1:1000,1) ).^2)
are quite different.
Thank you!
Contributor
sadeghmir commented on 6 Jul 2016 â€¢
edited
I have a line of code like this in my script file:
model.evaluate(testData, testLabels, verbose=1)
and it does not print the metrics, only this output:
5285/5285 [==============================] - 0s
but when the exact same line of code with model.evaluate is run at the python console, I get:
4000/5285 [=====================>........] - ETA: 0s0.0011901330899327374
I understand this is not an issue per se, but it seems better for evaluate to print the evaluation metrics when called (as well as outputting it) at least when default loss is used.
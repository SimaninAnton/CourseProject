Contributor
jstypka commented on 17 Mar 2016
I'm having a problem with this line:
https://github.com/fchollet/keras/blob/master/keras/layers/convolutional.py#L1108
Why do we multiply self.padding by 2? If I want to add one zero at the end, I pass padding=1 in the constructor and the output size then increases by 2. This does not make sense to me at all. If I wanted to increase the size by 2, I would pass 2 in the argument.
Is it just a mistake or there's something that I'm not seeing?
EDIT:
Ok, I figured out that the ZeroPadding1D appends zeros both at the end and the beginning, hence the multiplication. But why is it that way? Shouldn't we predominantly enable padding only at the end or only at the beginning? I have an impression that this would cover much more usecases.
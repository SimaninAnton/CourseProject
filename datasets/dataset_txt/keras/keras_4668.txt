Contributor
titu1994 commented on 1 Aug 2016
I'm attempting to implement Image Restoration Using Convolutional Auto-encoders with Symmetric Skip
Connections in Keras using the new Deconvolution2D layer.
I have a working version of this architecture using the UpSampling2D and Conv2D method to implement Deconvolutions, but due to max pooling and subsequent upsampling, I couldn't create a very deep model.
With the new Deconvolution2D, I can implement this, but it crashes giving an Input dimension mismatch when using Deconv stacks with different number of output filters. An example script is given below. (I know that the authors use skip connections every 2 corresponding layers and that I use skip connection after every layer, but I have tested it with every two layers and the same error occurs.)
Gist : Conv Auto Encoder with Symmetric Skip Connections
System config:
Windows 10
Theano 0.9.devr2
Keras (master branch)
CuDNN 5.1 RC
Crash report:
Using Theano backend.
Using gpu device 0: GeForce GTX 980M (CNMeM is enabled with initial size: 80.0% of memory, cuDNN 5103)
Epoch 1/10
Traceback (most recent call last):
File "D:\Users\Yue\Anaconda3\lib\site-packages\theano\compile\function_module.py", line 866, in call
self.fn() if output_subset is None else
ValueError: GpuElemwise. Input dimension mis-match. Input 3 (indices start at 0) has shape[0] == 64, but the output's size on that axis is 128.
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
File "D:/Users/Yue/PycharmProjects/ImageSuperResolution/conv_auto_encoder.py", line 52, in
model.fit(dataX, dataY, batch_size=batch_size, nb_epoch=10)
File "D:\Users\Yue\Anaconda3\lib\site-packages\keras\engine\training.py", line 1107, in fit
callback_metrics=callback_metrics)
File "D:\Users\Yue\Anaconda3\lib\site-packages\keras\engine\training.py", line 825, in _fit_loop
outs = f(ins_batch)
File "D:\Users\Yue\Anaconda3\lib\site-packages\keras\backend\theano_backend.py", line 643, in call
return self.function(*inputs)
File "D:\Users\Yue\Anaconda3\lib\site-packages\theano\compile\function_module.py", line 879, in call
storage_map=getattr(self.fn, 'storage_map', None))
File "D:\Users\Yue\Anaconda3\lib\site-packages\theano\gof\link.py", line 325, in raise_with_op
reraise(exc_type, exc_value, exc_trace)
File "D:\Users\Yue\Anaconda3\lib\site-packages\six.py", line 685, in reraise
raise value.with_traceback(tb)
File "D:\Users\Yue\Anaconda3\lib\site-packages\theano\compile\function_module.py", line 866, in call
self.fn() if output_subset is None else
ValueError: GpuElemwise. Input dimension mis-match. Input 3 (indices start at 0) has shape[0] == 64, but the output's size on that axis is 128.
Apply node that caused the error: GpuElemwise{Composite{((i0 * i1) + (i2 * i3))}}[(0, 1)](GpuDimShuffle{x,x,x,x}.0, <CudaNdarrayType%28float32, 4D%29>, GpuDimShuffle{x,x,x,x}.0, GpuDnnConvGradW{algo='none', inplace=True}.0)
Toposort index: 364
Inputs types: [CudaNdarrayType(float32, (True, True, True, True)), CudaNdarrayType(float32, 4D), CudaNdarrayType(float32, (True, True, True, True)), CudaNdarrayType(float32, 4D)]
Inputs shapes: [(1, 1, 1, 1), (128, 64, 3, 3), (1, 1, 1, 1), (64, 64, 3, 3)]
Inputs strides: [(0, 0, 0, 0), (576, 9, 3, 1), (0, 0, 0, 0), (576, 9, 3, 1)]
Inputs values: [b'CudaNdarray([[[[ 0.89999998]]]])', 'not shown', b'CudaNdarray([[[[ 0.10000002]]]])', 'not shown']
Outputs clients: [['output', GpuElemwise{Composite{(i0 - ((i1 * i2) / (i3 + sqrt(clip(i4, i5, i6)))))}}[(0, 0)](convolution2d_3_W, GpuDimShuffle{x,x,x,x}.0, GpuElemwise{Composite{%28%28i0 * i1%29 + %28i2 * i3%29%29}}[%280, 1%29].0, CudaNdarrayConstant{[[[[ 9.99999994e-09]]]]}, GpuElemwise{Composite{%28%28i0 * i1%29 + %28i2 * sqr%28i3%29%29%29}}[%280, 1%29].0, CudaNdarrayConstant{[[[[ 0.]]]]}, CudaNdarrayConstant{[[[[ inf]]]]})]]
HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
To remove this error
If n1 = n2 = any number, then crash does not occur. This isn't very useful since accuracy depends on number of filters as well. The previous version used 64, 128 and 256 filters, achieving an accuracy of 37.39 PSNR (Peak Signal to Noise Ratio). This one doesn't go above 36.41 PSNR with n1 = n2 = 64.
1
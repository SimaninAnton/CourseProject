Contributor
TimZaman commented on 15 May 2017 â€¢
edited
Snippet from the Keras MNIST (LeNet) example (source) :
(...)
model.add(Dense(num_classes, activation='softmax'))
model.compile(loss=keras.losses.categorical_crossentropy,
(...)
Implementation of categorical_crossentropy uses tf.nn.softmax_cross_entropy_with_logits() (source):
But the Tensorflow doc on tf.nn.softmax_cross_entropy_with_logits() (source) states:
WARNING: This op expects unscaled logits, since it performs a softmax on logits internally for efficiency. Do not call this op with the output of softmax, as it will produce incorrect results.
Am I missing something or are we violating the above warning due to Dense() calling the softmax activation?
blauigris commented on 3 Feb 2016
I'm new to OSS and english is not my native language, but I think I found a little bug in the docs and since this framework is very useful to me I would like to help a bit to improve it.
The problem I found is that in the official docs section devoted to the AutoEncoder layer, at http://keras.io/layers/core/#autoencoder . There is a small example code which uses output_reconstruction to use the decoder or the encoder as a output.
`from keras.layers import containers
input shape: (nb_samples, 32)
encoder = containers.Sequential([Dense(16, input_dim=32), Dense(8)])
decoder = containers.Sequential([Dense(16, input_dim=8), Dense(32)])
autoencoder = Sequential()
autoencoder.add(AutoEncoder(encoder=encoder, decoder=decoder,
output_reconstruction=True))
training the autoencoder:
autoencoder.compile(optimizer='sgd', loss='mse')
autoencoder.fit(X_train, X_train, nb_epoch=10)
predicting compressed representations of inputs:
autoencoder.output_reconstruction = False # the autoencoder has to be recompiled after modifying this property
autoencoder.compile(optimizer='sgd', loss='mse')
representations = autoencoder.predict(X_test)
the model is still trainable, although it now expects compressed representations as targets:
autoencoder.fit(X_test, representations, nb_epoch=1) # in this case the loss will be 0, so it's useless
to keep training against the original inputs, just switch back output_reconstruction to True:
autoencoder.output_reconstruction = False
autoencoder.compile(optimizer='sgd', loss='mse')
autoencoder.fit(X_train, X_train, nb_epoch=10)`
The problem with this is that output_reconstruction is set on the Sequential, not in the AutoEncoder layer, so the layer never notices that has to change the output. Additionally, the last time is set should be set to True according to "just switch back output_reconstruction to True". The correct code would be according to my opinion:
``from keras.layers import containers
input shape: (nb_samples, 32)
encoder = containers.Sequential([Dense(16, input_dim=32), Dense(8)])
decoder = containers.Sequential([Dense(16, input_dim=8), Dense(32)])
autoencoder = Sequential()
autoencoder.add(AutoEncoder(encoder=encoder, decoder=decoder,
output_reconstruction=True))
training the autoencoder:
autoencoder.compile(optimizer='sgd', loss='mse')
autoencoder.fit(X_train, X_train, nb_epoch=10)
predicting compressed representations of inputs:
autoencoder.layers[0].output_reconstruction = False # the autoencoder has to be recompiled after modifying this property
autoencoder.compile(optimizer='sgd', loss='mse')
representations = autoencoder.predict(X_test)
the model is still trainable, although it now expects compressed representations as targets:
autoencoder.fit(X_test, representations, nb_epoch=1) # in this case the loss will be 0, so it's useless
to keep training against the original inputs, just switch back output_reconstruction to True:
autoencoder.layers[0].output_reconstruction = True
autoencoder.compile(optimizer='sgd', loss='mse')
autoencoder.fit(X_train, X_train, nb_epoch=10)``
Furthermore, I have been trouble also while compiling the network because I found that for some reason the build method of the AutoEncoder layer is never called, but since I'm not sure it is not a bug in my code I'm not posting it here.
Thank you for your time and for your great software!
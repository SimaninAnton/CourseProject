bernardohenz commented on 19 Aug 2016
I am trying to train a neural net by feeding an image and N masks. The masks are the same for all images, thus, I would like to optimize the memory usage. Currently I am doing as follow:
allInputs = []
for i in range( len(masks) ):
   allInputs.append(masks[i])

for i in range(len(allInputs)):
    allInputs[i] = np.tile(allInputs[i],(x_train.shape[0],1,1,1))

allInputs = [x_train]+allInputs
model.fit(allInputs, x_train)
It works perfectly, but it consumes so much memory (due to the fact that I need to tile each mask the same number of samples in x_train. Is there a way to optimize this, i.e., instead of replicating the same mask N times (N is the number of samples in x_train), I have it fixed? It had became a problem when using several masks (>9).
I am starting to think of extending the 'ImageDataGenerator' and create a class to do so, but I'm not really sure about that.
Please make sure that the boxes below are checked before you submit your issue. Thank you!
Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps
If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps
Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
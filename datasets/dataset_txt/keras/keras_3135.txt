mathetes87 commented on 24 Feb 2017 â€¢
edited
Hi, I'm having a problem when trying to finetune a model. If I save the model with some layers "freezed", when trying to load that model again it gives an error that the same number of layers are missing.
For example, when I try to load a model which was saved with all the layers freezed I get this error:
ValueError: You are trying to load a weight file containing 85 layers into a model with 0 layers.
I am freezing my layers using this code:
for layer in model.layers[:x]:
   layer.trainable = False
for layer in model.layers[x:]:
   layer.trainable = True

model.compile(...)
To save the model I'm using the following Callback
checkpoint = ModelCheckpoint(model_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')
I'm using keras 1.2.2 with Tensorflow 1.0 as my backend.
Thanks for the help
avolny commented on 23 Apr 2017 â€¢
edited
Hello, I am confused when it comes to the size of the network saved on the hdd. It takes up 2.4 GB on disk, when I would expect it to take only 810 MB.
When I initialize the model and save it to disk before learning, it really takes up 810 MB but once I train it, it takes up 2.4 GB what are the two additional parameters stored per weight and is it possible to save the model in the basic representation?
I am using Theano backend. Also, this network barely fits into my 6 GB VRAM, I have to use batch size of 48 so that it doesn't overflow. How many variables are there per weight? I am using Adam optimizer, so I would expect 4 variables: the weight/bias, the first momentum, the second momentum, the cumulative gradient. Then a single parameter per neuron for storing the current gradient w.r.t. its inputs but that's only a few. So that still adds up to 4 * 810 = 3240 MB but in reality, it takes 1.3 GB more VRAM. What is the overhead?
Thanks in advance!
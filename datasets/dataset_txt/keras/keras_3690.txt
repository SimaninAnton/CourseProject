Tingbopku commented on 13 Dec 2016 â€¢
edited
I wonder whether I can make an rnn structure showing in the following picture within keras, where each timestep in a sequence has a label.
If yes, what is wrong with the following codes?
# x.shape is (1000,5) double for example.
# y.shape is (1000,1) bool

weight_label = y.mean()
y = np_utils.to_categorical((y>0)+0, 2);
x = x.reshape(1,x.shape[0],x.shape[1])
y = y.reshape(1,y.shape[0],y.shape[1])


model = Sequential()
model.add(LSTM(
 return_sequences = True,
 output_dim=32, 
 input_shape = (x.shape[1], x.shape[2]), 
 activation='sigmoid', 
 inner_activation='hard_sigmoid',
 ))
model.add(TimeDistributed(Dense(32)))
model.add(Activation('sigmoid'))
model.add(TimeDistributed(Dense(2)))
model.add(Activation('softmax'))

model.compile(loss='sparse_categorical_crossentropy',
 optimizer='adam',
 metrics=['accuracy'])

model.fit(x, y, 
 batch_size=16, 
 nb_epoch=10,
 verbose=1,
 class_weight = {0: weight_label, 1: 1}
 )
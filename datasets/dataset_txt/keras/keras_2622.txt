liujxing commented on 18 Apr 2017 â€¢
edited
I am trying out using the HDF5 file as the format of training/testing data, so that I can avoid the problem of big dataset which cannot fit into the memory.
As a test, I used a dataset with about 20 million rows and 10 columns as my input, and my response variable is a real-valued vector. The model is a simple sequential model with 2 hidden layers and 50 neurons per hidden layer, and the training batch size is 10000. I am still using Keras version 1.2.0.
When the dataset is fully loaded into the memory, one epoch of training takes about 30 seconds. However, if I used HDF5 matrix with HDF5Matrix, one epoch of training takes about 360 seconds. Is this huge slow down common due to the I/O bottleneck? Shall I implement some perhaps better data loading process with fit_generator by myself by considering the specifications of my dataset?
3
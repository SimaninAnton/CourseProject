ternaus commented on 9 May 2016
Problem appears when I save model to file, load it later, try to do prediction. Sample script: https://github.com/ternaus/kaggle_statefarm/blob/master/src/keras_bug.py
What script does:
[1] creates a model
[2] makes prediction (And it works)
[3] saves architecture and weights to files
[4] loads model from weights
[5] Tries to make prediction, but it does not work.
Here is output:
python keras_bug.py 
Using Theano backend.
Using gpu device 0: GeForce GTX 980 Ti (CNMeM is disabled, cuDNN 5004)
[[ 0.10087813  0.09831175  0.09730584  0.09975019  0.10368711  0.10139024
   0.09724771  0.10462044  0.09375019  0.1030584 ]]

Traceback (most recent call last):
  File "keras_bug.py", line 111, in <module>
    print model_new.predict(X_train)
  File "/home/vladimir/anaconda2/lib/python2.7/site-packages/keras/models.py", line 460, in predict
    return self.model.predict(x, batch_size=batch_size, verbose=verbose)
  File "/home/vladimir/anaconda2/lib/python2.7/site-packages/keras/engine/training.py", line 1125, in predict
    batch_size=batch_size, verbose=verbose)
  File "/home/vladimir/anaconda2/lib/python2.7/site-packages/keras/engine/training.py", line 845, in _predict_loop
    batch_outs = f(ins_batch)
  File "/home/vladimir/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.py", line 518, in __call__
    return self.function(*inputs)
  File "/home/vladimir/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.py", line 871, in __call__
    storage_map=getattr(self.fn, 'storage_map', None))
  File "/home/vladimir/anaconda2/lib/python2.7/site-packages/theano/gof/link.py", line 314, in raise_with_op
    reraise(exc_type, exc_value, exc_trace)
  File "/home/vladimir/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.py", line 859, in __call__
    outputs = self.fn()
ValueError: dimension mismatch in args to gemm (1,4096)x(1000,10)->(1,10)
Apply node that caused the error: GpuDot22(GpuElemwise{Composite{Switch(i0, (Composite{(i0 + Abs(i0))}((i1 + i2)) * i3), (i4 * Composite{(i0 + Abs(i0))}((i1 + i2))))}}[(0, 1)].0, dense_4_W)
Toposort index: 301
Inputs types: [CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)]
Inputs shapes: [(1, 4096), (1000, 10)]
Inputs strides: [(0, 1), (10, 1)]
Inputs values: ['not shown', 'not shown']
Outputs clients: [[GpuSoftmaxWithBias(GpuDot22.0, dense_4_b)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
Contributor
StefanoD commented on 11 May 2017 â€¢
edited
Looking at the source code, the L1_L2 (also known as elastic net) regularization differs dramatically from description of this paper.
class L1L2(Regularizer):
    """Regularizer for L1 and L2 regularization.

    def __call__(self, x):
        regularization = 0.
        if self.l1:
            regularization += K.sum(self.l1 * K.abs(x))
        if self.l2:
            regularization += K.sum(self.l2 * K.square(x))
        return regularization
Is this done on purpose or do you understand something different on the term L1/L2 regularization?
sun-peach commented on 21 Jan 2017 â€¢
edited
Hi, dear all,
I am trying to merge two bidirectional layers, however, keras pops up errors from the following codes:
E1 = Sequential()
E2 = Sequential()
E1.add(Bidirectional(LSTM(hidden_dim,unroll=unroll,stateful=stateful,return_sequences=True,batch_input_shape=(shape[0],shape[1],I1_dim)),mode='sum'))
E2.add(Bidirectional(LSTM(hidden_dim,unroll=unroll,stateful=stateful,return_sequences=True,batch_input_shape=(shape[0],shape[1],shape[2]-I1_dim)),mode='sum'))
encoder = Merge([E1,E2],mode='concat')
If I remove the bidirectional part, everything is OK, like this:
E1 = Sequential()
E2 = Sequential()
E1.add(LSTM(hidden_dim,unroll=unroll,stateful=stateful,return_sequences=True,batch_input_shape=(shape[0],shape[1],I1_dim)))
E2.add(LSTM(hidden_dim,unroll=unroll,stateful=stateful,return_sequences=True,batch_input_shape=(shape[0],shape[1],shape[2]-I1_dim)))
encoder = Merge([E1,E2],mode='concat')
Could anyone tell me how I can merge two bidirectional layers? Thank you.
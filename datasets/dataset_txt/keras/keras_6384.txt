Contributor
amitbeka commented on 26 Nov 2015
Is it possible to use context window approach with the Embedding layer?
IIUC, the Embidding layer gets a 2-d matrix of (nb_samples, maxlen) so it isn't possible to use a context window shape like (nb_samples, maxlen, cwindow).
However, I would like to have a single embedding layer for all the words in the context window (and not multiple Embedding layers, one for each position in the window). Is it possible somehow with a Graph model?
Thanks, Beka
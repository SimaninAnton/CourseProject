Tokukawa commented on 11 Apr 2016
I am trying to include a different loss function in Keras. I found an implementation in Theano of some of the most important loss functions here.
I have installed as always the module, I call it with
from tmetrics.classification import roc_auc_loss def auc(y_true, y_pred): return roc_auc_loss(y_true,y_pred)
In the definition of the net I call it as
... model.compile(loss=auc,optimizer=sgd) ...
And at the run time Keras returns me
theano.gradient.DisconnectedInputError: grad method was asked to compute the gradient with respect to a variable that is not part of the computational graph of the cost, or is used only by a non-differentiable operator: dense_W Backtrace when the node is created: File "bag_of_networks.py", line 110, in <module> model.add(Dense(n_nodes,input_dim=max_var,W_regularizer=Lterm, init=init)) File "/Users/toku/anaconda2/envs/venv_tmetrics/lib/python2.7/site-packages/keras/layers/core.py", line 1007, in __init__ super(Dense, self).__init__(**kwargs) File "/Users/toku/anaconda2/envs/venv_tmetrics/lib/python2.7/site-packages/keras/layers/core.py", line 60, in __init__ self.set_input_shape((None,) + tuple(kwargs['input_shape'])) File "/Users/toku/anaconda2/envs/venv_tmetrics/lib/python2.7/site-packages/keras/layers/core.py", line 223, in set_input_shape self.build() File "/Users/toku/anaconda2/envs/venv_tmetrics/lib/python2.7/site-packages/keras/layers/core.py", line 1013, in build name='{}_W'.format(self.name)) File "/Users/toku/anaconda2/envs/venv_tmetrics/lib/python2.7/site-packages/keras/initializations.py", line 53, in glorot_normal return normal(shape, s, name=name) File "/Users/toku/anaconda2/envs/venv_tmetrics/lib/python2.7/site-packages/keras/initializations.py", line 36, in normal name=name) File "/Users/toku/anaconda2/envs/venv_tmetrics/lib/python2.7/site-packages/keras/backend/theano_backend.py", line 36, in variable return theano.shared(value=value, name=name, strict=False)
The model it is working perfect with standard loss functions as 'categorical_crossentropy'. The problem seems to me that Keras try to optimize the wrong shared variables
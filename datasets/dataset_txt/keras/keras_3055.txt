YitzhakSp commented on 7 Mar 2017
When using recurrent nets (LSTM etc.) the the training set X_train will have 3 dimensions of size
(numTrainSequences, SequenceLength, InputDim)
and the labels are provided per sequence.
Now looking at the example:
http://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/
When we use the model for the prediction the input X_test has the same amount of dimensions which means, that each sequence will get some label. such an approach might be problematic from two perspectives and certain questions arise
is the inner state inherited from one test sample to the next? if it is not the case, is there a way do make it happen (a certain parameter maybe)
what if we want do have predictions input by input, ? Is there some way that the datavector for prediction can have dimension [nTestSamples, inputDim] ?
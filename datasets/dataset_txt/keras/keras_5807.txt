Contributor
keunwoochoi commented on 7 Mar 2016
I posted a residual block implementation in Keras here: https://github.com/keunwoochoi/residual_block_keras
However it doesn't seem to work properly.
I'm using Max-pooling as pooling size > kernel size sometimes, and current version also have dropouts layers. It didn't seem not working even without dropouts. The loss oscillates, huge gap between training loss and validation loss, etc. What would be the problem? It's quite difficult to spot one.
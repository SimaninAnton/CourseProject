dapurv5 commented on 3 Oct 2016 â€¢
edited
I am trying to implement bilinear tensor layer in keras. If e1 and e2 are two input vectors to the layer, the output would be e1.W.e2.T. I looked at code from Dense and Merge layers in keras to come up with the implementation.
e1: d_1
e2: d_1
W: d*d
My code is as follows
#!/usr/bin/python

import numpy as np
import scipy.stats as stats

from keras import backend as K
from keras.engine.topology import Layer

from keras.models import Sequential
from keras.optimizers import SGD
from keras.layers import Lambda, Merge, Dense

from get_data import Datasets



class NeuralTensorLayer(Layer):
  """Simple Impl of Neural Tensor Layer in keras based on the bilinear tensor product.
  Parameters are shared across all relations
  """
  def __init__(self, layers, input_dim, **kwargs):
    #self.output_dim = output_dim

    # layer parameters
    self.inbound_nodes = []
    self.outbound_nodes = []
    self.constraints = {}
    self.regularizers = []
    self.trainable_weights = []
    #Commenting these out didn't have any effect
    #self.non_trainable_weights = []
    #self.supports_masking = False
    self.uses_learning_phase = False
    self.input_spec = None  # compatible with whatever
    self.name = "NTN"

    #init weights
    self.input_dim = input_dim

    d = self.input_dim
    mean = 0.0
    std = 1.0
    # W : k*d*d
    initial_W_values = stats.truncnorm.rvs(-2 * std, 2 * std, loc=mean, scale=std, size=d * d)
    initial_W_values = np.reshape(initial_W_values, (d, d))

    self.W = K.variable(initial_W_values)
    self.trainable_weights = [self.W]

    node_indices = None
    tensor_indices = None
    self.built = True
    self.add_inbound_node(layers, node_indices, tensor_indices)


  def call(self, inputs, mask=None):
    if type(inputs) is not list or len(inputs) <= 1:
      raise Exception('Merge must be called on a list of tensors '
                      '(at least 2). Got: ' + str(inputs))
    e1 = inputs[0]
    e2 = inputs[1]
    f = K.transpose(K.batch_dot(e1, K.transpose(K.dot(e2, self.W)), axes=1))
    return f

  def get_output_shape_for(self, input_shape):
    #return (input_shape[0], self.output_dim)
    print input_shape
    batch_size = 5
    return (batch_size, 1)


def main():
  #The first layer to a Sequential model must specify the input_shape
  model1 = Sequential()
  model1.add(Lambda(lambda x: x, input_shape=(64,)))
  model2 = Sequential()
  model2.add(Lambda(lambda x: x, input_shape=(64,)))

  model = Sequential()
  model.add(NeuralTensorLayer([model1, model2], input_dim=64))
  model.add(Dense(1))

  sgd = SGD(lr=0.0000001, decay=1e-6, momentum=0.9, nesterov=True)
  model.compile(loss='mean_squared_error', optimizer=sgd)

  ds = Datasets()
  X_train, Y_train, X_test, Y_test = ds.get_data(ds.DIGITS_DATASET)

  model.fit([X_train, X_train], Y_train, nb_epoch=500, batch_size=5, show_accuracy=True)
  #score = model.evaluate([X_test, X_test], Y_test, batch_size=1)
  #print score

main()
The get_data.py used to prepare the input data for a small toy network is
#!/usr/bin/python

"""
One script to get all datasets !
"""
import math
from sklearn.datasets import load_digits

class Datasets:
  #Add new dataset here
  DIGITS_DATASET = 'sklearn_digits_dataset'
  dict = {}

  def get_data(self, dataset_name):
    """Lazy loading of datasets
    """
    #Add new dataset here
    self.dict[self.DIGITS_DATASET] = self.get_sklearn_digits_data
    f = self.dict[dataset_name]
    return f()

  def get_sklearn_digits_data(self):
    digits = load_digits()
    L = int(math.floor(digits.data.shape[0] * 0.15))
    X_train = digits.data[:L]
    y_train = digits.target[:L]
    X_test = digits.data[L + 1:]
    y_test = digits.target[L + 1:]
    return X_train, y_train, X_test, y_test



def main():
  ds = Datasets()
  X_train, y_train, X_test, y_test = ds.get_data(ds.DIGITS_DATASET)
  print X_train.shape

if __name__ == "__main__":
  main()
I get the following error.
/usr/bin/python2.7 /home/dapurv5/MyCode/anahata/src/play/python/keras/neural_tensor_layer.py
Using TensorFlow backend.
[(None, 64), (None, 64)]
/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py:1531: UserWarning: Model inputs must come from a Keras Input layer, they cannot be the output of a previous non-Input layer. Here, a tensor specified as input to "sequential_3_model" was not an Input tensor, it was generated by layer lambda_1.
Note that input tensors are instantiated via tensor = Input(shape).
The tensor that caused the issue was: lambda_input_1:0
str(x.name))
/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py:1531: UserWarning: Model inputs must come from a Keras Input layer, they cannot be the output of a previous non-Input layer. Here, a tensor specified as input to "sequential_3_model" was not an Input tensor, it was generated by layer lambda_2.
Note that input tensors are instantiated via tensor = Input(shape).
The tensor that caused the issue was: lambda_input_2:0
str(x.name))
/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py:1531: UserWarning: Model inputs must come from a Keras Input layer, they cannot be the output of a previous non-Input layer. Here, a tensor specified as input to "sequential_2_model" was not an Input tensor, it was generated by layer lambda_2.
Note that input tensors are instantiated via tensor = Input(shape).
The tensor that caused the issue was: lambda_input_2:0
str(x.name))
/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py:1531: UserWarning: Model inputs must come from a Keras Input layer, they cannot be the output of a previous non-Input layer. Here, a tensor specified as input to "sequential_1_model" was not an Input tensor, it was generated by layer lambda_1.
Note that input tensors are instantiated via tensor = Input(shape).
The tensor that caused the issue was: lambda_input_1:0
str(x.name))
[(None, 64), (None, 64)]
/usr/local/lib/python2.7/dist-packages/keras/models.py:380: UserWarning: The "show_accuracy" argument is deprecated, instead you should pass the "accuracy" metric to the model at compile time:
model.compile(optimizer, loss, metrics=["accuracy"])
warnings.warn('The "show_accuracy" argument is deprecated, '
Epoch 1/500
Traceback (most recent call last):
File "/home/dapurv5/MyCode/anahata/src/play/python/keras/neural_tensor_layer.py", line 93, in
main()
File "/home/dapurv5/MyCode/anahata/src/play/python/keras/neural_tensor_layer.py", line 89, in main
model.fit([X_train, X_train], Y_train, nb_epoch=500, batch_size=5, show_accuracy=True)
File "/usr/local/lib/python2.7/dist-packages/keras/models.py", line 397, in fit
sample_weight=sample_weight)
File "/usr/local/lib/python2.7/dist-packages/keras/engine/training.py", line 1011, in fit
callback_metrics=callback_metrics)
File "/usr/local/lib/python2.7/dist-packages/keras/engine/training.py", line 749, in _fit_loop
outs = f(ins_batch)
File "/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py", line 581, in call
updated = session.run(self.outputs + self.updates, feed_dict=feed_dict)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 717, in run
run_metadata_ptr)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 915, in _run
feed_dict_string, options, run_metadata)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 965, in _do_run
target_list, options, run_metadata)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 985, in _do_call
raise type(e)(node_def, op, message)
tensorflow.python.framework.errors.InvalidArgumentError: Incompatible shapes: [64,1] vs. [5,1]
[[Node: gradients/sub_grad/BroadcastGradientArgs = BroadcastGradientArgs[T=DT_INT32, _device="/job:localhost/replica:0/task:0/cpu:0"](gradients/sub_grad/Shape, gradients/sub_grad/Shape_1)]]
Caused by op u'gradients/sub_grad/BroadcastGradientArgs', defined at:
File "/home/dapurv5/MyCode/anahata/src/play/python/keras/neural_tensor_layer.py", line 93, in
main()
File "/home/dapurv5/MyCode/anahata/src/play/python/keras/neural_tensor_layer.py", line 89, in main
model.fit([X_train, X_train], Y_train, nb_epoch=500, batch_size=5, show_accuracy=True)
File "/usr/local/lib/python2.7/dist-packages/keras/models.py", line 397, in fit
sample_weight=sample_weight)
File "/usr/local/lib/python2.7/dist-packages/keras/engine/training.py", line 958, in fit
self._make_train_function()
File "/usr/local/lib/python2.7/dist-packages/keras/engine/training.py", line 633, in _make_train_function
training_updates = self.optimizer.get_updates(trainable_weights, self.constraints, self.total_loss)
File "/usr/local/lib/python2.7/dist-packages/keras/optimizers.py", line 115, in get_updates
grads = self.get_gradients(loss, params)
File "/usr/local/lib/python2.7/dist-packages/keras/optimizers.py", line 48, in get_gradients
grads = K.gradients(loss, params)
File "/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py", line 606, in gradients
return tf.gradients(loss, variables)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients.py", line 469, in gradients
in_grads = _AsList(grad_fn(op, *out_grads))
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_grad.py", line 566, in _SubGrad
rx, ry = gen_array_ops._broadcast_gradient_args(sx, sy)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_array_ops.py", line 388, in _broadcast_gradient_args
name=name)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py", line 749, in apply_op
op_def=op_def)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py", line 2380, in create_op
original_op=self._default_original_op, op_def=op_def)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py", line 1298, in init
self._traceback = _extract_stack()
...which was originally created as op u'sub', defined at:
File "/home/dapurv5/MyCode/anahata/src/play/python/keras/neural_tensor_layer.py", line 93, in
main()
File "/home/dapurv5/MyCode/anahata/src/play/python/keras/neural_tensor_layer.py", line 84, in main
model.compile(loss='mean_squared_error', optimizer=sgd)
File "/usr/local/lib/python2.7/dist-packages/keras/models.py", line 329, in compile
**kwargs)
File "/usr/local/lib/python2.7/dist-packages/keras/engine/training.py", line 562, in compile
sample_weight, mask)
File "/usr/local/lib/python2.7/dist-packages/keras/engine/training.py", line 289, in weighted
score_array = fn(y_true, y_pred)
File "/usr/local/lib/python2.7/dist-packages/keras/objectives.py", line 7, in mean_squared_error
return K.mean(K.square(y_pred - y_true), axis=-1)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py", line 751, in binary_op_wrapper
return func(x, y, name=name)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.py", line 2368, in sub
result = _op_def_lib.apply_op("Sub", x=x, y=y, name=name)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py", line 749, in apply_op
op_def=op_def)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py", line 2380, in create_op
original_op=self._default_original_op, op_def=op_def)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py", line 1298, in init
self._traceback = _extract_stack()
InvalidArgumentError (see above for traceback): Incompatible shapes: [64,1] vs. [5,1]
[[Node: gradients/sub_grad/BroadcastGradientArgs = BroadcastGradientArgs[T=DT_INT32, _device="/job:localhost/replica:0/task:0/cpu:0"](gradients/sub_grad/Shape, gradients/sub_grad/Shape_1)]]
Process finished with exit code 1
I checked my matrix multiplication dimensions but they seem correct to me. Anything I am missing?
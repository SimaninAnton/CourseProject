valexandersaulys commented on 22 Aug 2015
Has anybody every had this error before?
Traceback (most recent call last):
  File "OneColumn.py", line 67, in <module>
    ze_model = ze_model.fit(train_x,train_y)
  File "/home/vincent/workspace/machine_learning/keras/keras/wrappers/scikit_learn.py", line 126, in fit
    self.compiled_model_.compile(optimizer=self.optimizer, loss=self.loss)
  File "/home/vincent/workspace/machine_learning/keras/keras/models.py", line 391, in compile
    updates = self.optimizer.get_updates(self.params, self.constraints, train_loss)
  File "/home/vincent/workspace/machine_learning/keras/keras/optimizers.py", line 119, in get_updates
    grads = self.get_gradients(loss, params)
  File "/home/vincent/workspace/machine_learning/keras/keras/optimizers.py", line 38, in get_gradients
    grads = T.grad(loss, params)
  File "/home/vincent/workspace/machine_learning/Theano/theano/gradient.py", line 547, in grad
    grad_dict, wrt, cost_name)
  File "/home/vincent/workspace/machine_learning/Theano/theano/gradient.py", line 1288, in _populate_grad_dict
    rval = [access_grad_cache(elem) for elem in wrt]
  File "/home/vincent/workspace/machine_learning/Theano/theano/gradient.py", line 1246, in access_grad_cache
    term = access_term_cache(node)[idx]
  File "/home/vincent/workspace/machine_learning/Theano/theano/gradient.py", line 953, in access_term_cache
    output_grads = [access_grad_cache(var) for var in node.outputs]
  File "/home/vincent/workspace/machine_learning/Theano/theano/gradient.py", line 1246, in access_grad_cache
    term = access_term_cache(node)[idx]
  File "/home/vincent/workspace/machine_learning/Theano/theano/gradient.py", line 1093, in access_term_cache
    input_grads = node.op.grad(inputs, new_output_grads)
  File "/home/vincent/workspace/machine_learning/Theano/theano/tensor/nnet/conv.py", line 850, in grad
    "ERROR: We disable ConvOp.grad now when dx or "
NotImplementedError: ERROR: We disable ConvOp.grad now when dx or dy are different from 1 and 2, as there is a bug i
n it. 
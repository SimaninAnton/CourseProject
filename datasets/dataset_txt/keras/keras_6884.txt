gitowes commented on 7 Jul 2015
I am reading the code of SimpleRNN and LSTM, but I am still not sure how keras trains a network to deal with multiple samples (multiple time series). Someone also called the problem "Multi-Dimensional Recurrent Neural Networks": http://people.idsia.ch/~juergen/icann_2007.pdf
It seems that Kera can handle it since it gives us a 3D tensor where one dimension can be the specific sample. However, when I read the code, it seems that it will reshuffle the tensor, and scan along the time dimension first by Theano. Here is the scan order that I learn from the code:
[timestamp 1, sample 1, features11]
[timestamp 1, sample 2, features12]
[timestamp 2, sample 1, feature21]
[timestamp 2, sample 2, feature22]
...
Here comes the question: how do you guarantee the feedback loop (the hidden layer output) is for the same sample? Will the output of sample1 be used as an input of sample2?
Thanks,
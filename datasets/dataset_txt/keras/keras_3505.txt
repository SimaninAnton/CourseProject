eromoe commented on 11 Jan 2017
Hello!
I found that using sparse matrix would cause ValueError: setting an array element with a sequence
Version:
Keras (1.2.0)
tensorflow (0.12.1)
Input data
X <9516x28934 sparse matrix of type '<type 'numpy.float64'>'
 with 946932 stored elements in Compressed Sparse Row format>

y numpy.ndarray  (9516,)
Code
from keras.models import Sequential
model = Sequential()

from keras.layers import Dense, Activation

model.add(Dense(output_dim=64, input_dim=X.shape[1]))
model.add(Activation("relu"))
model.add(Dense(output_dim=2))
model.add(Activation("softmax"))

from keras.utils.np_utils import to_categorical
# would convert to one-hot
y_binary = to_categorical(y)

model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])
model.fit(X, y_binary, nb_epoch=20, batch_size=32)
Log
Epoch 1/20


ValueErrorTraceback (most recent call last)
<ipython-input-37-894211790f97> in <module>()
     14 
     15 model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])
---> 16 model.fit(X, y_binary, nb_epoch=20, batch_size=32)
     17 
     18 # https://github.com/fchollet/keras/issues/4865

/usr/local/lib/python2.7/dist-packages/keras/models.pyc in fit(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs)
    662                               shuffle=shuffle,
    663                               class_weight=class_weight,
--> 664                               sample_weight=sample_weight)
    665 
    666     def evaluate(self, x, y, batch_size=32, verbose=1,

/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc in fit(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch)
   1141                               val_f=val_f, val_ins=val_ins, shuffle=shuffle,
   1142                               callback_metrics=callback_metrics,
-> 1143                               initial_epoch=initial_epoch)
   1144 
   1145     def evaluate(self, x, y, batch_size=32, verbose=1, sample_weight=None):

/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc in _fit_loop(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)
    841                 batch_logs['size'] = len(batch_ids)
    842                 callbacks.on_batch_begin(batch_index, batch_logs)
--> 843                 outs = f(ins_batch)
    844                 if not isinstance(outs, list):
    845                     outs = [outs]

/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc in __call__(self, inputs)
   1601         session = get_session()
   1602         updated = session.run(self.outputs + [self.updates_op],
-> 1603                               feed_dict=feed_dict)
   1604         return updated[:len(self.outputs)]
   1605 

/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc in run(self, fetches, feed_dict, options, run_metadata)
    764     try:
    765       result = self._run(None, fetches, feed_dict, options_ptr,
--> 766                          run_metadata_ptr)
    767       if run_metadata:
    768         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)

/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc in _run(self, handle, fetches, feed_dict, options, run_metadata)
    935                 ' to a larger type (e.g. int64).')
    936 
--> 937           np_val = np.asarray(subfeed_val, dtype=subfeed_dtype)
    938 
    939           if not subfeed_t.get_shape().is_compatible_with(np_val.shape):

/usr/local/lib/python2.7/dist-packages/numpy/core/numeric.pyc in asarray(a, dtype, order)
    480 
    481     """
--> 482     return array(a, dtype, copy=False, order=order)
    483 
    484 def asanyarray(a, dtype=None, order=None):

ValueError: setting an array element with a sequence.
Though convert sparse matrix to np array can walk through, I think it would be better to support it.
grantwwoodford commented on 1 Jun 2018
I have been running code for doing predictions with uncertainty for a number of models and have noticed an issue of my memory usage just continually going up for no obvious reason.
Basically I am performing a large number of predictions with the dropout layers enabled. I am using tensorflow as a backend. This method is described in #9412
I have created a minimal version of this problem:
https://gist.github.com/eyesonlyhack/e676a0e2230a5a09d31aa3401a59d009
You can probably call K.clear_session to free up this memory but then you would have to rebuild/reload the model after every clear which seems wasteful.
For interest sake, I switched to mxnet for my Keras backend and the problem is goes away.
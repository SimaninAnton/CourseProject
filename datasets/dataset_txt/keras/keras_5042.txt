tuming1990 commented on 2 Jun 2016 â€¢
edited
I want to keep some weights fixed during training the neural network, which means not updating these weights since they are initialized.
''Some weights'' means some values in weight matrices, not specific rows or columns or weight matrix of a specific layer. They can be any element in weight matrices.
Is there a way to do this in Keras? I know Caffe can do this by setting a mask to the weight matrix so the masked weight will not affect the output.
8
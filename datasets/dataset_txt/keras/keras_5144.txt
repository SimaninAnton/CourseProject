phdowling commented on 19 May 2016
Should be a fairly simple question:
I am training a sequence to sequence model, and I would like to have accuracy reported during training. Note that this score should measure exact accuracy, i.e. all output symbols need to be correct for one input sequence in order for the prediction to be correct. In other words, the metric should measure zero-one loss over all outputs together, rather than per individual output.
For instance:
target: bcdefgh, output: bcdefha -> score 0
target: abcdefg, output: abcdefg -> score 1

overall accuracy: 50%
Most letters are correct, but the prediction only counts if all of them are.
Currently, my last layers are:
model.add(LSTM(self.decoder_hidden_units, return_sequences=True))
model.add(Dropout(0.3))
model.add(TimeDistributed(Dense(self.num_inputs, activation="softmax")))
and I compile using
self.model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=self.lr), metrics=["accuracy"])
Is this correct, or will this report per-symbol accuracy? If so, how can I best implement the custom metric?
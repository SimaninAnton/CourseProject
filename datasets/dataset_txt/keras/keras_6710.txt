lan2720 commented on 28 Aug 2015
I run the example cifar10_cnn.py and then find something strange.
When I use data_augmentation with "width_shift_range" and "height_shift_range" = 0.2, time of one epoch is around 290s, but when "width_shift_range" and "height_shift_range" = 0.0, time of one epoch is around 160s.(GPU=NVIDIA GTX 970)
This transformation didn't change the size of input or shape of image, why it slowed down the training process?
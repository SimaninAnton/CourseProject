Contributor
cocuh commented on 21 Jun 2017 â€¢
edited
Tensorflow variables which is not used in model are initialized when model.save() is called.
def unexpected_initialization():
    sess = tf.Session()
    K.set_session(sess)

    var_global_step = tf.Variable(0, trainable=False)

    x = L.Input((8,))
    y = L.Dense(2)(x)
    model = Model(x, y)

    sess.run(tf.global_variables_initializer())

    step_initial = sess.run(var_global_step)
    print(' initial step: {}'.format(step_initial)) # -> outputs 0

    sess.run(var_global_step.assign(16))

    step_assigned = sess.run(var_global_step)
    print('assigned step: {}'.format(step_assigned)) # -> outputs 16 

    model.save('model.h5')

    step_saved = sess.run(var_global_step)
    print('   saved step: {}'.format(step_saved)) # -> outputs 0 !!!!!! expected 16
If the model have no layers, this unexpected initialization is not occurred. (See my gist)
I sought cause of this bug, but I didn't find it....
Note: This keras and tensorflow combination technique is introduced in official keras blog. So I think this code is not tricky, and keras should fix this bug.
wmylxmj commented on 19 May 2019
I trained a model(conv1d neural network), and use function 'model. save_weights ()' to save my weights. But when I re-import weights using function 'model. load_weights()'，losses suddenly increase on the same data set (much better than random initialization, but much worse than the training just done). That seems to be adding some random noise to the trained weights. And the sudden increase of the loss value will rapidly decline.
The same problem has been encountered in training LSTM before.
It looks strange，and it will affect my performance on the test set. what should I do to solve the problem?
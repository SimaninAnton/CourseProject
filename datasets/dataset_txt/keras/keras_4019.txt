mthmn20 commented on 2 Nov 2016
Theano recently introduced cuDNN5 support for recurrent networks and I decided to give it a spin with a Keras LSTM network. However, I noticed only a marginal benefit that seems more likely noise than anything else. Any reason I shouldn't be seeing bigger performance improvements?
cuDNN 4, theano 0.8.2, keras 1.1.0
Train on 3000000 samples, validate on 857222 samples
Epoch 1/100
3000000/3000000 [==============================] - 781s - loss: 2.2539 - acc: 0.6299 - val_loss: 1.6206 - val_acc: 0.7274
cuDNN 5, theano 0.9.0, keras 1.1.0
Train on 3000000 samples, validate on 857222 samples
Epoch 1/100
3000000/3000000 [==============================] - 765s - loss: 2.2588 - acc: 0.6289 - val_loss: 1.6214 - val_acc: 0.7274
cuDNN 5, theano 0.9.0, keras 1.1.1
Train on 3000000 samples, validate on 857222 samples
Epoch 1/100
3000000/3000000 [==============================] - 761s - loss: 2.2578 - acc: 0.6292 - val_loss: 1.6234 - val_acc: 0.7271
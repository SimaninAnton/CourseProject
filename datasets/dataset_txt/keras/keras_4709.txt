vanjoe commented on 26 Jul 2016
I'm training a net with 2 LSTM layers followed by a dense layer.
I've run into a problem that that loss tends to jump suddenly, and never recovers. I can't figure out why, my first though is that there is some sort of overflow in the weights that is causing this.
The model that I'm training is
{
    "class_name": "Sequential",
    "config": [
        {
            "class_name": "Masking",
            "config": {
                "batch_input_shape": [
                    2048,
                    400,
                    7
                ],
                "input_dtype": "float32",
                "mask_value": 0.0,
                "name": "masking_1",
                "trainable": true
            }
        },
        {
            "class_name": "LSTM",
            "config": {
                "U_regularizer": {
                    "l1": 0.0,
                    "l2": 0.009999999776482582,
                    "name": "WeightRegularizer"
                },
                "W_regularizer": {
                    "l1": 0.0,
                    "l2": 0.009999999776482582,
                    "name": "WeightRegularizer"
                },
                "activation": "tanh",
                "b_regularizer": {
                    "l1": 0.0,
                    "l2": 0.009999999776482582,
                    "name": "WeightRegularizer"
                },
                "batch_input_shape": [
                    2048,
                    400,
                    7
                ],
                "consume_less": "cpu",
                "dropout_U": 0.2,
                "dropout_W": 0.2,
                "forget_bias_init": "one",
                "go_backwards": false,
                "init": "glorot_uniform",
                "inner_activation": "hard_sigmoid",
                "inner_init": "orthogonal",
                "name": "lstm_1",
                "output_dim": 20,
                "return_sequences": true,
                "stateful": true,
                "trainable": true,
                "unroll": false
            }
        },
        {
            "class_name": "LSTM",
            "config": {
                "U_regularizer": {
                    "l1": 0.0,
                    "l2": 0.009999999776482582,
                    "name": "WeightRegularizer"
                },
                "W_regularizer": {
                    "l1": 0.0,
                    "l2": 0.009999999776482582,
                    "name": "WeightRegularizer"
                },
                "activation": "tanh",
                "b_regularizer": {
                    "l1": 0.0,
                    "l2": 0.009999999776482582,
                    "name": "WeightRegularizer"
                },
                "batch_input_shape": [
                    2048,
                    400,
                    20
                ],
                "consume_less": "cpu",
                "dropout_U": 0.2,
                "dropout_W": 0.2,
                "forget_bias_init": "one",
                "go_backwards": false,
                "init": "glorot_uniform",
                "inner_activation": "hard_sigmoid",
                "inner_init": "orthogonal",
                "name": "lstm_2",
                "output_dim": 20,
                "return_sequences": false,
                "stateful": true,
                "trainable": true,
                "unroll": false
            }
        },
        {
            "class_name": "Dense",
            "config": {
                "W_constraint": null,
                "W_regularizer": null,
                "activation": "sigmoid",
                "activity_regularizer": null,
                "b_constraint": null,
                "b_regularizer": null,
                "batch_input_shape": [
                    null,
                    20
                ],
                "bias": true,
                "init": "glorot_uniform",
                "input_dim": 20,
                "input_dtype": "float32",
                "name": "dense_1",
                "output_dim": 1,
                "trainable": true
            }
        }
    ]
}
The phenomenon that I am trying to understand is
Epoch 928/2048
83968/86016 [============================>.] - ETA: 1s - loss: 0.3499 - acc: 0.8518Epoch 00927: val_loss did not improve
86016/86016 [==============================] - 73s - loss: 0.3499 - acc: 0.8518 - val_loss: 0.2777 - val_acc: 0.8893
Epoch 929/2048
83968/86016 [============================>.] - ETA: 1s - loss: 0.3543 - acc: 0.8485Epoch 00928: val_loss did not improve
86016/86016 [==============================] - 73s - loss: 0.3547 - acc: 0.8484 - val_loss: 0.2791 - val_acc: 0.8892
Epoch 930/2048
83968/86016 [============================>.] - ETA: 1s - loss: 0.3533 - acc: 0.8493Epoch 00929: val_loss did not improve
86016/86016 [==============================] - 73s - loss: 0.3539 - acc: 0.8488 - val_loss: 0.2781 - val_acc: 0.8900
Epoch 931/2048
83968/86016 [============================>.] - ETA: 1s - loss: 0.3558 - acc: 0.8490Epoch 00930: val_loss did not improve
86016/86016 [==============================] - 73s - loss: 0.3552 - acc: 0.8491 - val_loss: 0.2808 - val_acc: 0.8891
Epoch 932/2048
83968/86016 [============================>.] - ETA: 1s - loss: 0.3528 - acc: 0.8495Epoch 00931: val_loss did not improve
86016/86016 [==============================] - 73s - loss: 0.3531 - acc: 0.8494 - val_loss: 0.2795 - val_acc: 0.8895
Epoch 933/2048
83968/86016 [============================>.] - ETA: 1s - loss: 0.3543 - acc: 0.8488Epoch 00932: val_loss did not improve
86016/86016 [==============================] - 73s - loss: 0.3548 - acc: 0.8485 - val_loss: 0.2789 - val_acc: 0.8898
Epoch 934/2048
83968/86016 [============================>.] - ETA: 1s - loss: 0.3650 - acc: 0.8427Epoch 00933: val_loss did not improve
86016/86016 [==============================] - 73s - loss: 0.3664 - acc: 0.8418 - val_loss: 0.3192 - val_acc: 0.8689
Epoch 935/2048
83968/86016 [============================>.] - ETA: 1s - loss: 0.4382 - acc: 0.8015Epoch 00934: val_loss did not improve
86016/86016 [==============================] - 73s - loss: 0.4377 - acc: 0.8019 - val_loss: 0.3374 - val_acc: 0.8586
Epoch 936/2048
83968/86016 [============================>.] - ETA: 1s - loss: 0.4256 - acc: 0.8085Epoch 00935: val_loss did not improve
86016/86016 [==============================] - 73s - loss: 0.4252 - acc: 0.8086 - val_loss: 0.3351 - val_acc: 0.8608
Epoch 937/2048
83968/86016 [============================>.] - ETA: 1s - loss: 0.4191 - acc: 0.8131Epoch 00936: val_loss did not improve
86016/86016 [==============================] - 73s - loss: 0.4194 - acc: 0.8128 - val_loss: 0.3326 - val_acc: 0.8616
Notice how loss jumps from 27 to 31 all of a sudden?
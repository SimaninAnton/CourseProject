AidaSamri commented on 19 Feb 2017
Hi,
I'm using keras to train a deep convnet for a regression problem.
the thing is that the loss decreases during an epoch but at the begining of a new epoch the loss is increased:

there is a similar issue mentioned here by hadi-ds but not answered.
I'm using a data generator to get data, the data is produced in a loop and isn't exactly the same for each epoch. I'm also using a custom loss function.
I can't think of anything to explain this behavior, any ideas?
Thanks
1
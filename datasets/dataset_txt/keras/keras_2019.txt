rueberger commented on 1 Jul 2017
Currently, conv1D causal padding 0 pads. This can be undesirable, for instance when training Wavenet like architectures that have massive receptive fields - where when training on mini-batches 0 padding massively biases training.
How challenging would it be to fix this?
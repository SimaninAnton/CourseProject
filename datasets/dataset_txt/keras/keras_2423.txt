veqtor commented on 10 May 2017
For a lot of data, in particular temporal data, you sometimes lack valid data for certain training steps, not just input data but valid activation outputs, were there an auxiliary variable that could be fed when training, one could train on historic data that didn't have valid outputs for certain channels and without inputs respectively.
Furthermore, one could pad I/O arrays and add new input/output channels as well as use masking via weights to perform a naive form of transfer learning.
They way I'd like to see this implemented would be to provide samples with dimensions matching the input/output exactly, between 0 and 1, just like sample_weights but more granular.
Inputs-weights at 0 would essentially lock weights related to that input when reducing loss for samples.
I can see how this would make the loss reduction function a lot slower, perhaps it can be solved by only allowing for binary 0 and 1 and not weights such as 0.5, to reduce the number of matrix mults.
Could this be possible to implement?
Please make sure that the boxes below are checked before you submit your issue. If your issue is an implementation question, please ask your question on StackOverflow or join the Keras Slack channel and ask there instead of filing a GitHub issue.
Thank you!
Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps
If running on TensorFlow, check that you are up-to-date with the latest version. The installation instructions can be found here.
If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps
lxmeng commented on 16 Feb 2016
hi, guys:
why Merge layer doesn't exist 'similarity matrx' merge-mode? i implement a simiarity matrix layer, but i suspect its effectiveness? is my implementation right?
`class SimilarityMatrix(Layer):
def __init__(self, dim1, dim2, layers, init='uniform',
             W_regularizer=None, activity_regularizer=None,
             W_constraint=None, **kwargs):

    assert len(layers) == 2
    self.layers = layers
    self.dim1 = dim1
    self.dim2 = dim2

    self.init = initializations.get(init)
    self.W_constraint = constraints.get(W_constraint)
    self.W_regularizer = regularizers.get(W_regularizer)
    self.activity_regularizer = regularizers.get(activity_regularizer)

    self.params = []
    self.regularizers = []
    self.constraints = []
    self.updates = []
    for l in self.layers:
        params, regs, consts, updates = l.get_params()
        self.regularizers += regs
        self.updates += updates
        # params and constraints have the same size
        for p, c in zip(params, consts):
            if p not in self.params:
                self.params.append(p)
                self.constraints.append(c)

    self.W = self.init((self.dim1, self.dim2))
    self.params.append(self.W)

    if self.W_regularizer:
        self.W_regularizer.set_param(self.W)
        self.regularizers.append(self.W_regularizer)

    if self.activity_regularizer:
        self.activity_regularizer.set_layer(self)
        self.regularizers.append(self.activity_regularizer)

    super(SimilarityMatrix, self).__init__(**kwargs)

@property
def output_shape(self):
    return [self.layers[0].output_shape[0], 1]

def get_params(self):
    return self.params, self.regularizers, self.constraints, self.updates

def get_input(self, train=False):
    res = []
    for i in range(len(self.layers)):
        o = self.layers[i].get_input(train)
        if not type(o) == list:
            o = [o]
        for output in o:
            if output not in res:
                res.append(output)
    return res

def get_output(self, train):

    s1 = self.layers[0].get_output(train)
    s2 = self.layers[1].get_output(train)

    sim = T.sum(T.dot(s1, self.W)*s2, axis=1)

    return sim.dimshuffle(0,'x')

@property
def input(self):
    return self.get_input()

def supports_masked_input(self):
    return False

def get_output_mask(self, train=None):
    return None

def get_weights(self):
    weights = []
    for l in self.layers:
        weights += l.get_weights()
    return weights

def set_weights(self, weights):
    for i in range(len(self.layers)):
        nb_param = len(self.layers[i].params)
        self.layers[i].set_weights(weights[:nb_param])
        weights = weights[nb_param:]`
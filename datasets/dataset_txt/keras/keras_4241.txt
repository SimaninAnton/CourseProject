yaochengji commented on 4 Oct 2016 â€¢
edited
Hi,
I want to replace softmax with n sigmoid activations.
I wrote the code below:
ipt = Input(shape=(30000,))
dropout1 = Dropout(0.2)(ipt)
layer1 = Dense(3000, activation='tanh')
outputs = [Dense(1, activation = 'sigmoid')(layer1) for x in range(3000)]
models = []
for i in range(3000):
    models.append(Model(input=ipt,` output=outputs[i]))
for i in range(3000):
    models[i].compile(optimizer='adam', loss='binary_crossentropy', metrics=["accuracy"])
for i in range(3000):
    models[i].fit(x_data, y_data)
Howerver, after training the first 5 models, my code crash down because of
MemoryError: ('Error allocating 360000000 bytes of device memory (CNMEM_STATUS_OUT_OF_MEMORY).', "you might consider using 'theano.shared(..., borrow=True)'")
It seems that each model had a copy of layer1
Can any one tell me how to make the models truly share layer1 and they will update the weights of layer1 in the same addr when training.
Best
Chengji
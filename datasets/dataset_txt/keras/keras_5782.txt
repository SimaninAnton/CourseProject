liyi193328 commented on 10 Mar 2016
In https://github.com/fchollet/keras/blob/master/examples/imdb_bidirectional_lstm.py 's bidirectional_RNN, it achieve to concate two represtion vectors(using LSTM) to classify.
But the most import thing is :
the two vector in same index(order) is two different representions of one word, they should merge together to do something wonderful ,like the picture below:

How to achieve these models? need to custom bidirectional_RNN ?
1
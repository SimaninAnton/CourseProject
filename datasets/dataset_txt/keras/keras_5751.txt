Contributor
jlherren commented on 15 Mar 2016
Hello!
This is not an issue, but a fundamental question about how this library works.
When I started with machine learning, I was using matlab and quickly learned to always vectorize my code (for performance reasons, obviously). That means for example, when calculating the inputs to a first hidden layer, instead of calculating W * i (where W is a weight matrix and i is a single training item as a vector), I should be using W * I (where I is a matrix of all training items). Thus the entire training set gets computed in parallel, making efficient use of some BLAS implementation.
Yet I see none of this happening in 'keras'; training items seem to be running sequentially. Or am I grossly misreading the code? (And neither does 'blocks', as far as I can tell). So my question is: Is this not recommended for GPU code generation, or can keras just not do that for me at the moment?
I'm currently using manually constructed theano graphs that run all items in parallel as described above. Experimentation is very cumbersome, therefore I'd like to switch to keras if possible. However I worry about a significant loss in performance.
Thanks for any insights!
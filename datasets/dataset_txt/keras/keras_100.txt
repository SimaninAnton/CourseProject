kaankoken commented on 29 Jul 2019
Hi everyone. Right now, I am facing a weird problem. The problem occurs when I uncomment two or three lines of code, run the model(works perfectly fine). Then, turn back to the previous model, but now I cannot run the model.
The old model:
class Model:

def set_the_model(self, look_back):
    self.model = Sequential()
    self.model.add(LSTM(16, activation="relu", input_shape=(look_back, 3),return_sequences=True)) #, stateful=True
    self.model.add(Dropout(0.2))
    self.model.add(LSTM(32, activation="relu", return_sequences=True))
    self.model.add(Dropout(0.2))
    self.model.add(TimeDistributed(Dense(look_back)))
    #self.model.add(Dense(3))
    self.model.compile(loss="mse", optimizer="nadam", metrics=['acc']) #mse
    self.model.summary()

def start_train(self, trainD1, trainD2):
    es = EarlyStopping(monitor='loss', patience = 2, mode='min')
    #for i, j in trainD1, trainD2:
    self.model.fit(trainD1, trainD2, epochs = 200, batch_size = 32, verbose=1,  callbacks=[es])
    #  self.model.reset_states()

def predict_result(self, test_case):
    value = self.model.predict(test_case, verbose=0)
    return value`
The error starts when I uncomment two lines of code in start_train method, and I turned the code into this (current model):
class Model:

def set_the_model(self, look_back):
    self.model = Sequential()
    self.model.add(LSTM(16, activation="relu", batch_input_shape=(1,look_back, 3),return_sequences=True, stateful=True))
    self.model.add(Dropout(0.2))
    self.model.add(LSTM(32, activation="relu", return_sequences=True))
    self.model.add(Dropout(0.2))
    self.model.add(TimeDistributed(Dense(look_back)))
    #self.model.add(Dense(3))
    self.model.compile(loss="mse", optimizer="nadam", metrics=['acc']) #mse
    self.model.summary()

def start_train(self, trainD1, trainD2):
    es = EarlyStopping(monitor='loss', patience = 2, mode='min')
    for i, j in zip(trainD1, trainD2):
        self.model.fit(i, j, epochs=200, batch_size = 1, verbose=1,  callbacks=[es])
        self.model.reset_states()

def predict_result(self, test_case):
    value = self.model.predict(test_case, verbose=0)
    return value
Then, I wanted to turn back to the old model. When I started to train the model, It gives the error:
InvalidArgumentError: Incompatible shapes: [32,3,3] vs. [32,3] [[{{node Nadam/gradients/loss/time_distributed_loss/SquaredDifference_grad/BroadcastGradientArgs}}]]
As a running environment, I am using Google Colab with TPU cores.
This is how the model looks like:
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 3, 16)             1280      
_________________________________________________________________ 
dropout (Dropout)            (None, 3, 16)             0         
_________________________________________________________________
lstm_1 (LSTM)                (None, 3, 32)             6272      
_________________________________________________________________
dropout_1 (Dropout)          (None, 3, 32)             0         
_________________________________________________________________
time_distributed (TimeDistri (None, 3, 3)              99        
=================================================================
Total params: 7,651
Trainable params: 7,651
Non-trainable params: 0
I also post this issue on StackOverflow
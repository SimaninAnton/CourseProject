Rachnog commented on 16 Dec 2015
Hello,
I am trying to train a classifier to identify on which position in the sentence is some keyword.
For example, the sentence (e.g. X_train[0]) looks like [124, 345, 567, 234, 33] and Y_train[0] for him looks like [0, 0, 1, 0, 0]. I created padding with zero by myself, so all X[i] and Y[i] have length of 50 with zeros after the special word for end of the sentence.
My model looks like this:
    model = Sequential()
    model.add(LSTM(input_dim=1, output_dim=128, activation='sigmoid', inner_activation='hard_sigmoid', return_sequences=True))
    model.add(Dropout(0.5))  
    model.add(TimeDistributedDense(output_dim = 1, input_dim = 128))
    model.add(Activation('sigmoid'))
    model.compile(loss='mse', optimizer='adam', class_mode='binary')
    model.fit(X_train, Y_train, batch_size=64, nb_epoch=1,
              validation_data=(X_test, Y_test), verbose=1)
It learns really fast, in 1-2 epochs and shows me result like
loss: 0.0476 - val_loss: 0.0136
But when I am trying to predict some custom X_test[i] I always receive the same vector:
print model.predict(np.array([X_test[0]]), batch_size=1)
[[[ 0.20753609]
  [ 0.1890841 ]
  [ 0.18069594]
  [ 0.1773404 ]
  [ 0.17606619]
  [ 0.08856945]
  [ 0.05559467]
  [ 0.03789682]
  [ 0.02793388]
  [ 0.0219523 ]
  [ 0.01822288]
  [ 0.01579676]
  [ 0.01416638]
  [ 0.01303991]
  [ 0.01224276]
  [ 0.01166664]
  [ 0.01124237]
  [ 0.01092464]
  [ 0.01068295]
  [ 0.01049653]
  [ 0.0103509 ]
  [ 0.01023572]
  [ 0.01014369]
  [ 0.0100694 ]
  [ 0.01000886]
  [ 0.00995917]
  [ 0.00991799]
  [ 0.00988369]
  [ 0.00985489]
  [ 0.00983058]
  [ 0.00980998]
  [ 0.00979238]
  [ 0.0097773 ]
  [ 0.00976431]
  [ 0.00975307]
  [ 0.00974336]
  [ 0.00973488]
  [ 0.00972749]
  [ 0.009721  ]
  [ 0.00971526]
  [ 0.00971024]
  [ 0.0097058 ]
  [ 0.00970186]
  [ 0.00969837]
  [ 0.00969528]
  [ 0.0096925 ]
  [ 0.00969001]
  [ 0.00968782]
  [ 0.00968583]
  [ 0.00968403]]]
And also when I checked score with
score = model.evaluate(X_test, Y_test, batch_size=30, show_accuracy=True)
I receive almost the same results for different parameters and architectures, which is strange:
LSTM test accuracy: [0.013586199080640831, 0.98575535512964929]
Is this a problem devoted to data/architecture? Or I'm trying to predict new sequence incorrect?
Thanks for any tip or help!
Best,
Alex
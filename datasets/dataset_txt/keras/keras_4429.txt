Contributor
dolaameng commented on 6 Sep 2016
I was trying to modify the neural_style_transfer example for an neural doodle implementation.
There are original Torch implementations here and here. My Keras implementation can be found here.
Some results on the Monet and Renoir examples can be found below.
The top row are the inputs to the algorithm, and the bottom row are doodle results from original Torch implementation v.s. Keras implementation(60 iterations). There are some differences, e.g., the surface of water? It is probably because I used a very heavy weight for total_variation_loss (5000!), otherwise there seems to be some salt-pepper noise in the generated image.
Slight differences between original Torch and Keras implementationsare also observed in the renoir example, where a content image is used to help generation, besides style image and doodle (target_mask). But both doodle results are better than results from neural_style_transfer example, e.g., in drawing the clean sky.
My implementation is using VGG19 for images and a series of AveragePooling for masks. The image is generated by minimizing the combination of content_loss, style_loss, and total_variation_loss. It's very similar to the Torch versions but with some differences based on my understanding - I am still struggling with reading the Torch codes...
I appreciate it if someone can help read the code, explain the difference with the Torch and suggest potential improvements. Thanks!
7
jrosebr1 commented on 12 May 2016 â€¢
edited
I have a large dataset that does not fit into memory. I've coded a custom class that yields ~10K images + labels at a time. Looking at the Keras documentation, I see that train_on_batch is recommended.
However, in #68, I see that @fchollet is using fit. Right now, my code looks like:
for epoch in np.arange(0, conf["epochs"]):
    print("[PARENT EPOCH] epoch {}...".format(epoch + 1))
    for (images, labels) in trainDG.nextBatch():
        model.fit(
            images, labels,
            batch_size=conf["batch_size"],
            nb_epoch=1,
            verbose=conf["verbose"])
This is to replicate the behavior that fchollet recommended in #68. However, I'm wondering if I should instead be using train_on_batch like the documentation recommends:
for epoch in np.arange(0, conf["epochs"]):
    print("[PARENT EPOCH] epoch {}...".format(epoch + 1))
    for (images, labels) in trainDG.nextBatch():
        model.train_on_batch(images, labels)
Which function, fit or train_on_batch is more appropriate for this situation?
30
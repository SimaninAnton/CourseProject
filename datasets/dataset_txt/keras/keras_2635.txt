takingstock commented on 17 Apr 2017 •
edited
When i use an embedding layer (seq_lt = 10 and embeddim = 100) before a Conv1D (kernel = 6 and channels = 40), here’s what i see; input_shape Conv is (numSamples, 10, 100) and the output of conv1d is (numSamples,5, 40). Whatever happened to 100 ? (dimension of word vector). AFAIK, there's a weight vector/matrix that is multiplied (convolved) by the values contained in the window and this value is then passed on to the feature map. So is it fair to assume we perform a matrix multiplication of the weight for a particular cell with the contents of the cell ? please correct my example below. Simple example ;
input sequence is 3 words and 
embedding dimension of each word vector is 2 and the 
kernel_size = 2 and channels=1 
wt matrix = [0.5, 0.5]
input (embedded word vectors)     = [[-0.2, 0.1], [-0.1, 0.1], [0.5,0.1]]
     feature_map values = [ [0.5x(-0.2+0.1)]+[0.5x(-0.1+0.1) , [0.5x(-0.1+0.1)+[0.5x(0.5+0.1)] 
                        = [-0.05 , 0.3]
dr-costas commented on 2 Feb 2017 â€¢
edited
Hi,
I'm trying to implement a deep transition RNN with keras (see here: https://arxiv.org/pdf/1312.6026v5.pdf ) and the way that I'm thinking to implement it is to have a loop structure inside the step method of the Recurrent layer.
This means that for every iteration of the theano.scan (I'm using theano) there are gonna be calculations for inputs and outputs for all the inner layer in the step method.
How is the the gradient at the BPTT process calculated in such a case? I mean, does theano treat every iteration of theano.scan as a single time step and a single layer or it can "understand" that in the step method are also "inner time steps" and inner layers?
In general, if there are some multi-layered calculations inside step, will be treated by theano (in terms of BPTT) as a single layer and/or a single time step or the BPTT will take account all the calculations inside the step (and effectively, inside theano.scan) method?
Contributor
jfsantos commented on 20 Jan 2016
My model has an Embedding layer as its first layer, followed by a Dropout and LSTM layers, like this:
model = Sequential()
model.add(Embedding(input_dim=vocab_size, output_dim=vocab_size))
model.add(Dropout(input_dropout))
model.add(LSTM(n_hidden, return_sequences=True))
<remainder of the model here, which includes a few more LSTM layers>
If I try to use it like this, I'll get a warning message from Keras telling me that I need to specify batch_input_shape when using Tensorflow. However, even if I specify batch_input_shape up to the first LSTM layer, I still get the same error message.
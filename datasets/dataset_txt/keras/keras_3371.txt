hqsiswiliam commented on 25 Jan 2017 â€¢
edited
Hi There,
I encounter a problem about adding attention mechanism over single LSTM layer.
Want I want to do is to add all hidden states into an array, and sum up with x in the final step of calculation. Here is want I implemented my custom RNN step function:
def step(self, x, states):
    
    h_tm1,c_tm1,B_U,B_W,input_x = states
    
    #if rnn iterate to the last step:
    
    if len(self.hidden_states)==self.input_length-1:
        
      for hidden_state in self.hidden_states:
        
        #the input x would add up all previous hidden states
        
        x = x + hidden_state
        
    h, [h, c] = super(MyLSTM2, self).step(x, states)
    
    if len(self.hidden_states)!=self.input_length-1:
        
      #append hidden states to hidden states array
      
      self.hidden_states.append(h)
      
    else:
        
      #after previous hidden states added up, clear the array
      
      self.hidden_states = []
      
    return h, [h, c]
    
I judge last step of RNN via if statement in step function
I append each hidden states to an numpy array in step function.
However, I tested it and found that the step function was not functioning at all. Could you help me to figure out the problem and correct me wrong lines.
Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps
If running on TensorFlow, check that you are up-to-date with the latest version. The installation instructions can be found here.
If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps
Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
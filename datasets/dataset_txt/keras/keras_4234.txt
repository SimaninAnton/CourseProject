jekintrivedi commented on 5 Oct 2016
Hey Guys,
So I was testing the callback API on MNIST. I added a custom callback function to print the current Learning Rate and Momentum. However it prints the same initialized value, whereas in SGD with a decay value set, the Learning Rate should decay over epoch.
Please find the script here : https://gist.github.com/jekintrivedi/1e38b0f1d1e6c962bfba54febb4575a3
I have all the libraries updated to the master branch. Can anyone tell me what I am doing wrong here.
THEANO_FLAGS=mode=FAST_RUN,device=gpu7,floatX=float32 python m
nist_test.py
Using Theano backend.
Using gpu device 7: Tesla K20m (CNMeM is disabled, cuDNN 5005)
X_train shape: (60000, 1, 28, 28)
60000 train samples
10000 test samples
Train on 60000 samples, validate on 10000 samples
lr : 0.00999999977648 momentum : 0.899999976158
Epoch 1/12
60000/60000 [==============================] - 14s - loss: 0.4964 - acc: 0.8432 - val_loss: 0.1558 - val_acc: 0.9528
lr : 0.00999999977648 momentum : 0.899999976158
Epoch 2/12
60000/60000 [==============================] - 14s - loss: 0.2126 - acc: 0.9354 - val_loss: 0.0845 - val_acc: 0.9727
lr : 0.00999999977648 momentum : 0.899999976158
Epoch 3/12
60000/60000 [==============================] - 14s - loss: 0.1465 - acc: 0.9557 - val_loss: 0.0651 - val_acc: 0.9801
lr : 0.00999999977648 momentum : 0.899999976158
Epoch 4/12
60000/60000 [==============================] - 14s - loss: 0.1187 - acc: 0.9644 - val_loss: 0.0555 - val_acc: 0.9821
lr : 0.00999999977648 momentum : 0.899999976158
Epoch 5/12
60000/60000 [==============================] - 14s - loss: 0.1003 - acc: 0.9694 - val_loss: 0.0484 - val_acc: 0.9843
lr : 0.00999999977648 momentum : 0.899999976158
Epoch 6/12
60000/60000 [==============================] - 14s - loss: 0.0881 - acc: 0.9729 - val_loss: 0.0433 - val_acc: 0.9859
lr : 0.00999999977648 momentum : 0.899999976158
Epoch 7/12
60000/60000 [==============================] - 14s - loss: 0.0769 - acc: 0.9763 - val_loss: 0.0392 - val_acc: 0.9879
lr : 0.00999999977648 momentum : 0.899999976158
Epoch 8/12
60000/60000 [==============================] - 14s - loss: 0.0690 - acc: 0.9782 - val_loss: 0.0383 - val_acc: 0.9868
lr : 0.00999999977648 momentum : 0.899999976158
Epoch 9/12
60000/60000 [==============================] - 14s - loss: 0.0649 - acc: 0.9795 - val_loss: 0.0351 - val_acc: 0.9877
lr : 0.00999999977648 momentum : 0.899999976158
Epoch 10/12
60000/60000 [==============================] - 14s - loss: 0.0614 - acc: 0.9808 - val_loss: 0.0350 - val_acc: 0.9873
lr : 0.00999999977648 momentum : 0.899999976158
Epoch 11/12
60000/60000 [==============================] - 14s - loss: 0.0566 - acc: 0.9827 - val_loss: 0.0329 - val_acc: 0.9890
lr : 0.00999999977648 momentum : 0.899999976158
Epoch 12/12
60000/60000 [==============================] - 14s - loss: 0.0541 - acc: 0.9829 - val_loss: 0.0336 - val_acc: 0.9891
10000/10000 [==============================] - 2s
Test score: 0.0336044333406
Test accuracy: 0.9891
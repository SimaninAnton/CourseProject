Contributor
chsasank commented on 19 Apr 2016 â€¢
edited
Hi,
I observed that image augmentation slows down the training process considerably.
When I used the following,
datagen = ImageDataGenerator(
        featurewise_center=True,
        featurewise_std_normalization=True,
        rotation_range=0,
        width_shift_range=0,
        height_shift_range=0,
        horizontal_flip=False)
it took me about 300 seconds for an epoch.
When I added data augmentation,
datagen = ImageDataGenerator(
        featurewise_center=True,
        featurewise_std_normalization=True,
        rotation_range=10,
        width_shift_range=0.1,
        height_shift_range=0.1,
        shear_range=0.3,
        horizontal_flip=True) 
It takes 2900 seconds per epoch. Slow down by a factor of 10!
I suspect this is due to augmentation that's happening on CPU. I have gone through source of ImageDataGenerator and IMHO random_transform can be improved.
If rotations, translations and shear are enabled, each of these are now applied one after another.
We should be able to do all of this in one step as homographic transformation. An implementation is available in skimage.
Here's an example: https://gist.github.com/chsasank/4bda6a6dc7973ae206b09134b92d20f2
Added advantage is that random zoom is just another homography.
Have a look here for visual overview of homographies.
Sasank.
rubenohayon commented on 12 Jun 2017
I have pairs of movie witch contains 2783 features.
The vector is defined as: if the feature is in the movie it's 1 otherwise it's 0.
Example :
movie 1 = [0,0,1,0,1,0,1 ...] & movie 2 = [1,0,1,1,1,0,1 ...]
Each pair has for label 1 or 0.
movie1,movie2=0
movie1,movie4=1
movie2,movie150=0
The input is similar to SGNS (Skip gram negative sampling) word2vec model.
My goal is to find similarity between programs and learn embedding of each movie.
I'd to build a kind of 'SGNS implementation with keras'. However my input is not one hot and I can't use the Embedding layers. I tried to use Dense layers and merge them with a dot product. I'm not sure about the model architecture and I got errors.
from keras.layers import Dense,Input,LSTM,Reshape
from keras.models import Model,Sequential

n_of_features = 2783
n_embed_dims = 20

# movie1 vectors
word= Sequential()
word.add(Dense(n_embed_dims, input_dim=(n_words,)))

# movie2 vectors
context = Sequential()
context.add(Dense(n_embed_dims, input_dim=n_words,))

model = Sequential()

model.add(keras.layers.dot([word, context], axes=1))

model.add(Dense(1, activation='sigmoid'))

model.compile(optimizer='rmsprop',
     loss='mean_squared_error')
If someone has an idea how to implement it.
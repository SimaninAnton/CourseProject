jlfu commented on 7 Jan 2017 â€¢
edited
I try to add a pre-trained embedding layer, but i can't set "trainable=False". When i move "trainable=False", it can work correctly. How can i fix it?
model11 = Sequential()
model11.add(Embedding(len(vocabulary)+1, word_embedding_size, init='uniform',input_length=word_max_len,
weights=[embedding_matrix],
trainable=False))
ValueError: You called set_weights(weights) on layer "embedding_2" with a weight list of length 22803, but the layer was expecting 1 weights. Provided weights: [[-0.07056077 0.03531956 0.09292351 ..., -0.2440...
1
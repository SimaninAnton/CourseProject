KlaymenGC commented on 28 Jan 2016
Hello,
I'm trying to add weights to the classes during training right before the final softmax layer, the output shape of the layer is (batch_size, length, nb_class) with one-hot-label of the same size, and I'm using categorical_crossentropy loss here. I added a class balancing layer before softmax which did:
...
X = self.get_input(train)
x_balanced = X
# unique: label values in the training set, [0, 1, 2, ...] (1 x nb_class)
# putting weight to each class
for i in range(len(self.unique)):
    x_balanced = T.set_subtensor(x_balanced[:, self.unique[i]], x_balanced[:, self.unique[i]]*self.weight[i])
return x_balanced
...
but it didn't seem to help... any suggestions will be greatly appreciated!
Update: I've tried to use class_weight in fit and send class weight as dictionary: {0:w1, 1:w2, ...}, but got the error: Exception: class_weight not supported for 3+ dimensional targets.
1
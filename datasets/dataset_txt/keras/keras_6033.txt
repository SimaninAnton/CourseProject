AntreasAntoniou commented on 30 Jan 2016
I have included the model.py. Basically I can train the model just fine, however when I attempt to reload weights, it raises an exception that it can't find some part of the weights.
Using gpu device 0: GeForce GTX 980 (CNMeM is disabled)
/usr/local/lib/python2.7/dist-packages/theano/tensor/signal/downsample.py:5: UserWarning:

downsample module has been moved to the pool module.

Compiling models...
---------------------------------------------------------------------------
AssertionError                            Traceback (most recent call last)
/usr/lib/python2.7/dist-packages/IPython/utils/py3compat.pyc in execfile(fname, *where)
    202             else:
    203                 filename = fname
--> 204             __builtin__.execfile(filename, *where)

/home/ubuntumax/keras_branch/keras-dsb/experiment.py in <module>()
    309             run(sys.argv[2])
    310         elif sys.argv[1] == 'continue':
--> 311             run(sys.argv[2], cont=True)
    312         elif sys.argv[1] == 'submission':
    313             submission(sys.argv[2])

/home/ubuntumax/keras_branch/keras-dsb/experiment.py in run(experiment_name, cont)
     80     # load weights (if continue experiment)
     81     if cont:
---> 82         model_systole.load_weights(experiment_path + '/' + META_DIR + '/' + MODEL_SYS_W)
     83         model_diastole.load_weights(experiment_path + '/' + META_DIR + '/' + MODEL_DIAS_W)
     84     # import pre-process module

/usr/local/lib/python2.7/dist-packages/keras/models.pyc in load_weights(self, filepath)
   1230         g = f['graph']
   1231         weights = [g['param_{}'.format(p)] for p in range(g.attrs['nb_params'])]
-> 1232         self.set_weights(weights)
   1233         f.close()
   1234 

/usr/local/lib/python2.7/dist-packages/keras/layers/containers.pyc in set_weights(self, weights)
    526         for layer in self.nodes.values():
    527             nb_param = len(layer.get_weights())
--> 528             layer.set_weights(weights[:nb_param])
    529             weights = weights[nb_param:]

/usr/local/lib/python2.7/dist-packages/keras/layers/containers.pyc in set_weights(self, weights)
    157         for i in range(len(self.layers)):
    158             nb_param = len(self.layers[i].params)
--> 159             self.layers[i].set_weights(weights[:nb_param])
    160             weights = weights[nb_param:]
    161 

/usr/local/lib/python2.7/dist-packages/keras/layers/normalization.pyc in set_weights(self, weights)
     70         K.set_value(self.running_mean, weights[-2])
     71         K.set_value(self.running_std, weights[-1])
---> 72         super(BatchNormalization, self).set_weights(weights[:-2])
     73 
     74     def get_output(self, train):

/usr/local/lib/python2.7/dist-packages/keras/layers/core.pyc in set_weights(self, weights)
    211         assert len(self.params) == len(weights), ('Provided weight array does not match layer weights (' +
    212                                                   str(len(self.params)) + ' layer params vs. ' +
--> 213                                                   str(len(weights)) + ' provided weights)')
    214         for p, w in zip(self.params, weights):
    215             if K.get_value(p).shape != w.shape:

AssertionError: Provided weight array does not match layer weights (2 layer params vs. 0 provided weights)
Graph used:
conv = Sequential()
conv.add(Activation(activation=scale, input_shape=(30, 128, 128)))

conv.add(Convolution2D(64, 3, 3, border_mode='same'))
conv.add(Activation('relu'))
conv.add(Convolution2D(64, 3, 3, border_mode='same'))
conv.add(Activation('relu'))
conv.add(MaxPooling2D(pool_size=(2, 2)))
conv.add(BatchNormalization())
conv.add(Dropout(0.2))

conv.add(Convolution2D(128, 3, 3, border_mode='same'))
conv.add(Activation('relu'))
conv.add(Convolution2D(128, 3, 3, border_mode='same'))
conv.add(Activation('relu'))
conv.add(MaxPooling2D(pool_size=(2, 2)))
conv.add(BatchNormalization())
conv.add(Dropout(0.2))

conv.add(Convolution2D(256, 3, 3, border_mode='same'))
conv.add(Activation('relu'))
conv.add(Convolution2D(256, 3, 3, border_mode='same'))
conv.add(Activation('relu'))
conv.add(MaxPooling2D(pool_size=(2, 2)))
conv.add(BatchNormalization())
conv.add(Dropout(0.2))

conv.add(Convolution2D(512, 3, 3, border_mode='same'))
conv.add(Activation('relu'))
conv.add(Convolution2D(512, 3, 3, border_mode='same'))
conv.add(Activation('relu'))
conv.add(MaxPooling2D(pool_size=(2, 2)))
conv.add(BatchNormalization())
conv.add(Dropout(0.2))

conv.add(Convolution2D(512, 3, 3, border_mode='same'))
conv.add(Activation('relu'))
conv.add(Convolution2D(512, 3, 3, border_mode='same'))
conv.add(Activation('relu'))
conv.add(MaxPooling2D(pool_size=(2, 2)))
conv.add(BatchNormalization())
conv.add(Dropout(0.2))

conv.add(Convolution2D(512, 3, 3, border_mode='same'))
conv.add(Activation('relu'))
conv.add(Convolution2D(512, 3, 3, border_mode='same'))
conv.add(Activation('relu'))
conv.add(MaxPooling2D(pool_size=(2, 2)))
conv.add(BatchNormalization())
conv.add(Dropout(0.2))
conv.add(Flatten())
#conv.add(Reshape((1, 2048)))

meta = Sequential()
# meta.add(Dense(512, input_dim=4))
# meta.add(Activation('relu'))
# meta.add(Reshape((1, 512)))
meta.add(LSTM(512, input_shape=(1, 4), return_sequences=False))
meta.add(Dropout(0.5))
#meta.add(Reshape((1, 512)))

model = Graph()
model.add_input(name='conv_input', input_shape=(30, 128, 128))
model.add_input(name='meta_input', input_shape=(4,))
model.add_node(Reshape((1, 4)),name='meta_reshape', input='meta_input')
model.add_node(conv, name='conv', input='conv_input')
model.add_node(meta, name='meta', input='meta_reshape')
model.add_node(Dense(2048+512, W_regularizer=l2(1e-3)), name='merge', inputs=['conv', 'meta'], merge_mode='concat')
model.add_node(Reshape((1, 2048+512)), name='merge_reshape', input='merge')
model.add_node(LSTM(512, return_sequences=False), name='lstm_0', input='merge_reshape')
model.add_node(Dropout(0.5), name='lstm_do_0', input='lstm_0')
# model.add_node(LSTM(512), name='lstm_1', input='lstm_do_0')
# model.add_node(Dropout(0.5), name='lstm_do_1', input='lstm_1')
model.add_node(Dense(1), name='merge_out', input='lstm_do_0')
model.add_output(name='output', input='merge_out')
Flock1 commented on 27 Apr 2018 â€¢
edited
Hi,
I am trying to train a model on some grayscale images. The model I am using is:
model = Sequential()
model.add(Convolution2D(8, 3, 3, input_shape=(720, 1280,1)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(BatchNormalization())

model.add(Convolution2D(16, 3, 3))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(BatchNormalization())
#model.add(Dropout(0.6))

model.add(Convolution2D(32, 3, 3))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(BatchNormalization())

model.add(Convolution2D(64, 3, 3))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(BatchNormalization())
model.add(Dropout(0.5))

model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors
model.add(Dense(64))
model.add(Activation('relu'))
model.add(Dropout(0.5))
model.add(Dense(1))
model.add(Activation('sigmoid'))
Then I compile it:
model.compile(optimizer='rmsprop',
              loss='categorical_crossentropy',
              metrics=['accuracy'])
and then fit it:
model.fit(np.array(X_train), np.array(y_train_cat), batch_size=32,
          epochs=10, verbose=1, validation_split=0.1)
The shape of the image is (1280,720)
I get the error:
ValueError: Error when checking input: expected conv2d_1_input to have 4 dimensions, but got array with shape (315, 720, 1280)
If I don't use the np.array in fit, I get the following error:
Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 1 array(s), but instead got the following list of 315 arrays:
Can you please suggest what I should do? I have tried to resize it to 3D, something like (1280,720,1), but it's not working.
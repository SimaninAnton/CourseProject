robclouth commented on 23 Dec 2015
Hey guys, I'm trying to make the lstm_text_generation.py example stateful. I've added
batch_input_shape=(batch_size, sequence_length, len(chars)), stateful=True
To the two layers, and changed
model.fit(X, y, batch_size=128, nb_epoch=1)
to
for batch in range(X.shape[0] / batch_size):
        offset = batch * batch_size
        X_batch = X[offset:offset + batch_size, :, :]
        y_batch = y[offset:offset + batch_size, :]
        loss = model.train_on_batch(X_batch, y_batch)
        progbar.add(X_batch.shape[0], values=[('train loss', loss[0])])
But when it gets to the prediction and sampling part it crashes, complaining about a dimension mismatch:
ValueError: dimension mismatch in args to gemm (128,512)x(512,512)->(1,512)
Apply node that caused the error: GpuGemm{inplace}(GpuDot22.0, TensorConstant{0.20000000298}, <CudaNdarrayType(float32, matrix)>, <CudaNdarrayType(float32, matrix)>, TensorConstant{0.20000000298})
Toposort index: 10
Thanks! Any ideas?
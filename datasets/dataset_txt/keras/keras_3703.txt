stamas02 commented on 12 Dec 2016
Ok so I have been trying to figure this out for days now and I think there is some problem with the custom loss function. So I have the following code:
self._model.compile(loss=self.custom_loss, optimizer="sgd")
out = self._model.predict(x)
sum1 = np.sum(out)
self._model.fit(x=x,y=y,batch_size=len(x),nb_epoch=1,shuffle=False)

def custom_loss(self, y_true, y_pred):
        return K.sum(y_pred)
At this point I would expect the loss and sum1 to be the same but they are very different. Note that this code does not have any meaning but my loss calculation was incorrect and wanted to test what my loss function receives. I do not have any dropout layers.
rvallari1 commented on 8 Jul 2019 â€¢
edited
System information
Have I written custom code (as opposed to using example directory):
OS Platform and Distribution: Linux Ubuntu
TensorFlow backend (yes / no): yep
TensorFlow version: 1.13.1
Keras version: 2.2.4
Python version:
CUDA/cuDNN version: no
GPU model and memory:
Describe the current behavior
If we run model.fit_generator, evaluate_generator is called after every epoch..
So, If we are running a model on n cpus', where training and validation data is divided as per https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly . What is happening, since the validation data is 80 in size, evaluate_generator is running 80/n steps but each cpu is validating only its [80/n] samples [I am taking one sample per step].
So, if the validation list is 80; and I have 4 cpus' running ; each cpu is validating only 20 samples in its list in this order[1 2 3... 20]. Unlike training_generator, where this problem doesnot exist. Random index is thrown to getitem(index): to retreive the sample.
Other info / logs
where 1 is the index thrown to getitem and [ __ ] is the sample number.
indra215 commented on 24 Jan 2017
As described in image captioning example here https://keras.io/getting-started/sequential-model-guide/, I need to add a image model (image_model as in example) and append it to a language model (language_model as in example). What if I directly have a CNN feature embedding of the image and don't want to add the image_model instead directly use the language model (language_model) itself to generate the caption word by word.
For example, I have a CNN feature embedding of the image as X_train = (no_images, 512) and partial_captions and next_words as it is described in the example. So how would the model look like and what changes should be done similar to the one described in the example ?
Thanks in advance.
eanie commented on 8 Jun 2016
I'm having a weird problem where I am using a doc2vec Embedding layer and even though I'm pumping through unique examples for prediction, a lot of the outputs from the pred_proba method are returning the same prediction.
Here is the architecture:
print("Loading Doc2Vec...")
model = Doc2Vec.load("doc2vec.model")
gensim_dict = Dictionary()
gensim_dict.doc2bow(model.vocab.keys(),
allow_update=True)
w2indx = {v: k+1 for k, v in gensim_dict.items()}
w2vec = {word: model[word] for word in w2indx.keys()}
index_dict, word_vectors
print('Setting up Arrays for Keras Embedding Layer...')
n_symbols = len(w2indx) + 1 # adding 1 to account for 0th index
embedding_weights = np.zeros((n_symbols, maxlen))
for word, index in w2indx.items():
embedding_weights[index, :] = w2vec[word]
model = Sequential()
model.add(Embedding(output_dim=maxlen,
input_dim=n_symbols,
#mask_zero=True,
weights=[embedding_weights],
input_length=maxlen)) # Adding Input Length
model.add(Dropout(0.25))
model.add(Convolution1D(nb_filter=nb_filter,
filter_length=filter_length,
border_mode='valid',
activation='relu',
subsample_length=1))
model.add(MaxPooling1D(pool_length=pool_length))
model.add(LSTM(lstm_output_size))
model.add(Dense(1))
model.add(Activation('sigmoid'))
model.compile(loss='binary_crossentropy',
optimizer='adam',
metrics=['accuracy'])
print("Loading Weights")
model.load_weights(instrument + '-weights.hdf5')
classes = model.predict_proba(X_test, batch_size=1, verbose=0)
print(classes)
And the outputs are:
Using Theano backend.
X_test:
[[ -2.47382596e-02 2.32602060e-02 -6.53387140e-03 ..., -5.51625062e-03
-5.74239753e-02 -3.07026859e-02]
[ 3.29017431e-01 2.35613093e-01 -7.56662712e-02 ..., 7.71998167e-02
-3.64937872e-01 -2.01133800e+00]
[ -1.00101516e-01 -6.00816719e-02 -3.69741372e-03 ..., 5.17791100e-02
-7.46646821e-02 8.59571397e-02]
...,
[ 2.19638228e-01 -8.07978734e-02 4.71501723e-02 ..., 4.79124673e-02
1.00293700e-02 1.53316772e-02]
[ -1.25041693e-01 -6.55420348e-02 4.24071133e-01 ..., 2.15420816e-02
-5.21663465e-02 -7.86688030e-02]
[ -4.78273164e-03 3.24305370e-02 2.72341162e-01 ..., -8.28378797e-02
1.43599689e-01 -1.07673614e-03]]
Loading Doc2Vec...
Setting up Arrays for Keras Embedding Layer...
Loading Weights
Prediction:
[[ 0.50939184]
[ 0.34107986]
[ 0.50939184]
[ 0.50939184]
[ 0.50939184]
[ 0.50939184]
[ 0.50939184]
[ 0.50939184]
[ 0.48695773]
[ 0.50939184]
[ 0.62477738]
[ 0.50939184]
[ 0.50939184]
[ 0.58683521]
[ 0.50939184]
[ 0.50939184]
[ 0.50939184]
[ 0.50939184]
[ 0.50939184]
You can see 0.50939184 appears over and over again.
cmishra commented on 9 Mar 2016
I'm using the VGG-like Convnet example with the mnist dataset. I trained for 15 epoches and obtained this set of weights with a validation accuracy of 0.99%.
The problem arrives when I attempt to evaluate this model upon the MNIST test set. The test_loss is NaN. The test accuracy is still quite high (99.26%), but I find the nan troubling nonetheless.
Some inspection reveals none of the weights are nan, but 10 predictions upon MNIST test are NaN. Any idea why this may be?
You can reproduce my inspections with the code here. I'd recommend cloning the entire repository and executing that python file specifically. The code I originally used to generate the weights is also available in that repository (just comment out line 57 and uncomment 60-62).
Note that I use a normalization class I implemented instead of ImageDataGenerator because of a now-fixed issue (#1880).
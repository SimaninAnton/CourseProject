siddheshk commented on 7 Feb 2017 â€¢
edited
I am trying to implement a sentence level attention model for a set of Documents. So the idea is that I generate a sentence embedding using a CNN and then merge the sentence embeddings for a particular document by learning a sentence level attention.
The problem is that each document might have different number of sentences. I have tried padding each document with dummy sentences, but that only increases the training time. Is there a way by which I can have one of the dimensions in the Input Layer as None.
For example,
input_layer = Input(shape=(None,img_h,), dtype='int32', name='input_layer')
embedding_layer = TimeDistributed(Embedding(len(W2V), img_w, input_length=img_h, weights=[W2V], trainable=True, mask_zero=True, name='embedding_1'))(input_layer)
#Apply CNN
#Apply Pooling
#Get Sentence Level Attention Values
#Sum sentence embeddings based on attention
#Apply Dense Layer
So I implemented this and my model summary looks something like this
Layer (type)                     Output Shape          Param #     Connected to
====================================================================================================
input_layer (InputLayer)         (None, None, 82)      0
____________________________________________________________________________________________________
timedistributed_1 (TimeDistribut (None, None, 82, 50)  8034900     input_layer[0][0]
____________________________________________________________________________________________________________
timedistributed_4 (TimeDistribut (None, None, 230, 80, 41630     timedistributed_1[0][0]
____________________________________________________________________________________________________________________________________________
maxpooling2d_1                   (None, None, 690)     0           timedistributed_4[0][0]
____________________________________________________________________________________________________________________________
timedistributed_5 (TimeDistribut (None, None, 1)       477480      maxpooling2d_1[0][0]
____________________________________________________________________________________________________
flattenwithmasksentence_1 (Flatt (None, None)          0           timedistributed_5[0][0]
____________________________________________________________________________________________________
softmaxwithmask_1 (SoftmaxWithMa (None, None)          0           flattenwithmasksentence_1[0][0]
____________________________________________________________________________________________________
repeatvector_1 (RepeatVector)    (None, 690, None)     0           softmaxwithmask_1[0][0]
____________________________________________________________________________________________________
permute_1 (Permute)              (None, None, 690)     0           repeatvector_1[0][0]
____________________________________________________________________________________________________
merge_1 (Merge)                  (None, None, 690)     0           createsentencemask_1[0][0]
                                                                   permute_1[0][0]
____________________________________________________________________________________________________
documentembedding_1 (DocumentEmb (None, 690)           0           merge_1[0][0]
____________________________________________________________________________________________________
dropout_1 (Dropout)              (None, 690)           0           documentembedding_1[0][0]
____________________________________________________________________________________________________
dense_1 (Dense)                  (None, 27)            18657       dropout_1[0][0]
====================================================================================================
But this does not seem to perform as well as the case where I pad the documents with dummy sentences and fix the number of sentences for each document.
Am I doing something wrong?
Please make sure that the boxes below are checked before you submit your issue. If your issue is an implementation question, please ask your question on StackOverflow or join the Keras Slack channel and ask there instead of filing a GitHub issue.
Thank you!
Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps
If running on TensorFlow, check that you are up-to-date with the latest version. The installation instructions can be found here.
If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps
Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
maxaug commented on 8 Dec 2016 â€¢
edited
Hello there,
I don't have an exact message on me now as I am in the middle of training my model under TF but this is an issue i've had on two setups:
Setup 1: 32Gb RAM, no GPU
Setup 2: p2.xlarge instance - 60GB RAM, 1/2 Tesla K80
Model goes like this: LSTM 2, LSTM16, LSTM8, Dense1 ( but this happens on any lstm/gru network)
Data is 3GB CSV (4*0.75GB)
Memory usage on Theano is like:
What happens there roughly is theano invokes g++ and each compilation blows up (OOM)
What happens there with TF, it plateaus on 35GB of memory and runs happily, so even though Setup 1 might be out of question (leave optimization), Setup 2 works like a charm.
I think it'd be worth to investigating.
Theano==0.9.0.dev3
Keras==1.1.0
1
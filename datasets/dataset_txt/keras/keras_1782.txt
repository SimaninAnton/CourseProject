KeqiangWang commented on 8 Aug 2017 â€¢
edited
when labels or pred values are large, the results of categorical_crossentropy is different to the results of tf.nn.softmax_cross_entropy_with_logits, which may leads some wrongs like this issue:#7558
results:
X = np.array([[3.0, 1.0, 1.0], [-1.0, 2.0, 5.0]])
Y = np.array([[1, 0.0, 0.0], [0.0, 1.0, 0.0]])
categorical_crossentropy: 1.64524526487
tf.nn.softmax_cross_entropy_with_logits: 1.64524526487
X = np.array([[300.0, 100.0, 100.0], [-100.0, 200.0, 500.0]])
categorical_crossentropy: 8.05904786964
tf.nn.softmax_cross_entropy_with_logits: 150.0
The code is following:
import numpy as np
import tensorflow as tf
from keras import backend as K

sess = tf.Session()
K.set_session(sess)


X = np.array([[3.0, 1.0, 1.0], [-1.0, 2.0, 5.0]])
Y = np.array([[1, 0.0, 0.0], [0.0, 1.0, 0.0]])


cost1 = tf.reduce_mean(K.categorical_crossentropy(K.softmax(X), Y))
cost2 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=X, labels=Y))
print(K.eval(cost1))
print(K.eval(cost2))

X = np.array([[300.0, 100.0, 100.0], [-100.0, 200.0, 500.0]])


cost1 = tf.reduce_mean(K.categorical_crossentropy(K.softmax(X), Y))
cost2 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=X, labels=Y))
print(K.eval(cost1))
print(K.eval(cost2))
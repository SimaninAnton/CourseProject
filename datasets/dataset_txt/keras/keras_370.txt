xychenunc commented on 24 Feb 2019 â€¢
edited
from future import print_function
import keras
from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
from keras import backend as K
import numpy as np
batch_size = 128
num_classes = 10
epochs = 12
input image dimensions
img_rows, img_cols = 28, 28
the data, split between train and test sets
(x_train, y_train), (x_test, y_test) = mnist.load_data()
if K.image_data_format() == 'channels_first':
x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)
x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)
input_shape = (1, img_rows, img_cols)
else:
x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)
x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)
input_shape = (img_rows, img_cols, 1)
x_train = x_train.astype('float32')
x_test = x_test.astype('float32')
x_train /= 255
x_test /= 255
print('x_train shape:', x_train.shape)
print(x_train.shape[0], 'train samples')
print(x_test.shape[0], 'test samples')
convert class vectors to binary class matrices
y_train = keras.utils.to_categorical(y_train, num_classes)
y_test = keras.utils.to_categorical(y_test, num_classes)
model1 = Sequential()
model1.add(Conv2D(32, kernel_size=(3, 3),
activation='relu',
input_shape=input_shape))
model1.add(Conv2D(64, (3, 3), activation='relu'))
model1.add(MaxPooling2D(pool_size=(2, 2)))
model1.add(Dropout(0.25))
model1.add(Flatten())
model1.add(Dense(128, activation='relu'))
model1.add(Dropout(0.5))
model1.add(Dense(num_classes, activation='softmax'))
model1.compile(loss=keras.losses.categorical_crossentropy,
optimizer=keras.optimizers.Adadelta(),
metrics=['accuracy'])
model.fit
model1.fit(x_train, y_train,
batch_size=batch_size,
epochs=epochs,
verbose=1,
validation_data=(x_test, y_test))
score = model1.evaluate(x_test, y_test, verbose=0)
print('Test loss:', score[0])
print('Test accuracy:', score[1])
Test
Epoch 1/12
60000/60000 [==============================] - 16s 272us/step - loss: 0.2533 - acc: 0.9226 - val_loss: 0.0573 - val_acc: 0.9806
Epoch 2/12
60000/60000 [==============================] - 11s 178us/step - loss: 0.0856 - acc: 0.9756 - val_loss: 0.0393 - val_acc: 0.9870
Epoch 3/12
60000/60000 [==============================] - 10s 171us/step - loss: 0.0641 - acc: 0.9805 - val_loss: 0.0328 - val_acc: 0.9892
Epoch 4/12
60000/60000 [==============================] - 10s 172us/step - loss: 0.0546 - acc: 0.9837 - val_loss: 0.0332 - val_acc: 0.9889
Epoch 5/12
60000/60000 [==============================] - 10s 170us/step - loss: 0.0458 - acc: 0.9861 - val_loss: 0.0307 - val_acc: 0.9906
Epoch 6/12
60000/60000 [==============================] - 10s 171us/step - loss: 0.0408 - acc: 0.9877 - val_loss: 0.0297 - val_acc: 0.9906
Epoch 7/12
60000/60000 [==============================] - 9s 151us/step - loss: 0.0370 - acc: 0.9889 - val_loss: 0.0286 - val_acc: 0.9907
Epoch 8/12
60000/60000 [==============================] - 9s 157us/step - loss: 0.0340 - acc: 0.9893 - val_loss: 0.0270 - val_acc: 0.9921
Epoch 9/12
60000/60000 [==============================] - 10s 170us/step - loss: 0.0330 - acc: 0.9893 - val_loss: 0.0277 - val_acc: 0.9915
Epoch 10/12
60000/60000 [==============================] - 10s 170us/step - loss: 0.0284 - acc: 0.9911 - val_loss: 0.0309 - val_acc: 0.9905
Epoch 11/12
60000/60000 [==============================] - 10s 169us/step - loss: 0.0276 - acc: 0.9913 - val_loss: 0.0258 - val_acc: 0.9925
Epoch 12/12
60000/60000 [==============================] - 10s 171us/step - loss: 0.0252 - acc: 0.9921 - val_loss: 0.0285 - val_acc: 0.9919
Test loss: 0.028468665385381155
Test accuracy: 0.9919
model.fit_generator
model2 = Sequential()
model2.add(Conv2D(32, kernel_size=(3, 3),
activation='relu',
input_shape=input_shape))
model2.add(Conv2D(64, (3, 3), activation='relu'))
model2.add(MaxPooling2D(pool_size=(2, 2)))
model2.add(Dropout(0.25))
model2.add(Flatten())
model2.add(Dense(128, activation='relu'))
model2.add(Dropout(0.5))
model2.add(Dense(num_classes, activation='softmax'))
model2.compile(loss=keras.losses.categorical_crossentropy,
optimizer=keras.optimizers.Adadelta(),
metrics=['accuracy'])
def train_gen(batch_size=batch_size, x_train=x_train, y_train=y_train):
while True:
permute = np.random.permutation(np.shape(x_train)[0])
x_train = x_train[permute]
y_train = y_train[permute]
numBatch = x_train.shape[0] // batch_size
for idx in range(numBatch):
input_batch = x_train[idx*batch_size:(idx+1)batch_size]
output_batch = y_train[idxbatch_size:(idx+1)*batch_size]
yield (input_batch, output_batch)
train_gen = train_gen()
model2.fit_generator(train_gen, steps_per_epoch=x_train.shape[0]//batch_size, epochs=epochs)
score = model2.evaluate(x_test, y_test, verbose=0)
print('Test loss:', score[0])
print('Test accuracy:', score[1])
Test results
Epoch 1/12
468/468 [==============================] - 14s 30ms/step - loss: 0.2682 - acc: 0.9176
Epoch 2/12
468/468 [==============================] - 10s 21ms/step - loss: 0.0904 - acc: 0.9732
Epoch 3/12
468/468 [==============================] - 10s 21ms/step - loss: 0.0654 - acc: 0.9805
Epoch 4/12
468/468 [==============================] - 9s 19ms/step - loss: 0.0544 - acc: 0.9836
Epoch 5/12
468/468 [==============================] - 8s 17ms/step - loss: 0.0469 - acc: 0.9860
Epoch 6/12
468/468 [==============================] - 10s 21ms/step - loss: 0.0412 - acc: 0.9876
Epoch 7/12
468/468 [==============================] - 10s 21ms/step - loss: 0.0370 - acc: 0.9885
Epoch 8/12
468/468 [==============================] - 10s 21ms/step - loss: 0.0338 - acc: 0.9894
Epoch 9/12
468/468 [==============================] - 10s 21ms/step - loss: 0.0295 - acc: 0.9914
Epoch 10/12
468/468 [==============================] - 10s 21ms/step - loss: 0.0284 - acc: 0.9913
Epoch 11/12
468/468 [==============================] - 10s 21ms/step - loss: 0.0261 - acc: 0.9917
Epoch 12/12
468/468 [==============================] - 10s 21ms/step - loss: 0.0238 - acc: 0.9925
Test loss: 0.031697582448167304
Test accuracy: 0.9914
model.train_on_batch
batch_size = 1
model3 = Sequential()
model3.add(Conv2D(32, kernel_size=(3, 3),
activation='relu',
input_shape=input_shape))
model3.add(Conv2D(64, (3, 3), activation='relu'))
model3.add(MaxPooling2D(pool_size=(2, 2)))
model3.add(Dropout(0.25))
model3.add(Flatten())
model3.add(Dense(128, activation='relu'))
model3.add(Dropout(0.5))
model3.add(Dense(num_classes, activation='softmax'))
model3.compile(loss=keras.losses.categorical_crossentropy,
optimizer=keras.optimizers.Adadelta(),
metrics=['accuracy'])
def train_gen(batch_size=batch_size, x_train=x_train, y_train=y_train):
while True:
permute = np.random.permutation(np.shape(x_train)[0])
x_train = x_train[permute]
y_train = y_train[permute]
numBatch = x_train.shape[0] // batch_size
for idx in range(numBatch):
input_batch = x_train[idx*batch_size:(idx+1)batch_size]
output_batch = y_train[idxbatch_size:(idx+1)*batch_size]
yield (input_batch, output_batch)
train_gen = train_gen()
for epoch in range(epochs):
losses = []
for idx in range(x_train.shape[0]//batch_size):
batch_input, batch_output = next(train_gen)
loss = model3.train_on_batch(batch_input, batch_output)
losses.append(loss)
print("Mean loss is epoch {0} is {1}".format(epoch+1, np.mean(np.array(losses))))
score = model3.evaluate(x_test, y_test, verbose=0)
print('Test loss:', score[0])
print('Test accuracy:', score[1])
Test results
Mean loss is epoch 1 is 0.5734186172485352
Mean loss is epoch 2 is 0.5600767731666565
Mean loss is epoch 3 is 0.5610676407814026
Mean loss is epoch 4 is 0.5658792853355408
Mean loss is epoch 5 is 0.5709021687507629
Mean loss is epoch 6 is 0.5857939720153809
Mean loss is epoch 7 is 0.5922616124153137
Mean loss is epoch 8 is 0.6110633611679077
Mean loss is epoch 9 is 0.6241153478622437
Mean loss is epoch 10 is 0.6426184177398682
Mean loss is epoch 11 is 0.6563357710838318
Mean loss is epoch 12 is 0.6723470687866211
Test loss: 0.18805254324528078
Test accuracy: 0.9648
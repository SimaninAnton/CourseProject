Collaborator
robieta commented on 24 Jan 2018
I have observed an issue with layers using inferred dtypes rather than explicit ones. The code I provide is for the Conv1D layer, however I observe the same issue for Conv2D and LSTM layers. I am running Keras 2.1.3 with TensorFlow 1.4.0 backend. I am ran the code on a Windows 10 machine, using Python 3.6.0. All computations used the CPU. The following code causes an exception (I will put the full stack trace at the end):
import keras
print("Keras version: ", keras.__version__)
dtype="float16"
input_layer = keras.layers.Input(shape=(10, 5), dtype=dtype)
print("input_layer: ", input_layer)
conv_layer = keras.layers.Conv1D(10, 2, input_dtype=dtype, dtype=dtype)(input_layer) # <<Fails here
print("conv_layer:", conv_layer)
Changing the dtype to "float32" or changing the "floatx" field to "float16" in my ~/.keras/keras.json produces correct results. Similarly, setting dtype to "float32" and setting "floatx" to "float16" also produces an error.
Using the tensorflow implementation of keras works as expected (run with "floatx" set to "float32"):
from tensorflow import keras
import tensorflow as tf
print("TensorFlow version:", tf.__version__)
print("Keras version: ", keras.__version__)
dtype="float16"
input_layer = keras.layers.Input(shape=(10, 5), dtype=dtype)
print("input_layer: ", input_layer)
# The input_dtype argument is not present in the tensorflow implementation of keras
conv_layer = keras.layers.Conv1D(10, 2, dtype=dtype)(input_layer)
print("conv_layer: ", conv_layer)
Output:
TensorFlow version: 1.4.0
Keras version: 2.0.8-tf
input_layer: Tensor("input_1:0", shape=(?, 10, 5), dtype=float16)
conv_layer: Tensor("conv1d/BiasAdd:0", shape=(?, 9, 10), dtype=float16)
Reverting to keras version 2.0.8 (to match the tensorflow implementation) does not resolve the issue.
Code (repeated from above) and stack trace of problematic case:
import keras
print("Keras version: ", keras.__version__)
dtype="float16"
input_layer = keras.layers.Input(shape=(10, 5), dtype=dtype)
print("input_layer: ", input_layer)
conv_layer = keras.layers.Conv1D(10, 2, input_dtype=dtype, dtype=dtype)(input_layer)
print("conv_layer:", conv_layer)
Using TensorFlow backend.
Keras version: 2.1.3
input_layer: Tensor("input_1:0", shape=(?, 10, 5), dtype=float16)
Traceback (most recent call last):
File "C:\Users\rdxhm\AppData\Local\Continuum\Anaconda3\lib\site-packages\tensorflow\python\framework\op_def_library.py", line 510, in _apply_op_helper
preferred_dtype=default_dtype)
File "C:\Users\rdxhm\AppData\Local\Continuum\Anaconda3\lib\site-packages\tensorflow\python\framework\ops.py", line 926, in internal_convert_to_tensor
ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
File "C:\Users\rdxhm\AppData\Local\Continuum\Anaconda3\lib\site-packages\tensorflow\python\framework\ops.py", line 774, in _TensorTensorConversionFunction
(dtype.name, t.dtype.name, str(t)))
ValueError: Tensor conversion requested dtype float16 for Tensor with dtype float32: 'Tensor("conv1d_1/convolution/ExpandDims_1:0", shape=(1, 2, 5, 10), dtype=float32)'
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
File "C:/Users/rdxhm/.PyCharmCE2017.2/config/scratches/scratch_15.py", line 7, in
conv_layer = keras.layers.Conv1D(10, 2, input_dtype=dtype, dtype=dtype)(input_layer)
File "C:\Users\rdxhm\AppData\Local\Continuum\Anaconda3\lib\site-packages\keras\engine\topology.py", line 617, in call
output = self.call(inputs, **kwargs)
File "C:\Users\rdxhm\AppData\Local\Continuum\Anaconda3\lib\site-packages\keras\layers\convolutional.py", line 160, in call
dilation_rate=self.dilation_rate[0])
File "C:\Users\rdxhm\AppData\Local\Continuum\Anaconda3\lib\site-packages\keras\backend\tensorflow_backend.py", line 3294, in conv1d
data_format=tf_data_format)
File "C:\Users\rdxhm\AppData\Local\Continuum\Anaconda3\lib\site-packages\tensorflow\python\ops\nn_ops.py", line 751, in convolution
return op(input, filter)
File "C:\Users\rdxhm\AppData\Local\Continuum\Anaconda3\lib\site-packages\tensorflow\python\ops\nn_ops.py", line 835, in call
return self.conv_op(inp, filter)
File "C:\Users\rdxhm\AppData\Local\Continuum\Anaconda3\lib\site-packages\tensorflow\python\ops\nn_ops.py", line 499, in call
return self.call(inp, filter)
File "C:\Users\rdxhm\AppData\Local\Continuum\Anaconda3\lib\site-packages\tensorflow\python\ops\nn_ops.py", line 187, in call
name=self.name)
File "C:\Users\rdxhm\AppData\Local\Continuum\Anaconda3\lib\site-packages\tensorflow\python\ops\nn_ops.py", line 177, in _conv1d
data_format=data_format, name=name)
File "C:\Users\rdxhm\AppData\Local\Continuum\Anaconda3\lib\site-packages\tensorflow\python\ops\nn_ops.py", line 2204, in conv1d
data_format=data_format)
File "C:\Users\rdxhm\AppData\Local\Continuum\Anaconda3\lib\site-packages\tensorflow\python\ops\gen_nn_ops.py", line 630, in conv2d
data_format=data_format, name=name)
File "C:\Users\rdxhm\AppData\Local\Continuum\Anaconda3\lib\site-packages\tensorflow\python\framework\op_def_library.py", line 546, in _apply_op_helper
inferred_from[input_arg.type_attr]))
TypeError: Input 'filter' of 'Conv2D' Op has type float32 that does not match type float16 of argument 'input'.
foolkk commented on 20 Feb 2017
I was running it on my PC, which is on CPU. the 'frozen_model' takes longer time than the original 'trainable_model'.
A. when freeze the output layer,
model.add(Dropout(0.5))
model.add(Dense(nb_classes, trainable=False)) // freeze the output layer
model.add(Activation('softmax'))
Result A: much longer running time and very bad performance as compared to the original code
B. when freeze the 2nd conv layer
model.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1], trainable = False)) // freeze conv_layer
Result B : triple the running time, and compromising accuracy by 5%.
Accuracy aside, I was expecting a shorter running time. But apparently the result states otherwise. Why is this so?
----------------------- END ------------------
Please make sure that the boxes below are checked before you submit your issue. If your issue is an implementation question, please ask your question on StackOverflow or join the Keras Slack channel and ask there instead of filing a GitHub issue.
Thank you!
Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps
If running on TensorFlow, check that you are up-to-date with the latest version. The installation instructions can be found here.
If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps
Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
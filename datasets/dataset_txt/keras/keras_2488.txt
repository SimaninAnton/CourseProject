integrallyclosed commented on 3 May 2017 â€¢
edited
Hi,
I am training a text classification model with Embedding as the first layer. I am initializing this layer with pre-trained embeddings that were learnt on a much larger dataset and consequently have a larger vocabulary. Once the model is trained, the embeddings layer only has weights corresponding to the vocabulary of the training data. At prediction, time when I encounter a word not in the training data, it gets assigned an out of vocabulary index and cannot use weights from pre trained embeddings even if the word exists in there. Is there any way around this?
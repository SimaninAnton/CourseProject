cancan101 commented on 27 Feb 2016
GIST: https://gist.github.com/cancan101/1b4ad67d01b17fc8779d
When I run with:
    model.fit(
        X_train, Y_train, batch_size=8,
        nb_epoch=200,
        validation_data=(ret_valid['X'], ret_valid['y']))
I have no problem with running out of GPU RAM. However when I run with:
    datagen = ImageDataGenerator(featurewise_center=False, featurewise_std_normalization=False)
    datagen.fit(X_train)

    model.fit_generator(
        datagen.flow(X_train, Y_train, batch_size=8),
        samples_per_epoch=len(X_train),
        nb_epoch=200,
        validation_data=(ret_valid['X'], ret_valid['y']))
I get:
Epoch 1/200
1064/1067 [============================>.] - ETA: 0s - loss: 0.0359Traceback (most recent call last):
  File "src/proj/scripts/keras0.py", line 152, in <module>
    main()
  File "src/proj/scripts/keras0.py", line 144, in main
    validation_data=(ret_valid['X'], ret_valid['y']))
  File "/home/ubuntu/.virtualenvs/alex/local/lib/python2.7/site-packages/keras/models.py", line 1150, in fit_generator
    verbose=0)
  File "/home/ubuntu/.virtualenvs/alex/local/lib/python2.7/site-packages/keras/models.py", line 766, in evaluate
    outs = self._test_loop(f, ins, batch_size, verbose)
  File "/home/ubuntu/.virtualenvs/alex/local/lib/python2.7/site-packages/keras/models.py", line 383, in _test_loop
    batch_outs = f(ins_batch)
  File "/home/ubuntu/.virtualenvs/alex/local/lib/python2.7/site-packages/keras/backend/theano_backend.py", line 448, in __call__
    return self.function(*inputs)
  File "/home/ubuntu/.virtualenvs/alex/local/lib/python2.7/site-packages/theano/compile/function_module.py", line 871, in __call__
    storage_map=getattr(self.fn, 'storage_map', None))
  File "/home/ubuntu/.virtualenvs/alex/local/lib/python2.7/site-packages/theano/gof/link.py", line 314, in raise_with_op
    reraise(exc_type, exc_value, exc_trace)
  File "/home/ubuntu/.virtualenvs/alex/local/lib/python2.7/site-packages/theano/compile/function_module.py", line 859, in __call__
    outputs = self.fn()
MemoryError: Error allocating 1920466944 bytes of device memory (CNMEM_STATUS_OUT_OF_MEMORY).
Apply node that caused the error: GpuAllocEmpty(Shape_i{0}.0, Shape_i{0}.0, Elemwise{Composite{((i0 + i1) - (i2 + i3))}}[(0, 1)].0, Elemwise{Composite{((i0 + i1) - (i2 + i3))}}[(0, 1)].0)
Toposort index: 95
Inputs types: [TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar)]
Inputs shapes: [(), (), (), ()]
Inputs strides: [(), (), (), ()]
Inputs values: [array(128), array(32), array(296), array(396)]
Outputs clients: [[GpuDnnConv{algo='small', inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode='valid', subsample=(1, 1), conv_mode='conv', precision='float32'}.0, Constant{1.0}, Constant{0.0})]]
As far as I can tell, I have turned off any augmentation in the generator. Regarldess, I don't understand why it would allocate more GPU RAM.
Please make sure that the boxes below are checked before you submit your issue. Thank you!
Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps
If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps
Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
Contributor
ipod825 commented on 15 Mar 2016
Currently, when a layer is the first layer in the model, we need to add the input_dim or the input_shape argument since the input size induction mechanism does not work with the first layer.
I think the drawback of such design is that when a new layer is added to Keras, developer always needs to remember to add things such as (copy from the Dense layer):
self.input_dim = input_dim                                                                                                    
if self.input_dim:
     kwargs['input_shape'] = (self.input_dim,)
Another drawback is that when a user use containers.Sequential to build his model, he also needs to add input_dim or input_shape for the first layer for the container (as in #1542)
I suppose that this things is not well documented and might be confusing to the users.
If we add a layer called Input with an argument shape and simply let the input size induction mechanism works itself, we would get rid of input_dim and input_shape arguments for all layers.
Also, I think it's more nature for users to remember to add shape argument for a layer named Input instead of to remember whether they are adding the first layer.
1
sameermanek commented on 19 May 2017
It'd be useful if there was some batch-level logging in TensorBoard when using the TensorBoard callback (as defined in keras/callbacks.py). I think this'd be generally useful when trying to keep track of stats between epochs.
As an example, there could be a new boolean argument write_batch_performance in the init() method, and a new on_batch_end method, something like:
    def on_batch_end(self, batch, logs=None):
        logs = logs or {}

        if self.write_batch_performance == True:
            for name, value in logs.items():
                if name in ['batch','size']:
                    continue
                summary = tf.Summary()
                summary_value = summary.value.add()
                summary_value.simple_value = value.item()
                summary_value.tag = name
                self.writer.add_summary(summary, self.seen)
            self.writer.flush()

        self.seen += self.batch_size
I have a basic version of this locally; I'd need to slightly clean it up and incorporate it into the unit tests. Happy to do so if it makes sense to incorporate into keras. I couldn't find any matching outstanding feature requests.
Thanks!
32
9
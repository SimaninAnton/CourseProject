sanjeevmk commented on 2 May 2016
I have a training set of M samples, each being an N-dimensional vector. Each of the N-dimensional vectors can be thought of as a sequence. That is, vector[0] to vector[N] can be thought of as 1 signal across N timesteps. I want to stack 1D convolution layers on this input. I'm using Keras for this, but I ran into some dimensionality mismatch issues.
Here's how I'm adding the first layer (1D convolution), N=15000, each vector has 15k dimensions or timesteps:
  model.add(Convolution1D(nb_filter=10,filter_length=30,input_dim=15000,activation='relu'))
This compiles fine. My training set is put into a list of lists, where each sublist is 1 training example of 15k length, and there are 1000 such examples. So, the training set X is a list of lists containing 1000 sublists, each of length 15k.
    len(X) = 1000
    len(X[0]) = 15000  
When I call model.fit(X,y) using this X and my training labels y, I get the following error:
'Wrong number of dimensions: expected 3, got 2 with shape (1000, 15000).')
I don't understand in what format Keras is expecting the input. Why is it expecting 3 dimensions? What should be the right way to feed in my training set?
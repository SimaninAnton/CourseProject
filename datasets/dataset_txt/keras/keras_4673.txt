Contributor
jnphilipp commented on 1 Aug 2016
I recently added batch normalization to my CNN. During training the validation loss and accuracy oscillate wildly. Has anyone an idea why?
    inputs = Input(shape=input_shape, name='input')
    x = inputs 
    for i in range(3): 
        x = Convolution2D(filters[0], 3, 3, border_mode='same', name='convolution2d%s_0' % i)(x) 
        x = BatchNormalization(axis=1)(x) 
        x = SReLU(name='srelu%s_0' % i)(x) 
        x = Convolution2D(filters[i], 3, 3, border_mode='same', name='convolution2d%s_1' % i)(x) 
        x = BatchNormalization(axis=1)(x) 
        x = SReLU(name='srelu%s_1' % i)(x) 
        x = Convolution2D(filters[i], 3, 3, border_mode='same', name='convolution2d%s_2' % i)(x) 
        x = BatchNormalization(axis=1)(x) 
        x = SReLU(name='srelu%s_2' % i)(x) 
        x = Convolution2D(filters[i], 3, 3, border_mode='same', subsample=(2, 2), name='convolution2d%s_3' % i)(x) 
        x = BatchNormalization(axis=1)(x) 
        x = SReLU(name='srelu%s_3' % i)(x) 

    x = Convolution2D(nb_classes, 4, 4, name='convolution2d3_0')(x) 
    x = BatchNormalization(axis=1)(x) 
    x = Flatten()(x)
    predictions = Activation('softmax')(x)

    model = Model(input=inputs, output=predictions)
    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])

    train_datagen = ImageDataGenerator(
        rotation_range=30,
        width_shift_range=0.2,
        height_shift_range=0.2,
        rescale=1./255,
        shear_range=0.3,
        fill_mode='nearest')
    train_generator = train_datagen.flow(X, y, batch_size=batch_size, shuffle=True)

    test_datagen = ImageDataGenerator(rescale=1./255)
    validation_generator = test_datagen.flow(X, y, batch_size=batch_size)

    history = cnn.fit_generator(train_generator, len(X), nb_epoch, validation_data=validation_generator, nb_val_samples=len(X))
danielhers commented on 6 Sep 2016
I am trying to implement a transition-based parser with Keras, similar to Chen & Manning (2014), but with BiLSTM features rather than just embeddings, as in Kiperwasser & Goldberg (2016) or Cross & Huang (2016).
So rather than feeding embeddings or enumerated words at each time step, I need to feed in the whole input sentence before starting to parse, run the BiLSTM on it, and then start parsing while peeking at the relevant indices in the input for each action.
In the following gist, implemented with the help of @farizrahman4u, I am defining a network that gets input of size (BATCH_SIZE, INPUT_LEN + OUTPUT_LEN, INPUT_NUM) and returns output of size (BATCH_SIZE, OUTPUT_LEN, OUTPUT_DIM).
https://gist.github.com/danielhers/e08d723fd1409eed9d79c2ea8c138c77
The first INPUT_LEN input time points represent enumerated words in a sentence (only the first element in the first axis is used), and the last OUTPUT_LEN represent "guidance" as to which indices in the sentences to look at for each output time point. Sort of like attention but with fixed indices rather than a distribution over the whole input. The output represents a distribution over OUTPUT_DIM possible actions (corresponding to parser transitions that modify the internal structures), where the action determines the INPUT_NUM indices for the next time step.
In the gist I am just giving random input and labels to simplify, but in my real code it's more complicated, of course.
Right now I am feeding a whole batch whenever I want to query the model, and then taking only the relevant time point out. This is obviously extremely wasteful, but I'm not sure how to make the model run only on one batch and one time point at a time. I could make it a stateful RNN, but then how would I feed in the input sentence?
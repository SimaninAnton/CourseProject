IFeelBloated commented on 2 Nov 2017 â€¢
edited
so I wanna do some block-wise greedy pre-training (similar to stacked autoencoders), say I got 2 blocks, BlockA and BlockB, I'm gonna have to train BlockA alone first, then load BlockA's weights into a larger net that has both BlockA and BlockB in it, and mark BlockA untrainable in that net, then train the rest (BlockB) of that larger net, it sounds about right but I'm getting dimension errors like ValueError: Dimension 0 in both shapes must be equal, but are 9 and 1 for 'Assign_6' (op: 'Assign') with input shapes: [9,9,128,1], [1,64,9,9].
test code:
from keras import models, layers, optimizers
PatternSize = 159
Margin = 36

def GetBlockA():
    HiFreqGuess = layers.Input(shape=(PatternSize, PatternSize, 1))
    LowResBase = layers.Input(shape=(PatternSize - 2 * Margin, PatternSize - 2 * Margin, 1))
    
    Conv1a = layers.Conv2D(64, (3, 3), activation=None, padding='valid', name='c'+'1a')(HiFreqGuess)
    Conv1a = layers.advanced_activations.PReLU(shared_axes=[1, 2], name='r'+'1a')(Conv1a)
    Conv1b = layers.Conv2D(64, (3, 3), activation=None, padding='valid', name='c'+'1b')(Conv1a)
    Conv1b = layers.advanced_activations.PReLU(shared_axes=[1, 2], name='r'+'1b')(Conv1b)
    
    Ensemble = layers.Conv2D(1, (9, 9), activation=None, use_bias=False, padding='valid', name='Ensemble')(layers.convolutional.Cropping2D(30)(Conv1b))
    HighResolutionPatterns = layers.add([LowResBase, Ensemble])
    
    Model = models.Model(inputs=[HiFreqGuess, LowResBase], outputs=HighResolutionPatterns)
    Model.compile(loss='mse', optimizer=optimizers.Adam(lr=1e-4, decay=5e-4))
    return Model

def GetBlockB():
    HiFreqGuess = layers.Input(shape=(PatternSize, PatternSize, 1))
    LowResBase = layers.Input(shape=(PatternSize - 2 * Margin, PatternSize - 2 * Margin, 1))
    
    Conv1a = layers.Conv2D(64, (3, 3), activation=None, padding='valid', name='c'+'1a', trainable=False)(HiFreqGuess)
    Conv1a = layers.advanced_activations.PReLU(shared_axes=[1, 2], name='r'+'1a', trainable=False)(Conv1a)
    Conv1b = layers.Conv2D(64, (3, 3), activation=None, padding='valid', name='c'+'1b', trainable=False)(Conv1a)
    Conv1b = layers.advanced_activations.PReLU(shared_axes=[1, 2], name='r'+'1b', trainable=False)(Conv1b)

    Conv2 = layers.Conv2D(128, (3, 3), activation=None, padding='valid', name='c'+'2a')(Conv1b)
    Conv2 = layers.advanced_activations.PReLU(shared_axes=[1, 2], name='r'+'2a')(Conv2)
    
    Ensemble = layers.Conv2D(1, (9, 9), activation=None, use_bias=False, padding='valid', name='Ensemble')(layers.convolutional.Cropping2D(29)(Conv2))
    HighResolutionPatterns = layers.add([LowResBase, Ensemble])
    
    Model = models.Model(inputs=[HiFreqGuess, LowResBase], outputs=HighResolutionPatterns)
    Model.load_weights('BlockA.h5', by_name=True)
    Model.compile(loss='mse', optimizer=optimizers.Adam(lr=1e-4, decay=5e-4))
    return Model

ModelA = Model.GetBlockA()
ModelA.fit([HiFreq, Base], Target, epochs=50)
ModelA.save_weights('BlockA.h5')

ModelB = Model.GetBlockB()
ModelB.fit([HiFreq, Base], Target, epochs=50) #Error!
keras version: 2.0.8
keras.json:
{
    "floatx": "float32",
    "epsilon": 1e-07,
    "backend": "tensorflow",
    "image_data_format": "channels_last"
}
Am I doing something wrong? or is it like... some kind of bug?, the error would disappear immediately if I comment out "Model.load_weights('BlockA.h5', by_name=True)" in GetBlockB()
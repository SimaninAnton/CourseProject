zhaopku commented on 27 Jul 2016
I'm training a single-layer LSTM on a sentence classification task. Each sentence has two labels: pos/neg. But as I train the model, the training acc and loss do decrease, but the val_loss becomes higher, which is quite weird. Here is my code (I use pre-trained word embeddings):
model = Sequential()
model.add(Embedding(total_words + 1, EMBEDDING_DIM, weights = [embeddings_matrix], input_length = MAX_SEQUENCE_LENGTH,
                            trainable = True, mask_zero = True))
model.add(LSTM(100, return_sequences = False))
#model.add(Dense(1))
#model.add(Activation('sigmoid'))
model.add(Dense(2, activation='softmax'))

sgd = SGD(lr = 0.1, decay = 1e-6, momentum = 0.9, nesterov = True)
model.compile(loss = 'binary_crossentropy', optimizer = sgd, metrics = ['acc'])

model.fit(train_x, train_y, validation_data = (cv_x, cv_y), nb_epoch = 50, batch_size = 50)
score, acc = model.evaluate(test_x, test_y, batch_size = 100)
part of the result:
Train on 8529 samples, validate on 1067 samples
Epoch 1/50
8529/8529 [==============================] - 37s - loss: 0.6966 - acc: 0.5301 - val_loss: 0.7023 - val_acc: 0.5089
Epoch 2/50
8529/8529 [==============================] - 32s - loss: 0.6780 - acc: 0.5763 - val_loss: 0.7338 - val_acc: 0.5098
Epoch 3/50
8529/8529 [==============================] - 33s - loss: 0.6549 - acc: 0.6113 - val_loss: 0.7129 - val_acc: 0.5220
Epoch 4/50
8529/8529 [==============================] - 33s - loss: 0.6216 - acc: 0.6576 - val_loss: 0.7478 - val_acc: 0.5267
Epoch 5/50
8529/8529 [==============================] - 33s - loss: 0.5766 - acc: 0.6959 - val_loss: 0.8012 - val_acc: 0.5323
Epoch 6/50
8529/8529 [==============================] - 32s - loss: 0.5153 - acc: 0.7422 - val_loss: 0.8858 - val_acc: 0.5361
Epoch 7/50
8529/8529 [==============================] - 33s - loss: 0.4449 - acc: 0.7940 - val_loss: 0.8978 - val_acc: 0.5211
Epoch 8/50
8529/8529 [==============================] - 34s - loss: 0.3561 - acc: 0.8428 - val_loss: 1.1019 - val_acc: 0.5127
Epoch 9/50
8529/8529 [==============================] - 34s - loss: 0.2648 - acc: 0.8893 - val_loss: 1.1911 - val_acc: 0.5258
Epoch 10/50
1250/8529 [===>..........................] - ETA: 27s - loss: 0.1780 - acc: 0.9400^CTraceback (most recent call last):
Contributor
rodrigob commented on 31 Aug 2015
Running python3 mnist_cnn.py with latest Keras and Theano results in
> python3 mnist_cnn.py 
Using gpu device 0: Quadro K2000M (CNMeM is disabled)
X_train shape: (60000, 1, 28, 28)
60000 train samples
10000 test samples
Train on 60000 samples, validate on 10000 samples
Epoch 0
60000/60000 [==============================] - 290s - loss: 2.7128 - acc: 0.7091 - val_loss: 0.1638 - val_acc: 0.9501
Epoch 1
60000/60000 [==============================] - 289s - loss: 7.7192 - acc: 0.4924 - val_loss: 15.5040 - val_acc: 0.0381
Epoch 2
60000/60000 [==============================] - 288s - loss: 15.4231 - acc: 0.0431 - val_loss: 15.5040 - val_acc: 0.0381
Epoch 3
60000/60000 [==============================] - 289s - loss: 15.4266 - acc: 0.0429 - val_loss: 15.5040 - val_acc: 0.0381
Epoch 4
60000/60000 [==============================] - 289s - loss: 15.4266 - acc: 0.0429 - val_loss: 15.5040 - val_acc: 0.0381
To my understanding this means "not learning".
python3 mnist_mlp.py works fine
Epoch 19
2s - loss: 0.0416 - acc: 0.9861 - val_loss: 0.0677 - val_acc: 0.9815
Test score: 0.0677454245182
Test accuracy: 0.9815
My .theanorc looks like
[global]
mode = FAST_RUN
floatX = float32
device = gpu0

openmp = True

[nvcc]
fastmath = True
prinsherbert commented on 16 Jun 2016
I've seen some one-hot encoders in Theano and Keras code sniplets, for example in this Char-RNN(/LSTM) snipplet:
https://github.com/fchollet/keras/blob/master/examples/lstm_text_generation.py#L42
Very often one-hot encoded vectors are multiplied with a matrix, which simply extracts one row or column, depending on the order of the operands. This made me wonder why there are no indexing-layers and in particular why keras.layers.LSTM expects a one-hot encoded 2D input, instead of a index-encoded 1D input?
As similarly, sparse_categorical_crossentropy allows one to use more memory efficient targets w.r.t categorical_crossentropy, and 'Embeddingis a more input memory efficient version ofDense` when applied to one-hot encoded data.
Or am I missing something?
2
around1991 commented on 3 Jul 2016
Hi all
I'd like to extend the backend RNN function so that one can pass in precomputed initial states to use for the RNN recurrence. This is helpful for image captioning, among other things (pass your image through a convnet, set the RNN initial state to the convnet output, and let your RNN language model loose).
On the face of it, this seems easy enough: just add an initial_states argument to the Recurrent base class, and pass this through to the initial_states argument of K.rnn. However, it seems that Keras doesn't notice the layers that go into computing the initial states, and doesn't update the weights of these layers. Does anyone have an idea of a clean way of enhancing Keras to provide this functionality?
Kris
3
Maxfashko commented on 4 May 2017 â€¢
edited
Hello! I use the "UNet" network for semantic segmentation. The network "UNet" was used in the competition "kaggle ultra nerve". An example of implementing this neural network architecture is here:
https://github.com/jocicmarko/ultrasound-nerve-segmentation
For training, I prepared the data from Toronto's dataset:
https://www.cs.toronto.edu/~vmnih/data/"
I pre-cut the image of the original size 1500 * 1500 into smaller pictures with the size 96 * 96 and converted them into the format "* npy".
As a result of learning the neural network on my data, after the 1st, 5th, 20th era, I run a test on the test images. I get a completely gray picture, instead of a binary mask.
What could be the reason for this prediction? If I use the data used by the author of the above code, I get binary masks. Does anyone have any idea what might be the reason?
pred:

img:

label:
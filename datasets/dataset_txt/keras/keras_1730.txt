xionghan7427 commented on 16 Aug 2017 â€¢
edited
I am following the instruction on: http://machinelearningmastery.com/evaluate-performance-deep-learning-models-keras/ to do performance evaluation and found that with some data sets the training just does not show any progress. Here is the revised code from that website to reproduce the issue:
MLP with manual validation set
from keras.models import Sequential
from keras.layers import Dense
#from sklearn.model_selection import train_test_split
import numpy
fix random seed for reproducibility
seed = 7
numpy.random.seed(seed)
load pima indians dataset
dataset = numpy.loadtxt("pima-indians-diabetes.csv", delimiter=",")
split into input (X) and output (Y) variables
X = dataset[:100,0:8]
Y = dataset[:100,8]
split into 90% for train and 10% for test without shuffling the dataset
#X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=seed)
X_train=X[0:90,:]
y_train=Y[0:90]
X_test=X[90:,:]
y_test=Y[90:]
create model
model = Sequential()
model.add(Dense(12, input_dim=8, activation='relu'))
model.add(Dense(8, activation='relu'))
model.add(Dense(1, activation='sigmoid'))
Compile model
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
Fit the model
model.fit(X_train, y_train, validation_data=(X_test,y_test), epochs=150, batch_size=10)
and here is the output from the screen:
Epoch 135/150
90/90 [==============================] - 0s - loss: 6.2681 - acc: 0.6111 - val_loss: 3.2236 - val_acc: 0.8000
Epoch 136/150
90/90 [==============================] - 0s - loss: 6.2681 - acc: 0.6111 - val_loss: 3.2236 - val_acc: 0.8000
Epoch 137/150
90/90 [==============================] - 0s - loss: 6.2681 - acc: 0.6111 - val_loss: 3.2236 - val_acc: 0.8000
Epoch 138/150
90/90 [==============================] - 0s - loss: 6.2681 - acc: 0.6111 - val_loss: 3.2236 - val_acc: 0.8000
Epoch 139/150
90/90 [==============================] - 0s - loss: 6.2681 - acc: 0.6111 - val_loss: 3.2236 - val_acc: 0.8000
Epoch 140/150
90/90 [==============================] - 0s - loss: 6.2681 - acc: 0.6111 - val_loss: 3.2236 - val_acc: 0.8000
Epoch 141/150
90/90 [==============================] - 0s - loss: 6.2681 - acc: 0.6111 - val_loss: 3.2236 - val_acc: 0.8000
Epoch 142/150
90/90 [==============================] - 0s - loss: 6.2681 - acc: 0.6111 - val_loss: 3.2236 - val_acc: 0.8000
Epoch 143/150
90/90 [==============================] - 0s - loss: 6.2681 - acc: 0.6111 - val_loss: 3.2236 - val_acc: 0.8000
Epoch 144/150
90/90 [==============================] - 0s - loss: 6.2681 - acc: 0.6111 - val_loss: 3.2236 - val_acc: 0.8000
Epoch 145/150
90/90 [==============================] - 0s - loss: 6.2681 - acc: 0.6111 - val_loss: 3.2236 - val_acc: 0.8000
Epoch 146/150
90/90 [==============================] - 0s - loss: 6.2681 - acc: 0.6111 - val_loss: 3.2236 - val_acc: 0.8000
Epoch 147/150
90/90 [==============================] - 0s - loss: 6.2681 - acc: 0.6111 - val_loss: 3.2236 - val_acc: 0.8000
Epoch 148/150
90/90 [==============================] - 0s - loss: 6.2681 - acc: 0.6111 - val_loss: 3.2236 - val_acc: 0.8000
Epoch 149/150
90/90 [==============================] - 0s - loss: 6.2681 - acc: 0.6111 - val_loss: 3.2236 - val_acc: 0.8000
Epoch 150/150
90/90 [==============================] - 0s - loss: 6.2681 - acc: 0.6111 - val_loss: 3.2236 - val_acc: 0.8000
essentially there is no progress showing while training with this data set, However, if I randomly shuffle the data and split the training set and test set with 67% and 33%, then the training went on smoothly. I was wondering what could cause this kind of issue.
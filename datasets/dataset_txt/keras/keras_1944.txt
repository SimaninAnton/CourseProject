datwelk commented on 12 Jul 2017
I'm trying to implement Monte-Carlo sampling in keras within the loss function of my variational auto-encoder model. I am using the tensorflow backend.
I want to approximate the expectation of a distribution in y w.r.t. a distribution in z -> the parameters of this distribution in z are determined by a keras model, within my greater VAE model, that takes y as input. I can sample y inside the loss function of my VAE, but I am not sure how to transform this sample of y to obtain the parametrization of the distribution in z. This sample y needs to run through my submodel to obtain the parameters of the distribution in z. Thus I am effectively looking for a way to repeatedly run a part of my computation graph inside the loss function. I have tried using session.run(), but I get an error saying there is no value fed to the VAE input layer (quite surprising that in the loss function, the model's input tensor does not have a value...).
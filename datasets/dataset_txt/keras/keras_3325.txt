al3xsh commented on 1 Feb 2017
I have pretty much the same issue as #4669 (and exactly the same issue as @olivierhub) using the latest version of cifar10_cnn.py (commit 309f586).
It occurs using both the tensorflow backend and the theano backend. I am using:
Keras (1.2.1)
tensorflow (0.11.0)
Theano (0.8.2)
The output of my first 10 epochs using rmsprop is:
Epoch 1/200
50000/50000 [==============================] - 18s - loss: 1.6163 - acc: 0.4084 - val_loss: 1.1957 - val_acc: 0.5680
Epoch 2/200
50000/50000 [==============================] - 16s - loss: 1.2506 - acc: 0.5572 - val_loss: 1.0052 - val_acc: 0.6513
Epoch 3/200
50000/50000 [==============================] - 16s - loss: 1.1442 - acc: 0.6029 - val_loss: 1.2103 - val_acc: 0.5900
Epoch 4/200
50000/50000 [==============================] - 16s - loss: 1.1237 - acc: 0.6146 - val_loss: 0.9753 - val_acc: 0.6592
Epoch 5/200
50000/50000 [==============================] - 16s - loss: 1.1419 - acc: 0.6157 - val_loss: 1.2223 - val_acc: 0.6206
Epoch 6/200
50000/50000 [==============================] - 16s - loss: 1.1594 - acc: 0.6123 - val_loss: 1.2934 - val_acc: 0.5900
Epoch 7/200
50000/50000 [==============================] - 16s - loss: 1.1765 - acc: 0.6132 - val_loss: 1.2739 - val_acc: 0.5975
Epoch 8/200
50000/50000 [==============================] - 16s - loss: 1.2114 - acc: 0.6021 - val_loss: 1.2458 - val_acc: 0.5781
Epoch 9/200
50000/50000 [==============================] - 16s - loss: 1.2510 - acc: 0.5968 - val_loss: 1.1632 - val_acc: 0.6181
Epoch 10/200
50000/50000 [==============================] - 16s - loss: 1.2727 - acc: 0.5888 - val_loss: 1.1405 - val_acc: 0.6193
If I change to the adam optimizer I see convergence (but don't get anywhere near the quoted test logloss of 0.55 after 50 epochs (or even after 200). The output using the adam optimizer is:
Epoch 1/200
50000/50000 [==============================] - 19s - loss: 1.5838 - acc: 0.4166 - val_loss: 1.1944 - val_acc: 0.5750
Epoch 2/200
50000/50000 [==============================] - 17s - loss: 1.2323 - acc: 0.5597 - val_loss: 0.9938 - val_acc: 0.6481
Epoch 3/200
50000/50000 [==============================] - 17s - loss: 1.0958 - acc: 0.6116 - val_loss: 0.9272 - val_acc: 0.6728
Epoch 4/200
50000/50000 [==============================] - 17s - loss: 1.0040 - acc: 0.6442 - val_loss: 0.8661 - val_acc: 0.6956
Epoch 5/200
50000/50000 [==============================] - 17s - loss: 0.9557 - acc: 0.6633 - val_loss: 0.8207 - val_acc: 0.7112
Epoch 6/200
50000/50000 [==============================] - 17s - loss: 0.9136 - acc: 0.6798 - val_loss: 0.7965 - val_acc: 0.7232
Epoch 7/200
50000/50000 [==============================] - 17s - loss: 0.8924 - acc: 0.6891 - val_loss: 0.7561 - val_acc: 0.7332
Epoch 8/200
50000/50000 [==============================] - 17s - loss: 0.8595 - acc: 0.6972 - val_loss: 0.7483 - val_acc: 0.7355
Epoch 9/200
50000/50000 [==============================] - 17s - loss: 0.8466 - acc: 0.7040 - val_loss: 0.6868 - val_acc: 0.7622
Epoch 10/200
50000/50000 [==============================] - 17s - loss: 0.8258 - acc: 0.7097 - val_loss: 0.7217 - val_acc: 0.7406
Epoch 11/200
50000/50000 [==============================] - 16s - loss: 0.8235 - acc: 0.7112 - val_loss: 0.6927 - val_acc: 0.7629
Epoch 12/200
50000/50000 [==============================] - 17s - loss: 0.8066 - acc: 0.7173 - val_loss: 0.6813 - val_acc: 0.7648
Epoch 13/200
50000/50000 [==============================] - 16s - loss: 0.7941 - acc: 0.7206 - val_loss: 0.6608 - val_acc: 0.7696
Epoch 14/200
50000/50000 [==============================] - 16s - loss: 0.7870 - acc: 0.7248 - val_loss: 0.6551 - val_acc: 0.7733
Epoch 15/200
50000/50000 [==============================] - 17s - loss: 0.7841 - acc: 0.7255 - val_loss: 0.6516 - val_acc: 0.7758
Epoch 16/200
50000/50000 [==============================] - 17s - loss: 0.7751 - acc: 0.7297 - val_loss: 0.6302 - val_acc: 0.7859
Epoch 17/200
50000/50000 [==============================] - 17s - loss: 0.7683 - acc: 0.7333 - val_loss: 0.6372 - val_acc: 0.7793
Epoch 18/200
50000/50000 [==============================] - 17s - loss: 0.7543 - acc: 0.7377 - val_loss: 0.6648 - val_acc: 0.7733
Epoch 19/200
50000/50000 [==============================] - 16s - loss: 0.7585 - acc: 0.7373 - val_loss: 0.6236 - val_acc: 0.7840
Epoch 20/200
50000/50000 [==============================] - 16s - loss: 0.7476 - acc: 0.7399 - val_loss: 0.6206 - val_acc: 0.7842
Epoch 21/200
50000/50000 [==============================] - 16s - loss: 0.7418 - acc: 0.7443 - val_loss: 0.6242 - val_acc: 0.7891
Epoch 22/200
50000/50000 [==============================] - 17s - loss: 0.7414 - acc: 0.7445 - val_loss: 0.6129 - val_acc: 0.7928
Epoch 23/200
50000/50000 [==============================] - 16s - loss: 0.7355 - acc: 0.7455 - val_loss: 0.6109 - val_acc: 0.7933
Epoch 24/200
50000/50000 [==============================] - 17s - loss: 0.7343 - acc: 0.7455 - val_loss: 0.6027 - val_acc: 0.7940
Epoch 25/200
50000/50000 [==============================] - 17s - loss: 0.7305 - acc: 0.7483 - val_loss: 0.6418 - val_acc: 0.7787

...

Epoch 50/200
50000/50000 [==============================] - 17s - loss: 0.6697 - acc: 0.7683 - val_loss: 0.5651 - val_acc: 0.8103

...

Epoch 200/200
50000/50000 [==============================] - 16s - loss: 0.6192 - acc: 0.7911 - val_loss: 0.5102 - val_acc: 0.8332
Any ideas how I can go about improving this accuracy or making rmsprop converge?
Regards,
Alex
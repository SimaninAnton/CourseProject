GitLele92 commented on 13 May 2017 â€¢
edited
Hi everyone, i got this problem, I'm using keras for some NLP stuff. i Trained my net, but even if i have over 89% of accuracy over model.evaluate I have 8% of accuracy when i check the data after predict. Here is the code
with open ("data\en-ud-train.conllu", encoding="utf8") as f:
    
    dataTrain = f.readlines()
myNewWords = []
X_train, Y_train, myNewWords = getXandY(dataTrain, myNewWords)

with open("data\en-ud-test.conllu", encoding="utf8") as f:
    dataTest = f.readlines()

X_test, Y_test, myNewWords = getXandY(dataTest, myNewWords)

model = Sequential()
model.add(Convolution1D(300, 3, activation='sigmoid', input_shape =(5,300)))
model.add(LSTM(52,input_shape =(5,300)))
model.add(Dropout(0.5))
model.add(Dense(17,activation='sigmoid'))
model.compile(loss='binary_crossentropy',
              optimizer='adam',
              metrics=['accuracy'],
              )


model.fit(np.asarray(X_train),np.asarray(Y_train),batch_size=32,nb_epoch=1, verbose = 1,validation_data=(np.asarray(X_test),np.asarray(Y_test)))

score = model.evaluate(np.asarray(X_test),np.asarray(Y_test), batch_size=32, verbose = 0)
print(model.metrics_names)
print(score[0])
print(score[1])


aTest = []
aTest.append(X_test[0])
anotherTest = []
anotherTest.append(Y_test[0])
aTest = np.array(aTest)
model.compile(loss='binary_crossentropy',
              optimizer='adam',
              metrics=['accuracy'],
              )

predictLabels =model.predict(np.asarray(X_test), batch_size = 32, verbose = 0)

count = 0
#print(Y_test[0])
for i in range(0,len(Y_test)):
    uguale = 1
    for k in range (0,len(Y_test[i])):
        predictLabels[i][k] = np.around(predictLabels[i][k])
        if((predictLabels[i][k])!=Y_test[i][k]):
            uguale = 0
            #print(i)
    if(uguale == 1):
        count = count + 1
    #print(predictLabels[i])
 

print(count/len(Y_test))
                     
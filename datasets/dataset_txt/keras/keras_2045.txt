waissbluth commented on 29 Jun 2017 â€¢
edited
I recently hit a MemoryError when using to_categorical(y) (with a big dataset, 'y.shape = (10000,256,256,4)', 16 categories). The error was in the line np.zeros((n, num_clases)), which, according to the numpy docs, defaults to numpy.float64.
I fixed the issue by calling np.zeros((n, num_clases), dtype=numpy.int8) instead. It could also be numpy.bool. Could there be any unforeseen side effects of this? Should I submit a pull request?
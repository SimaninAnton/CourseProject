YoelShoshan commented on 18 Oct 2016
I am seeing very different convergence results when using 'th' and 'tf' in keras config file.
On both cases I'm using tensorflow backend.
I am fully aware of the different convention of dimension ordering between theano and tensorflow, and (hopefully) handle it correctly as you can see in the following gist.
The bottom line is that I'm currently forced to use 'th' image_dim_ordering and "suffer" from extra copies which slow the training process
Here's the gist of a standalone single-file reproducing of the problem:
https://gist.github.com/YoelShoshan/3ed8f827685d130cd01fbf787821ee87
I tried to make sure it runs without any issues, and has no external dependencies.
On one case I'm using this keras config file:
{
    "floatx": "float32",
    "epsilon": 1e-07,
    "backend": "tensorflow",
    "image_dim_ordering": "th"  
}
In on the other case I switch the 'th' to 'tf'.
using 'th' converges significantly faster! (less iterations) and yes, I've tried many different random seeds.
on the 'th' this is a typical convergence scenario: (4 epochs till convergence)
Epoch 1/100
640/640 [==============================] - 3s - loss: 0.6891 - acc: 0.5594     
Epoch 2/100
640/640 [==============================] - 2s - loss: 0.6079 - acc: 0.7328     
Epoch 3/100
640/640 [==============================] - 2s - loss: 0.3166 - acc: 0.9422     
Epoch 4/100
640/640 [==============================] - 2s - loss: 0.1767 - acc: 0.9969  
and on 'tf' this is a typical convergence scenario: (27 epochs till convergence!)
Epoch 1/100
640/640 [==============================] - 1s - loss: 0.6932 - acc: 0.4781     
Epoch 2/100
640/640 [==============================] - 0s - loss: 0.6932 - acc: 0.4938     
Epoch 3/100
640/640 [==============================] - 0s - loss: 0.6921 - acc: 0.5203     
Epoch 4/100
640/640 [==============================] - 0s - loss: 0.6920 - acc: 0.5469     
Epoch 5/100
640/640 [==============================] - 0s - loss: 0.6935 - acc: 0.4875     
Epoch 6/100
640/640 [==============================] - 0s - loss: 0.6941 - acc: 0.4969     
Epoch 7/100
640/640 [==============================] - 0s - loss: 0.6937 - acc: 0.5047     
Epoch 8/100
640/640 [==============================] - 0s - loss: 0.6931 - acc: 0.5312     
Epoch 9/100
640/640 [==============================] - 0s - loss: 0.6923 - acc: 0.5250     
Epoch 10/100
640/640 [==============================] - 0s - loss: 0.6929 - acc: 0.5281     
Epoch 11/100
640/640 [==============================] - 0s - loss: 0.6934 - acc: 0.4953     
Epoch 12/100
640/640 [==============================] - 0s - loss: 0.6918 - acc: 0.5234     
Epoch 13/100
640/640 [==============================] - 0s - loss: 0.6930 - acc: 0.5125     
Epoch 14/100
640/640 [==============================] - 0s - loss: 0.6939 - acc: 0.4797     
Epoch 15/100
640/640 [==============================] - 0s - loss: 0.6936 - acc: 0.5047     
Epoch 16/100
640/640 [==============================] - 0s - loss: 0.6917 - acc: 0.4922     
Epoch 17/100
640/640 [==============================] - 0s - loss: 0.6945 - acc: 0.4891     
Epoch 18/100
640/640 [==============================] - 0s - loss: 0.6948 - acc: 0.5000     
Epoch 19/100
640/640 [==============================] - 0s - loss: 0.6968 - acc: 0.4594     
Epoch 20/100
640/640 [==============================] - 0s - loss: 0.6919 - acc: 0.5391     
Epoch 21/100
640/640 [==============================] - 0s - loss: 0.6904 - acc: 0.5172     
Epoch 22/100
640/640 [==============================] - 0s - loss: 0.6881 - acc: 0.5906     
Epoch 23/100
640/640 [==============================] - 0s - loss: 0.6804 - acc: 0.6359     
Epoch 24/100
640/640 [==============================] - 0s - loss: 0.6470 - acc: 0.8219     
Epoch 25/100
640/640 [==============================] - 0s - loss: 0.4134 - acc: 0.9625     
Epoch 26/100
640/640 [==============================] - 0s - loss: 0.2347 - acc: 0.9953     
Epoch 27/100
640/640 [==============================] - 0s - loss: 0.1231 - acc: 1.0000 
For simplification, all that the neural network needs to do in the gist that I provided, is to distinguish between patches containing only the value -1.0 and between patches containing only the value 1.0
This is a toy example, and it might be worst on actual examples.
Is this expected behavior or a bug?
Cheers and thanks for this awesome lib! :)
Yoel.
5
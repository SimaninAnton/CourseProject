GPistre commented on 27 Apr 2016 â€¢
edited
I am trying to implement pixel-wise image segmentation, but am having trouble figuring out to shape the network to get the right output.
I have X = n images of 60 * 80
and y = n binary matrices of the same size
In the simplest case, I would have:
model = Sequential()
model.add(Convolution2D(32, 3, 3, border_mode='same', input_shape=(1, X.shape[2], X.shape[3])))
model.add(Activation('sigmoid'))
sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)
model.compile(loss='binary_crossentropy', optimizer=sgd)
model.fit(X, y)
Which results in this:
Exception: A target array with shape (n, 60, 80) was passed for an output of shape (None, 32, 60, 80) while using as loss binary_crossentropy. This loss expects targets to have the same shape as the output.
And I cannot figure out which layers to add to get the right output.
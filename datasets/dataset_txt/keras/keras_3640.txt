PsychoGeek13 commented on 20 Dec 2016 â€¢
edited
Hello,
Please I'm trying to reproduce the work in this paper
http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Kendall_PoseNet_A_Convolutional_ICCV_2015_paper.pdf
I believe I managed to implement the network, the problem is that I have two outputs I need to apply the same objective function on them both at the same time, not each on its own
so,I tried Model(input=input, output = merge([output_1,output_2],mode='concat'))
where output_1 is a dense layer of length 3 , output_2 is of length 4
is it possible to define a loss function something like:
def customLoss(y_true,y_pred):
return np.linalg.norm(y_true[0:3]-y_pred[0:3])+BETA*np.linalg.norm(y_true[3:7]-y_pred[3:7]/np.linalg.norm(y_pred[3:7]))
when I try the above code as my custom loss function I get
ValueError: Input dimension mis-match. (input[0].shape[0] = 3, input[2].shape[0] = 4)
Apply node that caused the error: Elemwise{Composite{(i0 + (i1 * i2))}}(Elemwise{Composite{sqrt(sqr(i0))}}.0, TensorConstant{(1, 1) of 250.0}, Elemwise{Composite{sqrt(sqr(i0))}}.0)
Toposort index: 1045
Inputs types: [TensorType(float32, matrix), TensorType(float32, (True, True)), TensorType(float32, matrix)]
Inputs shapes: [(3, 7), (1, 1), (4, 7)]
Inputs strides: [(28, 4), (4, 4), (28, 4)]
Inputs values: ['not shown', array([[ 250.]], dtype=float32), 'not shown']
Outputs clients: [[Sum{axis=[1], acc_dtype=float64}(Elemwise{Composite{(i0 + (i1 * i2))}}.0)]]
Similar issues seem to use objective functions for each output separately as if they don't share the deep structure behind, however, this isn't my objective here :S
I can't find the correct syntax to do it, also, it is my first post ever on github so, apologies for any inconvenience.
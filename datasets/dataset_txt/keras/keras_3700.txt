chithangduong commented on 12 Dec 2016
Keras gives an excellent example on how to use pre-trained vectors for text classification:
https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html
However, the provided example uses minibatches. As my dataset is small, I want to process the training data one sample at a time. From my understanding of the provided code, I can do this easily by removing
input_length=MAX_SEQUENCE_LENGTH from the Embedding layer
and
setting
batch_size=1 in model.fit.
Is it correct? Should I also remove the pad_sequences part ?
tokestermw commented on 16 Aug 2016 â€¢
edited
I have a large text dataset that I'd like to train on using a custom embedding model. I'd like to use fit_generator or train_on_batch so it uses minimal memory.
I've tested a word2vec example and the results are random when using fit_generator and I can't seem to point out the problem.
The other notable difference is that it takes a few minutes to train using train_on_batch but a few seconds using fit_generator.
One thing to note may be the batch size for the loop is different for each sentence.
My link to the self-contained example:
https://gist.github.com/tokestermw/0da8fd1b0a25e14a014b0a0037a56830
Thanks.
possible related issue (data shuffling): #2389
Please make sure that the boxes below are checked before you submit your issue. Thank you!
Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps
If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps
Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
liyi193328 commented on 5 Mar 2016
I want do some experiments in stanford sentiment treebank dataset(http://nlp.stanford.edu/sentiment/),
To do 3 classes classification, I only use Google's news word2vec to init word embedding, every sentence's maxlen is 200,use LSTM as classifier, below is my main code:
    word_vec_dim=300
    lstm_output_dim=300
    maxlen=150
    model.add(LSTM(output_dim=lstm_output_dim,return_sequences=False,input_length=maxlen,input_dim=word_vec_dim))  
    model.add(BatchNormalization())

    model.add(Dense(100,W_regularizer=l2(0.1), activity_regularizer=activity_l2(0.1)))
    model.add(Activation('sigmoid'))
    model.add(BatchNormalization())
    model.add(Dense(200,W_regularizer=l2(0.25), activity_regularizer=activity_l2(0.25)))
    model.add(Dropout(0.2))
    model.add(Activation('relu'))

    model.add(Dense(3))
    model.add(Activation('softmax'))
    model.compile(loss="categorical_crossentropy",optimizer=sgd, class_mode="categorical")
    model.fit(train_data,train_label,batch_size=30,nb_epoch=150,verbose=1,shuffle=True,validation_data=(dev_data,dev_label),show_accuracy=True)
But when training , loss decrease, validation accuracy don't change any more( the results is all samples is classifed to same class) like:
Train on 8541 samples, validate on 1101 samples:
data and label shape is , train: (8541, 150, 300) (8541, 3) ; validation: (1101, 150, 300) (1101, 3)
The different class sizes of samples in train and validation is [3308, 1624, 3609] and [428, 229, 444]
Epoch 1/150
8541/8541 [=========] - 77s - loss: 47.6056 - acc: 0.3641 - val_loss: 1.0943 - val_acc: 0.3906
Epoch 2/150
8541/8541 [=========] - 77s - loss: 43.3670 - acc: 0.4015 - val_loss: 1.0897 - val_acc: 0.3933
Epoch 3/150
8541/8541 [=========] - 77s - loss: 39.2919 - acc: 0.4052 - val_loss: 1.0858 - val_acc: 0.3987
Epoch 4/150
8541/8541 [=========] - 77s - loss: 35.4499 - acc: 0.4050 - val_loss: 1.0822 - val_acc: 0.4015
Epoch 5/150
8541/8541 [=========]- 77s - loss: 31.8382 - acc: 0.4155 - val_loss: 1.0791 - val_acc: 0.4078
Epoch 6/150
8541/8541 [=========] - 77s - loss: 28.4549 - acc: 0.4179 - val_loss: 1.0763 - val_acc: 0.4033
Epoch 7/150
8541/8541 [=========]- 77s - loss: 25.2974 - acc: 0.4218 - val_loss: 1.0737 - val_acc: 0.4042
Epoch 8/150
8541/8541 [=========] - 77s - loss: 22.3631 - acc: 0.4228 - val_loss: 1.0714 - val_acc: 0.4051
Epoch 9/150
8541/8541 [=========] - 77s - loss: 19.6483 - acc: 0.4229 - val_loss: 1.0694 - val_acc: 0.4042
Epoch 10/150
8541/8541 [=========]- 77s - loss: 17.1500 - acc: 0.4223 - val_loss: 1.0676 - val_acc: 0.4033
Epoch 11/150
8541/8541 [=========] - 77s - loss: 14.8637 - acc: 0.4226 - val_loss: 1.0661 - val_acc: 0.4033
Epoch 12/150
8541/8541 [=========]- 77s - loss: 12.7852 - acc: 0.4226 - val_loss: 1.0648 - val_acc: 0.4033
8541/8541 [=========] - 77s - loss: 10.9088 - acc: 0.4226 - val_loss: 1.0638 - val_acc: 0.4033
Epoch 13/150
8541/8541 [=========] - 77s - loss: 9.2280 - acc: 0.4226 - val_loss: 1.0630 - val_acc: 0.4033
Epoch 14/150
8541/8541 [=========] - 77s - loss: 7.7362 - acc: 0.4226 - val_loss: 1.0623 - val_acc: 0.4033
....
when I check the prediction of validation data,find that:
1101/1101 [==============================] - 2s
pred_now.shape: (1101,)
true label shape: (1101,)
acc: 0.4032697547683924
Out[56]:
[ 0.39525932, 0.18716642, 0.41757429],
[ 0.39530191, 0.18713304, 0.41756511],
...,
[ 0.39533255, 0.18708916, 0.41757837],
[ 0.39531669, 0.18714626, 0.41753712],
[ 0.39531103, 0.18713255, 0.41755641]])
array([2, 2, 2, ..., 2, 2, 2], dtype=int64): meaning the predicted result of all validation is always the class label 2.
I change some parameters like learning rate, which result to same; I do some test in 5 classes, which also results to one same class.
So what's going on here? Please help, Thanks sincerely.
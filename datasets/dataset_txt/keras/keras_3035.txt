miguelmartin75 commented on 9 Mar 2017 â€¢
edited
I have put my loss function within my metric:
def mean_euc_dist_sq(y_true, y_output):
    return K.mean(K.sum(K.square(y_true - y_output), axis=-1))

def mean_euc_dist(y_true, y_output):
    return K.mean(K.sqrt(K.sum(K.square(y_true - y_output), axis=-1)))

def max_euc_dist(y_true, y_output):
    return K.max(K.sqrt(K.sum(K.square(y_true - y_output), axis=-1)))

def min_euc_dist(y_true, y_output):
    return K.min(K.sqrt(K.sum(K.square(y_true - y_output), axis=-1)))

def stddev_euc_dist(y_true, y_output):
    return K.std(K.sqrt(K.sum(K.square(y_true - y_output), axis=-1)))

# ...

model.compile(optimizer=sgd, loss=mean_euc_dist_sq, metrics=[mean_euc_dist_sq, mean_euc_dist, min_euc_dist, max_euc_dist, stddev_euc_dist])
Yet my metric is entirely different, for example here is some training output:
35328/41344 [========================>.....] - ETA: 78s - loss: 3040.6511 - mean_euc_dist_sq: 6.4321 - mean_euc_dist: 2.1256 - min_euc_dist: 0.1785 - max_euc_dist: 8.9086 - stddev_euc_dist: 1.3548
Note that my output per sample is two (coordinate for x and y). I can't work out why this it's so different. This different is consistent even when a new epoch starts.
I train with fit_generator, like so:
checkpoint = ModelCheckpoint(args.out, monitor=monitor_loss, period=1, save_best_only=True) tensorboard = TensorBoard(log_dir=args.log_dir, histogram_freq=1, write_images=True)

model.fit_generator(data(all_data_points, batch_size=batch_size, mean=mean_imgs, aug=args.aug_count > 0),
                                  nb_epoch=epochs_to_do, 
                                  samples_per_epoch=iterations_per_epoch * batch_size, 
                                  callbacks=[checkpoint, tensorboard],
                                  validation_data=val,
                                  nb_val_samples=amount_of_val,
                                  verbose=1)
Where my generator outputs multiple inputs
yield { 'in1': in1, 'in2': in2, 'in3
: in3, 'in4
: in4 }, batch_outputs
Where shape of batch_outputs is of shape (batch_size, 2), which is similar to the inputs. batch_size in this instance is 128.
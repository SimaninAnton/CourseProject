bth5032 commented on 24 Mar 2018
Hi, I am having an issue with crashes whenever I try to save a sequential model with a skip connection. It looks like there were some other closed issues along these lines that others have reported here, and here, but none of these threads held any answers.
The basic premise is that I want to do a skip connection with only a subset of my input vector. For instance, if my input vector is 10 numbers, I might want to take the first 5 entries and add them to a later layer. To do this, I am using a lambda layer that returns the first 5 entries of the input layer, and then adding that back in to a later layer.
My network trains just fine and gives reasonable output. That is to say, this seems to be purely an issue with saving the model, not with implementing the skip connection. When I attempt to save I'm getting an error which is a long stacktrace through the guts of "deepcopy" followed by
TypeError: can't pickle NotImplementedType objects
When running my code in a jupyter notebook, I get a slightly different stacktrace through the same file, but the final error is
AttributeError: 'NoneType' object has no attribute 'update'
I've implemented a minimal script that reproduces the error below. The network just generates 10 random digits and tries to train itself to output 1 regardless of the inputs.
import keras.backend.tensorflow_backend as K
import keras
from keras.models import Sequential, Model, load_model
from keras.layers import Dense, LeakyReLU, Lambda
from keras.layers import Input, Add
from keras.losses import binary_crossentropy
import numpy as np

class CrashingKeras():
    def __init__(self, **kwargs):
        self.input_shape=(int(10),)
        self.lambda_output_shape=(int(5),)
        self.batch_size=100
        self.nepochs_max=5
        self.NN = self.build_net()
        self.NN.compile(loss="binary_crossentropy", optimizer="adam")
    
    def build_net(self):
        inputs = Input(shape=self.input_shape)
        x = Dense(10)(inputs)
        x = LeakyReLU(alpha=0.2)(x)
        x = Dense(5)(x)
        x = LeakyReLU(alpha=0.2)(x)
        z = Lambda(lambda y: y[:,0:self.lambda_output_shape[0]], output_shape=self.lambda_output_shape)(inputs)
        x = Add()([x,z])
        x = Dense(1)(x)
        model = Model(inputs=inputs, outputs=[x])
        return model

    def train(self):        
        noise = np.random.normal(0, 1, (self.batch_size, self.input_shape[0]))
        for epoch in range(self.nepochs_max):
            valid_y = np.array([1] * self.batch_size)
            loss = self.NN.train_on_batch(noise, valid_y)
            self.NN.save("gen_{}.weights".format(epoch))

network = CrashingKeras()

network.train()
Thanks for your help!
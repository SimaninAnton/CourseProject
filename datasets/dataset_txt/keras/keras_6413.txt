davebs commented on 20 Nov 2015
Is there any concept of a warmup period for RNN training in Keras?
For instance, say you have a 100 timestep sample and you're making predictions at each timestep. Because each prediction should act on long term dependencies, and there are no long term dependencies at the first timestep, the output for the first ~20 timesteps may be assumed to be garbage.
In that case, the warmup period would be 20. Is there a way to remove those first 20 timesteps from the loss computations?
Prediction is easier as you just slice the piece you want to keep, but I think training could benefit from this?
ebilal commented on 31 Aug 2016 â€¢
edited
Is there a way to drop the same elements with the Dropout layer between different training batches? I'd like to drop the same nodes over an entire epoch:
for e in range(nb_epoch):
    for batch_X, batch_y in train_batches:
        np.random.seed(e) # This didn't work
        model.train_on_batch(batch_X, batch_y)
Thank you for releasing this project.
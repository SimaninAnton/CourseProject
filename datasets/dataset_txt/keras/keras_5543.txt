BUPTLdy commented on 10 Apr 2016
I am a newer to keras, and I use LTSM to text classification,here is my model:
`def train_lstm(n_symbols,embedding_weights,x_train,y_train,x_test,y_test):
print 'Defining a Simple Keras Model...' 
model = Sequential()  # or Graph or whatever
model.add(Embedding(output_dim=vocab_dim,
                    input_dim=n_symbols,
                    mask_zero=True,
                    weights=[embedding_weights],
                    input_length=input_length))  # Adding Input Length
model.add(LSTM(output_dim=50, activation='sigmoid', inner_activation='hard_sigmoid'))
model.add(Dropout(0.5))
model.add(Dense(1))
model.add(Activation('sigmoid'))

print 'Compiling the Model...' 
model.compile(loss='binary_crossentropy',
              optimizer='adam')

print "Train..." 
model.fit(x_train, y_train, batch_size=batch_size, nb_epoch=n_epoch,
          validation_data=(x_test, y_test),verbose=1, show_accuracy=True)
cPickle.dump(model,open("./lstm_model.pkl","wb"))
print "Evaluate..." 
score, acc = model.evaluate(x_test, y_test,
                            batch_size=batch_size,
                            show_accuracy=True)
print 'Test score:', score 
print 'Test accuracy:', acc `
and the x_train shape is (16884, 100),y_train shape is (16884,);
I save the model and then load it to predict:
model.predict(data)
and the data shape is (1,100)
but I get the follow error:
`ValueError: Shape mismatch: x has 100 cols (and 1 rows) but y has 300 rows (and 64 cols)
Apply node that caused the error: Dot22(<TensorType(float32, matrix)>, dense_W)
Toposort index: 1
Inputs types: [TensorType(float32, matrix), TensorType(float32, matrix)]
Inputs shapes: [(1, 100), (300, 64)]
Inputs strides: [(400, 4), (256, 4)]
Inputs values: ['not shown', 'not shown']
Outputs clients: [[Elemwise{Composite{tanh((i0 + i1))}}[(0, 0)](Dot22.0, InplaceDimShuffle{x,0}.0)]]
HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.`
Sorry about my poor English,Thank you every much if anyone can help me !
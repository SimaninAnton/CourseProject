filipemtz commented on 14 Mar 2017
Hey guys, I observed an intriguing fact when implementing a [Q-Network] (https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf) using Keras. Hope you can help me to figure out what is going on.
Basically, when I train the model using Keras, it does not learn anything, but when I train the exactly same model using Tensorflow it works fine. The figure below shows it. In the figure, the x-axis is the number of episodes; the red line is 1 when the agent reached the goal in the episode, and 0 otherwise; the blue line is the percentage of times the agent reached the goal in the last 30 episoes (higher is better); and the green line represents how many random actions the agent have taken (1 = 100% => all actions are random, and 0 = 0% => all actions are greedy).
The differences between the codes are just the model definition, and the methods to forward, and to train the networks. I have no idea why the results are not equivalent. If someone can give me some feedback on the following investigative questions, I would be really grateful.
Are there any problem in using a Keras model inside a class?
Are predict_on_batch, and train_on_batch restricted to classification problems or they can be used for regression? Reinforcement learning using Q-nets is a regression problem.
Are the executions of predict_on_batch, and train_on_batch independent of each other? Is it OK to train some data from the training set using train_on_batch, and test data from the testing set using predict_on_batch iteratively? Or information (gradients, model variables, etc.) are shared between calls of these methods?
The code is quite small and simple. It is available at:
[link to code] (https://gist.github.com/filipemtz/3176165e9b22e2f8d992ce9f1fd0adfe)
It contains 3 files:
main.py : it loads the environment and, iteratively, executes an episode, and train the network.
qnet.py: class containing the model. You can choose to use Keras ou Tensorflow by setting the flag USE_KERAS to True or False.
slow_avg.py: utility code to compute the percentage of times the agent reached the goal in the last 30 episodes.
To run the code, use:
python main.py > report.txt
To plot the graph (run from the same dir of the code):
gnuplot
[in the gnuplot prompt:]
!grep Episode report.txt > a.txt && python slow_avg.py > b.txt
plot './a.txt' u 11 w l, './a.txt' u 4 w l axis x1y2, './b.txt' u 4 w l
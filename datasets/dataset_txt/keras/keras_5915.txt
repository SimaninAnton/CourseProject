ghost commented on 19 Feb 2016
Hi,
I'm working on a deep neural network (Sequential Dense), but i don't understand why the training accuracy is lower than the validation accuracy (the two sets being separated and having roughly the same distribution).
I started working on machine learning not so long ago and i was told that a way(the only one i know) to check if my network is not overfitting is to compare validation and train accuracy. If validation accuracy start dropping while the training accuracy continue to increase that's when i should be concerned.
Problem is validation accuracy is higher than training accuracy which doesn't make any sense for me...
I'm sure i missed something somewhere (maybe the training accuracy displayed by keras is not the one i think of) or the way i put my validation data is not the good one... Or maybe am I just wrong all along.
So if any one could give me an advice, or knows if there is a way to plot or visualize the data training within Keras to prevent overfit that would help.
I'm talking about that kind of thing (i'm copy pasting a random epoch but all are roughly the same):
50000/50000 [==============================] - 32s - loss: 1.7436 - acc.: 0.5749 - val. loss: 1.5925 - val. acc.: 0.6434
My network parameters are the following : a sequential dense network of that kind 20000>1000>1000>1000>1000
trained on ReLU for all except the last Softmax. The Loss is categorical crossentropy
9
1
1
1
1
WilliamOu commented on 30 Mar 2017 â€¢
edited
Hi guys, I am writing a LRCN with keras. I built my model like this:
    vgg_model = VGG16(weights='imagenet', include_top=False)
    model = Sequential()
    model.add(TimeDistributed(vgg_model, batch_input_shape=batch_input_shape, name='VisualModule'))
    model.add(Reshape((TimeLen, -1), name='Reshape'))
    model.add(LSTM(512, stateful=True, return_sequences=True, name='LSTM'))
    model.add(Dense(126, name='Dense1'))
    model.add(Dropout(0.5, name='Drpout1'))
    model.add(Dense(2, name='Dense2'))
I tried to train this model, however I found that the output in the origianl VGG16 is not changing, which means parameters in vgg16 is not trainable in this model.
I also tried to use TimeDistributed to every layer in VGG16, like this
model.add(TimeDistributed(Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')))
model.add(TimeDistributed(Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')))
model.add(TimeDistributed(Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')))
model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool'))),

# Block LSTM
model.add(Reshape((TimeLen, -1), name='Reshape1'))
model.add(LSTM(256, stateful=True, return_sequences=True))
model.add(Reshape((TimeLen, -1), name='Reshape2'))
model.add(TimeDistributed(Dense(126)))
model.add(Dropout(0.5))
model.add(TimeDistributed(Dense(2)))
I get the output of the last maxpooling layers and found that the output is not changing, which means parameters in vgg16 is not trainable in this model. The learning rate is 0.00001, and I trained on 10 batches.
Can anyone tell me how to implement lrcn in keras correctly and check whether the parameters in this model is changed by training??
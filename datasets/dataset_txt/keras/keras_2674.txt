parunach commented on 12 Apr 2017 â€¢
edited
I have a simple problem for NLP which runs fine without TensorBoard callback.
vec_size = 32
model = Sequential()
model.add(Embedding(top_words, vec_size, input_length=max_words))
model.add(Convolution1D(nb_filter=vec_size, filter_length=3, border_mode='same', activation='relu'))
model.add(MaxPooling1D(pool_length=2))
model.add(Flatten())
model.add(Dense(250, activation='relu'))
model.add(Dense(1, activation='sigmoid'))
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
print model.summary()

# Fit the model                                                                                                          
model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=2, batch_size=128,
                verbose=1, callbacks=[TensorBoard(histogram_freq=1)])
With the callback, it crashes with
ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[25000,500,32]
[[Node: embedding_1/Gather = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device="/job:localhost/replica:0/task:0/gpu:0"](embedding_1/embeddings/read, _recv_embedding_1_input_0/_77)]]
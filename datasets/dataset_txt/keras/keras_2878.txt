zehzhang commented on 23 Mar 2017 â€¢
edited
Here is my model
model = Sequential()
base_model = VGG16(weights='imagenet', include_top=False, input_tensor=Input(batch_shape=(my_batch_size, img_width, img_height, 3)))
model.add(base_model)
model.add(Flatten())
model.add(Dense(4096, activation='relu'))
model.add(Dense(4096, activation='relu'))
model.add(Dense(24, activation='relu'))
model.add(Activation('softmax'))
If I use print_summary, I get:
Layer (type) Output Shape Param
vgg16 (Model) (1, 7, 7, 512) 14714688
flatten_1 (Flatten) (1, 25088) 0
dense_1 (Dense) (1, 4096) 102764544
dense_2 (Dense) (1, 4096) 16781312
dense_3 (Dense) (1, 24) 98328
activation_1 (Activation) (1, 24) 0
which seems to be perfect.
But if I use print(model.layers[-4].output.shape), I get (?, 4096). And every output shape after the flatten layer throws away the batch size which is actually defined. But the shape of the layer before the flatten layer still has the correct batch size.
Here is every layer's output shape by calling print(model.layers[i].output.shape)
(1, 7, 7, 512)
(?, ?)
(?, 4096)
(?, 4096)
(?, 24)
(?, 24)
I need the correct specific shape to call tf.zeros(shape)
Anyone knows how to fix this?
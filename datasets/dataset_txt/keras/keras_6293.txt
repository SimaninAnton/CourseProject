mowayao commented on 9 Dec 2015
graph = Graph()


graph.add_input(name='input1',input_shape=(1,28,28))
graph.add_input(name='input2',input_shape=(1,28,28))
#graph.add

graph.add_shared_node(Convolution2D(96,4,4),name="shared_conv1",inputs=['input1','input2'],merge_mode=None)
graph.add_shared_node(MaxPooling2D((3,3)),name='shared_P1',inputs=['shared_conv1'],merge_mode=None)
graph.add_shared_node(Convolution2D(256,4,4),name='shared_conv2',inputs=['shared_P1'],merge_mode=None)
graph.add_shared_node(MaxPooling2D((3,3)),name='shared_P2',inputs=['shared_conv2'],merge_mode='concat')



graph.add_node(Convolution2D(96,4,4),name='Tconv1',input='shared_P2')
graph.add_node(MaxPooling2D((3,3)),name='TP1',input='Tconv1')
graph.add_node(Convolution2D(256,4,4),name='Tconv2',input='TP1')
graph.add_node(MaxPooling2D((3,3)),name='TP2',input='Tconv2')
graph.add_node(Flatten(),name='Fla',input='TP2')
graph.add_node(Dense(10),name='dense1',input='Fla')
graph.add_node(Activation('softmax'),name='act',input='dense1')
graph.add_output(name='output',input='act')
graph.compile('Adam', {'output':'categorical_crossentropy'})

X_train1 = d['feature'][:1000,0].reshape((1000,1,28,28))
X_train2 = d['feature'][:1000,1].reshape((1000,1,28,28))
Y_train = d['label'][:1000]
hist = model.fit(data={'input1':X_train1, 'input2':X_train2, 'output':Y_train},batch_size=64, nb_epoch=6, verbose=1)
WARNING: probably bad CudaNdarray_set_dim arguments: self->ndim=4, idx=3 stride=-1
WARNING: probably bad CudaNdarray_set_dim arguments: self->ndim=4, idx=2 stride=-2
Traceback (most recent call last):
File "/home/mowayao/PycharmProjects/dl/siamese1.py", line 113, in
train()
File "/home/mowayao/PycharmProjects/dl/siamese1.py", line 101, in train
hist = model.fit(data={'input1':X_train1, 'input2':X_train2, 'output':Y_train},batch_size=64, nb_epoch=6, verbose=1)
File "build/bdist.linux-x86_64/egg/keras/models.py", line 692, in fit
File "build/bdist.linux-x86_64/egg/keras/models.py", line 226, in _fit
File "build/bdist.linux-x86_64/egg/keras/backend/theano_backend.py", line 357, in call
File "/home/mowayao/anaconda/lib/python2.7/site-packages/Theano-0.7.0-py2.7.egg/theano/compile/function_module.py", line 871, in call
storage_map=getattr(self.fn, 'storage_map', None))
File "/home/mowayao/anaconda/lib/python2.7/site-packages/Theano-0.7.0-py2.7.egg/theano/gof/link.py", line 314, in raise_with_op
reraise(exc_type, exc_value, exc_trace)
File "/home/mowayao/anaconda/lib/python2.7/site-packages/Theano-0.7.0-py2.7.egg/theano/compile/function_module.py", line 859, in call
outputs = self.fn()
AssertionError: Can't store in size_t for the bytes requested 18446744073709551615 * 4
Apply node that caused the error: GpuAllocEmpty(Shape_i{0}.0, Shape_i{0}.0, Elemwise{Composite{(i0 + (i1 - i2))}}[(0, 1)].0, Elemwise{Composite{(i0 + (i1 - i2))}}[(0, 1)].0)
Toposort index: 135
Inputs types: [TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar)]
Inputs shapes: [(), (), (), ()]
Inputs strides: [(), (), (), ()]
Inputs values: [array(64), array(96), array(-2), array(-1)]
Outputs clients: [[GpuDnnConv{algo='small', inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode='valid', subsample=(1, 1), conv_mode='conv'}.0, Constant{1.0}, Constant{0.0})]]
Backtrace when the node is created:
File "build/bdist.linux-x86_64/egg/keras/backend/theano_backend.py", line 556, in conv2d
subsample=strides)
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
paba commented on 5 Jul 2017 â€¢
edited
I recently started working with keras to build a LSTM model.
I find it difficult to understand the shape of the input data that we provide to batch_input_shape and the exact structure of the LSTM model that results.
Here is my problem: I am trying to do time series model of revenue. My training dataset, X, has the shape 803,7 -- 803 samples and 7 features (these seven features are the lagged values of the revenue ).
I reshaped this input as:
X = X.reshape(X.shape[0], 1, X.shape[1])
Now the new shape of my input is 803, 1, 7
I created the model as follows:
model = Sequential()
neurons = 4
model.add(LSTM(neurons, batch_input_shape=(1, X.shape[1], X.shape[2]), stateful=True, return_sequences=True ) )
model.add(Dense(1))
I have three questions.
Does the model created by the above code look like this?
 y_t0     y_t1      y_t2
    |             |            |
 LSTM -> LSTM ->LSTM --------
    |            |            |
X_t0      X_t1       X_t2
where X_tn = [ feature1, feature2, feature3, feature4, feature5, feature6, feature7]
How shouldI shape the data/ what input should I provide if I want a many to one model like this
                                                                                       Y
                                                                                        |
LSTM -> LSTM ->LSTM ->LSTM ->LSTM ->LSTM ->LSTM
    |          |            |            |              |             |             |
X_t0     X_t1       X_t2     X_t3       X_t4      X_t5       X_t6
What does the batch size exactly mean?
The Keras document did not give me a clear understanding.
Thank you very much.
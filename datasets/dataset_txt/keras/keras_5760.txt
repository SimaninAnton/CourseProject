Contributor
cmyr commented on 15 Mar 2016
On a new dataset interface
As per some discussions in relation to the proposed functional API (#1960) and a discussion on twitter and some other places, I'd like to talk about data interfaces.
This could potentially be a part of Keras, or some sort of separate package Ã  la Fuel.
The goal of this work would be to create a unified API + interface for training/testing data, and perhaps some simple tools for preparing datasets.
initial thoughts
I've been building/maintaining some version of this functionality in various ways over the past six months or so. I'm not really happy with any of the solutions I've come up with, and I would be curious to hear about everyone else's experiences.
My current implementation is to have an abstract DataStore class which implements training_data and testing_data functions which return iterators over mini-batches of (X, y, sample_weight) tuples. To make use of this with keras, I've used my own implementation of fit, built on top of the train_on_batch function.
Subclasses of DataStore can implement these iterators however they wish; the simplest case would just be to wrap an existing numpy array or hdf5 file, but you can also imagine consuming some stream over the network, or generating examples on the fly, etc.
I am definitely not married to these ideas, but wanted to at least have a jumping off point. @jfsantos / @EderSantana / everyone else, what are your thoughts? What are the issues you've been dealing with?
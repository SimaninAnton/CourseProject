ngopee commented on 10 Feb 2016
Hi,
I am working on an NLP task. I am currently feeding my own pre-trained word vectors to an LSTM layer. Each of the word in my sentence has it's own multi class tag. And I added a TimeDistributedDense for the many-to-many architecture. But...
I am having this error:
ValueError: Input dimension mis-match. (input[0].shape[2] = 4, input[1].shape[2] = 100)
Apply node that caused the error: Elemwise{Composite{(i0 * log(i1))}}(<TensorType(float32, 3D)>, Elemwise{clip,no_inplace}.0)
Inputs types: [TensorType(float32, 3D), TensorType(float32, 3D)]
Inputs shapes: [(32, 100, 4), (32, 100, 100)]
Inputs strides: [(1600, 16, 4), (40000, 400, 4)]
Inputs values: ['not shown', 'not shown']
Below is my code. Note that I am initialising the dataset with zeroes just just for testing. Trying to get the proper input structure.
vocab_dim = 300
maxlen = 100
batch_size = 32
nb_epoch = 1
nb_classes =4


X = np.zeros((128, maxlen,vocab_dim), dtype=np.float32)
y = np.zeros((128,maxlen, nb_classes), dtype=np.int8)

print('Build model...')
model = Sequential()
model.add(LSTM(100, return_sequences=True, input_shape=(maxlen, vocab_dim)))
model.add(Dropout(0.2))
model.add(LSTM(100, return_sequences=False))
model.add(Dropout(0.2))
model.add(TimeDistributedDense(output_dim = maxlen,input_dim= maxlen, activation='softmax'))

print('compiling')
model.compile(loss='categorical_crossentropy', optimizer='rmsprop', class_mode="categorical")


print('fitting')
model.fit(X, y, batch_size=batch_size, nb_epoch=1)
Thanks you very much!
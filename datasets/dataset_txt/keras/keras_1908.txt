AyanKumarBhunia commented on 16 Jul 2017 â€¢
edited
How can I define my own loss function which requires Weight and Bias parameters from previous layers in Keras?
How can I get [W1, b1, W2, b2, Wout, bout] from every layer? Here, we need to pass few more variables than usual (y_true, y_pred). I have attached two images for your reference.
I need to implement this loss function.
W(H) denote the linear prediction functions of the class labels based on the outputs of the latent layer. W(l) is the weight matrix of the l-th layer. To formalize the quantization error, we use H and B to represent the outputs of the latent layer and the expected binary matrix. The ideal binary matrix can be computed by B = sign(H). Beta is a non-negative parameter.

Please make sure that the boxes below are checked before you submit your issue. If your issue is an implementation question, please ask your question on StackOverflow or join the Keras Slack channel and ask there instead of filing a GitHub issue.
Thank you!
[ Yes] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps
[ Yes] If running on TensorFlow, check that you are up-to-date with the latest version. The installation instructions can be found here.
[Yes ] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps
[ Yes] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
jingweimo commented on 8 Jul 2017 â€¢
edited
There are three options for implementation in recurrent.py, one of {0, 1, or 2}.
According to the document, if set to 0, the RNN will use an implementation that uses fewer, larger matrix products, thus running faster on CPU but consuming more memory, which should correspond to consume_less=cpu mode in the keras before 2.0; If set to 1, the RNN will use more matrix products, but smaller ones, thus running slower (may actually be faster on GPU) while consuming less memory, which should correspond to consume_less=mem previously; and lastly if set to 2 (LSTM/GRU only), the RNN will combine the input gate, the forget gate and the output gate into a single matrix, enabling more time-efficient parallelization on the GPU, which should be correspond to consume_less=gpu in the old keras.
But if I don't set up implementation for my network, such as LSTM, which mode the program is actually using? Is theimplementationset to 0 or cpu by default?
Collaborator
fchollet commented on 14 Jul 2016
Currently Keras implements its own batchnorm system "manually", i.e. by creating update ops to maintain exponential averages of relevant statistics. However batchnorm ops are available natively in TF, and now Theano, which wrap the more efficient cuDNN implementation when available.
We should consider creating a batchnorm op in the Keras backend, which would wrap the TF and Theano implementations, and thus leverage cuDNN when available.
Anyone interested in making a valuable contribution to Keras is welcome to look into this.
raspstephan commented on 29 Mar 2019
I have noticed a difference between the loss that Keras returns during training and model.evaluate and what I compute myself from the predictions.
import numpy as np
import keras
from keras.layers import Dense
from keras.models import Sequential
import keras.backend as K

X = np.random.rand(10000)
Y = X + np.random.rand(10000) / 5

X_train, X_valid = X[:8000], X[8000:]
Y_train, Y_valid = Y[:8000], Y[8000:]

model = Sequential([
    Dense(1, input_shape=(1,), activation='linear'),
])
model.compile('adam', 'mae')
model.fit(X_train, Y_train, epochs=1, batch_size=1024, validation_data=(X_valid, Y_valid))
>> Train on 8000 samples, validate on 2000 samples
>> Epoch 1/1
>> 8000/8000 [==============================] - 0s 51us/step - loss: 0.1900 - val_loss: 0.1845

model.evaluate(X_valid, Y_valid)
>> 0.18448934221267702

preds = model.predict(X_valid)
np.abs(Y_valid - preds).mean()
>> 0.4463157837393756
I have noticed the same for different architectures, data and loss functions (e.g. MSE). How does Keras compute the loss and how can I reproduce it from the predictions?
Keras version : 2.2.4
Tensorflow version: 1.12.0
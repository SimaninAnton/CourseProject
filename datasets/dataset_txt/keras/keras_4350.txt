cdj0311 commented on 19 Sep 2016 â€¢
edited
hi all,
I take fit_generator for large scale text classification, however, I get an overfit result, my code as follows:
def data_generator(istrain):
    if istrain:
        max_batch_index = len(x_train) // self.batch_size
    else:
        max_batch_index = len(x_test) // self.batch_size
    i = 0
    while 1:
        if istrain:
            yield (x_train[i * self.batch_size: (i + 1) * self.batch_size], y_train[i * self.batch_size: (i + 1) * self.batch_size])
        else:
            yield (x_test[i * self.batch_size: (i + 1) * self.batch_size], y_test[i * self.batch_size: (i + 1) * self.batch_size])
        i += 1
        i = i % max_batch_index
model.fit_generator(data_generator(True),
                    samples_per_size=len(x_train),
                    nb_epoch=self.nb_epoch,
                    validation_data=data_generator(False),
                    nb_val_samples=len(x_test))
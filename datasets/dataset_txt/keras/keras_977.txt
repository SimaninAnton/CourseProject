budach commented on 11 Jun 2018
Hi,
the following code results in a segfault after the model was fitted a second time:
import numpy as np
from keras.models import Sequential
from keras.layers import Dense
from keras.backend import clear_session

def test():
    data = np.random.random((1000, 100))
    labels = np.random.randint(2, size=(1000, 1))
    model = Sequential()
    model.add(Dense(32, activation='relu', input_dim=100))
    model.add(Dense(1, activation='sigmoid'))
    model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])
    model.fit(data, labels, epochs=3, batch_size=32)

test()
clear_session()
test()
The output:
Using TensorFlow backend.
Epoch 1/3
1000/1000 [==============================] - 3s 3ms/step - loss: 0.7174 - acc: 0.4910
Epoch 2/3
1000/1000 [==============================] - 0s 72us/step - loss: 0.7056 - acc: 0.5050
Epoch 3/3
1000/1000 [==============================] - 0s 70us/step - loss: 0.6989 - acc: 0.5150
Epoch 1/3
1000/1000 [==============================] - 0s 187us/step - loss: 0.6936 - acc: 0.5320
Epoch 2/3
1000/1000 [==============================] - 0s 67us/step - loss: 0.6854 - acc: 0.5600
Epoch 3/3
1000/1000 [==============================] - 0s 70us/step - loss: 0.6802 - acc: 0.5720
Segmentation fault (core dumped)
Not calling clear_session() prevents the segfault. This only happens with keras 2.2 and tensorflow 1.8 (both CPU and GPU version). All other combinations of keras (2.1.x) and tensorflow (<1.8 and also 1.9.0rc0) don't result in a segfault.
Is this a keras or tensorflow issue?
7
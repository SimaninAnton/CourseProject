dr-costas commented on 6 Jul 2016
Hi,
I'm doing a text synthesis network in word-by-word level. I have an arbitrary length of sentences, split into words/lemmas, and used as inputs to the network. As targeted output I have the same sentences shifted by 1 word. E.g.
sentence = word_0 word_1 ... word_N,
inputs = [word_0, ..., word_N-1],
outputs = [word_1, ..., word_N]
My problem regards the reflection of the usage of this network to the training procedure.
On using this network for sentence creation given one and only one word, e.g. given a word_X, the network should create a sequence of words with arbitrary length. Up to now, I have a matrix of Y with size NxM with N = maximum amount of words in a sentence and M = amount of values in word representation.
When creating sentences, I have Y[0, :] = representation of word_0 and Y[1:, :] = zeros for predicting the first (word_1) word. Then, I do Y[1, :] = representation of word_1 and I predict word_2 by using the Y as input to the network and so on.
But, when training I do it by using a matrix NxM as input and a matrix NxM as output, which is not the procedure followed in the usage of the network.
So, how can one use a loop in the training for implementing the above procedure in the training phase?
dpappas commented on 19 Feb 2016
I wrote the following code
max_features = embeddings.shape[0]
embedding_dims = embeddings.shape[-1]
out_dim = 5
maxlen = 100
model = Sequential()
model.add(Embedding(max_features, embedding_dims, weights=[embeddings], input_length = maxlen, trainable=trainable))
model.add(Convolution1D( nb_filter = nb_filter, filter_length=filter_length, border_mode='valid', subsample_length=1  ))
sh = model.layers[-1].output_shape
model.add(MaxPooling1D(pool_length=sh[-2]))
model.add(Flatten())
model.add(Dense(Dense_size))
model.add(Dense(out_dim, activation='linear'))
model.compile(loss='mse', optimizer=opt)
The output when fitting is this one
Epoch 1/20
314/314 [==============================] - 0s - loss: 0.7279 - val_loss: 0.0430
Epoch 2/20
314/314 [==============================] - 0s - loss: 0.5672 - val_loss: 0.0424
Epoch 3/20
314/314 [==============================] - 0s - loss: 0.5391 - val_loss: 0.0424
Epoch 4/20
314/314 [==============================] - 0s - loss: 0.5137 - val_loss: 0.0434
Epoch 5/20
314/314 [==============================] - 0s - loss: 0.4909 - val_loss: 0.0440
Epoch 6/20
314/314 [==============================] - 0s - loss: 0.4703 - val_loss: 0.0444
Epoch 7/20
314/314 [==============================] - 0s - loss: 0.4508 - val_loss: 0.0421
Epoch 8/20
314/314 [==============================] - 0s - loss: 0.4329 - val_loss: 0.0419
Epoch 9/20
314/314 [==============================] - 0s - loss: 0.4161 - val_loss: 0.0422
Epoch 10/20
314/314 [==============================] - 0s - loss: 0.4005 - val_loss: 0.0438
Epoch 11/20
314/314 [==============================] - 0s - loss: 0.3865 - val_loss: 0.0421
Epoch 12/20
314/314 [==============================] - 0s - loss: 0.3724 - val_loss: 0.0432
Epoch 13/20
314/314 [==============================] - 0s - loss: 0.3607 - val_loss: 0.0456
Epoch 14/20
314/314 [==============================] - 0s - loss: 0.3485 - val_loss: 0.0418
Epoch 15/20
314/314 [==============================] - 0s - loss: 0.3374 - val_loss: 0.0433
Epoch 16/20
314/314 [==============================] - 0s - loss: 0.3273 - val_loss: 0.0459
Epoch 17/20
314/314 [==============================] - 0s - loss: 0.3181 - val_loss: 0.0417
Epoch 18/20
314/314 [==============================] - 0s - loss: 0.3089 - val_loss: 0.0435
Epoch 19/20
314/314 [==============================] - 0s - loss: 0.3011 - val_loss: 0.0441
Epoch 20/20
314/314 [==============================] - 0s - loss: 0.2935 - val_loss: 0.0453

>>> model.evaluate(train_data['features'],T_l)
314/314 [==============================] - 0s
0.042102484922310349
>>> model.evaluate(validation_data['features'],t_l)
34/34 [==============================] - 0s
0.04533623531460762
question no.1
Why does the val_loss start at a low point and continues as is ?
Question no.2
Since 'loss' shows the error on training set
why is the error 0.042102... on training set when evaluating
but 0.2935 on epoch 200 ?
I tried many models, including LSTM and the outcome is the same.
I shuffled the data before feeding them to the model for fitting.
I also changed my labels' values to reside between 0 and 1 but not much changed.
What am i doing wrong ?
Thank you in advance for your support
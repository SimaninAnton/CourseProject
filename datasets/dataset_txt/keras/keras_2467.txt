liujxing commented on 4 May 2017 â€¢
edited
I am trying to use predict_generator to batch-load data from disk and make prediction for each batch. The version of my Keras is 1.12.1.
Say I have 20011 rows and my batch size is 10000 expect for the last batch, so the batch size is 10000 -> 10000 -> 11 in my example. I take great care to make sure each batch has the correct data.
When using this generator in predict_generator, the behaviour is different from what I expected: it gives me "ValueError: could not broadcast input array from shape (10000,1) into shape (11,1)".
Then I looked at the source code of training.py, on line 1728 outs = self.predict_on_batch(x), I print out the shape of x and outs. When len(x) is equal to 11, but len(outs) is equal to 10000, although they should have the same length!
To make things worse, I expect my added line to print out the size of my x as 10000->10000->1 if the data are loaded in the same order as I coded it. However, in fact the data are loaded in the order of 10000 -> 1 -> error, so it is out of order!
So I am suspecting this has something to do with multithreading or multiprocessing used to load the data, because if I add time.sleep(3) after the yield in the generator function, the value error goes away. I did not check if the data are in order, and I think my fix is stupid. Perhaps in the second load when self.predict_on_batch is called, the length of x and outs are 10000, but before it can do any work x is changed by the third load so the nb_samples are in fact length of x from the last load.
Contributor
alito commented on 4 Dec 2016 â€¢
edited
I think adding an 'every' parameter to the ModelCheckpoint callback would be useful, for it to save every N epochs (defaulting to 1 of course).
ie change the constructor to:
    def __init__(self, filepath, monitor='val_loss', verbose=0,
                 save_best_only=False, save_weights_only=False,
                 mode='auto', every=1):
Sometimes epochs are very short and the loss function is noisy so relying on loss function changes to decide when to save isn't great.
The code for the patch is trivial. I can open a PR if others think this would be useful
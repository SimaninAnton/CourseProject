n33raj3 commented on 9 Jan 2019
import numpy as np
import cv2
import tensorflow as tf
import keras.backend as K
K.set_image_data_format('channels_last')
train=np.empty((16,288,512,6), dtype='uint8')
y_train=np.empty((16,288,512),dtype='uint8')
y_train_u=np.empty((16,288,512),dtype='uint8')
rel_path1 = "DeepStab/stable/"
rel_path2 = "DeepStab/unstable/"
Start the webcam
for i in range (1,2):
k=0
t=0
current_file=str(i)+".avi"
cap1 = cv2.VideoCapture(rel_path1+current_file)
cap2 = cv2.VideoCapture(rel_path2+current_file)
no_of_frame1=int(cap1.get(7))
no_of_frame2=cap2.get(7)
ret, frame = cap1.read()
ret, frameu = cap2.read()
print(i)
print(no_of_frame1)
framearray = np.empty((no_of_frame1,720,1280,3), dtype=frame.dtype)
framearray_u = np.empty((no_of_frame1,720,1280,3), dtype=frameu.dtype)
for j in range(1,no_of_frame1):
ret, framearray[j] = cap1.read()
ret, framearray_u[j] = cap2.read()
while(True):
    # Take the first frame and convert it to gray
    j=448
   
    if ret == True:
        if j+k<(no_of_frame1-1):
            prvs1 = cv2.cvtColor(framearray[30+k], cv2.COLOR_BGR2GRAY)
            prvs1=cv2.resize(prvs1, (512, 288), interpolation = cv2.cv2.INTER_CUBIC) 
            prvs2 = cv2.cvtColor(framearray_u[30+k], cv2.COLOR_BGR2GRAY)
            #cv2.resizeWindow('image', 512,288)
            #cv2.imshow('',prvs2)
            prvs2=cv2.resize(prvs2, (512, 288), interpolation = cv2.INTER_CUBIC) 
            nex1 = cv2.cvtColor(framearray[j+k+1],cv2.COLOR_BGR2GRAY)
            nex1=cv2.resize(nex1, (512, 288), interpolation = cv2.INTER_CUBIC)
            nex2 = cv2.cvtColor(framearray_u[j+k+1],cv2.COLOR_BGR2GRAY)
            nex1=cv2.resize(nex1, (512, 288), interpolation = cv2.INTER_CUBIC)
            nex2=cv2.resize(nex2, (512, 288), interpolation = cv2.INTER_CUBIC)
            optical_flow = cv2.DualTVL1OpticalFlow_create()
            #flow = optical_flow.calc(prvs1, nex1, None)
            #print(flow.shape)
            # Show the convoluted result
            #cv2.imshow('convolution', warp_image(prvs2,flow)) {1/D*||F*nex2-w(F*prvs2)||}
            #print(warp_image(predicted_prvs,flow)) \\previously predicted frame
            #print(j)
        if 30<j+k<no_of_frame1-1:
            s_1=cv2.cvtColor(framearray[j+k-30],cv2.COLOR_BGR2GRAY)
            s_1=cv2.resize(s_1, (512, 288), interpolation = cv2.INTER_CUBIC)
            s_2=cv2.cvtColor(framearray[j+k-24],cv2.COLOR_BGR2GRAY)
            s_2=cv2.resize(s_2, (512, 288), interpolation = cv2.INTER_CUBIC)
            s_3=cv2.cvtColor(framearray[j+k-18],cv2.COLOR_BGR2GRAY)
            s_3=cv2.resize(s_3, (512, 288), interpolation = cv2.INTER_CUBIC)
            s_4=cv2.cvtColor(framearray[j+k-12],cv2.COLOR_BGR2GRAY)
            s_4=cv2.resize(s_4, (512, 288), interpolation = cv2.INTER_CUBIC)
            s_5=cv2.cvtColor(framearray[j+k-6],cv2.COLOR_BGR2GRAY)
            s_5=cv2.resize(s_5, (512, 288), interpolation = cv2.INTER_CUBIC)
            s=np.dstack((s_1,s_2,s_3,s_4,s_5,nex2))
            ss=np.dstack((s_1,s_2,s_3,s_4,s_5,nex1))
            #print(s.shape)
            #x = image.img_to_array(s)
            #x = np.expand_dims(x, axis=0)
            #x = preprocess_input(x)
            #print('Input image shape:', x.shape)
            print(j+k)
            train[t]=(s)
            y_train[t]=(nex1)
            #y_train_u[t]=nex2
            y_train_u[t]=(nex2)
            
            print('value of t:'+str(t))
            t=t+1
        k=k+1
        prvs1 = nex1
        prvs2 = nex2
        if (j+k)==(no_of_frame1):
            break
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break
else:
    break
#train=tf.convert_to_tensor(train,dtype=np.float32)
#y_train=tf.convert_to_tensor(y_train,dtype=np.float32)
#y_train_u=tf.convert_to_tensor(y_train_u,dtype=np.float32)
cap1.release()
cv2.destroyAllWindows()
from keras.applications.resnet50 import ResNet50
import keras as ke
from keras import layers
from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D
from keras.models import Model, load_model
from keras.preprocessing import image
from keras.utils import layer_utils
from keras.utils.data_utils import get_file
from keras.applications.imagenet_utils import preprocess_input
import pydot_ng as pydot
from IPython.display import SVG
from keras.utils.vis_utils import model_to_dot
from keras.utils import plot_model
from keras.initializers import glorot_uniform
import scipy.misc
from matplotlib.pyplot import imshow
%matplotlib inline
from keras.applications import resnet50
#resnet_model = resnet50.ResNet50(weights='imagenet',include_top=False)
import sys
sys.path.append(r"C:\Users\ECE22\AppData\Local\Programs\Python\Python36\Lib\site-packages\tensorflow\contrib\slim\python\slim\nets");
import resnet_utils
#import dataset
from resnet_utils import *
#from dataset import load_datasets
import keras.backend as K
K.set_image_data_format('channels_last')
K.set_learning_phase(1)
import matplotlib.pyplot as plt
from keras.optimizers import Adam
from keras.layers import Lambda
from keras.callbacks import EarlyStopping
from keras.layers import Flatten, Dense, Reshape
def identity_block(X, f, filters, stage, block):
"""
Implementation of the identity block as defined in Figure 3
Arguments:
X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)
f -- integer, specifying the shape of the middle CONV's window for the main path
filters -- python list of integers, defining the number of filters in the CONV layers of the main path
stage -- integer, used to name the layers, depending on their position in the network
block -- string/character, used to name the layers, depending on their position in the network

Returns:
X -- output of the identity block, tensor of shape (n_H, n_W, n_C)
"""

# defining name basis
conv_name_base = 'res' + str(stage) + block + '_branch'
bn_name_base = 'bn' + str(stage) + block + '_branch'

# Retrieve Filters
F1, F2, F3 = filters

# Save the input value. You'll need this later to add back to the main path. 
X_shortcut = X

# First component of main path
X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a')(X)
X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)
X = Activation('relu')(X)


# Second component of main path 
X = Conv2D(filters = F2, kernel_size=(f,f), strides = (1,1), padding='same', name = conv_name_base + '2b')(X)

X = BatchNormalization(axis=3, name = bn_name_base + '2b')(X)
X = Activation('relu')(X)

# Third component of main path 
X = Conv2D(filters = F3, kernel_size=(1,1), strides = (1,1), padding="valid", name = conv_name_base + '2c')(X)
X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)

# Final step: Add shortcut value to main path, and pass it through a RELU activation 
X = Add()([X,X_shortcut])
X = Activation('relu')(X)


return X
def convolutional_block(X, f, filters, stage, block, s = 2):
"""
Implementation of the convolutional block as defined in Figure 4
Arguments:
X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)
f -- integer, specifying the shape of the middle CONV's window for the main path
filters -- python list of integers, defining the number of filters in the CONV layers of the main path
stage -- integer, used to name the layers, depending on their position in the network
block -- string/character, used to name the layers, depending on their position in the network
s -- Integer, specifying the stride to be used

Returns:
X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)
"""

# defining name basis
conv_name_base = 'res' + str(stage) + block + '_branch'
bn_name_base = 'bn' + str(stage) + block + '_branch'

# Retrieve Filters
F1, F2, F3 = filters

# Save the input value
X_shortcut = X


##### MAIN PATH #####
# First component of main path 
X = Conv2D(filters = F1, kernel_size= (1, 1), strides = (s,s),padding="valid", name = conv_name_base + '2a')(X)
X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)
X = Activation('relu')(X)


# Second component of main path 
X = Conv2D(filters = F2, kernel_size=(f,f), strides=(1,1), name = conv_name_base + '2b', padding="same")(X)
X = BatchNormalization(axis = 3, name= bn_name_base + '2b')(X)
X = Activation('relu')(X)

# Third component of main path 
X = Conv2D(filters = F3, kernel_size=(1,1), strides = (1,1), name= conv_name_base + '2c',padding="valid")(X)
X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)

##### SHORTCUT PATH #### 
X_shortcut = Conv2D(filters = F3, kernel_size= (1,1), strides=(s,s), name=conv_name_base + '1', padding="valid")(X_shortcut)
X_shortcut = BatchNormalization(axis=3, name=bn_name_base+'1')(X_shortcut)

# Final step: Add shortcut value to main path, and pass it through a RELU activation 
X = Add()([X_shortcut,X])
X = Activation("relu")(X)


return X
def conv2d(x):
return tf.nn.conv2d(x[0], x[1], strides=[1, 1, 1, 1], padding='SAME')
def ResNet50(input_shape,output_shape,data_a,data_b,labels,weights='imagenet'):
"""
Implementation of the popular ResNet50 the following architecture:
CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK2 -> CONVBLOCK -> IDBLOCK3
-> CONVBLOCK -> IDBLOCK5 -> CONVBLOCK -> IDBLOCK2 -> AVGPOOL -> TOPLAYER
Arguments:
input_shape -- shape of the images of the dataset
classes -- integer, number of classes
Returns:
model -- a Model() instance in Keras
"""
# Define the input as a tensor with shape input_shape
#X_input = tf.placeholder(tf.float32,shape=input_shape)
X_input=Input(input_shape)
# Zero-Padding
X = ZeroPadding2D((3, 3))(X_input)
Stage 1
X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1')(X)
X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)
X = Activation('relu')(X)
X = MaxPooling2D((3, 3), strides=(2, 2))(X)

# Stage 2
X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)
X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')
X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')


# Stage 3
X = convolutional_block(X, f=3, filters = [128,128,512], stage = 3, block='a', s=2)
X = identity_block(X, 3, filters = [128,128,512],stage=3, block='b')
X = identity_block(X, 3, filters = [128,128,512], stage=3, block='c')
X = identity_block(X, 3, filters = [128,128,512], stage =3, block='d')

# Stage 4 
X = convolutional_block(X, f=3, filters = [256,256,1024],stage=4, block='a', s=2)
X = identity_block(X, 3, filters = [256,256,1024], stage=4, block='b')
X = identity_block(X, 3, filters = [256, 256, 1024], stage=4, block='c')
X = identity_block(X, 3, filters= [256,256,1024], stage=4, block='d')
X = identity_block(X, 3, filters=[256,256,1024], stage=4, block='e')
X = identity_block(X, 3, filters=[256,256,1024], stage=4, block='f')

# Stage 5 
X = convolutional_block(X, f=3, filters=[256,256,2048], stage=5,block='a', s=3)
X = identity_block(X, 3, filters=[256,256,2048], stage=5, block='b')
X = identity_block(X,3, filters=[256,256,2048], stage=5, block='c')

# AVGPOOL (≈1 line). Use "X = AveragePooling2D(...)(X)"
X = AveragePooling2D((6,6), name='avg_pool')(X)
F=Conv2D(8,(1,1),strides=(1,1),name='Parameter',dilation_rate=(1, 1),kernel_initializer = glorot_uniform(seed=0))(X)
#F=F[0][0][0]

#F_=[[F[0],F[1],F[2]],[F[3],F[4],F[5]],[[F[6],F[7],1]]]
F_= Reshape((8,1,1), name='predictions')(F)
#F_=tf.reshape(F,shape=(3,3,1,1),name=None)

print(F_)
#F_=tf.keras.backend.cast(F,dtype=tf.float32)
#F_=tf.to_float(F_, name='ToFloat')

Y_u=Input(output_shape)
#ypred=(ke.backend.conv2d( Y_u,F_, [1, 1], "same"))
#ypred=ke.layers.Lambda((ke.backend.conv2d( Y_u,F_, [1, 1], "same")))
#ypred=conv2d( Y_u,F_)
ypred=Lambda(conv2d)([Y_u,F_])
#ypred=tf.keras.backend.cast(ypred, 'float32')
#ypred=tf.reshape(F,[288,512])
#print(ypred)
model = Model(inputs=[X_input, Y_u], outputs=ypred,name='ResNet50')
#model = Model(inputs =X_input, outputs = ypred, name='ResNet50')

return model
y_train=np.reshape(y_train,(16,288,512,1))
y_train_u=np.reshape(y_train_u,(16,288,512,1))
model=ResNet50(input_shape=(288,512,6),output_shape=(288,512,1),data_a=train,data_b=y_train_u,labels=y_train)
sgd=ke.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)
model.compile(sgd,loss='mean_squared_error', metrics=['accuracy'])
model.fit([train, y_train_u],y_train,batch_size=8, epochs=2)
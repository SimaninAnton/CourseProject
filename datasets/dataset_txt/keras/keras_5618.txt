indra215 commented on 31 Mar 2016
I've trained a CNN regression model where input are image patches of size 32x32 and output is a real value between 0 and 1. The training loss decreased for each epoch, so I think the model has trained well. But when i test it on new patches, the output is same number (0.76677054) for all the test data. Below is the training log.
Epoch 1/10
157500/157500 [==============================] - 27s - loss: 67.4626
Epoch 2/10
157500/157500 [==============================] - 28s - loss: 0.0416
Epoch 3/10
157500/157500 [==============================] - 28s - loss: 0.0399
Epoch 4/10
157500/157500 [==============================] - 28s - loss: 0.0384
Epoch 5/10
157500/157500 [==============================] - 28s - loss: 0.0369
Epoch 6/10
157500/157500 [==============================] - 28s - loss: 0.0356
Epoch 7/10
157500/157500 [==============================] - 28s - loss: 0.0344
Epoch 8/10
157500/157500 [==============================] - 28s - loss: 0.0335
Epoch 9/10
157500/157500 [==============================] - 28s - loss: 0.0330
Epoch 10/10
157500/157500 [==============================] - 28s - loss: 0.0328
The predictions from the model for 100 test examples are [[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]
[ 0.72903597]]
where as the actual values are [ 0.98310286 0.99902654 0.98400015 0.97930992 0.98817956 0.98120451
0.9810034 0.99848258 0.98457533 0.99963462 0.99202013 0.99134362
0.98644668 0.99062026 0.99015951 0.98438585 0.98900211 0.98767084
0.98369926 0.98538613 0.98686498 0.98822546 0.99942929 0.9840979
0.9831208 0.9861989 0.9854362 0.97022384 0.98503685 0.98317361
0.98572952 0.98618585 0.98530596 0.98547059 0.99931002 0.98678994
0.98149586 0.98218203 0.98272216 0.9970932 0.98966181 0.9771812
0.99216288 0.99134213 0.99915296 0.98414373 0.98620075 0.99930561
0.985811 0.98439544 0.98012143 0.99588025 0.99901617 0.98042828
0.98559868 0.98549771 0.98482186 0.9838171 0.99734801 0.98864162
0.97996467 0.99959683 0.98265719 0.98295158 0.98595458 0.97992152
0.98100066 0.99938887 0.99171072 0.98087996 0.9885301 0.98847991
0.97887361 0.98546422 0.99837124 0.98957223 0.98080635 0.99232441
0.9907316 0.97276324 0.96823871 0.98753953 0.98204005 0.97736055
0.99608529 0.97974199 0.98512524 0.98920614 0.99310815 0.99986422
0.98227423 0.97727633 0.99976826 0.98718786 0.98313379 0.97858363
0.9850468 0.99430633 0.98553413]
Can anyone please help me solve this issue ?
siddBanPsu commented on 8 Apr 2016
I am using the sequence to sequence type generation and training on parallel text.
I have taken X as the indices of words in a vocabulary and Y as a sequence of one-hot vectors.
model = Sequential()
model.add(Embedding(vocab_size, EMBED_HIDDEN_SIZE,mask_zero=True))
model.add(Dropout(0.3))
model.add(LSTM(EMBED_HIDDEN_SIZE, return_sequences=True))
model.add(Dropout(0.3))
model.add(LSTM(EMBED_HIDDEN_SIZE, return_sequences=False))
model.add(Dropout(0.3))
model.add(Dense(vocab_size, activation='softmax'))
model.compile(optimizer='adam', loss='categorical_crossentropy')
When I try to predict:
X=pad_sequences([[1,1,2],[2,3]], maxlen=max_web_len) 

Y= s2s_model.predict(X)[0]
I do not get one-hot but dense representations. How do I use the values to find out the sequence of words from Y?
1
superlilian commented on 8 Nov 2017 â€¢
edited
I try to write my own loss and metrics. For the fit step, it works perfectly, nevertheless, for the evaluate step, I obtain different results (seems to use another metrics and loss). To check, I use the same set for training and for evaluation with a batch_size of 100%, I should obtain the same result ? And absolutely not.
I try to write a sample:
from __future__ import print_function

import keras
from keras.models import Sequential
from keras.layers import Dense, Dropout
from keras.optimizers import RMSprop
from keras import backend as K

from scipy.stats import norm
import numpy as np

batch_size = 10000
num_classes = 2
epochs = 100


len = 50

B = norm.rvs(size=(10000,1))
y_train = (B > 0) * 1
L = np.arange(0,len)/len
x_train = B * L

print(x_train.shape)
print(y_train.shape)

x_test = x_train
y_test = y_train

y_train = keras.utils.to_categorical(y_train, num_classes)
y_test  = keras.utils.to_categorical(y_test, num_classes)
print(y_train.shape)
print(y_test.shape)


model = Sequential()
model.add(Dense(4, activation='relu', input_shape=(len,)))
model.add(Dense(4, activation='relu'))
model.add(Dense(num_classes, activation='softmax'))

model.summary()

def bbb(y_true, y_pred):
  a11 = K.sum(y_pred[:,1]*y_true[:,1])
  a10 = K.sum(y_pred[:,1]*y_true[:,0])
  return a11-a10


def acc(y_true, y_pred):
    a11 = K.sum(y_pred[:, 1] * y_true[:, 1])
    a10 = K.sum(y_pred[:, 1] * y_true[:, 0])
    ratio = (a11+a10)
    return ratio

model.compile(loss=bbb,
              optimizer=RMSprop(),
              metrics=[acc])

history = model.fit(x_train, y_train,
                    batch_size=batch_size,
                    epochs=epochs,
                    verbose=1)
model.summary()


score = model.evaluate(x_train, y_train)

print(score)`
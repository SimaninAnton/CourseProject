NoamGit commented on 2 Dec 2016
Hi all,
I am running a model which contains some GRU modules in an RNN with keras. While training, the CPU spikes between ~400% to ~950%, when every spike ends after several seconds and returns to 99% CPU usage baseline. Ideally I would like the CPU to stay steady in > 700%, as the spiking translates to inefficient runtime. My .theanorc file:
[global]
device = cpu
floatx = float32
allow_gc = false
mode = FAST_RUN
openmp = true 

[scan]
allow_gc = false
Any suggestions?
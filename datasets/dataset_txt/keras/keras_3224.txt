isaacgerg commented on 13 Feb 2017
keras 1.2.2 using tensorflow-gpu 0.12.1.
When using the model.evaluate_generator(), val_samples is not honored by the threads queuing the generator even when nb_worker=1 and max_q_size=1.
For example, suppose my generator returns 32 samples per batch. Calling model.evaluate_generator(myGenerator, 64, max_q_size=1, nb_worker=1) should result in the next(myGenerator) being called 2 times. However, it is called at least 3 times by data_generator_task() in training.py. This is problematic for generators that loop through finite datasets.
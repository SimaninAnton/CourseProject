jkarimi91 commented on 15 Apr 2017
In a properly configured network, the expected initial loss should be ~log(num_classes) = ~2.3, however, instead we have a log of ~14; what is causing this discrepancy?
from cs231n.data_utils import get_CIFAR10_data
from keras.models import Sequential
from keras.layers import Conv2D, MaxPool2D, Dense, Flatten
from keras.optimizers import Adam
from keras.utils import to_categorical


data = get_CIFAR10_data()
for k, v in data.iteritems():
  print '%s: ' % k, v.shape

#X_val:  (1000, 3, 32, 32)
#X_train:  (49000, 3, 32, 32)
#X_test:  (1000, 3, 32, 32)
#y_val:  (1000,)
#y_train:  (49000,)
#y_test:  (1000,)

X_val, y_val = data['X_val'], data['y_val']
X_train, y_train = data['X_train'], data['y_train']
X_test, y_test = data['X_test'], data['y_test']

y_train = to_categorical(y_train, num_classes=10)
y_val = to_categorical(y_val, num_classes=10)

model = Sequential()
model.add(Conv2D(32, 3, padding='same', activation='relu', input_shape=(3, 32, 32),
                 data_format='channels_first'))
model.add(Conv2D(32, 3, padding='same', activation='relu', data_format='channels_first'))
model.add(MaxPool2D(data_format='channels_first'))

model.add(Conv2D(32, 3, padding='same', activation='relu', data_format='channels_first'))
model.add(Conv2D(32, 3, padding='same', activation='relu', data_format='channels_first'))
model.add(MaxPool2D(data_format='channels_first'))

model.add(Flatten())
model.add(Dense(500, activation='relu'))
model.add(Dense(10, activation='softmax'))

optim = Adam(lr=1e-3)
model.compile(loss='categorical_crossentropy',
              optimizer=optim,
              metrics=['accuracy'])

model.fit(X_train, y_train, batch_size=100, epochs=1, validation_data=(X_val, y_val))
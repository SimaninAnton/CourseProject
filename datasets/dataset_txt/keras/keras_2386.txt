amir-rahnama commented on 14 May 2017
I am very new to Keras. That said, I am trying to avoid using Scikit's pipeline code since it is relatively slower than using the keras network.
estimators = []
estimators.append(('standardize', StandardScaler()))
estimators.append(('mlp', KerasRegressor(build_fn=wider_model, epochs=100, batch_size=5, verbose=0)))
pipeline = Pipeline(estimators)
kfold = KFold(n_splits=10, random_state=seed)
results = cross_val_score(pipeline, X.T, Y, cv=kfold)
How can you achieve the same result using Keras's implementation? Can I achieve the same using NormalizationLayer? I could not figure out how but I tried the following:
X_norm = utils.normalize(X)
model = Sequential()
model.add(Dense(20, input_dim=12, kernel_initializer='normal', activation='relu'))
model.add(Dense(1, kernel_initializer='normal'))
# Compile model
model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])
# Fit the model
history = model.fit(X_norm.T, Y, validation_split=10, epochs=100, batch_size=15, verbose=0)
I am using Keras 2.0.4 with Tensorflow 0.12.1.
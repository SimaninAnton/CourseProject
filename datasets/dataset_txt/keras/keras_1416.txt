linetor commented on 11 Dec 2017
I need to freeze lstm layer(using Bidirectional wrapper).
So I freeze layer using
singleModel.layers[x].trainable = False
But it seems to not be frozen.
After checking layer(by seeing # of Trainable params), I find that forward_layer,backward_layer flag need to be set. like below
from keras.layers import Dense, Activation,LSTM,Input,Bidirectional,Dropout,CuDNNLSTM
for x in range(len(classificationWithString.layers)-2):
    if classificationWithString.layers[x].__class__==Bidirectional:
        classificationWithString.layers[x].forward_layer.trainable = False        
        classificationWithString.layers[x].backward_layer.trainable = False            
    classificationWithString.layers[x].trainable = False
I wonder is it intended?
If not, I think that if layers.trainable=False, it needs to be freeze forward_layer,backward_layer.
Thanks
anik786 commented on 15 Mar 2016
When running my neural network and fitting it like so:
model.fit(x, t, batch_size=256, nb_epoch=100, verbose=2, validation_split=0.1, show_accuracy=True)
I have found that as the number of epochs increases, there are times where the validation accuracy actually decreases.
For example at epoch 12 I got:
Epoch 12/100
4s - loss: 0.1026 - acc: 0.9667 - val_loss: 0.1384 - val_acc: 0.9733
But by the end I git:
Epoch 95/100
3s - loss: 4.6988e-04 - acc: 1.0000 - val_loss: 0.1290 - val_acc: 0.9600
Epoch 96/100
2s - loss: 5.7437e-04 - acc: 1.0000 - val_loss: 0.1321 - val_acc: 0.9600
Epoch 97/100
1s - loss: 6.3242e-04 - acc: 1.0000 - val_loss: 0.1312 - val_acc: 0.9600
Epoch 98/100
1s - loss: 5.3643e-04 - acc: 1.0000 - val_loss: 0.1322 - val_acc: 0.9600
Epoch 99/100
2s - loss: 4.2413e-04 - acc: 1.0000 - val_loss: 0.1326 - val_acc: 0.9600
Epoch 100/100
1s - loss: 4.8201e-04 - acc: 1.0000 - val_loss: 0.1295 - val_acc: 0.9600
Is this supposed to happen. Why?
Also will the final network have an accuracy of 0.96 or 0.9733.
3
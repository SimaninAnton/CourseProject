spate141 commented on 4 Sep 2019 â€¢
edited
System information
Have I written custom code (as opposed to using example directory): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
TensorFlow backend (yes / no): Yes
TensorFlow version: 1.14.0
Keras version: 2.2.5
Python version: 3.6.8
CUDA/cuDNN version: N/A
GPU model and memory: N/A
Describe the current behavior:
Error when loading model with model = load_model(file.h5)
ValueError: axes don't match array
Describe the expected behavior
Model is not loading again after saving with model.save(file.h5)
Here is what I'm trying to do:
I have 15 models as a single merged_model which are basically just the classification models with 15 inputs and 15 outputs.
I'm trying to combine the these 15 model's input into a single input model. So I don't have to provide 15 inputs!
Here is how I'm doing that: (this is working without any issue)
>> model_single_input = layers.Input((15,), dtype='int32', name='single.input')
>> model_multiple_inputs = layers.Lambda(lambda x: [x] * 15, name='single.input.multiplier')(model_single_input)
>> single_input_model = Model(inputs=model_single_input, outputs=model_multiple_inputs)
>> single_input_model.input, single_input_model.output

(<tf.Tensor 'single.input:0' shape=(?, 15) dtype=int32>,
 [<tf.Tensor 'single.input.multiplier/Identity:0' shape=(?, 15) dtype=int32>,
  <tf.Tensor 'single.input.multiplier/Identity_1:0' shape=(?, 15) dtype=int32>,
  <tf.Tensor 'single.input.multiplier/Identity_2:0' shape=(?, 15) dtype=int32>,
  <tf.Tensor 'single.input.multiplier/Identity_3:0' shape=(?, 15) dtype=int32>,
  <tf.Tensor 'single.input.multiplier/Identity_4:0' shape=(?, 15) dtype=int32>,
  <tf.Tensor 'single.input.multiplier/Identity_5:0' shape=(?, 15) dtype=int32>,
  <tf.Tensor 'single.input.multiplier/Identity_6:0' shape=(?, 15) dtype=int32>,
  <tf.Tensor 'single.input.multiplier/Identity_7:0' shape=(?, 15) dtype=int32>,
  <tf.Tensor 'single.input.multiplier/Identity_8:0' shape=(?, 15) dtype=int32>,
  <tf.Tensor 'single.input.multiplier/Identity_9:0' shape=(?, 15) dtype=int32>,
  <tf.Tensor 'single.input.multiplier/Identity_10:0' shape=(?, 15) dtype=int32>,
  <tf.Tensor 'single.input.multiplier/Identity_11:0' shape=(?, 15) dtype=int32>,
  <tf.Tensor 'single.input.multiplier/Identity_12:0' shape=(?, 15) dtype=int32>,
  <tf.Tensor 'single.input.multiplier/Identity_13:0' shape=(?, 15) dtype=int32>,
  <tf.Tensor 'single.input.multiplier/Identity_14:0' shape=(?, 15) dtype=int32>])
Now here is I'm combining single input model with 15 models. (this is working without any issue)
>> single_input_merged_output_model = Model(inputs  = single_input_model.input, outputs = merged_model(single_input_model.output))
>> encoded_data = np.array([
[12073, 14512, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
[336, 0, 744, 481, 13043, 118, 2563, 0, 0, 0, 0, 0, 0, 0, 0]
])
>> predictions = single_input_merged_output_model.predict(encoded_data)
>> predictions

[array([[ 0.        , 18.        ,  0.23679169],
        [ 0.        , 13.        ,  0.5127094 ]], dtype=float32),
 array([[1.0000000e+00, 2.0700000e+02, 4.9950428e-02],
        [1.0000000e+00, 9.2000000e+01, 3.4491304e-01]], dtype=float32),
 array([[  2.       , 229.       ,   0.9984485],
        [  4.       ,  60.       ,   0.9372796]], dtype=float32),
 array([[2.000000e+00, 1.194000e+03, 9.985555e-01],
        [3.000000e+00, 1.030000e+02, 9.584518e-01]], dtype=float32),
 array([[2.000000e+00, 1.558000e+03, 9.996946e-01],
        [3.000000e+00, 8.800000e+01, 9.738545e-01]], dtype=float32),
 array([[2.000000e+00, 1.997000e+03, 9.998343e-01],
        [7.000000e+00, 7.020000e+02, 9.954461e-01]], dtype=float32),
 array([[2.0000000e+00, 1.7690000e+03, 9.9997449e-01],
        [3.0000000e+00, 1.7900000e+02, 9.9776447e-01]], dtype=float32),
 array([[2.000000e+00, 1.448000e+03, 9.999393e-01],
        [3.000000e+00, 2.430000e+02, 9.982481e-01]], dtype=float32),
 array([[2.0000000e+00, 1.0770000e+03, 9.9984264e-01],
        [3.0000000e+00, 2.0700000e+02, 9.9882430e-01]], dtype=float32),
 array([[  2.        , 754.        ,   0.9998847 ],
        [  3.        , 493.        ,   0.99971205]], dtype=float32),
 array([[  2.       , 536.       ,   0.9996455],
        [  3.       , 239.       ,   0.9998828]], dtype=float32),
 array([[  2.        , 444.        ,   0.99973446],
        [  3.        ,  98.        ,   0.99974567]], dtype=float32),
 array([[8.0000000e+00, 1.0400000e+02, 1.3962857e-01],
        [2.0000000e+00, 2.3600000e+02, 7.3362941e-01]], dtype=float32),
 array([[ 2.        , 34.        ,  0.06541887],
        [ 2.        , 46.        ,  0.3399737 ]], dtype=float32),
 array([[ 2.        , 52.        ,  0.24562976],
        [ 2.        ,  7.        ,  0.5339988 ]], dtype=float32)]
Here is how I'm saving the final model. (this is working without any issue)
>> single_input_merged_output_model.save('file.h5', include_optimizer=False)
...and here is the issue when I try to load this above model which I just saved!
>> single_input_merged_output_model = load_model('file.h5', compile=False)
Error:
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<timed exec> in <module>

~/anaconda3/lib/python3.6/site-packages/keras/engine/saving.py in load_wrapper(*args, **kwargs)
    456                 os.remove(tmp_filepath)
    457             return res
--> 458         return load_function(*args, **kwargs)
    459 
    460     return load_wrapper

~/anaconda3/lib/python3.6/site-packages/keras/engine/saving.py in load_model(filepath, custom_objects, compile)
    548     if H5Dict.is_supported_type(filepath):
    549         with H5Dict(filepath, mode='r') as h5dict:
--> 550             model = _deserialize_model(h5dict, custom_objects, compile)
    551     elif hasattr(filepath, 'write') and callable(filepath.write):
    552         def load_function(h5file):

~/anaconda3/lib/python3.6/site-packages/keras/engine/saving.py in _deserialize_model(h5dict, custom_objects, compile)
    290                                                        original_keras_version,
    291                                                        original_backend,
--> 292                                                        reshape=False)
    293         if len(weight_values) != len(symbolic_weights):
    294             raise ValueError('Layer #' + str(k) +

~/anaconda3/lib/python3.6/site-packages/keras/engine/saving.py in preprocess_weights_for_loading(layer, weights, original_keras_version, original_backend, reshape)
    821         weights = convert_nested_time_distributed(weights)
    822     elif layer.__class__.__name__ in ['Model', 'Sequential']:
--> 823         weights = convert_nested_model(weights)
    824 
    825     if original_keras_version == '1':

~/anaconda3/lib/python3.6/site-packages/keras/engine/saving.py in convert_nested_model(weights)
    809                     weights=weights[:num_weights],
    810                     original_keras_version=original_keras_version,
--> 811                     original_backend=original_backend))
    812                 weights = weights[num_weights:]
    813         return new_weights

~/anaconda3/lib/python3.6/site-packages/keras/engine/saving.py in preprocess_weights_for_loading(layer, weights, original_keras_version, original_backend, reshape)
    821         weights = convert_nested_time_distributed(weights)
    822     elif layer.__class__.__name__ in ['Model', 'Sequential']:
--> 823         weights = convert_nested_model(weights)
    824 
    825     if original_keras_version == '1':

~/anaconda3/lib/python3.6/site-packages/keras/engine/saving.py in convert_nested_model(weights)
    797                     weights=weights[:num_weights],
    798                     original_keras_version=original_keras_version,
--> 799                     original_backend=original_backend))
    800                 weights = weights[num_weights:]
    801 

~/anaconda3/lib/python3.6/site-packages/keras/engine/saving.py in preprocess_weights_for_loading(layer, weights, original_keras_version, original_backend, reshape)
    940             weights[0] = np.reshape(weights[0], layer_weights_shape)
    941         elif layer_weights_shape != weights[0].shape:
--> 942             weights[0] = np.transpose(weights[0], (3, 2, 0, 1))
    943             if layer.__class__.__name__ == 'ConvLSTM2D':
    944                 weights[1] = np.transpose(weights[1], (3, 2, 0, 1))

~/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py in transpose(a, axes)
    637 
    638     """
--> 639     return _wrapfunc(a, 'transpose', axes)
    640 
    641 

~/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds)
     54 def _wrapfunc(obj, method, *args, **kwds):
     55     try:
---> 56         return getattr(obj, method)(*args, **kwds)
     57 
     58     # An AttributeError occurs if the object does not have

ValueError: axes don't match array
Things that I have already tried:
Saving model architecture and weights separately and loading (Not Working)
Any suggestions on loading model?
ddofer commented on 15 Oct 2016
I'm trying to apply the fasttext example on my own data, and am running into trouble (mainly due to not understanding the existing implementation example).
https://github.com/fchollet/keras/blob/master/examples/imdb_fasttext.py
My data is a list of char level text sequences, loaded using Keras's text tokenizer.
X_train.shape
(62665, 25)
i.e 62,665 sequences, each of length 25.
The sample code gave me the followng error when I tried applying it:
`Adding 2-gram features
AttributeError Traceback (most recent call last)
in ()
19
20 # Augmenting X_train and X_test with n-grams features
---> 21 X_train_ft = add_ngram(X_train, token_indice, ngram_range)
22 X_test_ft = add_ngram(X_test, token_indice, ngram_range)
23 print('Average train sequence length: {}'.format(np.mean(list(map(len, X_train_ft)), dtype=int)))
in add_ngram(sequences, token_indice, ngram_range)
68 ngram = tuple(new_list[i:i+ngram_value])
69 if ngram in token_indice:
---> 70 new_list.append(token_indice[ngram])
71 new_sequences.append(new_list)
72
AttributeError: 'numpy.ndarray' object has no attribute 'append'`
I'm sure this is a trivial thing to fix on my end in terms of the stage at which to apply the n-grams. Any advice?
Thank you very much!
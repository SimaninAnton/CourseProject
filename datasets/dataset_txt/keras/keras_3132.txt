isaacgerg commented on 25 Feb 2017 â€¢
edited
keras 1.2.2, python 3.5.2, tensorflow 0.12, windows 7
Taken from https://github.com/fchollet/keras/blob/master/tests/keras/test_multiprocessing.py
import numpy as np
from keras.models import Sequential
from keras.layers.core import Dense
from keras.utils.test_utils import keras_test

reached_end = False

arr_data = np.random.randint(0, 256, (500, 2))
arr_labels = np.random.randint(0, 2, 500)

def myGenerator():

    batch_size = 32
    n_samples = 500

    while True:
        batch_index = np.random.randint(0, n_samples - batch_size)
        start = batch_index
        end = start + batch_size
        X = arr_data[start: end]
        y = arr_labels[start: end]
        yield X, y

# Build a NN
model = Sequential()
model.add(Dense(1, input_shape=(2, )))
model.compile(loss='mse', optimizer='adadelta')

model.fit_generator(myGenerator(),
                    samples_per_epoch=320,
                    nb_epoch=1,
                    verbose=1,
                    max_q_size=10,
                    nb_worker=4,
                    pickle_safe=True)
gives
File "D:\HFPE\development\idgTools\test.py", line 36, in <module>
  pickle_safe=True)
File "c:\Python35\Lib\site-packages\keras\models.py", line 935, in fit_generator
  initial_epoch=initial_epoch)
File "c:\Python35\Lib\site-packages\keras\engine\training.py", line 1512, in fit_generator
  enqueuer.start(max_q_size=max_q_size, nb_worker=nb_worker)
File "c:\Python35\Lib\site-packages\keras\engine\training.py", line 455, in start
  thread.start()
File "c:\Python35\Lib\multiprocessing\process.py", line 105, in start
  self._popen = self._Popen(self)
File "c:\Python35\Lib\multiprocessing\context.py", line 212, in _Popen
  return _default_context.get_context().Process._Popen(process_obj)
File "c:\Python35\Lib\multiprocessing\context.py", line 313, in _Popen
  return Popen(process_obj)
File "c:\Python35\Lib\multiprocessing\popen_spawn_win32.py", line 66, in __init__
  reduction.dump(process_obj, to_child)
File "c:\Python35\Lib\multiprocessing\reduction.py", line 59, in dump
  ForkingPickler(file, protocol).dump(obj)

builtins.AttributeError: Can't pickle local object 'GeneratorEnqueuer.start.<locals>.data_generator_task'
Addendum 1:
@patyork @Dref360 on slack dont see the problem and run in linux. Perhaps windows issue?
Addendum 2:
Verified issue exists with python 3.6. Using same config as above with tensorflow-gpu compiled for python 3.6.
angelo337 commented on 21 Dec 2015
hi there
I am new to eras, and learning about it, for my fist model I am trying create a CNN 1D and every time I try to compile this I am getting the same error I try with even and Odds parameters,
here is the errors and bellow is the source code of my model. could some one please point me out my error and some resource for the solution?
thanks a lot
angelo
Traceback (most recent call last):
File "character_cnn.py", line 206, in
model.add(Dense(hidden_dims))
File "/usr/local/lib/python2.7/dist-packages/keras/layers/containers.py", line 32, in add
self.layers[-1].set_previous(self.layers[-2])
File "/usr/local/lib/python2.7/dist-packages/keras/layers/core.py", line 34, in set_previous
assert self.input_ndim == len(layer.output_shape), "Incompatible shapes: layer expected input with ndim=" +
File "/usr/local/lib/python2.7/dist-packages/keras/layers/core.py", line 588, in output_shape
return (input_shape[0], np.prod(input_shape[1:]))
File "/usr/local/lib/python2.7/dist-packages/numpy/core/fromnumeric.py", line 2481, in prod
out=out, keepdims=keepdims)
File "/usr/local/lib/python2.7/dist-packages/numpy/core/_methods.py", line 35, in _prod
return umr_prod(a, axis, dtype, out, keepdims)
TypeError: unsupported operand type(s) for *: 'NoneType' and 'int'
nb_samples = X_train.shape[0]
nb_features = X_train.shape[1]
newshape = (nb_samples, 1, nb_features, 1)
X_train = np.reshape(X_train, newshape).astype(np.int)
We set some hyperparameters
BATCH_SIZE = 16
maxlen = 10
max_features = a.shape[1]
FIELD_SIZE = 5 * 300
STRIDE = 300
N_FILTERS = a.shape[1]
nb_classes =22
embedding_dims = 50
nb_filters = 250
filter_length = 2
number of hidden nodes in full connected layer
hidden_dims = 250
print('Build model...')
model = Sequential()
model.add(Embedding(max_features, embedding_dims))
model.add(Dropout(0.25))
print "embedding dims: ", embedding_dims
we add a Convolution1D, which will learn nb_filter
word group filters of size filter_length:
model.add(Convolution1D(input_dim=embedding_dims,
nb_filter=nb_filters,
filter_length=filter_length,
border_mode="valid",
activation="relu",
subsample_length=1))
model.add(Activation('relu'))
we use standard max pooling (halving the output of the previous layer):
model.add(MaxPooling1D(pool_length=2))
We flatten the output of the conv layer,
so that we can add a vanilla dense layer:
model.add(Flatten())
Computing the output shape of a conv layer can be tricky;
for a good tutorial, see: http://cs231n.github.io/convolutional-networks/
output_size = nb_filters * (((maxlen - filter_length) / 1) + 1) / 2
print output_size
print nb_filters
I get the error in here no matter any parameter that I change
model.add(Dense(hidden_dims))
model.add(Dropout(0.25))
model.add(Activation('relu'))
model.add(Dense(nb_classes))
We project onto a single unit output layer, and squash it with a sigmoid:
model.add(Activation('softmax'))
model.compile(loss='categorical_crossentropy',
optimizer='adadelta')
print "fitting model"
model.fit(X_train, y_train, batch_size=BATCH_SIZE, verbose=1,
nb_epoch=10, show_accuracy=True,
validation_split=0.1)
score = model.evaluate(X_test, Y_test, show_accuracy=True, verbose=0)
print('Test score:', score[0])
print('Test accuracy:', score[1])
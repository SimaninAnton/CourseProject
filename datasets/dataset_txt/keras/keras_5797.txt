jllombart commented on 8 Mar 2016
I'm trying perform some one input to multiple output models
This is accomplished with graph model like here
model = Graph()
model.add_input(name='input',input_shape=(784,))
model.add_node(Dense(512,activation='relu'),name='c1',input='input')
model.add_node(Dense(512,activation='relu'),name='c2',input='c1')
model.add_node(Dense(512,activation='relu'),name='c3',input='c2')
model.add_node(Dense(512,activation='relu'),name='c4',input='c3')


model.add_node(Dense(512,activation='relu'),name='l5',input='l4')
model.add_node(Dense(512,activation='relu'),name='l6',input='l5')
model.add_node(Dense(10,activation='softmax'),name='sl1',input='l6')
model.add_output(name='out',input='sl1')

model.add_node(Dense(256,activation='relu'),name='r5',input='l4')
model.add_node(Dense(256,activation='relu'),name='r6',input='r5')
model.add_node(Dense(2,activation='softmax'),name='sr1',input='r6')
model.add_output(name='out2',input='sr1')


rms = RMSprop()
model.compile(rms,{'out':'categorical_crossentropy','out2':'categorical_crossentropy'})
This works fine for me but the gradient is merged in the common node ( in examale in l4 ), like the sum of the gradients of each side of the graph
My question is how or where I can change this way to merge the gradiente. I would interested in some kind of weighted add, like 0.2_gradient(left)+0.8_gradient(right). I suppose this is possible in code but I did't find it.
The thing is I would like to provide more importance to the training to learn from one side than the other
Tanks for your attention
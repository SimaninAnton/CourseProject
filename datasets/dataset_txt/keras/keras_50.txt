Predrag-A commented on 29 Sep 2019 •
edited
The architecture I'm trying to implement is here:
Patient-data adapted model architecture: ResNet-50. My images are split into folders by labels as such:
    root/
        ├── train/
        │   ├── class1/
        │   ├── class2/
        │   ...
        │
        └── validation/
           ├── class1/
           ├── class2/
           ...
I also have a CSV file that contains the image name, image labels (an image can have multiple class labels) and additional information:
    +--------+---------------+-------+------+
    | File  |    Labels     | Info1 | Info2 |
    +-------+---------------+-------+-------+
    | 1.png | class1        | 0.512 |     1 |
    | 2.png | class2        |   0.4 |     0 |
    | 3.png | class1|class2 |  0.64 |     1 |
    +-------+---------------+-------+-------+
My network model has two inputs, one which will be used to process the image and another one which will concatenate to the final layer before the dense layer:
    input_shape = (img_height, img_width, 1)
    
    img_input= Input(input_shape)
    vec_input = Input((2,))
    
    res = ZeroPadding2D((3, 3))(img_input)
    
    # Processing ...
    
    res = Flatten()(res)
    res = Concatenate()([res, vec_input])
    res = Dense(classes, activation='softmax', name='fc' + str(classes))(res)
To get the images I am using ImageDataGenerator with flow_from_directory, which works fine for getting only the image data:
    validation_datagen = ImageDataGenerator(rescale=1. / 255)
    validation_generator = validation_datagen.flow_from_directory(
            validation_dir,
            target_size=(target_size, target_size),
            batch_size=batch_size,
            class_mode=class_mode,
            color_mode=color_mode)
    
    # Similarly for the train data generator ...
    
    # Train the model using above defined data generators
    history = model.fit_generator(
        train_generator,
        epochs=epochs,
        validation_data=validation_generator)
I now need to use the additional information for each image as the vec_input in my model. I have looked at using flow_from_dataframe and creating custom generators, but am unsure how to go about this. I can restructure the images by putting them in the same folder if needed, although then I suppose I cannot use flow_from_directory. Any ideas on how I can achieve this?
EDIT: Solved by implementing a custom generator which implements the Sequence class
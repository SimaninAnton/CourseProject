tshauck commented on 5 Sep 2016 â€¢
edited
Please make sure that the boxes below are checked before you submit your issue. Thank you!
Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps
If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps
Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
It looks like if you pass oov_char=None into imdb.load_data the new dataset is created with only words above nb_words or below skip_top. I may be misunderstanding, but it seems like it should be the negation of that.
Here's a quick example:
from keras.datasets import imdb
import numpy as np

(X_train, y_train), (X_test, y_test) =  imdb.load_data(oov_char=None, nb_words=200)
print(np.min([np.min(x) for x in X_train]))
#200
print(np.max([np.max(x) for x in X_train]))
#88587
I would expect that the dataset would only retain values less than 200.
For the potentially offending code, starting on line 83 of keras/imdb.py...
    if oov_char is not None:
        X = [[oov_char if (w >= nb_words or w < skip_top) else w for w in x] for x in X]
    else:
        nX = []
        for x in X:
            nx = []
            for w in x:
                if (w >= nb_words or w < skip_top):
                    nx.append(w)
            nX.append(nx)
        X = nX
In particular if (w >= nb_words or w < skip_top). If this is in fact an issue, happy to submit a PR.
yanranwang commented on 1 Nov 2016
The raw data is several 256^3 3D images. The input to the network is 25^3 size patch, extracted from the large 3D image. While, for each 3D image, we extract millions of such patch with different location (coordinates) for training. Preprocessing and store all of the patches ahead is really not efficient. Thus, I am wondering can we generate the patches and do the training parallelly, using Keras?
Thank you very much!
2
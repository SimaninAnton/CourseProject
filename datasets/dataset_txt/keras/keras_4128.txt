monaj07 commented on 19 Oct 2016 â€¢
edited
@fchollet I am really desperate to realize how to apply my desired modifications to a custom RNN layer, but could not find a good hint anywhere.
I am going to implement a custom RNN layer and I tried to follow what explained in this link. However, the update equation of the hidden layer in my formulation is a bit different: h(t) = tanh(W.x + U.h(t-1) + V.r(t) + b) and I am a bit confused. In this equation, r(t) = f(x, p(t)) is a function of x, the fixed input distributed over time, and also p(t) = O(t-1).alpha + p(t-1), where O(t) is the Softmax output of each RNN cell. I think after calling super(customRNN, self).step in step function, the standard h(t) should be overridden by my definition of h(t). However I am not sure how to modify the states and get_constants functions, and whether or not I need to modify any other parts of the recurrent and simpleRNN classes.
My intuition is that the get_constants function only returns the dropout matrices as extra states to the step function, so I am guessing at least one state should be added for the dropout matrix of V in my equations.
I have just recently started using Keras and I could not find many references on custom Keras layer definition, and this is my first post here. Sorry if my issue is a bit overwhelmed with a lot of parameters, I just wanted to make sure that I am not missing any point. Thanks!
3
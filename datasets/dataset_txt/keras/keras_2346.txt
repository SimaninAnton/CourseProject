Hazarapet commented on 19 May 2017 â€¢
edited
Guys I wanted to create a custom loss and noticed something weird.When I use my custom function (which returns the same keras' loss ) the accuracy is quite different.I think it's better to explain with code.
import keras
import numpy as np
import keras.backend as K
from keras import losses
from utils import components
from keras.models import Sequential
from keras.layers import Dense

def reg_binary_cross_entropy(y_true, y_pred):
    return losses.binary_crossentropy(y_true, y_pred)

model = Sequential()
model.add(Dense(4, activation='relu', input_dim=100))
model.add(Dense(3, activation='sigmoid'))

model.compile(optimizer='adam',
              loss=losses.binary_crossentropy,
              metrics=['accuracy'])
``
# Generate dummy data
data = np.random.random((10, 100)).astype(np.int8)
labels = np.zeros((10, 3)).astype(np.int8)

for i in range(labels.shape[0]):
    r_int = np.random.randint(3)
    labels[i][r_int] = 1

print 'training...'
# Train the model, iterating on the data in batches of 32 samples
loss = model.fit(data, labels, epochs=2, batch_size=32, verbose=1)
the losses.binary_crossentropy or 'binary_crossentropy' loss function returns loss: 0.6931 - acc: 0.6667, but when I use the function which returns the same calculation (reg_binary_cross_entropy), the accuracy starts to flap, here is what I've got loss: 0.6931 - acc: 0.3000 or loss: 0.6931 - acc: 0.5000 or loss: 0.6931 - acc: 0.2000, loss: 0.6931 - acc: 0.1000, which is so weird.I don't know, maybe the issue is not related with keras, but can you try this code and see what you got? and of course any idea about this issue. By the way I run the code multiple times and the keras' loss alway gives the same result, but the custom returns quite different results. the inputs always are zeros, then the accuracy should be 0.66 (cause the output shape is 3 and only one of it is 1, the others are zeros)
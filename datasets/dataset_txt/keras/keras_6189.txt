Contributor
PiranjaF commented on 28 Dec 2015
From Advances in Optimizing Recurrent Networks: "The cutoff threshold for gradient clipping is set based on the average norm of the gradient over one pass on the data". I would therefore like to compute the average norm of the gradient to find a fitting gradient clipping value for my LSTM. How can this be done in Keras?
A good starting point seems to be get_gradients() in optimizers.py, but I can't see how I can pass the loss to this function.
I've tried to get inspiration from how the training loss is passed to get_gradients() when calling get_updates() as part of Sequential.compile() in models.py, but it is not clear to me how I can extract the gradients in a similar way.
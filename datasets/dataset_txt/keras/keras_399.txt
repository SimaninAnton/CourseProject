hendaboudegga commented on 5 Feb 2019
hello everyone,
i am working for vessel segmentation from retinal image. i am using an autoencoder network with softmax activation function for the final layer. this is my following code for training and prediction:
** training code
//loss function
losses =tf.nn.softmax_cross_entropy_with_logits(labels=net_output, logits=network)
cost = tf.reduce_mean(losses)
tf.summary.scalar("cross_entropy", cost)
//Adam optimizer
opt = tf.train.AdamOptimizer(args.learning_rate).minimize(cost, var_list=[var for var in tf.trainable_variables()])
init = tf.global_variables_initializer()
correct_prediction = tf.equal(tf.argmax(network, 1), tf.argmax(net_output, 1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
for epoch in range(0, args.num_epochs):
for i in range(0, len(train_input_names)):

   input_black_ring_image = preprocessing(train_input_names[i])
   input_image, segmented_image = data_augmentation(input_black_ring_image, train_segmented_names[i])
       for k in range(0, len(input_image)):

            for j in range(0, args.batch_size):

                index= k*args.batch_size + j
                    with tf.device('/gpu:0'):
                      input_slice = np.float32(input_image[index]) / 255.0

                      output_slice = np.float32(helpers.one_hot_it(label=segmented_image[index], label_values=label_values))


                                input_image_batch.append(np.expand_dims(input_slice, axis=0))
                                segmented_image_batch.append(np.expand_dims(output_slice, axis=0))                        
            if args.batch_size == 1:
                input_img = input_image_batch[0]


                 output_img = segmented_image_batch[0]

            else:
                 input_img = np.squeeze(np.stack(input_image_batch, axis=1))
                 output_img = np.squeeze(np.stack(segmented_image_batch, axis=1))  
//training
_,current=sess.run([opt, cost],feed_dict={net_input:input_img, net_output:output_img})
print("loss of img "+str(i) +" slice " +str(k)+" ="+str(current))
**prediction code
            //image for prediction
             input_slice_test = np.float32(input_image_test[15]) / 255.0 


            input_image_test = np.expand_dims(input_slice_test, axis=0)
            print("input     ", input_image_test)
         //prediction    
            output_image = sess.run(network, feed_dict={net_input:input_image_test})
            print("output", output_image)`
the value of accuracy look logic it converge after each epoch but when i try to predict an image after training all the epochs, the value of predicted array output look like this:
//result of prediction
[[[[4.4425573e-02 8.8295966e-01]
[5.4390044e-03 9.7242403e-01]
[1.9392670e-03 9.8569876e-01]
and the image is full white.
any help please!!
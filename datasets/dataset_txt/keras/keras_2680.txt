vinayakumarr commented on 11 Apr 2017 â€¢
edited
my network is given below
case 1 42 features
model = Sequential()
model.add(LSTM(4,input_dim=42)) # try using a GRU instead, for fun
model.add(Dropout(0.1))
model.add(Dense(5))
model.add(Activation('softmax'))
#Visualizing the average activation values of the input features for 10 samples of class 0
def get_activations(model, layer, X_batch):
get_activations = K.function([model.layers[0].input, K.learning_phase()], model.layers[layer].output)
activations = get_activations([X_batch,0])
return activations
my_featuremaps = get_activations(model, 0, ([X_train[:5], 0])[0])
print(my_featuremaps)
activation values
[[ 0.762 -0.122 0.044 -0.758]
[ 0.762 -0.122 0.044 -0.758]
[ 0.762 -0.122 0.044 -0.758]
[ 0.762 -0.038 0.043 -0.752]
[ 0.762 -0.038 0.043 -0.752]
[ 0.762 -0.038 0.043 -0.752]
[ 0.125 -0. 0.038 -0.083]
[ 0.762 -0.121 0.044 -0.758]
[ 0.762 -0.038 0.043 -0.752]
[ 0.762 -0.433 0.091 -0.755]]
case 2 12 features
giveing the below output
[[ 0.62 -0.122 0.044 -0.58]
[ 0.62 -0.122 0.044 -0.58]
[ 0.62 -0.122 0.044 -0.58]
[ 0.62 -0.038 0.043 -0.52]
[ 0.62 -0.038 0.043 -0.52]
[ 0.62 -0.038 0.043 -0.52]
[ 0.225 -0. 0.038 -0.093]
[ 0.62 -0.121 0.044 -0.58]
[ 0.62 -0.038 0.043 -0.52]
[ 0.62 -0.433 0.091 -0.55]]
case 2 8 features
[[ 0.62 -0.22 0.44 -0.58]
[ 0.62 -0.22 0.44 -0.58]
[ 0.62 -0.22 0.44 -0.58]
[ 0.62 -0.38 0.43 -0.52]
[ 0.62 -0.38 0.43 -0.52]
[ 0.62 -0.38 0.43 -0.52]
[ 0.225 -0. 0.38 -0.093]
[ 0.62 -0.21 0.44 -0.58]
[ 0.62 -0.38 0.43 -0.52]
[ 0.62 -0.33 0.91 -0.55]]
Could anybody tell how to plot average of the values in a plot (like described in https://www.sec.in.tum.de/assets/Uploads/ConvolutionalNetworks.pdf) Fig 3
Empowering Convolutional Networks for Malware Classification and Analysis
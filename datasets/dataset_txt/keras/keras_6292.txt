Contributor
ekerazha commented on 9 Dec 2015
In #1217 (comment) you said
However, one remaining gotcha with statefulness is that the RNN states won't be updated if you use predict, evaluate, etc. In other words, statefulness only works in training mode. The reason being that predict & co are implemented to be idempotent. Changing that would require crafting an exception specifically for RNN statefulness.
Also, there's a "ValueError: operands could not be broadcast together" exception when data size is not divisible by batch size. Maybe this should be handled gracefully. This can be particularly annoying when you set a validation_split parameter in fit(), because the final data size varies.
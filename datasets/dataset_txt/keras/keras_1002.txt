iliaschalkidis commented on 31 May 2018
I would like to know if there is any straight-forward way on how you can train 2 different layers with the same weights matrix (e.g. use 2 LSTMs that "learn" the exact same transformations).
So far I investigated to different options, which lead to errors:
A single shared layer
input_1 = Input()
input_2 = Input()
lstm = LSTM()
output_1 = lstm(input_1)
output_2 = lstm(input_2)
Error: Graph disconnected: cannot obtain value for tensor Tensor [...]
Two layers sharing weights
input_1 = Input()
input_2 = Input()
lstm_1 = LSTM()
lstm_2 = LSTM()
output_1 = lstm(input_1)
output_2 = lstm(input_2)
lstm_1.set_weights(lstm_2.weights)
Error: ValueError: setting an array element with a sequence.
@farizrahman4u it is highly possible that you already know the right way :)
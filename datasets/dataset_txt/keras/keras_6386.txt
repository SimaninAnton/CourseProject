Contributor
Sebubu commented on 26 Nov 2015
My model gets stuck as soon as i use ELU. PReLU works without a problem.
I've tried to train it with adadelta and sgd. I've trained it about 60 epochs during the night. Same results.
batch_size = 128
nb_classes = 2
nb_epoch = 500

# input image dimensions
img_rows, img_cols = 50, 50
# number of convolutional filters to use
nb_filters1 = 64
nb_filters2 = 128
nb_filters3 = 256
# size of pooling area for max pooling
nb_pool = 2
# convolution kernel size
nb_conv = 3
#image is rgb
img_channels = 3

#Lamda for L2 regularization
lmda = 5e-4


print("put convnet together")
model = Sequential()

model.add(Convolution2D(nb_filters1, nb_conv, nb_conv, border_mode='full', input_shape=(img_channels, img_rows, img_cols)))
model.add(ELU())
model.add(Dropout(0.2))
model.add(Convolution2D(nb_filters1, nb_conv, nb_conv))
model.add(ELU())
model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))

model.add(Dropout(0.2))
model.add(Convolution2D(nb_filters2, nb_conv, nb_conv))
model.add(ELU())
model.add(Dropout(0.2))
model.add(Convolution2D(nb_filters2, nb_conv, nb_conv))
model.add(ELU())
model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))

model.add(Dropout(0.2))
model.add(Convolution2D(nb_filters3, nb_conv, nb_conv))
model.add(ELU())
model.add(Dropout(0.2))
model.add(Convolution2D(nb_filters3, nb_conv, nb_conv))
model.add(ELU())
model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))

model.add(Flatten())

model.add(Dropout(0.5))
model.add(Dense(2048, W_regularizer=l2(lmda)))
model.add(ELU())

model.add(Dropout(0.5))
model.add(Dense(1024, W_regularizer=l2(lmda)))
model.add(ELU())

model.add(Dropout(0.5))
model.add(Dense(nb_classes, W_regularizer=l2(lmda)))
model.add(Activation('softmax'))

sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)
model.compile(loss='categorical_crossentropy', optimizer=sgd)

model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch, show_accuracy=True, verbose=1, validation_data=(X_test, Y_test))

train_loss decreases until 2.0 and remains there. Train_acc, test_loss and test_acc remain on the same level.
Theano and keras has been updated.
Pull Request: #1079
Anyone with the same problem?
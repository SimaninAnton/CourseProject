hrayrhar commented on 4 Aug 2017
Hi,
This is not a very big issue, but when dividing by K.mean(mask) in _masked_objective and _weighted_masked_objective I suggest to add epsilon. The problem arises when one of your outputs has zero mask. I have the following situation where I need to have a zero mask. Suppose you have a model which learns to predict some value and you want to add extra supervision / regularization by predicting also some other value. It you don't have that second value for each training example, but you still want you use it when you have then you can set the mask of the prediction of the second value to be equal 0 if it is not present and the total loss function will not depend on the prediction of the second value.
Thanks
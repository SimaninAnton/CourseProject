hadi-ds commented on 9 Jul 2016 â€¢
edited
I am trying to build a simple three layer auto-encoder. The .fit() method progressive log shows that by the end of three epochs the training loss drops to 0.0376. I use 'mse' loss. At this point, I expect the network to be able to reconstruct the training data quite well.
However, when I explicitly reconstruct the training data using the trained network, output is way off compared to input. In fact, explicit calculation of cost for training data shows that it is 86.26, compared to 0.0376 reported by .fit() at the end of training (I set aside 10% of data for validation, but it should matter this much).
So, I wonder what those low loss values logged during training actually correspond to? I supposed those are the total cost function given the state of network (weights) at any moment.
Here is part of my code and its log:
hidden_dim = 1000
dropout_p = 0.25
l2_lambda = 1e-3
n_epochs = 3
batch_size = 256
AE = autoencoder_nn(n_features, hidden_dim, l2_lambda, dropout_p) 
'''
function definition for 'autoencoder_nn' includes networks design and compilation,
autoencoder.compile(optimizer='adadelta', loss='mse')] 
'''
AE.fit(X_data, X_data,
        nb_epoch=n_epochs, batch_size=batch_size,
        validation_split=0.1, shuffle=True)
Epoch 1/3 124643/124643 [==============================] - 136s - loss: 1.7028 - val_loss: 0.0032 Epoch 2/3 124643/124643 [==============================] - 128s - loss: 0.2450 - val_loss: 0.0032 Epoch 3/3 124643/124643 [==============================] - 129s - loss: 0.0376 - val_loss: 0.0032
And I calculate training error using the following:
cost = 0.
for row in X_data:
    input = row.reshape((1, X_data.shape[1]))
    pred = AE.predict(input)
    cost += np.linalg.norm(row - pred)**2
print "average cost: ", cost/X_data.shape[0]
average cost: 86.2644608377
1
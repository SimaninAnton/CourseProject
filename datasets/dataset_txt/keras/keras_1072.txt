SankBad commented on 27 Apr 2018
import numpy as np
from keras import applications
from keras.preprocessing.image import ImageDataGenerator
from keras import optimizers
from keras.models import Sequential
from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D
from keras.models import Model
from keras.optimizers import SGD

# dimensions of our images.
img_width, img_height = 224,224

train_data_dir = '/train/'
validation_data_dir = '/val/'

# number of samples used for determining the samples_per_epoch
nb_train_samples = 7749
nb_validation_samples = 583
epochs = 10
batch_size = 8 

def vgg_preprocess_img(img):
    img[:,:,2] -= 103.939
    img[:,:,0] -= 116.779
    img[:,:,1] -= 123.68
    #img = img.transpose((2,0,1))
    img = np.expand_dims(img, axis=0)
    return img


train_datagen = ImageDataGenerator(
        rescale=None,             
         preprocessing_function=vgg_preprocess_img,
         shear_range=0.2,       # randomly applies shearing transformation
         zoom_range=0.2,    # randomly applies shearing transformation  
         featurewise_std_normalization=True,
         samplewise_std_normalization=True,
         zca_whitening=True,
         rotation_range=90,
         width_shift_range=.2,
         height_shift_range=.2,
        vertical_flip=True,
        horizontal_flip=True)  # randomly flip the images


val_datagen = ImageDataGenerator(
        preprocessing_function=vgg_preprocess_img,
         rescale=None)       # normalize pixel values to [0,1]


train_generator = train_datagen.flow_from_directory(
    train_data_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='binary')

validation_generator = train_datagen.flow_from_directory(
    validation_data_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='binary')


history = model.fit_generator(
            train_generator,
            steps_per_epoch=nb_train_samples // batch_size,
            epochs=epochs,
            validation_data=validation_generator,
            validation_steps=nb_validation_samples // batch_size,
            callbacks=[reduce_lr])
with this, I am getting an error
Epoch 1/10
TypeError Traceback (most recent call last)
~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/utils/data_utils.py in get(self)
577 while self.is_running():
--> 578 inputs = self.queue.get(block=True).get()
579 self.queue.task_done()
~/anaconda3/envs/tensorflow/lib/python3.6/multiprocessing/pool.py in get(self, timeout)
607 else:
--> 608 raise self._value
609
~/anaconda3/envs/tensorflow/lib/python3.6/multiprocessing/pool.py in worker(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)
118 try:
--> 119 result = (True, func(*args, **kwds))
120 except Exception as e:
~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/utils/data_utils.py in get_index(uid, i)
400 """
--> 401 return _SHARED_SEQUENCES[uid][i]
402
~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/preprocessing/image.py in getitem(self, idx)
824 self.batch_size * (idx + 1)]
--> 825 return self._get_batches_of_transformed_samples(index_array)
826
~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/preprocessing/image.py in _get_batches_of_transformed_samples(self, index_array)
1232 if self.image_data_generator.preprocessing_function:
-> 1233 img = self.image_data_generator.preprocessing_function(img)
1234 if self.target_size is not None:
in vgg_preprocess_img(img)
27 def vgg_preprocess_img(img):
---> 28 img[:,:,2] -= 103.939
29 img[:,:,0] -= 116.779
TypeError: 'PngImageFile' object is not subscriptable
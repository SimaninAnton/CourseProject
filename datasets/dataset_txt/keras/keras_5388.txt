Contributor
cmyr commented on 21 Apr 2016
I've been playing around with some new metrics, some of which are informative but computationally inefficient. It would be useful if I could specify metrics that would only be used during the validation phase.
In the naive case this might be as simple as passing a validation_metrics list to model.compile, and including these metrics in _make_test_function. @fchollet, is this a feature you would consider merging? Should I take a stab?
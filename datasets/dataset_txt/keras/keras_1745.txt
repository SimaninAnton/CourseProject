namp commented on 13 Aug 2017
I'm running the mnist mlp example with a custom optimizer which for the time being is just a carbon copy of SGD from optimizers.py, i.e.
from __future__ import print_function
import keras
from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense, Dropout
from keras.optimizers import Optimizer
from keras import backend as K
from legacy import interfaces
import numpy as np

class testsgd(Optimizer):
..... [everything same as sgd] .....

myopt = testsgd()

....[define model]....

model.compile(loss='categorical_crossentropy',
              optimizer=myopt,
              metrics=['accuracy'])

history = model.fit(x_train, y_train,
                    batch_size=batch_size,
                    epochs=epochs,
                    verbose=1,
                    validation_data=(x_test, y_test))

score = model.evaluate(x_test, y_test, verbose=0)
print('Test loss:', score[0])
print('Test accuracy:', score[1])
Now, in my custom optimizer I need to compute the dot product of the gradient with the velocity, i.e. after line 168 in optimizers.py, I need something similar to
angle=K.dot(g,v)
or
angle=K.dot(K.transpose(g),v)
or
angle=K.dot(g, K.transpose(v))
Unfortunately none of the above work, I just get the error
ValueError: Shape must be rank 2 but is rank 1 for 'MatMul' (op: 'MatMul') with input shapes: [512], [512].
I understand that g and v are tensors which perhaps might need to be flattened to numpy arrays so as to use numpy for the dot product.
The closest that I came was by inspecting line 75 in optimizers.py, which calculates the norm of the gradient, but even then, the statement
print(K.get_value(norm))
still returns a tensor!
Many thanks in advance for any help
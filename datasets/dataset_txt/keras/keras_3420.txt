indra215 commented on 20 Jan 2017 â€¢
edited
Hi,
I want to train a model which predicts multiple labels for a given video. I have 5000 classes in total. I extracted 20 frames from each video and computed a 512 dimensional feature embedding by passing each frame through a CNN. So my training data is of the form X_train = (no_videos, 20, 512). For a each video there can be multiple labels as targets, so I represent the target label as a 5000 dimensional vector of 1's and 0's, where 1's for the classes for that video. So my target label vector is of the form Y_train=(no_videos, 5000).
I trained a LSTM model on this data but unfortunately when I predict the labels on the training data, I'm getting same labels for all the videos in the training data.
model = Sequential()
model.add(LSTM(256, input_shape=X_train.shape[1:], return_sequences=True))
model.add(LSTM(256))
model.add(Dropout(0.2))
model.add(Dense(no_classes, activation='sigmoid'))

sgd = SGD(lr=0.00001, decay=1e-6, momentum=0.9, nesterov=True)
model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])
print(model.summary())

model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=no_epoch)
Is it the right way to train the LSTM or is there anything wrong ?
Can anyone please help me how to solve this ?
Thanks in advance.
ymcui commented on 26 Mar 2016
I've just moved to 0.3.2 versions from 0.2.0.
There are many tasks relies on bi-RNN, so I think setting up a bi-directional RNN layer is necessary.
When building the bi-RNN, i have noticed that current version of Keras cannot correctly deal with the backward RNN with masked input.
if the input is [0,0,A,B,C] with mask [0,0,1,1,1]
[issue 1]
the backward RNN will make the input as [C,B,A,0,0] and produce outputs in this order. but this cannot be concatenated with forward one to form bi-RNN, because the corresponding position is not correct.
[0,0,A,B,C]
+
[C,B,A,0,0]
[issue 2]
the backward RNN will not correctly invert the mask.
one possible solution is that, create another input in reverse order and corresponding mask.
say, create [0,0,C,B,A] with mask[0,0,1,1,1]
and put them into two individual RNN w/o setting one with go_backwards=True.
[issue 3]
But here comes another question: what if I have a Embedding layer before RNN?
Normally, we will use graph.add_shared_node(), and put Embedding layer in it. But, add_shared_node() cannot correctly produce masked output.
one solution is that, i'll have to create two Embedding layers for both forward and backward inputs, and set the second one as weights=graph.nodes['first_embedding'].get_weights(), trainable=False. but i am not sure about this.
Any suggestion on these issues?
Please make sure that the boxes below are checked before you submit your issue. Thank you!
Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps
If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps
Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
4
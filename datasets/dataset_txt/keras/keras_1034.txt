ziyigogogo commented on 11 May 2018 â€¢
edited
Hi there,
I am confused with the document here:
steps_per_epoch: Total number of steps (batches of samples) to yield from generator before declaring one epoch finished and starting the next epoch. It should typically be equal to the number of unique samples of your dataset divided by the batch size.
In my poor understanding, the steps_per_epoch should be "EXACTLY THE SAME" as "NUM_OF_SAMPLES / batch_size", so all the samples can be iterated once.
To understand more about this param, I really want to know what keras dose when step_per_epoch is set un-typically .
To be clear, my questions are:
when step_per_epoch < NUM_OF_SAMPLES / batch_size
if some of the samples were skipped? So, the trainer gets the input size < NUM_OF_SAMPLES?
when step_per_epoch > NUM_OF_SAMPLES / batch_size,
if some of the samples imported multiple times to the trainer, so the actual input size > NUM_OF_SAMPLES?
Thank you so much for your time.
6
flybass commented on 28 Apr 2016 â€¢
edited
Hi,
I have a Keras code set up to create an ensemble of neural networks for regression. I prefer if I can preserve the api calls. As it stands, this has been achievable for MLP's via
inputLayer = Input( shape =( featDim, ) )
mOut = merge( [ m(inputLayer) for m in models ] , mode='ave' )
model = Model( input = inputLayer, output = mOut )
To make my code very general purpose, LSTM's are fed flat data that is then first reshaped within the network. I.E. Every LSTM first has the layer addition
lstmModel = Sequential()
lstmModel.add( Reshape( nTimeSteps, featDim), input_shape = (nTimeSteps*featDim, ) ) )
so on and so forth to an eventual dense layer
I'm trying to ensemble these LSTM's and I believe the code should be identical to my prior example except with the shape set to (nTimeSteps*featDim,) . However, I'm getting some dimensionality issues when trying to predict with the model (despite the fact that it builds and saves correctly. I'm 100% confident in that process.
Also, this LSTM pipeline works as is (save/load/predict) except for this ensembling step.
I get "ValueError: Shapes( featDim, first LSTM weight dim) and (featDim, ) are not compatible" during the loading of the weights.
When I output the png graph it looks exactly as expected. Input layer has directed arrows to Sequential LSTM networks 1 through k. In turn, these have directed arrows to the merge.
Has anyone else encountered this issue with model API and ensembling?
Also - thank you for Keras. I've been on-board for a number of months now to build this pipeline.
As a side-note, the code to build the arbitrary LSTM configurations used input_shape rather than the new input_length and input_dim combination. Should this matter?
Daniel
CloudResearch commented on 13 Dec 2017
I build a binary classifier to either predict true or false. The reported binary accuracy during training is different than the accuracy calculated using a confusion matrix after the training phase:
Epoch 1000/1000 180/836 [=====>........................] - ETA: 0s - loss: 0.1821 - binary_accuracy: 0.9556 360/836 [===========>..................] - ETA: 0s - loss: 0.1690 - binary_accuracy: 0.9583 540/836 [==================>...........] - ETA: 0s - loss: 0.1546 - binary_accuracy: 0.9556 725/836 [=========================>....] - ETA: 0s - loss: 0.1868 - binary_accuracy: 0.9503 836/836 [==============================] - 0s 367us/step - loss: 0.1730 - binary_accuracy: 0.9533 - val_loss: 3.1886 - val_binary_accuracy: 0.6393 [[ 0.77313433 0.22686567] [ 0.7961165 0.2038835 ]] Precision: 0.773134328358 Recall: 0.492677341312 F1: 0.60183639399 Accuracy: 0.488508911752
Do you know why it differs so much? Saw your implementation and normaly it shouldn't differ at all.
IFeelBloated commented on 31 Oct 2018 â€¢
edited
I am trying to train a complex model with 2000+ layers on 8 GPUs with multi_gpu_model
It seems that the training could not get started, instead it got stuck like forever at "Epoch 1/xxx"

seems like one CPU core is freaking out and other cores are just idle, what is happening here?
or more specifically, where is this thing getting stuck and how do I fix it?
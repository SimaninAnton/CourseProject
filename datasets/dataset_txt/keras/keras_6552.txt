Contributor
NickShahML commented on 15 Oct 2015
Hey everyone,
I've been trying to figure out a way to cluster words based upon similarity.
Suppose you read many books that total to 100k different words used. It would be great if you could make ~1000 clusters with approx 100 words/cluster. In each cluster, words are similar to each other. "Dog" and "Cat" in one cluster and "truck" and "car" in a different cluster.
I saw that there's the well-made skipgram word-embedding script example: https://github.com/fchollet/keras/blob/master/examples/skipgram_word_embeddings.py
And I also saw that word2vec has made word clusters: https://code.google.com/p/word2vec/
I know that they usually apply a k-means on top of of the word vectors created. I thought it would be good to start a discussion about this in case other keras-users are interested in the same thing.
Thanks!
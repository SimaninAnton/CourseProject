Imorton-zd commented on 26 Apr 2016 â€¢
edited
If I use a single model without merge, the stateful model has no errors. But as long as I merge two models, the stateful merging model will get the errors as following:
Loading data...
1400 sina train sequences
200 sina validation sequences
400 sina test sequences
Pad sequences (samples x time)
X_train shape: (1400L, 500L)
X_val shape: (200L, 500L)
X_test shape: (400L, 500L)
Loading data...
1400 tencent train sequences
200 tencent validation sequences
400 tencent test sequences
Pad sequences (samples x time)
X_train shape: (1400L, 500L)
X_val shape: (200L, 500L)
X_test shape: (400L, 500L)
Build model...
Traceback (most recent call last):

  File "<ipython-input-4-a335e4ab16b7>", line 1, in <module>
    runfile('E:/EMNLP/experiment/knowledge_transfer_shared.py', wdir='E:/EMNLP/experiment')

  File "C:\Anaconda2\lib\site-packages\spyderlib\widgets\externalshell\sitecustomize.py", line 699, in runfile
    execfile(filename, namespace)

  File "C:\Anaconda2\lib\site-packages\spyderlib\widgets\externalshell\sitecustomize.py", line 74, in execfile
    exec(compile(scripttext, filename, 'exec'), glob, loc)

  File "E:/EMNLP/experiment/knowledge_transfer_shared.py", line 493, in <module>
    trainConnMergeModel('sina','tencent')

  File "E:/EMNLP/experiment/knowledge_transfer_shared.py", line 429, in trainConnMergeModel
    validation_data = ([datas[2],datat[2]],datat[3]))

  File "C:\Anaconda2\lib\site-packages\keras\engine\training.py", line 971, in fit
    batch_size=batch_size)

  File "C:\Anaconda2\lib\site-packages\keras\engine\training.py", line 898, in _standardize_user_data
    exception_prefix='model input')

  File "C:\Anaconda2\lib\site-packages\keras\engine\training.py", line 98, in standardize_input_data
    str(array.shape))

Exception: Error when checking model input: expected input_7 to have shape (25, 500) but got array with shape (1400L, 500L)
Subsequently, my model:
sequence_a = Input(batch_shape=(batch_size,maxlen,),dtype='int32')
    sequence_b = Input(batch_shape=(batch_size,maxlen,),dtype='int32')
    tweet_a = Embedding(max_features, embedding_dims, input_length=maxlen)(sequence_a)
    tweet_b = Embedding(max_features, embedding_dims, input_length=maxlen)(sequence_b)

    lstm0 = LSTM(hidden_dims,stateful=True)
    lstm1 = LSTM(hidden_dims,stateful=True)

    encoded_a = lstm0(tweet_a)
    encoded_b = lstm1(tweet_b)

    merged_vector = merge([encoded_a, encoded_b], mode='sum')

    predictions = Dense(1, activation='sigmoid')(merged_vector) 

    model = Model(input=[sequence_a, sequence_b], output=predictions)

    model.compile(optimizer='rmsprop',
                  loss='binary_crossentropy',
                  metrics=['accuracy'])
    best_acc = 0.0
    for e in range(nb_epoch): 
        hist = model.fit([datas[0], datat[0]], datat[1],batch_size=batch_size, nb_epoch=1, verbose=1,
                  validation_data = ([datas[2],datat[2]],datat[3]))

    score,acc = model.evaluate([datas[4],datat[4]],datat[5],batch_size=batch_size)
In fact, I have try the function: train_on_batch(), test_on_batch(). However, I am not familiar with these two functions. I know test_on_batch() can't return acc and score, how should I get the score and accuracy from test_on_batch() or other function. Any suggestions would be appreciated!
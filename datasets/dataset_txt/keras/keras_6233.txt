versis commented on 20 Dec 2015
Hi, I'm just starting to learn how keras is working and I have few questions.
How exactly is preditct_prob() working? Especially for recurrent layers.
After training I would like to compare sequences and check which one is more probable given the model. Is this method providing this funcionality? I can't figure this out from the code :/
Another question regarding example lstm_text_generation.py. How many layers this network contains? I see 2xLSTM and 1xDense, but do we also asume that there is input layer and output layer?
EDITED:
I see that the first layer always specify the input so it does the job for two layers. I guess output of the Dense layer here is output of the whole network, then in summary we have 4 layers (input, LSTM, LSTM, output). Am I right?
Second LSTM (in the same example) looks like this:
model.add(LSTM(512, return_sequences=False))
Why return_sequence is False? Don't we want the network to backpropagate for every element in sequence in each layer?
Is there any parameter for truncated backpropagation?
Contributor
jpeg729 commented on 7 Mar 2016
I am looking into using a Keras built LSTM network on a timeseries prediction problem, and I would love to be able to code it and simply set it going, training itself while providing predictions. However, one difficulty is that the predictions are not immediate, in other words, new data keeps coming in, modifying the internal state of the LSTM nodes... Here is a rough outline of what I think is needed.
I think I would need to save the internal state at each step, so that when a prediction's results come in, I could re-apply the internal state before calculating the weight adjustments. Then I would have to re-apply the latest state before accepting more input data. Execution speed is not a big concern.
I had a look at the implementation of reset_states() and at first glance I could use K.get_value() instead of K.set_value() to save state. Which doesn't seem too difficult.
I would need to find and adapt the training code, so that I could run it on demand given a single prediction.
I would need to filter out gaps in the data in order to avoid training the network on bad data, but I would have to do that on datasets for batch training too.
All that doesn't seem too difficult, or am I crazy?
N.B. I do understand there are other ways of training a network, but I can get a larger breadth of input data in real time than I can for batch training. I know the training will be slower, but I do want it to fit the breadth of data I will be using it on afterwards. That is why I want to train it in real time.
Sushobhan04 commented on 1 May 2017
I have to successively compile a model in loop (making trainable = true and false alternatively as in GAN). This results in increasing compilation time and memory usage as pointed out in issue #2828. I cannot use K.clear_session() as it will reset the weights learned. Please provide a method to get around this memory leak problem.
I am currently using this implementation to make layers trainable=true or False
def make_trainable(net, val):
net.trainable = val
for l in net.layers:
l.trainable = val
where val = True/False
Any help will be appreciated
1
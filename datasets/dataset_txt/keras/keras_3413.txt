Contributor
neptunes5thmoon commented on 21 Jan 2017
For the architecture I want to implement I need layers that work on inputs of different sizes while sharing weights.
The following code snippet from the guide to the functional API (The concept of layer 'node') achieves that for Convolution2D and works fine:
from keras.layers import Input, Convolution2D
a = Input(shape=(32, 32, 3))
b = Input(shape=(64, 64, 3))

conv = Convolution2D(16, 3, 3, border_mode='same')
conved_a = conv(a)

# only one input so far, the following will work:
assert conv.input_shape == (None, 32, 32, 3)

conved_b = conv(b)
# now the `.input_shape` property wouldn't work, but this does:
assert conv.get_input_shape_at(0) == (None, 32, 32, 3)
assert conv.get_input_shape_at(1) == (None, 64, 64, 3)
However, running the equivalent code for Convolution3D results in a ValueError because the input shape expected by the layer seems to be fixed to the first shape it saw.
from keras.layers import Input, Convolution3D
a = Input(shape=(32, 32, 32, 3))
b = Input(shape=(64, 64, 64, 3))

conv = Convolution3D(16, 3, 3, 3, border_mode='same')
conved_a = conv(a)

# only one input so far, the following will work:
assert conv.input_shape == (None, 32, 32, 32, 3)

conved_b = conv(b)
ValueError: Input 0 is incompatible with layer convolution3d_1: expected shape=(None, 32, 32, 32, 3), found shape=(None, 64, 64, 64, 3)
I'm using the tensorflow backend (and dim_ordering) on gpu.
Any ideas what might cause this inconsistency between Convolution2D and 3D?
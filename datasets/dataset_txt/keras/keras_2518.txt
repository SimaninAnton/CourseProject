hamzamerzic commented on 29 Apr 2017 â€¢
edited
I want to rescale the outputs of my model, so I do the following.
state_in = ...
h = ...
scale_vector = K.variable(value=np_scale_vector) # np_scale_vector is a numpy array
out = Lambda(lambda x: x * scale_vector, output_shape=(n_out,))(h)

model = Model(inputs=[state_in], outputs=[out])
model.save(filename)
I get:
  File "/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py", line 2434, in save
    save_model(self, filepath, overwrite, include_optimizer)
  File "/usr/local/lib/python2.7/dist-packages/keras/models.py", line 102, in save_model
    'config': model.get_config()
  File "/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py", line 2311, in get_config
    return copy.deepcopy(config)
  File "/usr/lib/python2.7/copy.py", line 163, in deepcopy
    y = copier(x, memo)
  File "/usr/lib/python2.7/copy.py", line 182, in deepcopy
    rv = reductor(2)
TypeError: can't pickle NotImplementedType objects
If I, on the other hand do
out = Lambda(lambda x: x * np_scale_vector, output_shape=(n_out,))(h)
I get:
  File "/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py", line 2434, in save
    save_model(self, filepath, overwrite, include_optimizer)
  File "/usr/local/lib/python2.7/dist-packages/keras/models.py", line 103, in save_model
    }, default=get_json_type).encode('utf8')
  File "/usr/lib/python2.7/json/__init__.py", line 251, in dumps
    sort_keys=sort_keys, **kw).encode(obj)
  File "/usr/lib/python2.7/json/encoder.py", line 207, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "/usr/lib/python2.7/json/encoder.py", line 270, in iterencode
    return _iterencode(o, 0)
  File "/usr/local/lib/python2.7/dist-packages/keras/models.py", line 77, in get_json_type
    return obj.item()
ValueError: can only convert an array of size 1 to a Python scalar
I want to emphasize that the model compiles, works, I can see that I am getting proper outputs, but the save fails.
Contributor
NickShahML commented on 11 Oct 2015
Hey Guys, I'm trying to replicate this paper on skip-thoughts: http://arxiv.org/pdf/1506.06726v1.pdf
I'm getting the following error when i do model.fit
Epoch 0
Traceback (most recent call last):
  File "sentencesequencearticle.py", line 305, in <module>
    model.fit(X_train, y_train, validation_split=0.2, callbacks=[early_stopping], nb_epoch=1, batch_size = 4096, show_accuracy=True)
  File "/usr/local/lib/python2.7/dist-packages/keras/models.py", line 490, in fit
    shuffle=shuffle, metrics=metrics)
  File "/usr/local/lib/python2.7/dist-packages/keras/models.py", line 211, in _fit
    outs = f(*ins_batch)
  File "/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.py", line 513, in __call__
    allow_downcast=s.allow_downcast)
  File "/usr/local/lib/python2.7/dist-packages/theano/tensor/type.py", line 169, in filter
    data.shape))
TypeError: ('Bad input argument to theano function with name "/usr/local/lib/python2.7/dist-packages/keras/models.py:402"  at index 1(0-based)', 'Wrong number of dimensions: expected 3, got 2 with shape (9, 30).')
Which says that I'm only giving one layer 2 dimensions rather than 3. My model is:
hidden_variables = 256 #number of hidden variables in all layers, keep this betwen 256 and 512
dropout = 0.5 #the dropout between each layer -- recommendation is 0.5

model = Sequential()
model.add(Embedding(max_features, embedding_size, mask_zero=True)) #THIS IS THE EMBEDING LAYER
model.add(LSTM(embedding_size, hidden_size))
model.add(RepeatVector(maxlen))
for _ in xrange(LAYERS):
    model.add(LSTM(hidden_size, hidden_size, return_sequences=True))
    model.add(Dropout(dropout))
model.add(TimeDistributedDense(hidden_size,(len(vocab)+2)))
model.add(Activation('softmax')) #this is good
model.compile(loss='categorical_crossentropy', optimizer='adam')
my x train and y train are of 2 dimensional shape:
X_train is printed below
[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   6   8 147  45  58 134  90   7]
 [  3  18   2  34  14   4  11  26   3  14  24   3   2  28   1 112  22   3
   13   1  19  51   9   3  15   9  75  94 110   7]
 [144 129  44  98  99  62  83 140 116  36   5   2   3  13   4  80  20 146
    5  11  25  74  19  12  20 160  44  11  29   7]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   6   8  41
    2  37  24  17   4  16  78  11   3  15   9   7]
 [ 10  54   1 109   1  50  55 133 107 100   1  41   2  36   5   2  17   2
   20   4   2  82   5   1 158  12   1  11  29   7]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    6   8  77  79 137 153   3  13   2  39 163   7]
 [  1 121 154   2 119  14 145   4   1  87  81 118  27  47   4  40  47 141
  111   5   2  21  14  12  88   4   1 139  76   7]
 [  1 103 126   1  57  56  73   1  92  28 104   1  61   4   1 152  86   1
  125 148  10 165   1  19  12 159  91  60  29   7]
 [ 15   9  85 161  12   3  13  45  32   9  23 128  10  26  19  22  32 122
   67 150   9 124   9 105 115  12   3  15   9   7]
 [ 31 168  10 101  46   4  12  31 113  30   4   1  17   2  48   5  35  59
    5  12  30   5   2  37   2 131 106   4  51   7]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   6   8
    3  18   2  34  14   5 166  33  42   3  15   7]
 [ 43   2  28  16  38  11   3  13   9   1 136  49  70   9   1  97  21  18
   10 142  50  16  38  11   3  18  72   1 167   7]]


y_train is printed below
[[ 94  75   9  15   3   9  51  19   1  13   3  22 112   1  28   2   3  24
   14   3  26  11   4  14  34   2  18   3   8   6]
 [ 11  44 160  20  12  19  74  25  11   5 146  20  80   4  13   3   2   5
   36 116 140  83  62  99  98  44 129 144   8   6]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   7   9  15
    3  11  78  16   4  17  24  37   2  41   8   6]
 [  1  12 158   1   5  82   2   4  20   2  17   2   5  36   2  41   1 100
  107 133  55  50   1 109   1  54  10  53   8   6]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    7 163  39   2  13   3 153 137  79  77   8   6]
 [118  81  87   1   4 145  14 119   2 154 121   1   4  89 135 138  10  68
   42  52  33 108  12  95   2  13   3  39   8   6]
 [  1  86 152   1   4  61   1 104  28  92   1  73  56  57   1 126 103   1
  157   1 117  71  24 143  10 169  27  17   8   6]
 [ 11   5  23  20  22 123  84   1   5 164  26 151  63   4 155   2   5  93
   27  14  43  10  14 162  35   5 130 149   8   6]
 [ 10 168  31   4  46 132 114   4  48   1  25  11 127  16 102   4  23  96
    2  13   3   1  10 120  25  40   5  69   8   6]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   7  15
    3  42  33 166   5  14  34   2  18   3   8   6]
 [ 18  21  97   1   9  70  49 136   1   9  13   3  11  38  16  28   2  43
  156  10  13  21  64   1   9  65  49  66   8   6]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   7   9   6]]
For the life of me, I just can't figure out why this is the case. Embedding is supposed to output a 3d dimensional shape correct? I apologize if this is a beginner question. But perhaps, it will help others who are struggling with this?
Apologies for the long post. I figured more info, the better.
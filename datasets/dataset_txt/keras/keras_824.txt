li2109 commented on 12 Aug 2018 â€¢
edited
Like in SGD optimizer, we obtain gradients by grads = self.get_gradients(loss, params)
However, when i tried to get grads like grads = self.get_gradients(loss, 2*params), it returned None. I was trying to modify params and then taking gradients.
Thanks in advance.
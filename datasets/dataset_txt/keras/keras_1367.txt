changkun commented on 30 Dec 2017 â€¢
edited
Hey guys, happy new year :) Thanks for your fantastic framework. I am now facing an issue with defining custom loss based on each training batch.
Here is a runable gist example: https://gist.github.com/changkun/56a11eab9dee138de1180b733c9a4c10
The gist is a simple CNN example, I customize loss function by using some intermediate result of the network, the part of customization is as follows:
# 3. define loss
def darc1_loss(intermediate, lamb=0.01):
    def _loss(y_true, y_pred):
        original_loss = K.categorical_crossentropy(y_true, y_pred)
        custom_loss = lamb*K.max(K.sum(K.abs(intermediate), axis=0))
        # print(custom_loss) # how can I output the custom_loss to console log while each training batch?
        return original_loss + custom_loss
    return _loss
My questions are:
Is here the right way to custom loss function when using some intermediate results?
If so, am I here successfully access the intermediate results of x in each training batch?
If so, how can I verify the darc1_loss is calculated correctly?
I feel sorry for open an issue here, but my question on StackOverflow doesn't get a reply. Thank you in advance.
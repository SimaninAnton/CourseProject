jagiella commented on 27 Jul 2017 â€¢
edited
I am using keras in the context of an PyQt application. Since the new backend it is not working anymore. During training I get loss: nan.
The minimal example:
from PyQt5.Qt import QApplication
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense
from keras.utils import to_categorical
import numpy as np
import sys
   
app = QApplication( sys.argv)

X,y = np.random.rand( 1000,1,100,100), np.random.rand( 1000,4)
model = Sequential([
 Conv2D(filters=4, kernel_size=(9,9), padding='same', input_shape=X.shape[1:] ),
 MaxPooling2D( pool_size=(2,2)),
 Conv2D(filters=4, kernel_size=(7,7), padding='same'),
 MaxPooling2D( pool_size=(2,2)),
 Conv2D(filters=4, kernel_size=(5,5), padding='same'),
 MaxPooling2D( pool_size=(2,2)),
 Flatten(),
 Dense( 128),
 Dense( y.shape[1], activation='softmax')
])
model.compile( loss='mse', optimizer='adadelta')
model.fit( X, y, epochs=10)
The output is:
Epoch 1/1
1000/1000 [==============================] - 0s - loss: nan
Possible workarounds:
Using the old backend.
Removing or commenting out the line app = QApplication( sys.argv) "fixes" the problem:
Epoch 1/1
1000/1000 [==============================] - 0s - loss: 0.1604
But of course that's not the solution, when you want to use keras in combination with PyQt ;)
Replacing activation='softmax' by activation='tanh' AND reducing the number of convolution-maxpooling-blocks to 2 also works:
Epoch 1/1
1000/1000 [==============================] - 0s - loss: 0.3343
But obviously that is not a true fix.
Mako18 commented on 17 Feb 2017
Hello, thanks in advance for your help and for the developers of Keras!
I am working with LSTM networks, actually I am trying to create a CNN+LSTM network that takes as inputs images with 3 channels. I have been reading a lot, but I still have several doubts about how LSTM layers really work, because the results I am obtaining in my experiments are horrible, and this networks are told to give great results.
I have read #4149 and #2403 and I have clear my mind enough to know that I have to learn a lot.
First I will told you my task and then enumerate the doubts I have about recurrent layers.
My inputs are images with 3 channels, I have reshape my data set with the following code in order to have sequences in time:
data = scipy.io.loadmat('cnn_1p.mat')
X = data_test["imgL"]
Y = data_test["target"]
X_seq = []
seq_len = 2
for i in range(len(X)-seq_len+1):
X_seq.append(X[i:i+seq_len,:,:,:])
X_seq = np.asarray(X_seq)
Y_seq = Y[(seq_len-1):10*len(Y),:]
And that gives me structures with the following shapes:
In [173]: X_seq.shape
Out[173]: (2126, 2, 3, 10, 8)
In [174]: Y_seq.shape
Out[174]: (2126, 3)
So if I am right, that means that I have nb_samples=2126 (number of samples), each sample is a sequence of length 2 and each element of that sequence is an image of 3 channels and dimensions 10x8, am I right?
My outputs is a matrix of dimensions (nb_samples, 3), so each input image has associated 3 numbers as outputs. What I want is to feed my net with my input sequences of image so each sequence has the image for t-1 and t, I want my net to give me as output the 3 numbers associated with the image at time t. I have read a lot about problems where the sequences are t-1,t and the output is t+1, but I want the output that correspond to the last element of my input sequence.
Having this in mind, I don't know if that is what I am doing with this net:
model = Sequential()
model.add(TimeDistributed(Convolution2D(40, 3, 3, border_mode='valid', activation='relu'), input_shape=(seq_len,3, 10, 8)))
model.add(TimeDistributed(Dropout(0.2)))
model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))
model.add(TimeDistributed(Convolution2D(20, 2, 2, border_mode='valid', activation='relu')))
model.add(TimeDistributed(Dropout(0.2)))
model.add(TimeDistributed(Flatten()))
model.add(LSTM(30, return_sequences = True))
model.add(Dropout(0.2))
model.add(LSTM(15))
model.add(Dropout(0.2))
model.add(Dense(3, init='uniform'))
model.compile(optimizer='adam', loss='mse')
So as long as I knew, with TimeDistributed I make sure that the convolutional layer is applayed to each element in the sequence separated. And I added return_sequences = True in the first LSTM layer to connect with the second LSTM layer. Finally the Dense layer is to obtain the 3 outputs I need.
And here comes my doubts (generals and about my problem):
With this network, am I calculating the output of the last element of the sequences or the output of the future instant t+1?
Are my data reshape right?
I don't really understand all the parameters the LSTM and recurrent layers have (I have read the keras documentation but it is not clear to me). Moreover, I don't understand the difference between the cases in this image:
I don't understand the difference and I don't know how can I programm the layer to obtain the different cases.
I have read that is recommended to use reshape instead of flatten() to connect the cnn layer with the lstm layer, but to me, the reshape is not working.
Am I using well the TimeDistributed layer?
I have read this : https://github.com/fchollet/keras/blob/master/examples/imdb_cnn_lstm.py
I know is 1D instead of 2D, but in that example they don't use TimeDistributed nor flatten() layer.
I think that's all for the moment. Sorry about the big post, and hope some of you could help me.
MoZZez commented on 24 Sep 2016
I am trying to build L1 layer(For Siameese net) which will took input split it in the middle in two vectors and then compute weighted sum of their element-wise l1 norm like L1_layer(X)=sum(Wi*abs(X1i-X2i)) where X-input vector X1=X[:len(X)/2] and X2=X[len(X)/2:], Wi ith weight, i-index.
Here is the code of layer
`class L1_layer(Layer):
def init(self, **kwargs):
self.output_dim = (1,)
super(L1_layer, self).init(**kwargs)
def build(self, input_shape):
    input_dim = input_shape[1]
    initial_weight_value = np.ones((input_dim, self.output_dim[0]))
    self.W = K.variable(initial_weight_value)

    self.trainable_weights = [self.W]
    self.input_dim=input_shape[0]

def call(self, x, mask=None):
    x1=x[:self.input_dim/2]
    x2=x[:self.input_dim/2]
    abs_=x1-x2
    abs_=K.abs(abs_)
    abs_=K.dot(x,self.W)
    abs_=K.sum(abs_)
    return abs_

def get_output_shape_for(self, input_shape):
    return self.output_dim`
So after I am inserting it in model and intitializeing the model like that:
`def get_model(inp_shape):
w=np.identity(inp_shape[0])
b=np.zeros(shape=(100,))
#print w.shape
net=Graph()
net.add_input(name="input", input_shape=inp_shape,dtype='float')

net.add_node(Dense(inp_shape[0],weights=[w,b]),name="dense1",input="input")
#net.add_node(Activation(activation="relu"),name="act1",input="dense1")
net.add_node(L1_layer(),name="l1_layer",input="dense1")
net.add_output(name="out",input="l1_layer")

net.compile(optimizer="sgd",loss="mse",metrics=["accuracy"])

return net
shape=(100,)
model=get_model(shape)`
After that I got an error:
in call(self, x, mask)
13
14 def call(self, x, mask=None):
---> 15 x1=x[:self.input_dim/2]
16 x2=x[:self.input_dim/2]
17 abs_=x1-x2
TypeError: unsupported operand type(s) for /: 'NoneType' and 'int'
What is wrong with x?
when I just do dot(x,self.W) it goes fine
Mel-Peng commented on 17 Jan 2018
When I'm training a siamese network, I come across the following code and use it in my program:
def euclidean_distance(vects):
    x, y = vects
    return K.sqrt(K.sum(K.square(x - y), axis=1, keepdims=True))
But it turns out nan loss when two inputs are the same. (Interestingly, it can be only discovered when GPU is not used. When GPU is used, the loss won't be nan but the network is not trainable.) However, when I add small dummy bias into it, the network can work.
def euclidean_distance(vects):
    x, y = vects
    return K.sqrt(K.sum(K.square(x - y), axis=1, keepdims=True) + 0.01)
I'm just wondering why K.sqrt() cannot take zero tensor as input.
Btw, I'm using Keras 2.1.2 and tensorflow-gpu 1.4.0.
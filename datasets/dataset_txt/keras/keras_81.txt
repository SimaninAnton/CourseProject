NaNAGISaSA commented on 26 Aug 2019
I have Python version 3.7.0. When I run babi_rnn and babi_memnn examples, this function is failed:
def tokenize(sent):
    '''Return the tokens of a sentence including punctuation.
    >>> tokenize('Bob dropped the apple. Where is the apple?')
    ['Bob', 'dropped', 'the', 'apple', '.', 'Where', 'is', 'the', 'apple', '?']
    '''
    return [x.strip() for x in re.split(r'(\W+)?', sent) if x.strip()]
In Python 3.7,
re.split(r'(\W+)?', 'Bob dropped the apple. Where is the apple?')
returns
['', None, 'B', None, 'o', None, 'b', ' ', '', None, 'd', None, 'r', None, 'o', None, 'p', None, 'p', None, 'e', None, 'd', ' ', '', None, 't', None, 'h', None, 'e', ' ', '', None, 'a', None, 'p', None, 'p', None, 'l', None, 'e', '. ', '', None, 'W', None, 'h', None, 'e', None, 'r', None, 'e', ' ', '', None, 'i', None, 's', ' ', '', None, 't', None, 'h', None, 'e', ' ', '', None, 'a', None, 'p', None, 'p', None, 'l', None, 'e', '?', '', None, '']
and will raise an AttributeError: 'NoneType' object has no attribute 'strip'
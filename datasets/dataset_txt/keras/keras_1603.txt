christian-rauch commented on 10 Oct 2017
I created a model with multiple outputs:
self.input = Input(shape=(h,w,d))

self.out = []

x = self.add_part1(x)
self.out.append(x)

mod2_out = ...
self.mod2 = Model(inputs=self.input, outputs=mod2_out)

for i in range(nparts):
    x = self.add_stageN(self.input, x)
    self.out.append(x)

self.model = Model(inputs=self.input, outputs=self.out)
f = open(yaml_path, "w")
f.write(self.model.to_yaml())
and export it. The exported file contains the multi-output (e.g. yaml):
[...]
  output_layers:
  - [softmax_stage1, 0, 0]
  - [softmax_stage2, 0, 0]
  - [softmax_stage3, 0, 0]
  - [softmax_stage4, 0, 0]
[...]
After training, when I want to predict on a single sample, I load the model from a model checkpoint
mymodel = load_model(model_path),
but depending on how I call predict on the model, I receive different output results that differ from the softmax output.
Calling predict via:
pred = mymodel.predict(img, batch_size=1)
gives me different results than what I see in the softmax_stage<N> layers. E.g. the first output seems reasonable, but it still different from softmax_stage1, but the remaining predictions are zero and do not match the softmax output at all.
If I instantiate the model again manually via:
out = Model(inputs=mymodel.input, outputs=mymodel.output)
out_output = out.predict(img, batch_size=1)
I get the expected results from the softmax_stage<N> layers.
Shouldn't the restoring from a checkpoint result in the same instantiated model?
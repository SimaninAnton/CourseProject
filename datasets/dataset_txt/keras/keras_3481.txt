cbaziotis commented on 13 Jan 2017 â€¢
edited
I want to stack two bidirectional RNNs and i was wondering what is the correct way to do it. My main question is what data each of the deeper RNNs read. To be more specific:
Lets say that we have two RNNs each one with 64 cells, lets call them F1 and B1 (F-forward, B-backwards). Lets say that for our problem we just want to create a dense representation of our input. In the case of Bidirectional RNNs we take the outputs from the last timestep for each one and concatenate them to get a vector of size 128.
output = Bidirectional(GRU(64))(input)
Now in order to get a more high-level representation, i want to stack another bidirectional layer on top, again with each RNN having 64 cells, F2 and B2. Is this correct?
output1 = Bidirectional(GRU(64, return_sequences=True))(input)
output2 = Bidirectional(GRU(64))(output1)
This example runs just fine. But is it the correct way to do it?
Question 1 - How exactly does the previous example work? I want to understand what exactly is the input of the second forward RNN F2.
A) is it the output(s) of just the F1?
B) is it the concatenation of the outputs of both F1 and B1?
which one is it?
Question 2 - is there even a correct way (A-B)? Are there scenarios that both make sense?
4
MarkusLund commented on 27 Feb 2017 â€¢
edited
As seen in the code snippet below I have a network which ends with an Lambda layer. This layer use the softmax_to_onehot() (also in snippet) to convert from a softmax-represenation of a vector to a one-hot represenation eg. [0.1, 0.5, 0.24] -> [0, 1, 0]
def model():
 model = Sequential()
 model.add(LSTM(512, input_shape=(MAX_SEQUENCE_LENGTH, NOISE_SIZE), return_sequences=True))
 model.add(Dropout(0.2))
 model.add(TimeDistributed(Dense(NB_WORDS, activation="softmax")))
 model.add(Lambda(soft_to_one, output_shape=output_shape_lambda))
 return model
def softmax_to_onehot(t):
 k_max = K.max(t, keepdims=True, axis=2)
 equal = K.equal(t, k_max)
 return K.cast(equal, 'float32')
However when using Tensorflow as backend this gives the following error message:
   File "LSTM.py", line 254, in test
    loss = model.train_on_batch(g_input_noise_batch, one_hot_caption_batch)
  File "/.virtualenvs/keras/lib/python2.7/site-packages/keras/models.py", line 766, in train_on_batch
    class_weight=class_weight)
  File "/.virtualenvs/keras/lib/python2.7/site-packages/keras/engine/training.py", line 1319, in train_on_batch
    self._make_train_function()
  File "/.virtualenvs/keras/lib/python2.7/site-packages/keras/engine/training.py", line 760, in _make_train_function
    self.total_loss)
  File "/.virtualenvs/keras/lib/python2.7/site-packages/keras/optimizers.py", line 433, in get_updates
    m_t = (self.beta_1 * m) + (1. - self.beta_1) * g
  File "/.virtualenvs/keras/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py", line 883, in binary_op_wrapper
    y = ops.convert_to_tensor(y, dtype=x.dtype.base_dtype, name="y")
  File "/.virtualenvs/keras/lib/python2.7/site-packages/tensorflow/python/framework/ops.py", line 651, in convert_to_tensor
    as_ref=False)
  File "/.virtualenvs/keras/lib/python2.7/site-packages/tensorflow/python/framework/ops.py", line 716, in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File "/.virtualenvs/keras/lib/python2.7/site-packages/tensorflow/python/framework/constant_op.py", line 176, in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
  File "/.virtualenvs/keras/lib/python2.7/site-packages/tensorflow/python/framework/constant_op.py", line 165, in constant
    tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))
  File "/.virtualenvs/keras/lib/python2.7/site-packages/tensorflow/python/framework/tensor_util.py", line 360, in make_tensor_proto
    raise ValueError("None values not supported.")
ValueError: None values not supported.
This error does not however occur when I use Theano as backend, but I need to use Tenorflow.
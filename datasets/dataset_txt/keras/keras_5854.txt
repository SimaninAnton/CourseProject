shyamupa commented on 29 Feb 2016
This is a question to understand what exactly is the purpose of Masking layer. I have a complicated model in which I have input sequences of different lengths. I am 0-padding using the pad_sequences method in keras.preprocessing.sequence. The problem is my model is not learning at all (loss remains same), and I suspect 0-padding is the problem.
I tried adding a masking layer just after the input and before the embedding layer using model.add_node(Masking(), name='masked_input', input='input') as good measure, but this lead to compilation errors. I am using things like TimeDistributedDense so I suspect I will not be able to use masking.
Shouldn't 0-padding be enough? Why exactly do I need to have a masking layer?
Please make sure that the boxes below are checked before you submit your issue. Thank you!
Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps
If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps
Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
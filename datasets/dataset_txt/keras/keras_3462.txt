Contributor
mjdietzx commented on 16 Jan 2017
When training a GAN for example your discriminator may take a batch of images (either generated or real), and then multiple expected outputs for these images [is_image_real, image_label].
In my case I have real images, some of which I have label's and others do not have labels. I want to use all of these images when training my GAN. This leads me to:
disc.train_on_batch(image_batch_has_labels, [y_real, label_batch])
disc.train_on_batch(image_batch_no_labels, [y_real, no_labels_so_ignore_this_loss])
where y_real = np.ones(shape=(batch_size, )).
The problem I am running into is how to specify the no_labels_so_ignore_this_loss. I don't want the discriminator to be penalized for predicting these labels since I don't have any ground truth label to evaluate against.
What is the most 'keras' way to accomplish this? The only thing I can really think of at this point is to somehow make the class weights 0 for the case of no labels.
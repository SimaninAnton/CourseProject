naure commented on 12 May 2016 •
edited
The RNN layers include a matrix multiplication of their input. However when the input is a trainable embedding, this linear transformation is redundant in terms of both parameters and computation, and actually creates an ill-defined optimization problem.
I suggest trimming down the RNN implementations to the recurrent part, and reusing the Dense layer for the input transformation.
Example current stack:
Input: N-vector
LSTM input part: 4 gates at NxN
LSTM recurrent part: NxN
The decoupling would allow the following use-case:
Trainable Embedding: 4N-vector
LSTM recurrent part: 4 gates at NxN
The existing full LSTM would be re-implemented as:
Input: M-vector
TimeDistributed(Dense()): 4NxM
LSTM recurrent part: NxN
This removes all redundant code involving inputs (weights, bias, regularizations, …) out of each RNN implementation, reusing the code of the Dense layer. It also allows experimenting with any other combination of layers.
I implemented it for myself, and I heard others had the same need, so I can contribute it if you are interested in this change.
1
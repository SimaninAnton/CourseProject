calclavia commented on 10 Apr 2017
Using Keras 2.0.0, Tensorflow 1.0.1.
I think this is more of a feature request, but it would be great if there's a way to specify/use batch size in model.fit during validation. Currently, it seems like the validation feeds in the entire validation set into the neural network, which, in my case, my GPU runs out of memory. Training works fine because batch size of 32 is small enough. A solution would be to chunk the validation into batches of 32 and validate them each individually, which will enable validation to run on large data sets on GPUs that have insufficient memory.
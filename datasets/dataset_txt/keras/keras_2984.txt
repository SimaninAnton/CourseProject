bhedayat commented on 15 Mar 2017
Hello I am using Keras with a Tensorflow backend.
I am looking to Finetune ResNet 50 on the cifar10 dataset. I am hoping to set layer.trainable to False for the ResNet50 base model and then to attach my own top model and train only the top model.
Here is the ResNet50 model I want to train. I make the base model trainable layers equal to False.
https://gist.github.com/bhedayat/af2546dabddd5bb110f04f7646f0f809
However after Training I see that the weights for earlier layers have changed as shown below:
Finetuned Model weights for Layer: 'bn5a_branch2c'
[array([-0.9835369 , -0.52230012, -0.96178067, ..., -1.05353284,
-0.821365 , -1.01705575], dtype=float32),
array([ 1.70413303, 1.84239435, 1.54684055, ..., 1.23078692,
1.63978779, 1.87585914], dtype=float32),
array([-0.02585154, -0.20711923, 0.02728466, ..., 0.00459914,
-0.14954448, -0.0389582 ], dtype=float32),
array([ 0.020256 , 0.0225403 , 0.01597571, ..., 0.01147314,
0.0205538 , 0.01977504], dtype=float32)]
Original Model weights for Layer: 'bn5a_branch2c'
[array([ 1.70413303, 1.84239435, 1.54684055, ..., 1.23078692,
1.63978779, 1.87585914], dtype=float32),
array([-0.9835369 , -0.52230012, -0.96178067, ..., -1.05353284,
-0.821365 , -1.01705575], dtype=float32),
array([-0.0307549 , -0.19764261, 0.02491251, ..., 0.00359258,
-0.14138627, -0.03583578], dtype=float32),
array([ 0.01984804, 0.02195232, 0.01520322, ..., 0.01161362,
0.01946743, 0.01979927], dtype=float32)]
As a result when I send an image through my model to extract features from my layer 'fc1000'. These are the features: [[ -8543688. , -12302782. , 7139837.5, 12765346. , 13944379. ,
13991585. , -16508738. , 9055062. , -17216096. , -3976135.5]]
The numbers being of larger magnitude than expected.
Also this is the output of my final_model.summary() before I Finetune.
Total params: 23,616,394
Trainable params: 24,586
Non-trainable params: 23,591,808
Here is the main script I run to finetune. It calls my ResNet50finetune module
https://gist.github.com/bhedayat/608a03edba16cf61c0f3b5e4e2efb602
Thank you & I appreciate any help!
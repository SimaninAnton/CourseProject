phdowling commented on 23 May 2016 â€¢
edited
I want to merge two sequences together - I have an LSTM that encodes an input into a single vector that I replicate, and then I want to merge the resulting sequence with the input to another LSTM, zip style. I'm using the functional API.
text_input = Input((self.text_maxlen,), dtype="int32")
title_input = Input((self.title_maxlen,), dtype="int32")

# shared embedding for both inputs
embed = Embedding(  # TODO re-enable masking once merge supports it
    input_dim=self.vocab_size, output_dim=self.text_embedding_size, mask_zero=False, name="word_embeddings",
    weights=[get_word_vector_matrix()]
)
title_embedding = embed(title_input)
title_encoded = LSTM(self.title_lstm_size, return_sequences=False)(title_embedding)
title_encoded = Dropout(0.3)(title_encoded)

title_encoded_repeat = RepeatVector(self.text_maxlen)(title_encoded)

text_embedding = embed(text_input)

merged_aux_and_text = merge([title_encoded_repeat, text_embedding], mode="concat")

merged_text_lstm = LSTM(self.text_lstm_size, return_sequences=False)(merged_aux_and_text)
Is this the correct way to do this? I would use TimeDistributed here usually, but since merge is a function rather than a layer, I'm not sure it applies. Anyway, the model compiles, I just want to verify whether this does what I think it does.
matthiasreisser commented on 29 May 2018
Hey everyone.
There are at least three different sources for reported validation accuracy on mobilenet_v1_1.0_224 in the keras ecosystem:
https://github.com/keras-team/keras/blob/master/keras/applications/mobilenet.py reports 70.6%accuracy with 529 operations in the table right at the top of the fie.
Within this file, it is stated that the the weights for these models were obtained and translated from the original tf slim model checkpoints at https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1.md
. Within this file on the tf repo however, the reported validation accuracy for this model is 70.9% with 569 operations.
Finally, https://keras.io/applications/#documentation-for-individual-models reports a validation accuracy of only 66.5%.
I have implemented a validation script myself, using the provided keras checkpoints. The validation accuracy is at 66.5% with this setup. Subsequently, I have downloaded and converted the tf checkpoint provided at the second link above. Loading this checkpoint into the keras model doesn't change validation accuracy, so my suspicion is that the model is somehow ill-defined.
This was done on tf1.8+keras 2.1.6.
I would like to understand where those differences come from and why the keras model underperforms so significantly. Any help is greatly appreciated!
Mat
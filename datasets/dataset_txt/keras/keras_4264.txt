SwordPL commented on 1 Oct 2016 â€¢
edited
Hi,
I wrote simple multi-layer, layer-wise trained autoencoder. I would like to ask how to re-use the layers in order to proceed with supervised learning?
from keras.layers import Input, Dense
from keras.models import Model

import numpy as np

batch_size = 256
nb_classes = 6
nb_epoch = 50
nb_hidden_layers = [20000, 12500, 10000, 7500]

nb_noise = [0, 0.1, 0.25, 0.5]
input_layer = Input(size)

final_encoder = None

for i (n_in, n_out, noise) in enumerate(zip(nb_hidden_layers[:-1], nb_hidden_layers[1:], nb_noise[1:], start=1):
    print('Training the layer {}: Input {} -> Output {}'.format(i, n_in, n_out)
    input_lay = Input(shape=(n_in,))
    encoded = Dense(n_out, activation='relu')(input_lay)
    decoded = Dense(n_in, activation='sigmoid')(encoded))
    autoencoder = Model(input=input_lay, output=decoded)
    autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')
    x_noisy_in = x_train + noise * np.random.normal(loc=0.0, scale=1.0, size=x.train.shape)
    x_noisy_te = x_test + noise * np.random.normal(loc=0.0, scale=1.0, size=x.train.shape)
    x_noisy_in = np.clip(x_train_in, 0., 1.)
    x_noisy_te = np.clip(x_train_te, 0., 1.)
    autoencoder.fit(x_noisy_in, x_train,
                    nb_epoch=nb_epoch,
                    batch_size=batch_size,
                    shuffle=True,
                    validation_data=(x_noisy_te, x_test))
Please, assist.
likecoffee commented on 15 Apr 2016
I have run several Keras scripts including the official examples and my own scripts, but I found that the validation loss is always lower than the training loss. I have read the FAQ on this problem http://keras.io/getting-started/faq/#why-is-the-training-loss-much-higher-than-the-testing-loss. The FAQ says that the main cause of this problem is the training loss reported is averaged by each epoches, however the validation loss of the first epoch is usually lower than the training loss in most of the cases. Here are some examples:
cifar10_cnn:
Epoch 1/200
50000/50000 [==============================] - 14s - loss: 1.7222 - acc: 0.3636 - val_loss: 1.3246 - val_acc: 0.5282
imdb_cnn:
Epoch 1/2
20000/20000 [==============================] - 5s - loss: 0.4579 - acc: 0.7645 - val_loss: 0.3227 - val_acc: 0.8618
mnist_cnn
Epoch 1/12
60000/60000 [==============================] - 5s - loss: 0.2541 - acc: 0.9224 - val_loss: 0.0549 - val_acc: 0.9837
imdb_lstm_cnn
Epoch 1/15
20000/20000 [==============================] - 40s - loss: 0.5862 - acc: 0.6746 - val_loss: 0.4697 - val_acc: 0.7808
Also, The FAQ says the cause of this problem may be the regularization mechanisms of the models. I tried to eliminiate all the regularization parts of the official imdb_cnn example. But I get the same result too.
Here is my modified imdb_cnn code:
model = Sequential()

model.add(Embedding(max_features,
                    embedding_dims,
                    input_length=maxlen))

model.add(Convolution1D(nb_filter=nb_filter,
                        filter_length=filter_length,
                        border_mode='valid',
                        activation='relu',
                        subsample_length=1))

def max_1d(X):
    return K.max(X, axis=1)

model.add(Lambda(max_1d, output_shape=(nb_filter,)))

model.add(Dense(hidden_dims))
model.add(Activation('relu'))

model.add(Dense(1))
model.add(Activation('sigmoid'))

model.compile(loss='binary_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])
model.fit(X_train, y_train,
          batch_size=batch_size,
          nb_epoch=nb_epoch,
          validation_data=(X_test, y_test))
The result is :
Epoch 1/2
20000/20000 [==============================] - 5s - loss: 0.4061 - acc: 0.7960 - val_loss: 0.2804 - val_acc: 0.8806
I am confused why this happens.
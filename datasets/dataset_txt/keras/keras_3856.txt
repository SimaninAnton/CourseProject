christiantinauer commented on 23 Nov 2016 â€¢
edited
Using:
Keras latest from Git
Theano latest from Git
GPU mode
Hi,
I am new to keras and I want to build the autoencoder show on page 2 of this paper. The decoding convolutional layer is not "fully connected" with the encoding one. As far as I know convolutions normally use all feature maps of the previous layer. How can I build a model which corresponds to the paper? What came to my mind is the following (pseudo code):
input_img = Input(shape=input_shape)

decodeds= []

for kernel_index in range(0, 7):
  encoded = Convolution3D(1, 3, 3, 3, activation='relu', border_mode='full')(input_img)
  decoded = Convolution3D(1, 3, 3, 3, activation='relu', border_mode='valid')(encoded)
  decodeds.append(decoded)

#merge
merged = merge(decodeds, 'sum')

autoencoder = Model(input_img, merged)
autoencoder.compile(optimizer='adadelta', loss='mse', metrics=['accuracy'])
Is this the way to go? Am I missing something? I found LocalConvolution2D in the docs. I am not sure if that solves the problem in 2D. If so, why is there no 3D version?
Thanks,
Christian
smohsensh commented on 23 Feb 2016
I have a shared layer with join merge mode (like in this example) and then I want to feed the output of this layer (which is an ordered dictionary) to another shared node.
I tried splitting output of first shared node with lambda layer (like in code below) but I get errors on None output/input shape.
I was wondering what is the right way to stack two shared nodes?
g = Graph()
g.add_input(name='im1', input_shape=(input_dim,))
g.add_input(name='im2', input_shape=(input_dim,))
g.add_shared_node(base_network, name='shared', inputs=['im1', 'im2'], merge_mode='join')
g.add_node(Lambda(euclidean_distance), name='d', input='shared')
g.add_node(Lambda(lambda d: d['im1'], output_shape=(im_emb_dim,)), name='im1emb', input='shared')
g.add_node(Lambda(lambda d: d['im2'], output_shape=(im_emb_dim,)), name='im2emb', input='shared')
g.add_shared_node(Dense(att_dim, activation='sigmoid', input_shape=(im_emb_dim,)), name='att_pred', inputs=['shared'])
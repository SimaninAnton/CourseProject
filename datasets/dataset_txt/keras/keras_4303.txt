Contributor
dolaameng commented on 27 Sep 2016 â€¢
edited
I am not sure if I understand the role of Model.trainable = False correctly - it is a shortcut to freeze all the layers in the model, which is equivalent to layer.trainable = False for all the layers in the model, even though it has not been explicitly documented to work this way. If so, there seems to be an inconsistency between the states (trainable_weights vs non_trainable_weights) of the model and its layers. For example,
model = Sequential(layers = [Dense(100, input_shape=(5,)),
                                              Dense(2)])
# freeze all layers
model.trainable = False
model.compile(loss='mse', optimizer='adam')
x, y = np.random.normal(size=(100, 5)), np.random.normal(size=(100, 2))
model.fit(x, y)
Here is the inspection result
print keras.__version__
>>> '1.1.0'

# model state
print model.trainable
>>> False
print model.trainable_weights
>>> []
print model.non_trainable_weights
>>> [dense_16_W, dense_16_b, dense_17_W, dense_17_b]

# layer states
for layer in model.layers:
    print layer.name,
    print "trainable=", layer.trainable
    print "trainable_weights: ",layer.trainable_weights
    print "non_trainable_weights: ", layer.non_trainable_weights
    print ""
>>> dense_16 trainable= True
>>> trainable_weights:  [dense_16_W, dense_16_b]
>>> non_trainable_weights:  []
>>> 
>>> dense_17 trainable= True
>>> trainable_weights:  [dense_17_W, dense_17_b]
>>> non_trainable_weights:  []
As a result, those layer weights will be updated anyway as sublayers of model. So if this is not how model.trainable should be used, suggest to make it a private variable or document it properly? There have been some use cases of this - search for net.trainable.
Found the related topic: #3804, #839. Do we need to make a model's trainable a property so when it is turned off, states of sublayers will be updated? But that will probably fail the examples in #3804.
wAuner commented on 21 May 2017
keras 2.0.4, Tensorflow backend 1.1
Linux Mint 18.1
Python 3.5
use case:
predicting with an ensemble on the cats/dogs test data with test_gen = ImageDataGenerator().flow_from_directory(...)
Issue:
test_gen.batch_index shows unexpected behavior which leads to mixed up predictions:
for every model in the ensemble I want to make predictions for every file in the test_data_folder with:
model.predict_generator(test_gen, steps=test_gen.n/test_gen.batch_size, verbose=1).
For 12500 test files and a batch size of 50 this would give 250 batches and this works as long as you're only working with 1 model or only predict once.
expected behavior:
after predicting the last batch test_gen.batch_size goes back to 0 so that the next time you predict you get the same files in the same order and test_gen.total_batches_seen=1250 after predicting five times.
real behavior:
After making predictions with the first model in the described scenario,test_gen.batch_index starts of with 10 (or +10 than it's previous starting point) and in the end test_gen.total_batches_seen=1300. This leads to errors when trying to combine the ensembles predictions and doesn't match the user's intention.
predictions_ens = []
for model in ensemble:
    print("Batch index before: ",test_gen.batch_index)
    predictions_ens.append(model.predict_generator(test_gen, steps=test_gen.n / test_gen.batch_size, verbose=1))
    print(test_gen.batch_index)
    print("Batch index after: ", test_gen.batch_index)

print(test_gen.total_batches_seen)
Output:
Batch index before:  0
250/250 [==============================] - 75s    
Batch index after:  10
Batch index before:  10
250/250 [==============================] - 76s    
Batch index after:  20
Batch index before:  20
250/250 [==============================] - 76s    
Batch index after:  30
Batch index before:  30
250/250 [==============================] - 76s    
Batch index after:  40
Batch index before:  40
250/250 [==============================] - 77s    
Batch index after:  50

1300
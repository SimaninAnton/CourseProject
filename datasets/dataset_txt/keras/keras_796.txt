adingler711 commented on 30 Aug 2018 â€¢
edited
I am working on a data problem where the data has been improving over the years and not all variables exist in the past years. So I filled the older years values with zero. Since I am predicting T+1, I want to weight the most recent observations more.
I created a custom mean absolute error weighted function
def mae_weighted(y_true, y_pred):

    weights = y_true[:, 1]
    y_true = y_true[:, 0] * weights
    
    return K.mean(K.abs(y_pred - y_true), axis=-1)
My y_values look like this
        # y value       , observation weight
array([[0.28633344, 0.00122576],
       [0.26755273, 0.00442],
       [0.23721467, 0.00131925],
       ...,
       [0.09852643, 0.00284625],
       [0.12597515, 0.00454465],
       [0.26032937, 0.01225758]])
There is a unique weight every week. I calculated the observations weights using
train_unique_yr_wk = np.sort(train_data['year_wk'].unique())
scaler = MinMaxScaler(feature_range=(0.5, 5))
scaled = scaler.fit_transform(train_unique_yr_wk.reshape(-1, 1))
transformed_weights = scaled / np.sum(scaled)
When using the custom function in my compiler it gets stuck
parallel_model.compile(loss= mae_weighted, optimizer=learner)
I tried running the network using a loss of
def mae_weighted(y_true, y_pred):

    #weights = y_true[:, 1]
    y_true = y_true[:, 0] #* weights
    
    return K.mean(K.abs(y_pred - y_true), axis=-1)
and I was hoping it would produce the same results as but it does not
def mae_weighted(y_true, y_pred):  
    return K.mean(K.abs(y_pred - y_true), axis=-1)
suryasumukh commented on 20 Nov 2016 â€¢
edited
Hi,
I'm trying to define a custom loss function for a classification task. The inputs X and y are of shape [batch_size, max_timestep] int32 values. I get this error when trying to fit X and y. I was wondering if guys have any idea about the error.
Must y_pred always conform to [batch_size, num_labels] ?
ValueError: Cannot feed value of shape (32, 3) for Tensor u'lstm_39_target:0', which has shape '(?, ?, ?)'  
Code:
from keras.backend import tf
max_timestep = 3

def custom_loss(y_true, y_pred):
    y_true = tf.cast(y_true, dtype=tf.int32)
    y_true = tf.nn.embedding_lookup(label_embedding, y_true)
    y_true = tf.reshape(y_true, shape=[-1, num_labels])
    y_pred = tf.reshape(y_pred, shape=[-1, num_labels])
    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y_pred, y_true))
    return loss

model = Sequential()
model.add(Embedding(num_words, embedding_size, input_length=max_timestep))
model.add(LSTM(50, return_sequences=True))
model.add(LSTM(50, return_sequences=True))
model.add(LSTM(8, return_sequences=True))
model.compile(optimizer='adam',
             loss=custom_loss)
Thanks
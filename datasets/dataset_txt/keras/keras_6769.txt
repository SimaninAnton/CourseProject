pcyin commented on 15 Aug 2015
Sometimes it's highly beneficial if a Layer can have multiple inputs tensors (with different shapes). For example, if we want to compute the weighted sum of N vectors, which are stored in tensor T1 of shape (nb_vectors, dim) and the weights are given by another tensor T2 of shape (nb_vectors, 1). The weighted sum can be computed using a Layer with two input tensors T1 and T2. But in current implementation of Keras, it seems that we must concatenate T1 and T2 first and feed the concatenated tensor to a Layer and then split them during computation.
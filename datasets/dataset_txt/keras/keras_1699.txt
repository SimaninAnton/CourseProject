32nguyen commented on 31 Aug 2017 â€¢
edited
Hi,
I am using fit_generator for my training. However, I have weird issue from the log.
Epoch 00002: val_loss improved from 2.27473 to 1.17815, saving model to WeightsV2.h5
100/100 [==============================] - 930s - loss: 0.1982 - acc: 0.7890 - val_loss: 1.1782 - val_acc: 0.8090
Epoch 4/100
While the val_loss >> loss, the val_acc > acc. I am pretty sure that I processed training and validation in same way by using same data_generator() function (picking randomly files in training & validation directories)
here is my training.py
it_train = data_generator(params.path_train, batch_size=params.batch_size)
it_val = data_generator(params.path_valid, batch_size=params.batch_size)
checkpoint = ModelCheckpoint('3DUnetWeightsV2.h5', monitor='val_loss', verbose=1, save_best_only=True)
hist = models.fit_generator(it_train, steps_per_epoch=params.step_per_epoch_train, epochs=params.epochs, verbose=1,validation_data=it_val, validation_steps=params.steps_batch_valid, callbacks=[checkpoint])
epochs = 100
steps_per_epoch = 50
validation_steps = 15
Any hints to help me figure this out would be appreciated.
Bests,
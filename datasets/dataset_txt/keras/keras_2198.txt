AndZark commented on 7 Jun 2017
Greetings!
I have 2 questions.
The way for the full batch gradient descent is by setting the batch size equal to the number of examples and using as optimizer 'SGD' as it is?
Before I input the data to the network I standardize them, removing the mean and dividing by the standard deviation. The loss function (MSE) computed is of course for the standardized data. Is there a way to get the unstandardized MSE?
Thank you for your time!
santi-pdp commented on 21 Dec 2015
Hello people,
I have been working with a regression problem with LSTMs in which I predict a vector of output coefficients from an input sequence. What I want to do is to build multiple output layers on top of the same hidden structure, so that I will be training the different layers depending on the input sequence (inputs always have the same dimension). To sum up, when I backprop one output layer all other output layers will remain static. Is there any way to freeze the N-1 output layers and only fit a batch of data into the Nth layer, iterating the process for many batches and the N layers? Can I have any clue please?
Thank you
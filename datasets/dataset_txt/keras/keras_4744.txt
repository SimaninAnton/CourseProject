bkj commented on 20 Jul 2016 â€¢
edited
I'm training the following mode, predicting 1 out of 100 labels from short texts (>= 30 words):
model = Sequential()
model.add(Embedding(input_dim=100000, output_dim=128)) # 100000 is the vocab size, 128 is arbitrary
model.add(LSTM(output_dim=128)) # 128 is arbitrary
model.add(Dropout(0.5))
model.add(Dense(100, activation='softmax')) # 100 class prediction task
model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])

fitist = model.fit(
    sX_train, sy_train,  # 6M records
    verbose = True, 
    nb_epoch = 20,
    batch_size = 256, # 256 is arbitrary
    validation_data = (sX_valid, sy_valid), # 1M records
    shuffle = True
)
The resulting loss and accuracy plots look like:
Obviously there's some overfitting going on. I've been previously told that the solution to this is to increase regularization, usually via dropout. But I'm wondering where to increase the dropout? In the Embedding layer? In the LSTM layer? Alternatively, is there something else (like changing the optimizer or the learning rate) that could help address this?
Thanks
Ben
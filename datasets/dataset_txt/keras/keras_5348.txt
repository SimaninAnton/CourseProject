TheRushingWookie commented on 26 Apr 2016 â€¢
edited
Please make sure that the boxes below are checked before you submit your issue. Thank you!
[ x] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps
[ x] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps
[ x] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
The mnist example has .10ish accuracy when trainable=false is set for all layers. But when i switch the mnist example to using the functional api with trainable=false, it gets very very good accuracy. The functional API should not train the net if all the layers have trainable=false.
from keras.datasets import mnist
from keras.models import Model
from keras.layers import Dense, Dropout, Activation, Flatten, Input
from keras.layers.convolutional import Convolution2D, MaxPooling2D
from keras.utils import np_utils
batch_size = 128
nb_classes = 10
nb_epoch = 14

# input image dimensions
img_rows, img_cols = 28, 28
# number of convolutional filters to use
nb_filters = 32
# size of pooling area for max pooling
nb_pool = 2
# convolution kernel size
nb_conv = 3

layers = [Input(shape=(1, img_rows, img_cols)), ]
layers.append(Convolution2D(nb_filters, nb_conv, nb_conv,
                    border_mode='valid', trainable=False)(layers[-1]))
layers.append(Activation('relu', trainable=False)(layers[-1]))
layers.append(Convolution2D(nb_filters, nb_conv, nb_conv, trainable=False)(layers[-1]))
layers.append(Activation('relu', trainable=False)(layers[-1]))
layers.append(MaxPooling2D(pool_size=(nb_pool, nb_pool), trainable=False)(layers[-1]))
layers.append(Dropout(0.25, trainable=False)(layers[-1]))
layers.append(Flatten(trainable=False)(layers[-1]))
layers.append(Dense(128, trainable=False)(layers[-1]))
layers.append(Activation('relu', trainable=False)(layers[-1]))
layers.append(Dropout(0.5, trainable=False)(layers[-1]))
layers.append(Dense(nb_classes, name="lastdense", trainable=False)(layers[-1]))

layers.append(Activation('softmax')(layers[-1]))

model = Model(input=layers[0], output=layers[-1])
model.compile(loss='categorical_crossentropy',
            optimizer='adadelta',
            metrics=['accuracy'])

X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)
X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)
X_train = X_train.astype('float32')
X_test = X_test.astype('float32')
X_train /= 255
X_test /= 255
print('X_train shape:', X_train.shape)
print(X_train.shape[0], 'train samples')
print(X_test.shape[0], 'test samples')
# convert class vectors to binary class matrices
Y_train = np_utils.to_categorical(y_train, nb_classes)
Y_test = np_utils.to_categorical(y_test, nb_classes)


hist = model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,
          verbose=1, validation_data=(X_test, Y_test))


score = model.evaluate(X_test, Y_test, verbose=0)
print('Test score:', score[0])
print('Test accuracy:', score[1])
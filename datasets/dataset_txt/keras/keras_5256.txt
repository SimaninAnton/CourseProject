MRLoghmani commented on 5 May 2016
I have the following model for motion classification:
CLASSIFICATION
#params
in_neurons = 225
hidden_neurons_1 = 21
hidden_neurons_2 = 21
out_neurons = 4

#preprocessing
newNPZ = sequence.pad_sequences(NPZ,dtype='float32')
newY =  sequence.pad_sequences(y,dtype='int32')

# split dataset in training set and test set
X_train, X_test, y_train, y_test = train_test_split(newNPZ, newY, test_size=0.3, random_state=0)

#X_train = sequence.pad_sequences(X_train,dtype='float32')
#y_train = sequence.pad_sequences(y_train,dtype='int32') 

model = Sequential()

model.add(GRU(hidden_neurons_1, input_dim=in_neurons, return_sequences=True))
model.add(Dropout(0.2))
model.add(GRU(hidden_neurons_2, return_sequences=True))
model.add(Dropout(0.2))
model.add(TimeDistributed(Dense(out_neurons, activation = 'softmax')))

model.compile( loss = 'categorical_crossentropy', optimizer = 'rmsprop',  metrics=["accuracy"])

model.summary()

model.fit(X_train, y_train,batch_size =10,nb_epoch=1000,verbose=0)
It is strage to me the fact that all the output I get at the end of each time series sample (for the test set) indicate that one out of the 4 classes definitely wins against the others ( typical output: [0.01, 0.97, 0.01, 0.01] ) but the classification rate is 0.25 (= chance). This is even stranger if we consider that the accuracy indicated by fit() is between 0.65 and 0.7.
At the beginning I thought that 'mse' was not a good choice for the loss function, but with categorical crossentropy nothing changed.
How do you explain this behavior. Do you have any suggestion?
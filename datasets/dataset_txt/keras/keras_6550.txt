schlowm0 commented on 16 Oct 2015
I am currently trying to implement a method to allow the manipulation of the weights with a given bit precision and a given rounding method (e.g. randomized rounding, dual copy rounding).
First of all is there already a function implemented which does this kind of job?
If not maybe you can help either way:
what my code look like:
 method_list= ['randomized', 'dual_copy', 'dynamic_fp', 'iterative']
 bit_precision = np.arange(1,10) # from 1 to 10 bit precision

 for rounding_method in method_list:
     for bit_precision in bit_precision:

        # init bit precision
        family = FixedPoint.FXfamily(bit_precision)

        model.add(Convolution2D(nb_filters, nb_conv, nb_conv,
                                border_mode='full',
                                input_shape=(1, img_rows, img_cols)))
        model.add(Activation('relu'))
        model.add(Convolution2D(nb_filters_2, nb_conv, nb_conv))
        model.add(Activation('relu'))
        model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))
        model.add(Dropout(0.5))

        model.add(Flatten())
        model.add(Dense(128))
        model.add(Activation('relu'))
        model.add(Dropout(0.5))
        model.add(Dense(nb_classes))
        model.add(Activation('softmax'))
        # print('Compiling...')
        model.compile(loss='categorical_crossentropy', optimizer='adadelta')

        if rounding_method not in {'randomized', 'dual_copy', 'dynamic_fp', 'iterative'}:
           raise Exception('Invalid rounding method for Convolution2D_rounding:', rounding_method)
        if bit_precision < 1:
            raise Exception('Bit precision is to low:', bit_precision)

        if rounding_method == 'randomized':
            print('Randomized rounding selected')
            for layer in model.layers:
                 W_pre=layer.get_weights()
                 for i in range(len(W_pre)):
                      try:
                          # Apply given bit precision on each weight of a layer
                           # THIS DOES NOT WORK! I need to loop every single element of the weight array
                           W_post_tmp = FixedPoint.FXnum(W_pre[0][i], family)
                           # save W_post_tmp to W_post 
                        except IndexError: pass
                   layer.set_weight(W_post)     

        # so far this does only change the initial weights... I have implement the same kind of manipulation inside the model.fit() function...
        model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch, show_accuracy=True, verbose=1, validation_data=(X_test, Y_test))
FixedPoint (http://sourceforge.net/projects/fixedpoint/) is a python function which sets a certain bit precision to a value. Unfortunately, it only operates on single values and not on numpy arrays...
Do you know an alternative to FixedPoint.py which operates on numpy arrays?
Does your code can operate on other value types than float32?
Does my code make some sense?
And what is the exact structure of the weights... to get a single weight I need to index like:
W_pre[0][i][0][0, 0]
but when I do
W_pre[0][i][1][0, 0]
I get complete different matrix and not a single value... I'm lost
Thanks for your help :)
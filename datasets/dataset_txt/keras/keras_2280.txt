Lakedaemon commented on 28 May 2017
I am building an app for android with a keras model exported (through tenserflow).
Yet, it crashes at runtime because there are DT_BOOL node in the graph and the tensorflow library I use doesn't have KernelOp for DT_BOOL registered out of the box. So, I would like to try getting read of all DT_BOOL noes (if it is possible) from the model that I only use for inference on the device.
Is it possible to strip a keras model from all DT_BOOL nodes that depens on keras_learning_phase ?
How can it be done ?
I tried this :
K.set_learning_phase(0) # all new operations will be in test mode from now on
serialize the model and get its weights, for quick re-building
config = model.get_config()
weights = model.get_weights()
re-build a model where the learning phase is now hard-coded to 0
new_model = Sequential.from_config(config)
new_model.set_weights(weights)
And I also tried a few things on the tensorflow side (optimize_for_inference, freeze_graph, (wrongly) turning Switch node into Identity (I corrupted my graph), ...)
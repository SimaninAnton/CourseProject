panjinbo commented on 1 Feb 2016
I have tried the tutorial code lstm_text_generation.py.
And it seems that it just uses the previous n chars to predict the next one, not all the previous chars, which I think is just as n-gram model.
And I want to ask can I use keras to write a model which uses all the previous chars to predict the next one?
emb9357 commented on 6 Jul 2019 â€¢
edited
System information
Have I written custom code (as opposed to using example directory): used pre written code from here: https://github.com/MathiasGruber/PConv-Keras
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 19.04
TensorFlow backend (yes / no): yes
TensorFlow version: 1.14.0
Keras version: 2.2.4
Python version: 3.6.8
CUDA/cuDNN version:9 (edit)(thought i had it at 10 but it was not this code)
GPU model and memory: MB has quad RTX2080TI (11GB) but i'm only using one of them for this
You can obtain the TensorFlow version with:
python -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"
You can obtain the Keras version with:
python -c 'import keras as k; print(k.version)'
Describe the current behavior
Title says it all. I have a code which I trained on my 1080ti which was slow so i moved it to a 2080ti with the same everything. The code now uses the CPU rather than the GPU, i've tried reinstalling tensorflow/keras, even created a brand new env. and nothing worked. I made sure i had CUDA10 since from what i heard the new 2080ti can have a hard time with cuda9.
Describe the expected behavior
Should work on the gpu
Code to reproduce the issue
https://github.com/MathiasGruber/PConv-Keras
Other info / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
Sorry if i did something wrong in the formatting and such.
Contributor
dbonadiman commented on 9 Mar 2016
Hello everyone, i want to report (and probably resubmit) an old issue that is in Keras for a while.
I have tried to debug a known issue about reproducibility of the code on GPU.
Many of you have probably noticed that when run on GPU keras code produce slightly different results from time to time. So i tried to debug the problem starting from the the examples of the repository.
The only code that i found not reproducible is the code that involves the Embedding layers.
In particular all the imdb examples are not reproducible. At first i thought it was some problem related to the shuffling of the dataset (in the imdb dataset_loader). But the same lines of code are present in the reuter corpus. And the code is perfectly reproducible.
Can anybody help me to spot the bug?
PS i was thinking even on some convolution related stuff but on mnist everything is fine.
In personal experiments (work related) with this layer i get the same issue (and it occurs even with a preinitialised word embedding matrix) it may be related to gradient updates?
Please make sure that the boxes below are checked before you submit your issue. Thank you!
[x ] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps
[x ] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps
Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
hr0nix commented on 8 Dec 2015
When calling graph.to_json() on a model with a siamese layer created via a call to add_shared_node, I get the following error:
TypeError: <keras.layers.core.Siamese object at 0xf1cab10> is not JSON serializable
The results of graph.get_config() look as follows:
{   'input_config': [   {   'dtype': 'int32',
                            'input_shape': (1000,),
                            'name': 'encoder_input'},
                        {   'dtype': 'int32',
                            'input_shape': (1000,),
                            'name': 'decoder_input'}],
    'input_order': ['encoder_input', 'decoder_input'],
    'loss': {   'decoder_output': 'categorical_crossentropy'},
    'name': 'Graph',
    'node_config': [   {   'concat_axis': -1,
                           'create_output': False,
                           'dot_axes': -1,
                           'inputs': ['encoder_input', 'decoder_input'],
                           'merge_mode': None,
                           'name': 'embedding'},
                       {   'create_output': False,
                           'inputs': [   <keras.layers.core.Siamese object at 0xf1cab10>],
                           'name': 'embeddings_encoder'},
                       {   'create_output': False,
                           'inputs': [   <keras.layers.core.Siamese object at 0xf1cab10>],
                           'name': 'embeddings_decoder'},
                       {   'concat_axis': -1,
                           'create_output': False,
                           'dot_axes': -1,
                           'input': 'embeddings_encoder',
                           'inputs': [],
                           'merge_mode': 'concat',
                           'name': 'encoder_lstm'},
                       {   'concat_axis': -1,
                           'create_output': False,
                           'dot_axes': -1,
                           'input': 'encoder_lstm',
                           'inputs': [],
                           'merge_mode': 'concat',
                           'name': 'encoder_output'},
                       {   'concat_axis': -1,
                           'create_output': False,
                           'dot_axes': -1,
                           'input': 'encoder_output',
                           'inputs': [],
                           'merge_mode': 'concat',
                           'name': 'encoder_output_repeated'},
                       {   'concat_axis': -1,
                           'create_output': False,
                           'dot_axes': -1,
                           'input': None,
                           'inputs': [   'encoder_output_repeated',
                                         'embeddings_decoder'],
                           'merge_mode': 'concat',
                           'name': 'decoder_lstm'},
                       {   'concat_axis': -1,
                           'create_output': False,
                           'dot_axes': -1,
                           'input': 'decoder_lstm',
                           'inputs': [],
                           'merge_mode': 'concat',
                           'name': 'decoder_dense'},
                       {   'concat_axis': -1,
                           'create_output': False,
                           'dot_axes': -1,
                           'input': 'decoder_dense',
                           'inputs': [],
                           'merge_mode': 'concat',
                           'name': 'decoder_prob_est'}],
    'nodes': {   'decoder_dense': {   'W_constraint': None,
                                      'W_regularizer': None,
                                      'activation': 'tanh',
                                      'activity_regularizer': None,
                                      'b_constraint': None,
                                      'b_regularizer': None,
                                      'init': 'glorot_uniform',
                                      'input_dim': None,
                                      'input_length': None,
                                      'name': 'TimeDistributedDense',
                                      'output_dim': 512},
                 'decoder_lstm': {   'activation': 'tanh',
                                     'forget_bias_init': 'one',
                                     'go_backwards': False,
                                     'init': 'glorot_uniform',
                                     'inner_activation': 'hard_sigmoid',
                                     'inner_init': 'orthogonal',
                                     'input_dim': 428,
                                     'input_length': None,
                                     'name': 'LSTM',
                                     'output_dim': 512,
                                     'return_sequences': True,
                                     'stateful': False},
                 'decoder_prob_est': {   'W_constraint': None,
                                         'W_regularizer': None,
                                         'activation': 'fast_softmax',
                                         'activity_regularizer': None,
                                         'b_constraint': None,
                                         'b_regularizer': None,
                                         'init': 'glorot_uniform',
                                         'input_dim': None,
                                         'input_length': None,
                                         'name': 'TimeDistributedDense',
                                         'output_dim': 5000},
                 'embedding': {   'concat_axis': -1,
                                  'dot_axes': -1,
                                  'inputs': [   {   'input_shape': (1000,),
                                                    'name': 'Layer'},
                                                {   'input_shape': (1000,),
                                                    'name': 'Layer'}],
                                  'layer': <bound method Embedding.get_config of <keras.layers.embeddings.Embedding object at 0x6745050>>,
                                  'merge_mode': None,
                                  'name': 'Siamese'},
                 'embeddings_decoder': {   'head': 1, 'name': 'SiameseHead'},
                 'embeddings_encoder': {   'head': 0, 'name': 'SiameseHead'},
                 'encoder_lstm': {   'activation': 'tanh',
                                     'forget_bias_init': 'one',
                                     'go_backwards': False,
                                     'init': 'glorot_uniform',
                                     'inner_activation': 'hard_sigmoid',
                                     'inner_init': 'orthogonal',
                                     'input_dim': 300,
                                     'input_length': None,
                                     'name': 'LSTM',
                                     'output_dim': 512,
                                     'return_sequences': False,
                                     'stateful': False},
                 'encoder_output': {   'W_constraint': None,
                                       'W_regularizer': None,
                                       'activation': 'tanh',
                                       'activity_regularizer': None,
                                       'b_constraint': None,
                                       'b_regularizer': None,
                                       'init': 'glorot_uniform',
                                       'input_dim': None,
                                       'name': 'Dense',
                                       'output_dim': 128},
                 'encoder_output_repeated': {   'n': 1000,
                     'lr': 0.0010000000474974513,
                     'name': 'Adam'},
    'output_config': [   {   'concat_axis': -1,
                             'dot_axes': -1,
                             'input': 'decoder_prob_est',
                             'inputs': [],
                             'merge_mode': 'concat',
                             'name': 'decoder_output'}],
    'output_order': ['decoder_output'],
    'theano_mode': None}
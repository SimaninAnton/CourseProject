bkj commented on 6 May 2016 â€¢
edited
I'm trying to define a lambda function that averages all of the word embeddings from the embedding layer. This code words, but it includes the word embedding of the 0s in the input matrix -- those 0s are just placeholders, so we don't want to include them -- eg
model.predict(np.array([[0, 100]]))
should equal
model.predict(np.array([[100]]))
Does anyone have any ideas how to take the mean but drop the 0s? I'm assuming that it can be done with proper use of masking, but I'm not exactly sure how.
Thanks!
def s(x):
    return K.mean(x, axis=1)

input = Input(shape=(100,), dtype='int32')

embedding = Embedding(
    input_length = 10,
    input_dim = 100, 
    output_dim = 256,
    mask_zero = True
)(input)

lambda_ = Lambda(s)(embedding)

dense = Dense(1)(lambda_)

model = Model(input=labeled, output=dense)

model.compile(loss='mse', optimizer='rmsprop')
hadaev8 commented on 25 Jul 2018
Last keras, testing code:
text = open(os.path.join(work_dir, 'train_text_en.txt'), 'r', encoding='utf-8').read()
tokenizer = Tokenizer(char_level=False)
tokenizer.fit_on_texts(text)
print(tokenizer.word_index)
in output get chars
{'e': 1, 't': 2, 'a': 3, 'o': 4, 'i': 5, 'n': 6, 's': 7, 'r': 8, 'h': 9, 'l': 10, 'd': 11, 'm': 12, 'c': 13, 'u': 14, 'f': 15, 'p': 16, 'g': 17, 'y': 18, 'w': 19, 'b': 20, 'v': 21, 'k': 22, 'x': 23, '—': 24, "'": 25, 'z': 26, 'j': 27, 'q': 28, '0': 29, '1': 30, '5': 31, '2': 32, '3': 33, '4': 34, '6': 35, '7': 36, '9': 37, '8': 38, '…': 39, 'с': 40}
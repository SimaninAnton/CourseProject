OssamaAlshabrawy commented on 10 May 2017
Hi All,
I have a time series data which I reshaped to be 63x38365x128. I'm trying to use Convolutional LSTM (Convolutional network on top of LSTM). I've used Conv1D which I found it suitable to my data as I understood from keras documentation.
_The problem is Conv1D is going through the rows of the sequence rather going through the dimension, and then the output after convolutional, maxpooling,... make the sequence length became 4793 whilst the sequence length 38365 as you see in the shape of the original data _
So, I've got an error since the y (the label numpy array is 63x38365x2)
Therefore, is there any way to circumvent this problem
My code is below followed by the error
import numpy as np
from keras.layers import LSTM,Dense,Dropout,TimeDistributed
from keras.layers.convolutional import Conv1D,MaxPooling1D
from keras.utils import to_categorical
from keras.models import Sequential
from sklearn import metrics
import pandas as pd

dims = 128
timesteps = 38365

s = s.reshape(63,timesteps, dims)
y = to_categorical(y, num_classes=2)
y = y.reshape(63,timesteps, 2)

n_epochs=40

# model configration
model = Sequential()
model.add(Conv1D(input_shape=(timesteps,dims),
                 filters=64,
                 kernel_size=5,
                 padding='valid',
                 activation='relu',
                 strides=1))
model.add(MaxPooling1D(pool_size=4)) # strides=None means strides=pool_size
model.add(Conv1D(filters=64,
                 kernel_size=4,
                 padding='valid',
                 activation='relu',
                 strides=1))
model.add(MaxPooling1D(pool_size=2))
model.add(LSTM(128, return_sequences=True,
              activation='tanh', recurrent_activation='hard_sigmoid',
              dropout=0.2,recurrent_dropout=0.2)) # 100 num of LSTM units
model.add(LSTM(128, return_sequences=True,
              activation='tanh', recurrent_activation='hard_sigmoid',
              dropout=0.2,recurrent_dropout=0.2))
model.add(LSTM(128, return_sequences=True,
              activation='tanh', recurrent_activation='hard_sigmoid',
              dropout=0.2,recurrent_dropout=0.2))
model.add(LSTM(128, return_sequences=True,
              activation='tanh', recurrent_activation='hard_sigmoid',
              dropout=0.2,recurrent_dropout=0.2))
model.add(LSTM(128, return_sequences=True,
              activation='tanh', recurrent_activation='hard_sigmoid',
              dropout=0.2,recurrent_dropout=0.2))
model.add(TimeDistributed(Dense(2, activation='softmax')))

model.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])


print(model.summary())

for i in range(n_epochs):
    model.fit(s, y, batch_size=3, epochs=1)
The error in the line of fit as follows:
Traceback (most recent call last):
  File "src/ConvLSTM.py", line 146, in <module>
    model.fit(s, y, batch_size=3, epochs=1)
  File "/usr/lib/python2.7/site-packages/keras/models.py", line 845, in fit
    initial_epoch=initial_epoch)
  File "/usr/lib/python2.7/site-packages/keras/engine/training.py", line 1405, in fit
    batch_size=batch_size)
  File "/usr/lib/python2.7/site-packages/keras/engine/training.py", line 1299, in _standardize_user_data
    exception_prefix='model target')
  File "/usr/lib/python2.7/site-packages/keras/engine/training.py", line 133, in _standardize_input_data
    str(array.shape))
ValueError: Error when checking model target: expected time_distributed_1 to have shape (None, 4793, 2) but got array with shape (63, 38365, 2)
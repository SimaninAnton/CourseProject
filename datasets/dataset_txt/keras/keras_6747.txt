amirj commented on 20 Aug 2015
I'm going to train LSTM in the text generation example using the following line of code:
model.fit(X_train, y_train, batch_size=128, nb_epoch=25, callbacks=[checkpointer,callnap], validation_data=(X_val, y_val))
Here is the output:
Train on 390803 samples, validate on 43423 samples
Epoch 0
390803/390803 [==============================] - 1428s - loss: 2.5144 - val_loss: 2.1705
Epoch 00000: val_loss improved from inf to 2.17052, saving model to tmp/weights.hdf5
Epoch 1
78208/390803 [=====>........................] - ETA: 1135s - loss: 2.1143
RuntimeError Traceback (most recent call last)
in () 6 checkpointer = ModelCheckpoint(filepath="tmp/weights.hdf5", verbose=1, save_best_only=True) 7 ----> 8 model.fit(X_train, y_train, batch_size=128, nb_epoch=25, callbacks=[checkpointer,callnap], validation_data=(X_val, y_val)) /usr/local/lib/python2.7/site-packages/keras/models.pyc in fit(self, X, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, show_accuracy, class_weight, sample_weight) 411 metrics = ['loss', 'acc', 'val_loss', 'val_acc'] 412 return self._fit(f, ins, out_labels=out_labels, batch_size=batch_size, nb_epoch=nb_epoch, verbose=verbose, callbacks=callbacks, \ --> 413 validation_split=validation_split, val_f=val_f, val_ins=val_ins, shuffle=shuffle, metrics=metrics) 414 415 /usr/local/lib/python2.7/site-packages/keras/models.pyc in _fit(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, validation_split, val_f, val_ins, shuffle, metrics) 166 batch_logs['size'] = len(batch_ids) 167 callbacks.on_batch_begin(batch_index, batch_logs) --> 168 outs = f(*ins_batch) 169 if type(outs) != list: 170 outs = [outs] /usr/local/lib/python2.7/site-packages/theano/compile/function_module.pyc in call(self, _args, *_kwargs) 604 self.fn.nodes[self.fn.position_of_error], 605 self.fn.thunks[self.fn.position_of_error], --> 606 storage_map=self.fn.storage_map) 607 else: 608 # For the c linker We don't have access from /usr/local/lib/python2.7/site-packages/theano/compile/function_module.pyc in call(self, _args, *_kwargs) 593 t0_fn = time.time() 594 try: --> 595 outputs = self.fn() 596 except Exception: 597 if hasattr(self.fn, 'position_of_error'): /usr/local/lib/python2.7/site-packages/theano/scan_module/scan_op.pyc in rval(p, i, o, n, allow_gc) 670 def rval(p=p, i=node_input_storage, o=node_output_storage, n=node, 671 allow_gc=allow_gc): --> 672 r = p(n, [x[0] for x in i], o) 673 for o in node.outputs: 674 compute_map[o][0] = True /usr/local/lib/python2.7/site-packages/theano/scan_module/scan_op.pyc in (node, args, outs) 659 args, 660 outs, --> 661 self, node) 662 except (ImportError, theano.gof.cmodule.MissingGXX): 663 p = self.execute scan_perform.pyx in theano.scan_module.scan_perform.perform (/Users/AmirHJ/.theano/compiledir_Darwin-14.4.0-x86_64-i386-64bit-i386-2.7.10-64/scan_perform/mod.cpp:4206)() RuntimeError: CudaNdarray_ZEROS: allocation failed. Apply node that caused the error: forall_inplace,gpu,grad_of_scan_fn}(Elemwise{Composite{minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4)}}.0, GpuElemwise{mul,no_inplace}.0, GpuElemwise{mul,no_inplace}.0, GpuElemwise{tanh,no_inplace}.0, GpuDimShuffle{0,2,1}.0, GpuElemwise{Composite{(i0 - sqr(i1))},no_inplace}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, Subtensor{int64:int64:int64}.0, GpuSubtensor{::int64}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, Elemwise{Composite{minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4)}}.0, Elemwise{Composite{minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4)}}.0, Elemwise{Composite{minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4)}}.0, Elemwise{Composite{minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4)}}.0, <CudaNdarrayType(float32, matrix)>, <CudaNdarrayType(float32, matrix)>, <CudaNdarrayType(float32, matrix)>, <CudaNdarrayType(float32, matrix)>, GpuDimShuffle{1,0}.0, GpuDimShuffle{1,0}.0, GpuDimShuffle{1,0}.0, GpuDimShuffle{1,0}.0) Inputs types: [TensorType(int64, scalar), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), TensorType(int8, (False, False, True)), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)] Inputs shapes: [(), (20, 128, 512), (20, 128, 512), (20, 128, 512), (20, 512, 128), (20, 128, 512), (20, 128, 512), (20, 128, 512), (20, 128, 512), (20, 128, 512), (20, 128, 1), (21, 128, 512), (21, 128, 512), (1, 512, 512), (1, 512, 512), (1, 512, 512), (), (), (), (), (512, 512), (512, 512), (512, 512), (512, 512), (512, 512), (512, 512), (512, 512), (512, 512)] Inputs strides: [(), (65536, 512, 1), (65536, 512, 1), (65536, 512, 1), (65536, 1, 512), (65536, 512, 1), (-65536, 512, 1), (-65536, 512, 1), (-65536, 512, 1), (-65536, 512, 1), (-128, 1, 1), (-65536, 512, 1), (65536, 512, 1), (0, 512, 1), (0, 512, 1), (0, 512, 1), (), (), (), (), (512, 1), (512, 1), (512, 1), (512, 1), (1, 512), (1, 512), (1, 512), (1, 512)] Inputs values: [array(20), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', array(20), array(20), array(20), array(20), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown'] HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'. HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
6 checkpointer = ModelCheckpoint(filepath="tmp/weights.hdf5", verbose=1, save_best_only=True)
7
----> 8 model.fit(X_train, y_train, batch_size=128, nb_epoch=25, callbacks=[checkpointer,callnap], validation_data=(X_val, y_val))
/usr/local/lib/python2.7/site-packages/keras/models.pyc in fit(self, X, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, show_accuracy, class_weight, sample_weight) 411 metrics = ['loss', 'acc', 'val_loss', 'val_acc'] 412 return self._fit(f, ins, out_labels=out_labels, batch_size=batch_size, nb_epoch=nb_epoch, verbose=verbose, callbacks=callbacks, \ --> 413 validation_split=validation_split, val_f=val_f, val_ins=val_ins, shuffle=shuffle, metrics=metrics) 414 415 /usr/local/lib/python2.7/site-packages/keras/models.pyc in _fit(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, validation_split, val_f, val_ins, shuffle, metrics) 166 batch_logs['size'] = len(batch_ids) 167 callbacks.on_batch_begin(batch_index, batch_logs) --> 168 outs = f(*ins_batch) 169 if type(outs) != list: 170 outs = [outs] /usr/local/lib/python2.7/site-packages/theano/compile/function_module.pyc in call(self, _args, *_kwargs) 604 self.fn.nodes[self.fn.position_of_error], 605 self.fn.thunks[self.fn.position_of_error], --> 606 storage_map=self.fn.storage_map) 607 else: 608 # For the c linker We don't have access from /usr/local/lib/python2.7/site-packages/theano/compile/function_module.pyc in call(self, _args, *_kwargs) 593 t0_fn = time.time() 594 try: --> 595 outputs = self.fn() 596 except Exception: 597 if hasattr(self.fn, 'position_of_error'): /usr/local/lib/python2.7/site-packages/theano/scan_module/scan_op.pyc in rval(p, i, o, n, allow_gc) 670 def rval(p=p, i=node_input_storage, o=node_output_storage, n=node, 671 allow_gc=allow_gc): --> 672 r = p(n, [x[0] for x in i], o) 673 for o in node.outputs: 674 compute_map[o][0] = True /usr/local/lib/python2.7/site-packages/theano/scan_module/scan_op.pyc in (node, args, outs) 659 args, 660 outs, --> 661 self, node) 662 except (ImportError, theano.gof.cmodule.MissingGXX): 663 p = self.execute scan_perform.pyx in theano.scan_module.scan_perform.perform (/Users/AmirHJ/.theano/compiledir_Darwin-14.4.0-x86_64-i386-64bit-i386-2.7.10-64/scan_perform/mod.cpp:4206)() RuntimeError: CudaNdarray_ZEROS: allocation failed. Apply node that caused the error: forall_inplace,gpu,grad_of_scan_fn}(Elemwise{Composite{minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4)}}.0, GpuElemwise{mul,no_inplace}.0, GpuElemwise{mul,no_inplace}.0, GpuElemwise{tanh,no_inplace}.0, GpuDimShuffle{0,2,1}.0, GpuElemwise{Composite{(i0 - sqr(i1))},no_inplace}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, Subtensor{int64:int64:int64}.0, GpuSubtensor{::int64}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, Elemwise{Composite{minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4)}}.0, Elemwise{Composite{minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4)}}.0, Elemwise{Composite{minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4)}}.0, Elemwise{Composite{minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4)}}.0, <CudaNdarrayType(float32, matrix)>, <CudaNdarrayType(float32, matrix)>, <CudaNdarrayType(float32, matrix)>, <CudaNdarrayType(float32, matrix)>, GpuDimShuffle{1,0}.0, GpuDimShuffle{1,0}.0, GpuDimShuffle{1,0}.0, GpuDimShuffle{1,0}.0) Inputs types: [TensorType(int64, scalar), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), TensorType(int8, (False, False, True)), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)] Inputs shapes: [(), (20, 128, 512), (20, 128, 512), (20, 128, 512), (20, 512, 128), (20, 128, 512), (20, 128, 512), (20, 128, 512), (20, 128, 512), (20, 128, 512), (20, 128, 1), (21, 128, 512), (21, 128, 512), (1, 512, 512), (1, 512, 512), (1, 512, 512), (), (), (), (), (512, 512), (512, 512), (512, 512), (512, 512), (512, 512), (512, 512), (512, 512), (512, 512)] Inputs strides: [(), (65536, 512, 1), (65536, 512, 1), (65536, 512, 1), (65536, 1, 512), (65536, 512, 1), (-65536, 512, 1), (-65536, 512, 1), (-65536, 512, 1), (-65536, 512, 1), (-128, 1, 1), (-65536, 512, 1), (65536, 512, 1), (0, 512, 1), (0, 512, 1), (0, 512, 1), (), (), (), (), (512, 1), (512, 1), (512, 1), (512, 1), (1, 512), (1, 512), (1, 512), (1, 512)] Inputs values: [array(20), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', array(20), array(20), array(20), array(20), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown'] HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'. HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
411 metrics = ['loss', 'acc', 'val_loss', 'val_acc']
412 return self._fit(f, ins, out_labels=out_labels, batch_size=batch_size, nb_epoch=nb_epoch, verbose=verbose, callbacks=callbacks,
--> 413 validation_split=validation_split, val_f=val_f, val_ins=val_ins, shuffle=shuffle, metrics=metrics)
414
415
/usr/local/lib/python2.7/site-packages/keras/models.pyc in _fit(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, validation_split, val_f, val_ins, shuffle, metrics) 166 batch_logs['size'] = len(batch_ids) 167 callbacks.on_batch_begin(batch_index, batch_logs) --> 168 outs = f(*ins_batch) 169 if type(outs) != list: 170 outs = [outs] /usr/local/lib/python2.7/site-packages/theano/compile/function_module.pyc in call(self, _args, *_kwargs) 604 self.fn.nodes[self.fn.position_of_error], 605 self.fn.thunks[self.fn.position_of_error], --> 606 storage_map=self.fn.storage_map) 607 else: 608 # For the c linker We don't have access from /usr/local/lib/python2.7/site-packages/theano/compile/function_module.pyc in call(self, _args, *_kwargs) 593 t0_fn = time.time() 594 try: --> 595 outputs = self.fn() 596 except Exception: 597 if hasattr(self.fn, 'position_of_error'): /usr/local/lib/python2.7/site-packages/theano/scan_module/scan_op.pyc in rval(p, i, o, n, allow_gc) 670 def rval(p=p, i=node_input_storage, o=node_output_storage, n=node, 671 allow_gc=allow_gc): --> 672 r = p(n, [x[0] for x in i], o) 673 for o in node.outputs: 674 compute_map[o][0] = True /usr/local/lib/python2.7/site-packages/theano/scan_module/scan_op.pyc in (node, args, outs) 659 args, 660 outs, --> 661 self, node) 662 except (ImportError, theano.gof.cmodule.MissingGXX): 663 p = self.execute scan_perform.pyx in theano.scan_module.scan_perform.perform (/Users/AmirHJ/.theano/compiledir_Darwin-14.4.0-x86_64-i386-64bit-i386-2.7.10-64/scan_perform/mod.cpp:4206)() RuntimeError: CudaNdarray_ZEROS: allocation failed. Apply node that caused the error: forall_inplace,gpu,grad_of_scan_fn}(Elemwise{Composite{minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4)}}.0, GpuElemwise{mul,no_inplace}.0, GpuElemwise{mul,no_inplace}.0, GpuElemwise{tanh,no_inplace}.0, GpuDimShuffle{0,2,1}.0, GpuElemwise{Composite{(i0 - sqr(i1))},no_inplace}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, Subtensor{int64:int64:int64}.0, GpuSubtensor{::int64}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, Elemwise{Composite{minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4)}}.0, Elemwise{Composite{minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4)}}.0, Elemwise{Composite{minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4)}}.0, Elemwise{Composite{minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4)}}.0, <CudaNdarrayType(float32, matrix)>, <CudaNdarrayType(float32, matrix)>, <CudaNdarrayType(float32, matrix)>, <CudaNdarrayType(float32, matrix)>, GpuDimShuffle{1,0}.0, GpuDimShuffle{1,0}.0, GpuDimShuffle{1,0}.0, GpuDimShuffle{1,0}.0) Inputs types: [TensorType(int64, scalar), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), TensorType(int8, (False, False, True)), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)] Inputs shapes: [(), (20, 128, 512), (20, 128, 512), (20, 128, 512), (20, 512, 128), (20, 128, 512), (20, 128, 512), (20, 128, 512), (20, 128, 512), (20, 128, 512), (20, 128, 1), (21, 128, 512), (21, 128, 512), (1, 512, 512), (1, 512, 512), (1, 512, 512), (), (), (), (), (512, 512), (512, 512), (512, 512), (512, 512), (512, 512), (512, 512), (512, 512), (512, 512)] Inputs strides: [(), (65536, 512, 1), (65536, 512, 1), (65536, 512, 1), (65536, 1, 512), (65536, 512, 1), (-65536, 512, 1), (-65536, 512, 1), (-65536, 512, 1), (-65536, 512, 1), (-128, 1, 1), (-65536, 512, 1), (65536, 512, 1), (0, 512, 1), (0, 512, 1), (0, 512, 1), (), (), (), (), (512, 1), (512, 1), (512, 1), (512, 1), (1, 512), (1, 512), (1, 512), (1, 512)] Inputs values: [array(20), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', array(20), array(20), array(20), array(20), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown'] HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'. HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
166 batch_logs['size'] = len(batch_ids)
167 callbacks.on_batch_begin(batch_index, batch_logs)
--> 168 outs = f(_ins_batch)
169 if type(outs) != list:
170 outs = [outs]
/usr/local/lib/python2.7/site-packages/theano/compile/function_module.pyc in call(self, *args, *_kwargs) 604 self.fn.nodes[self.fn.position_of_error], 605 self.fn.thunks[self.fn.position_of_error], --> 606 storage_map=self.fn.storage_map) 607 else: 608 # For the c linker We don't have access from /usr/local/lib/python2.7/site-packages/theano/compile/function_module.pyc in call(self, _args, *_kwargs) 593 t0_fn = time.time() 594 try: --> 595 outputs = self.fn() 596 except Exception: 597 if hasattr(self.fn, 'position_of_error'): /usr/local/lib/python2.7/site-packages/theano/scan_module/scan_op.pyc in rval(p, i, o, n, allow_gc) 670 def rval(p=p, i=node_input_storage, o=node_output_storage, n=node, 671 allow_gc=allow_gc): --> 672 r = p(n, [x[0] for x in i], o) 673 for o in node.outputs: 674 compute_map[o][0] = True /usr/local/lib/python2.7/site-packages/theano/scan_module/scan_op.pyc in (node, args, outs) 659 args, 660 outs, --> 661 self, node) 662 except (ImportError, theano.gof.cmodule.MissingGXX): 663 p = self.execute scan_perform.pyx in theano.scan_module.scan_perform.perform (/Users/AmirHJ/.theano/compiledir_Darwin-14.4.0-x86_64-i386-64bit-i386-2.7.10-64/scan_perform/mod.cpp:4206)() RuntimeError: CudaNdarray_ZEROS: allocation failed. Apply node that caused the error: forall_inplace,gpu,grad_of_scan_fn}(Elemwise{Composite{minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4)}}.0, GpuElemwise{mul,no_inplace}.0, GpuElemwise{mul,no_inplace}.0, GpuElemwise{tanh,no_inplace}.0, GpuDimShuffle{0,2,1}.0, GpuElemwise{Composite{(i0 - sqr(i1))},no_inplace}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, Subtensor{int64:int64:int64}.0, GpuSubtensor{::int64}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, Elemwise{Composite{minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4)}}.0, Elemwise{Composite{minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4)}}.0, Elemwise{Composite{minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4)}}.0, Elemwise{Composite{minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4)}}.0, <CudaNdarrayType(float32, matrix)>, <CudaNdarrayType(float32, matrix)>, <CudaNdarrayType(float32, matrix)>, <CudaNdarrayType(float32, matrix)>, GpuDimShuffle{1,0}.0, GpuDimShuffle{1,0}.0, GpuDimShuffle{1,0}.0, GpuDimShuffle{1,0}.0) Inputs types: [TensorType(int64, scalar), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), TensorType(int8, (False, False, True)), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)] Inputs shapes: [(), (20, 128, 512), (20, 128, 512), (20, 128, 512), (20, 512, 128), (20, 128, 512), (20, 128, 512), (20, 128, 512), (20, 128, 512), (20, 128, 512), (20, 128, 1), (21, 128, 512), (21, 128, 512), (1, 512, 512), (1, 512, 512), (1, 512, 512), (), (), (), (), (512, 512), (512, 512), (512, 512), (512, 512), (512, 512), (512, 512), (512, 512), (512, 512)] Inputs strides: [(), (65536, 512, 1), (65536, 512, 1), (65536, 512, 1), (65536, 1, 512), (65536, 512, 1), (-65536, 512, 1), (-65536, 512, 1), (-65536, 512, 1), (-65536, 512, 1), (-128, 1, 1), (-65536, 512, 1), (65536, 512, 1), (0, 512, 1), (0, 512, 1), (0, 512, 1), (), (), (), (), (512, 1), (512, 1), (512, 1), (512, 1), (1, 512), (1, 512), (1, 512), (1, 512)] Inputs values: [array(20), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', array(20), array(20), array(20), array(20), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown'] HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'. HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
604 self.fn.nodes[self.fn.position_of_error],
605 self.fn.thunks[self.fn.position_of_error],
--> 606 storage_map=self.fn.storage_map)
607 else:
608 # For the c linker We don't have access from
/usr/local/lib/python2.7/site-packages/theano/compile/function_module.pyc in call(self, _args, *_kwargs) 593 t0_fn = time.time() 594 try: --> 595 outputs = self.fn() 596 except Exception: 597 if hasattr(self.fn, 'position_of_error'): /usr/local/lib/python2.7/site-packages/theano/scan_module/scan_op.pyc in rval(p, i, o, n, allow_gc) 670 def rval(p=p, i=node_input_storage, o=node_output_storage, n=node, 671 allow_gc=allow_gc): --> 672 r = p(n, [x[0] for x in i], o) 673 for o in node.outputs: 674 compute_map[o][0] = True /usr/local/lib/python2.7/site-packages/theano/scan_module/scan_op.pyc in (node, args, outs) 659 args, 660 outs, --> 661 self, node) 662 except (ImportError, theano.gof.cmodule.MissingGXX): 663 p = self.execute scan_perform.pyx in theano.scan_module.scan_perform.perform (/Users/AmirHJ/.theano/compiledir_Darwin-14.4.0-x86_64-i386-64bit-i386-2.7.10-64/scan_perform/mod.cpp:4206)() RuntimeError: CudaNdarray_ZEROS: allocation failed. Apply node that caused the error: forall_inplace,gpu,grad_of_scan_fn}(Elemwise{Composite{minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4)}}.0, GpuElemwise{mul,no_inplace}.0, GpuElemwise{mul,no_inplace}.0, GpuElemwise{tanh,no_inplace}.0, GpuDimShuffle{0,2,1}.0, GpuElemwise{Composite{(i0 - sqr(i1))},no_inplace}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, Subtensor{int64:int64:int64}.0, GpuSubtensor{::int64}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, Elemwise{Composite{minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4)}}.0, Elemwise{Composite{minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4)}}.0, Elemwise{Composite{minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4)}}.0, Elemwise{Composite{minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4)}}.0, <CudaNdarrayType(float32, matrix)>, <CudaNdarrayType(float32, matrix)>, <CudaNdarrayType(float32, matrix)>, <CudaNdarrayType(float32, matrix)>, GpuDimShuffle{1,0}.0, GpuDimShuffle{1,0}.0, GpuDimShuffle{1,0}.0, GpuDimShuffle{1,0}.0) Inputs types: [TensorType(int64, scalar), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), TensorType(int8, (False, False, True)), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)] Inputs shapes: [(), (20, 128, 512), (20, 128, 512), (20, 128, 512), (20, 512, 128), (20, 128, 512), (20, 128, 512), (20, 128, 512), (20, 128, 512), (20, 128, 512), (20, 128, 1), (21, 128, 512), (21, 128, 512), (1, 512, 512), (1, 512, 512), (1, 512, 512), (), (), (), (), (512, 512), (512, 512), (512, 512), (512, 512), (512, 512), (512, 512), (512, 512), (512, 512)] Inputs strides: [(), (65536, 512, 1), (65536, 512, 1), (65536, 512, 1), (65536, 1, 512), (65536, 512, 1), (-65536, 512, 1), (-65536, 512, 1), (-65536, 512, 1), (-65536, 512, 1), (-128, 1, 1), (-65536, 512, 1), (65536, 512, 1), (0, 512, 1), (0, 512, 1), (0, 512, 1), (), (), (), (), (512, 1), (512, 1), (512, 1), (512, 1), (1, 512), (1, 512), (1, 512), (1, 512)] Inputs values: [array(20), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', array(20), array(20), array(20), array(20), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown'] HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'. HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
593 t0_fn = time.time()
594 try:
--> 595 outputs = self.fn()
596 except Exception:
597 if hasattr(self.fn, 'position_of_error'):
/usr/local/lib/python2.7/site-packages/theano/scan_module/scan_op.pyc in rval(p, i, o, n, allow_gc) 670 def rval(p=p, i=node_input_storage, o=node_output_storage, n=node, 671 allow_gc=allow_gc): --> 672 r = p(n, [x[0] for x in i], o) 673 for o in node.outputs: 674 compute_map[o][0] = True /usr/local/lib/python2.7/site-packages/theano/scan_module/scan_op.pyc in (node, args, outs) 659 args, 660 outs, --> 661 self, node) 662 except (ImportError, theano.gof.cmodule.MissingGXX): 663 p = self.execute scan_perform.pyx in theano.scan_module.scan_perform.perform (/Users/AmirHJ/.theano/compiledir_Darwin-14.4.0-x86_64-i386-64bit-i386-2.7.10-64/scan_perform/mod.cpp:4206)() RuntimeError: CudaNdarray_ZEROS: allocation failed. Apply node that caused the error: forall_inplace,gpu,grad_of_scan_fn}(Elemwise{Composite{minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4)}}.0, GpuElemwise{mul,no_inplace}.0, GpuElemwise{mul,no_inplace}.0, GpuElemwise{tanh,no_inplace}.0, GpuDimShuffle{0,2,1}.0, GpuElemwise{Composite{(i0 - sqr(i1))},no_inplace}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, Subtensor{int64:int64:int64}.0, GpuSubtensor{::int64}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, Elemwise{Composite{minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4)}}.0, Elemwise{Composite{minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4)}}.0, Elemwise{Composite{minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4)}}.0, Elemwise{Composite{minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4)}}.0, <CudaNdarrayType(float32, matrix)>, <CudaNdarrayType(float32, matrix)>, <CudaNdarrayType(float32, matrix)>, <CudaNdarrayType(float32, matrix)>, GpuDimShuffle{1,0}.0, GpuDimShuffle{1,0}.0, GpuDimShuffle{1,0}.0, GpuDimShuffle{1,0}.0) Inputs types: [TensorType(int64, scalar), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), TensorType(int8, (False, False, True)), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)] Inputs shapes: [(), (20, 128, 512), (20, 128, 512), (20, 128, 512), (20, 512, 128), (20, 128, 512), (20, 128, 512), (20, 128, 512), (20, 128, 512), (20, 128, 512), (20, 128, 1), (21, 128, 512), (21, 128, 512), (1, 512, 512), (1, 512, 512), (1, 512, 512), (), (), (), (), (512, 512), (512, 512), (512, 512), (512, 512), (512, 512), (512, 512), (512, 512), (512, 512)] Inputs strides: [(), (65536, 512, 1), (65536, 512, 1), (65536, 512, 1), (65536, 1, 512), (65536, 512, 1), (-65536, 512, 1), (-65536, 512, 1), (-65536, 512, 1), (-65536, 512, 1), (-128, 1, 1), (-65536, 512, 1), (65536, 512, 1), (0, 512, 1), (0, 512, 1), (0, 512, 1), (), (), (), (), (512, 1), (512, 1), (512, 1), (512, 1), (1, 512), (1, 512), (1, 512), (1, 512)] Inputs values: [array(20), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', array(20), array(20), array(20), array(20), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown'] HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'. HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
670 def rval(p=p, i=node_input_storage, o=node_output_storage, n=node,
671 allow_gc=allow_gc):
--> 672 r = p(n, [x[0] for x in i], o)
673 for o in node.outputs:
674 compute_map[o][0] = True
/usr/local/lib/python2.7/site-packages/theano/scan_module/scan_op.pyc in (node, args, outs) 659 args, 660 outs, --> 661 self, node) 662 except (ImportError, theano.gof.cmodule.MissingGXX): 663 p = self.execute scan_perform.pyx in theano.scan_module.scan_perform.perform (/Users/AmirHJ/.theano/compiledir_Darwin-14.4.0-x86_64-i386-64bit-i386-2.7.10-64/scan_perform/mod.cpp:4206)() RuntimeError: CudaNdarray_ZEROS: allocation failed. Apply node that caused the error: forall_inplace,gpu,grad_of_scan_fn}(Elemwise{Composite{minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4)}}.0, GpuElemwise{mul,no_inplace}.0, GpuElemwise{mul,no_inplace}.0, GpuElemwise{tanh,no_inplace}.0, GpuDimShuffle{0,2,1}.0, GpuElemwise{Composite{(i0 - sqr(i1))},no_inplace}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, Subtensor{int64:int64:int64}.0, GpuSubtensor{::int64}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, Elemwise{Composite{minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4)}}.0, Elemwise{Composite{minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4)}}.0, Elemwise{Composite{minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4)}}.0, Elemwise{Composite{minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4)}}.0, <CudaNdarrayType(float32, matrix)>, <CudaNdarrayType(float32, matrix)>, <CudaNdarrayType(float32, matrix)>, <CudaNdarrayType(float32, matrix)>, GpuDimShuffle{1,0}.0, GpuDimShuffle{1,0}.0, GpuDimShuffle{1,0}.0, GpuDimShuffle{1,0}.0) Inputs types: [TensorType(int64, scalar), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), TensorType(int8, (False, False, True)), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)] Inputs shapes: [(), (20, 128, 512), (20, 128, 512), (20, 128, 512), (20, 512, 128), (20, 128, 512), (20, 128, 512), (20, 128, 512), (20, 128, 512), (20, 128, 512), (20, 128, 1), (21, 128, 512), (21, 128, 512), (1, 512, 512), (1, 512, 512), (1, 512, 512), (), (), (), (), (512, 512), (512, 512), (512, 512), (512, 512), (512, 512), (512, 512), (512, 512), (512, 512)] Inputs strides: [(), (65536, 512, 1), (65536, 512, 1), (65536, 512, 1), (65536, 1, 512), (65536, 512, 1), (-65536, 512, 1), (-65536, 512, 1), (-65536, 512, 1), (-65536, 512, 1), (-128, 1, 1), (-65536, 512, 1), (65536, 512, 1), (0, 512, 1), (0, 512, 1), (0, 512, 1), (), (), (), (), (512, 1), (512, 1), (512, 1), (512, 1), (1, 512), (1, 512), (1, 512), (1, 512)] Inputs values: [array(20), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', array(20), array(20), array(20), array(20), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown'] HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'. HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
659 args,
660 outs,
--> 661 self, node)
662 except (ImportError, theano.gof.cmodule.MissingGXX):
663 p = self.execute
scan_perform.pyx in theano.scan_module.scan_perform.perform (/Users/AmirHJ/.theano/compiledir_Darwin-14.4.0-x86_64-i386-64bit-i386-2.7.10-64/scan_perform/mod.cpp:4206)() RuntimeError: CudaNdarray_ZEROS: allocation failed. Apply node that caused the error: forall_inplace,gpu,grad_of_scan_fn}(Elemwise{Composite{minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4)}}.0, GpuElemwise{mul,no_inplace}.0, GpuElemwise{mul,no_inplace}.0, GpuElemwise{tanh,no_inplace}.0, GpuDimShuffle{0,2,1}.0, GpuElemwise{Composite{(i0 - sqr(i1))},no_inplace}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, Subtensor{int64:int64:int64}.0, GpuSubtensor{::int64}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, Elemwise{Composite{minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4)}}.0, Elemwise{Composite{minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4)}}.0, Elemwise{Composite{minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4)}}.0, Elemwise{Composite{minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4)}}.0, <CudaNdarrayType(float32, matrix)>, <CudaNdarrayType(float32, matrix)>, <CudaNdarrayType(float32, matrix)>, <CudaNdarrayType(float32, matrix)>, GpuDimShuffle{1,0}.0, GpuDimShuffle{1,0}.0, GpuDimShuffle{1,0}.0, GpuDimShuffle{1,0}.0) Inputs types: [TensorType(int64, scalar), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), TensorType(int8, (False, False, True)), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)] Inputs shapes: [(), (20, 128, 512), (20, 128, 512), (20, 128, 512), (20, 512, 128), (20, 128, 512), (20, 128, 512), (20, 128, 512), (20, 128, 512), (20, 128, 512), (20, 128, 1), (21, 128, 512), (21, 128, 512), (1, 512, 512), (1, 512, 512), (1, 512, 512), (), (), (), (), (512, 512), (512, 512), (512, 512), (512, 512), (512, 512), (512, 512), (512, 512), (512, 512)] Inputs strides: [(), (65536, 512, 1), (65536, 512, 1), (65536, 512, 1), (65536, 1, 512), (65536, 512, 1), (-65536, 512, 1), (-65536, 512, 1), (-65536, 512, 1), (-65536, 512, 1), (-128, 1, 1), (-65536, 512, 1), (65536, 512, 1), (0, 512, 1), (0, 512, 1), (0, 512, 1), (), (), (), (), (512, 1), (512, 1), (512, 1), (512, 1), (1, 512), (1, 512), (1, 512), (1, 512)] Inputs values: [array(20), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', array(20), array(20), array(20), array(20), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown'] HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'. HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
RuntimeError: CudaNdarray_ZEROS: allocation failed.
Apply node that caused the error: forall_inplace,gpu,grad_of_scan_fn}(Elemwise{Composite{minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4)}}.0, GpuElemwise{mul,no_inplace}.0, GpuElemwise{mul,no_inplace}.0, GpuElemwise{tanh,no_inplace}.0, GpuDimShuffle{0,2,1}.0, GpuElemwise{Composite{(i0 - sqr(i1))},no_inplace}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, Subtensor{int64:int64:int64}.0, GpuSubtensor{::int64}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, Elemwise{Composite{minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4)}}.0, Elemwise{Composite{minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4)}}.0, Elemwise{Composite{minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4)}}.0, Elemwise{Composite{minimum(minimum(minimum(minimum(i0, i1), i2), i3), i4)}}.0, <CudaNdarrayType(float32, matrix)>, <CudaNdarrayType(float32, matrix)>, <CudaNdarrayType(float32, matrix)>, <CudaNdarrayType(float32, matrix)>, GpuDimShuffle{1,0}.0, GpuDimShuffle{1,0}.0, GpuDimShuffle{1,0}.0, GpuDimShuffle{1,0}.0)
Inputs types: [TensorType(int64, scalar), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), TensorType(int8, (False, False, True)), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)]
Inputs shapes: [(), (20, 128, 512), (20, 128, 512), (20, 128, 512), (20, 512, 128), (20, 128, 512), (20, 128, 512), (20, 128, 512), (20, 128, 512), (20, 128, 512), (20, 128, 1), (21, 128, 512), (21, 128, 512), (1, 512, 512), (1, 512, 512), (1, 512, 512), (), (), (), (), (512, 512), (512, 512), (512, 512), (512, 512), (512, 512), (512, 512), (512, 512), (512, 512)]
Inputs strides: [(), (65536, 512, 1), (65536, 512, 1), (65536, 512, 1), (65536, 1, 512), (65536, 512, 1), (-65536, 512, 1), (-65536, 512, 1), (-65536, 512, 1), (-65536, 512, 1), (-128, 1, 1), (-65536, 512, 1), (65536, 512, 1), (0, 512, 1), (0, 512, 1), (0, 512, 1), (), (), (), (), (512, 1), (512, 1), (512, 1), (512, 1), (1, 512), (1, 512), (1, 512), (1, 512)]
Inputs values: [array(20), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', array(20), array(20), array(20), array(20), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown']
HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
Please note that this is a occasionally exception. So I think it may be important for Keras developers.
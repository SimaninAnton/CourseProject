bkj commented on 30 Oct 2015
For fun and practice, I'm trying to construct a network that can reproduce the behavior of the Luhn Checksum (https://en.wikipedia.org/wiki/Luhn_algorithm), which is an error-correcting code for validating credit card numbers. I was wondering if anyone could suggest an architecture that is flexible enough to model the behavior.
Here's how I'm generating the training data:
from pprint import pprint
from random import shuffle
from faker import Factory
fake = Factory.create()


# Run the Luhn Checksum on a credit card number
def cardLuhnChecksumIsValid(card_number):
    """ checks to make sure that the card passes a luhn mod-10 checksum """

    sum = 0
    num_digits = len(card_number)
    oddeven = num_digits & 1

    for count in range(0, num_digits):
        digit = int(card_number[count])

        if not (( count & 1 ) ^ oddeven ):
            digit = digit * 2
        if digit > 9:
            digit = digit - 9

        sum = sum + digit

    return ( (sum % 10) == 0 )


# Change one digit of the credit card number by 1
# This is guaranteed to corrupt a valid credit card number
def alter(x):
    return str(int(x) + 10 ** np.random.choice(range(8)))

K = 10000

X = [str(fake.credit_card_number()) for i in range(K)] + [alter(fake.credit_card_number()) for i in range(K)]
shuffle(X)
Y = map(cardLuhnChecksumIsValid, X)

pprint(X[0:5])
'''
['3112871329791258',
 '3158896578325611',
 '4392681270152917',
 '6011989628511339',
 '869986969145200']
 '''

pprint(Y[0:5])
''' [False, True, False, True, False] '''
Any advice would be much appreciated -- I'm trying to get a feel for what different architectures are designed for. I had tried breaking the strings into lists of ints, padding all to length 16, then using
model = Sequential()
model.add(Embedding(10, 128, input_length=16))
model.add(LSTM(128))
model.add(Dense(1))
model.add(Activation('sigmoid'))
model.compile(loss='binary_crossentropy', optimizer='adam', class_mode="binary")
but this didn't work particularly well.
Thanks!
Ben
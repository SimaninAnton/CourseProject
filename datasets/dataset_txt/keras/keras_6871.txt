ghost commented on 8 Jul 2015
Hi all,
So, the following snippet works fine with mean squared error as objective:
from keras.models import Sequential
from keras.layers.core import Dense, Activation
from keras.layers.recurrent import LSTM
from keras.optimizers import Adagrad

model = Sequential()
model.add(LSTM(2, 10, return_sequences=True))
model.add(Dense(10, 2))
model.add(Activation('sigmoid'))

opt = Adagrad()
model.compile(loss='mse', optimizer=opt)
However, if I replace the mse by binary cross entropy:
from keras.models import Sequential
from keras.layers.core import Dense, Activation
from keras.layers.recurrent import LSTM
from keras.optimizers import Adagrad

model = Sequential()
model.add(LSTM(2, 10, return_sequences=True))
model.add(Dense(10, 2))
model.add(Activation('sigmoid'))

opt = Adagrad()
model.compile(loss='binary_crossentropy', optimizer=opt)
It raises the following error when I try to do:
print np.shape(X)
>>> (1, 4, 2)

print np.shape(Y)
>>> (1, 4, 2)

model.train_on_batch(X,Y)
>>> ValueError: Input dimension mis-match. (input[0].shape[0] = 4, input[1].shape[0] = 8)
On the other hand, if I make a prediction and I compute the binary cross entropy directly with theano, it works properly:
yy = T.tensor3()
tt = T.tensor3()
get_bce_t = theano.function([yy, tt], T.nnet.binary_crossentropy(yy,tt).mean())
get_bce_t(model.predict(X).astype(np.float32), Y.astype(np.float32))
kris-mlguy commented on 28 Jun 2018 â€¢
edited
Trying to create a custom loss function, which includes saving updated model weights, subprocess calls and numpy operations based on the updated weights after training of every batch. The loss function is defined as given below:
def process():
model.save("path to updated weights' .hdf5 file")
subprocess.call(["path to .py code which writes weights into .c code",
"path to updated weights' .hdf5 file", "path to .c code",
"path to header file of .c code"])
subprocess.call(["cd", "path to project directory"])
subprocess.call(["make", "clean", "&", "make"])
subprocess.call(["path to executable that converts input pcm file to output pcm file based on updated weights", "path to input file","path to output file"])
data1 = np.memmap("path to output pcm file", dtype = 'h', mode = 'r')
data2 = np.memmap("path to reference pcm file", dtype = 'h', mode = 'r')
return data1, data2
def myloss(y_true, y_pred):
d, c = process()
return K.mean(K.square(d - c))
This causes the code to keep building the model as below:
/home//.local/lib/python2.7/site-packages/h5py/init.py:36: FutureWarning: Conversion of the second argument of issubdtype from float to np.floating is deprecated. In future, it will be treated as np.float64 == np.dtype(float).type.
from ._conv import register_converters as _register_converters
Using TensorFlow backend.
Build model...
2018-06-27 23:11:45.873601: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
/home//.local/lib/python2.7/site-packages/h5py/init.py:36: FutureWarning: Conversion of the second argument of issubdtype from float to np.floating is deprecated. In future, it will be treated as np.float64 == np.dtype(float).type.
from ._conv import register_converters as _register_converters
Using TensorFlow backend.
Build model...
2018-06-27 23:11:47.195850: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary wacustom loss functions not compiled to use: AVX2 FMA
/home//.local/lib/python2.7/site-packages/h5py/init.py:36: FutureWarning: Conversion of the second argument of issubdtype from float to np.floating is deprecated. In future, it will be treated as np.float64 == np.dtype(float).type.
from ._conv import register_converters as _register_converters
Using TensorFlow backend.
Read elsewhere that Keras loss functions accommodate only tensor/theano/CNTK operations and typically take only y_true and y_pred as arguments. Is there still a workaround to save model weights, make subprocess calls and perform numpy operations within the loss function ? Appreciate your help.
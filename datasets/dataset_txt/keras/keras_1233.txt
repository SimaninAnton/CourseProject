DeepWolf90 commented on 19 Feb 2018 â€¢
edited
I'm working on LSTM-based stacked autoencoder. i trained it by using layerwise pre-training approach, Now I'm in the fine-tuning phase, when i loaded the saved encoders and sets their weights to the full stacked model, i didn't get reproducible results.
Here is my fine-tuning phase code:
# load encoders layers

layer1 = load_model('encoder1_stateful.h5')
layer2 = load_model('encoder2_stateful.h5')

# rename layer2 
layer2.name = 'model_3'


# get LSTM layers from trained encoders
l1 = layer1.get_layer('lstm_1')
l2 = layer2.get_layer('lstm_1')


# get weights from LSTM layers
weights_l1 = l1.get_weights()
weights_l2 = l2.get_weights()


# # built forecasting model
timesteps = x_train.shape[1]
input_dim = x_train.shape[2]
inputs = Input(batch_shape=(1,timesteps, input_dim))
lstm_1 = LSTM(19,name='lstm_19',stateful = True)(inputs)
dropout1 = Dropout(droupout_rate)(lstm_1)
reshape = Reshape((1,19))(dropout1)
lstm_2 = LSTM(13,name='lstm_13',stateful = True)(reshape)
dropout2 = Dropout(droupout_rate)(lstm_2)
outputs = Dense(1)(dropout2)

model = Model(inputs,outputs)


#set weights of previously trained LSTMs to new model

z1 = model.get_layer('lstm_19')
z1.set_weights(weights_l1)

z2 = model.get_layer('lstm_13')
z2.set_weights(weights_l2)





model.compile(loss='mean_squared_error', optimizer='Adam')


for i in range(num_epochs):
 print('Epoch:',i+1)
 model.fit(x_train, y_train, epochs=1, batch_size=1, verbose=1,shuffle=False)
 model.reset_states()
Did i do something wrong, especially in setting weights?
NOTE: when i comment the part of setting weights, i get reproducible results....
ntungare commented on 20 Oct 2016
I tried to run a model on GTX 950 with Cuda 8 and CuDNN 5.0, not sure if there is a possible memory issue with the different ways to initializing a model.
Original code:
https://github.com/fchollet/keras/blob/master/examples/pretrained_word_embeddings.py
Edit made:
Changed model into Sequential and added the layer to it rather than create it like the queue mentioned in the original file.
Issue encountered:
Original code capable to running on the GPU without any issues.
When model is made into a queue and then compiled it runs out of memory.
Not sure if a sequential model is supposed to occupy more space on GPU or if its a possible memory issue.
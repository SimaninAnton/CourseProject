GratefulTony commented on 10 Feb 2016
I have seen this use case a few times in the issues here, but can't quite seem to get it working:
Simply, I have a dataset of pairs of co-occurring indices, and want to learn embeddings for them based on their co-occurrence.
I plan to feed the model two n_samp*1-d input vectors as follows:
...(and learn the embeddings using an autoencoder)...
src_model = Sequential()
src_model.add(Embedding(collapse_dim, embedding_size, input_length=1))
dst_model = Sequential()
dst_model.add(Embedding(collapse_dim, embedding_size, input_length=1))
It would seem to me here, that the output dims of each of the embedding layers are simply embedding_size...
Then I would expect after concat-merging them, my output dim would be 2*embedding_size?
encoder = Sequential()
encoder.add(Merge([src_model, dst_model], mode='concat'))
encoder.add(Dense(3*embedding_size, init='uniform'))
encoder.add(Activation('relu'))
This is where my code breaks... The library is having a tough time appending the dense layer onto the back of the merged embedding layers.
AssertionError: Incompatible shapes: layer expected input with ndim=2 but previous layer has output_shape (None, 1, 128)
There's probably something obvious I'm missing here-- but would appreciate a push in the right direction...
Anyway, for color, here's the rest of the plan...
decoder = Sequential([Dense(input_dim=3*embedding_size, output_dim=2*embedding_size, init='uniform')])

autoencoder = AutoEncoder(encoder=encoder, decoder=decoder, output_reconstruction=True)

model = Sequential()
model.add(autoencoder)
Thanks in advance to any of you fine folks who can help me out here.
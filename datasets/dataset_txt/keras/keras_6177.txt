matudor commented on 2 Jan 2016
I'm working my way toward implementing an adaptation of the MemNN architecture in the example. Unfortunately I've had a setback early on.
The following example uses a toy model acting as an autoenocder, same data is fed in as integer lists to input and as 3D one-hot targets.
    model1 = Sequential()
    model1.add(Embedding(input_dim=numtokens+1,output_dim=10,input_length=maxtokencount))

    model2 = Sequential()
    model2.add(Embedding(input_dim=numtokens+1,output_dim=10,input_length=maxtokencount))

    model = Sequential()
    model.add(Merge([model1,model2],mode='dot',dot_axes=[(2,),(2,)])) 
    model.add(TimeDistributedDense(numtokens,activation='sigmoid'))
    optim=Adam(lr=0.01,clipnorm=1)
    model.compile(loss='binary_crossentropy', class_mode='binary', optimizer=optim)
this fails during fitting with:
  File "/Users/tudor/pyenvs/keras/lib/python2.7/site-packages/keras/models.py", line 581, in fit
    shuffle=shuffle, metrics=metrics)
  File "/Users/tudor/pyenvs/keras/lib/python2.7/site-packages/keras/models.py", line 239, in _fit
    outs = f(ins_batch)
  File "/Users/tudor/pyenvs/keras/lib/python2.7/site-packages/keras/backend/theano_backend.py", line 365, in __call__
    return self.function(*inputs)
  File "/Users/tudor/pyenvs/keras/lib/python2.7/site-packages/theano/compile/function_module.py", line 779, in __call__
    allow_downcast=s.allow_downcast)
  File "/Users/tudor/pyenvs/keras/lib/python2.7/site-packages/theano/tensor/type.py", line 177, in filter
    data.shape))
TypeError: ('Bad input argument to theano function with name "/Users/tudor/pyenvs/keras/lib/python2.7/site-packages/keras/backend/theano_backend.py:362"  at index 1(0-based)', 'Wrong number of dimensions: expected 2, got 3 with shape (64, 500, 55).')
But somewhat surprisingly, the following does not:
    model1 = Sequential()
    model1.add(Embedding(input_dim=numtokens+1,output_dim=10,input_length=maxtokencount))

    model = Sequential()
    model.add(Merge([model1,model1],mode='dot',dot_axes=[(2,),(2,)])) 
    model.add(TimeDistributedDense(numtokens,activation='sigmoid'))
    optim=Adam(lr=0.01,clipnorm=1)
    model.compile(loss='binary_crossentropy', class_mode='binary', optimizer=optim)
(i.e. merging layer with itself works but merging two identically defined layers does not).
The error train above notwithstanding, it seems to me that this is related to the Merge layer, but I'm having trouble narrowing down the source of the issue.
Anyone ever seen something like this? Any suggestions?
Cheers,
-M
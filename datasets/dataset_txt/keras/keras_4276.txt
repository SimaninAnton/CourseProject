ShuaiW commented on 30 Sep 2016 â€¢
edited
Been following some related threads, such as #395, #2654, and #2403, but still cannot sort out how to get it to work. The Keras API doc is already very dated so it's not very helpful for this issue.
So I want to use a pretrained word2vec word presentation + Keras LSTM to do POS tagging.
My first question is: is there a better way to feed in the pretrained vector presentation than the embedding_weights method mentioned at #853?
Say we embed using the method mentioned in #853, and get a (M+2) by N embedding matrix. We also pad the variable-length sentences. Then we have
X_pad.shape = (M, N)
y_pad.shape = (M, N)
where M is the number of sentences in the corpus (in my case 18421), and N is padded sentence length (originals vary from 15-140 so in this case N=140)
Here is how I initialized the model
  model = Sequential()

  # first embedding layer
  model.add(Embedding(input_dim=vocab_size, output_dim=embed_size, input_length=N, mask_zero=True, weights=[embedding_matrix]))

  # hidden layer
  model.add(LSTM(output_dim=hidden_dim, return_sequences=True))

  # output layer
  model.add(TimeDistributed(Dense(num_class, activation='softmax')))

  # compile
  model.compile(loss='categorical_crossentropy', optimizer='adam')
When I run model.fit(X_pad, y_pad), I got this error:
Exception: Error when checking model target: expected timedistributed_1 to have 3 dimensions, but got array with shape (18421, 140)
Been stuck here for a while. Any suggestion is appreciated!
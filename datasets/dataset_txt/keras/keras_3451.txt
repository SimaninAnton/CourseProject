buaaliyi commented on 17 Jan 2017 â€¢
edited
Hi,
I'm new to keras, and I'm working to define a BiDNN (https://github.com/v-v/BiDNN) like model using keras (using tensorflow as backend).
However, it's a little bit confused for me to do such thing like Lasagne (https://github.com/Lasagne/Lasagne) does, that share weights between two layers with transposed input and output dimensions. Just like the following Lasagne code:
l1 = DenseLayer(4, num_units=8, W=GlorotUniform()) # with input dim (4) and output dim (8)
l2 = DenseLayer(8, num_units=4, W=l1.W.T) # with input dim (8) and output dim (4)
Thus l2 shares l1's weights by transposing this tensor.
Is this possible in keras implementation? Thank you for any advises.
1
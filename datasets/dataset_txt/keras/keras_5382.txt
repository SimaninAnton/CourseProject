siddk commented on 22 Apr 2016
I am having an issue where I can't build a model in which I use a TimeDistributed wrapper on an Embedding layer. The code is as follows:
def build_model(self):
        """
        Build Keras Model
        """
        model = Sequential()
        # Input Shape: (_, STORY_SIZE, SENTENCE_SIZE)
        model.add(TimeDistributed(Embedding(input_dim=self.V, output_dim=self.EMBEDDING_SIZE,
                                            input_length=self.SENTENCE_SIZE),
                                  input_shape=(self.STORY_SIZE, self.SENTENCE_SIZE)))
        # Shape: (_, STORY_SIZE, SENTENCE_SIZE, EMBEDDING_SIZE)
        model.add(TimeDistributed(Flatten()))
        # Shape: (_, STORY_SIZE, SENTENCE_SIZE * EMBEDDING_SIZE)
        model.add(LSTM(self.MEMORY_SIZE, return_sequences=True))
        # Shape: (_, STORY_SIZE, MEMORY_SIZE)
        model.add(TimeDistributed(Dense(self.V, activation='softmax')))
        # Shape: (_, STORY_SIZE, VOCAB_SIZE) --> Softmax

        return model
When I try and build this model, I get the following traceback:
Traceback (most recent call last):
  File "/Users/sidd/Projects/memory/naive_rnn/model/memrnn.py", line 35, in build_model
    input_shape=(self.STORY_SIZE, self.SENTENCE_SIZE)))
  File "/Users/sidd/Projects/virtualenv/nltk/lib/python2.7/site-packages/keras/models.py", line 107, in add
    layer.create_input_layer(batch_input_shape, input_dtype)
  File "/Users/sidd/Projects/virtualenv/nltk/lib/python2.7/site-packages/keras/engine/topology.py", line 341, in create_input_layer
    self(x)
  File "/Users/sidd/Projects/virtualenv/nltk/lib/python2.7/site-packages/keras/engine/topology.py", line 485, in __call__
    self.add_inbound_node(inbound_layers, node_indices, tensor_indices)
  File "/Users/sidd/Projects/virtualenv/nltk/lib/python2.7/site-packages/keras/engine/topology.py", line 543, in add_inbound_node
    Node.create_node(self, inbound_layers, node_indices, tensor_indices)
  File "/Users/sidd/Projects/virtualenv/nltk/lib/python2.7/site-packages/keras/engine/topology.py", line 148, in create_node
    output_tensors = to_list(outbound_layer.call(input_tensors[0], mask=input_masks[0]))
  File "/Users/sidd/Projects/virtualenv/nltk/lib/python2.7/site-packages/keras/layers/wrappers.py", line 125, in call
    y = self.layer.call(X)  # (nb_samples * timesteps, ...)
  File "/Users/sidd/Projects/virtualenv/nltk/lib/python2.7/site-packages/keras/layers/embeddings.py", line 133, in call
    out = K.gather(W, x)
  File "/Users/sidd/Projects/virtualenv/nltk/lib/python2.7/site-packages/keras/backend/theano_backend.py", line 156, in gather
    return reference[indices]
  File "/Users/sidd/Projects/virtualenv/nltk/lib/python2.7/site-packages/theano/tensor/var.py", line 503, in __getitem__
    return self.take(args[axis], axis)
  File "/Users/sidd/Projects/virtualenv/nltk/lib/python2.7/site-packages/theano/tensor/var.py", line 535, in take
    return theano.tensor.subtensor.take(self, indices, axis, mode)
  File "/Users/sidd/Projects/virtualenv/nltk/lib/python2.7/site-packages/theano/tensor/subtensor.py", line 2387, in take
    return take(a, indices.flatten(), axis, mode).reshape(shape, ndim)
  File "/Users/sidd/Projects/virtualenv/nltk/lib/python2.7/site-packages/theano/tensor/subtensor.py", line 2365, in take
    return advanced_subtensor1(a, indices)
  File "/Users/sidd/Projects/virtualenv/nltk/lib/python2.7/site-packages/theano/gof/op.py", line 611, in __call__
    node = self.make_node(*inputs, **kwargs)
  File "/Users/sidd/Projects/virtualenv/nltk/lib/python2.7/site-packages/theano/tensor/subtensor.py", line 1687, in make_node
    raise TypeError('index must be integers')
TypeError: index must be integers
This seems to be an issue with the dimension of the tensor passed to the Embedding layer. I'm not sure if I'm using TimeDistributed properly in this context, or how I might fix this. Any help resolving this would be much appreciated, thanks!
ghost commented on 9 Apr 2016
Please make sure that the boxes below are checked before you submit your issue. Thank you!
Script excerpt:
batch_size = 128
nb_classes = 10
nb_epoch = 12
input image dimensions
img_rows, img_cols = 28, 28
number of convolutional filters to use
nb_filters = 32
size of pooling area for max pooling
nb_pool = 2
convolution kernel size
nb_conv = 3
the data, shuffled and split between train and test sets
(X_train, y_train), (X_test, y_test) = mnist.load_data()
Error:
Downloading data from https://s3.amazonaws.com/img-datasets/mnist.pkl.gz
671744/15296311 [>.............................] - ETA: 25s�������������������������������������������������������������
ValueError Traceback (most recent call last)
in ()
13
14 # the data, shuffled and split between train and test sets
---> 15 (X_train, y_train), (X_test, y_test) = mnist.load_data()
C:\Users\ritraina\Anaconda2\lib\site-packages\keras\datasets\mnist.pyc in load_data(path)
7
8 def load_data(path="mnist.pkl.gz"):
----> 9 path = get_file(path, origin="https://s3.amazonaws.com/img-datasets/mnist.pkl.gz")
10
11 if path.endswith(".gz"):
C:\Users\ritraina\Anaconda2\lib\site-packages\keras\utils\data_utils.pyc in get_file(fname, origin, untar)
74 if os.path.exists(fpath):
75 os.remove(fpath)
---> 76 raise e
77 progbar = None
78
ValueError: I/O operation on closed file
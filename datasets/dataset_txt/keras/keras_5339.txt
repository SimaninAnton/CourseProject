Contributor
braingineer commented on 26 Apr 2016 â€¢
edited
Currently, I'm running some loss functions by ignoring the y_pred and y_true inputs. But it'd be nice to be able to define some unsupervised losses.
For example, cross covariance loss
or TD loss for RL applications
### SARSA TD
def TD(reward_t, gamma, Q_tp1,  Q_t):
    td_error = reward_t + gamma*Q_tp1 - Q_t
    def loss(*args):
        return K.mean(K.square(td_error))
    return loss 
There seems to be a couple different ways one could handle this. One is just like I've done.
Some initial ideas I have would be to make decisions about the relationship between the numbers of outputs vs the number of losses or whether to just mark certain outputs as not needing an input, which could be done here, and then ignored in the following loop.
3
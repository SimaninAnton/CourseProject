prinsherbert commented on 2 May 2016 â€¢
edited
I found some of my personal tests failing after upgrading from 0.3.2 to 1.0.1 (0.3.3 als didn't work, but I did not investigate that).
The problem is that when I train a model with inputs of shape (100, N0), (100, N1), ... etc I would expect an output of (100, Nout), yet I get an output of shape (Nout). This is illustrated by this minimal working example (using version 1.0.1):
import keras
from keras.models import Graph
from keras.layers import Dense
import numpy

N_continuous = 10
N_categorical = 5
N_output = 2

categorical = (numpy.random.randn(100,N_categorical) > 0).astype(numpy.float32)
continuous  = numpy.random.randn(100,N_continuous)
output      = numpy.random.randn(100, N_output)

graph = Graph()

graph.add_input(name='continuous', input_shape=(N_continuous, ))
graph.add_node(Dense(N_output, activation='linear'), name='linear_models', input='continuous')

graph.add_output(name='regression_output', input='linear_models')

graph.compile(optimizer='rmsprop', loss={'regression_output': 'mse'})

graph.fit(data={'continuous': continuous, 'categorical': categorical, 'regression_output': output}, nb_epoch=1)
print( graph.predict({
    'continuous': continuous,
    'categorical': categorical,
    'regression_output': output
})['regression_output'].shape )

print(keras.__version__)
The output is (2, ) for the shape and 1.0.1 for the __version__.
In version 0.3.2 the output shape is (100, 2), which I would expect. Why are the shapes different for different versions? Which one is/ones are correct? Is my NN-architecture 'defective'?
Theano has version 0.9.0dev0.dev-5e5e5cc5581a88ab425b9bd73b7719efbd10f6d3
Thank you in advance!
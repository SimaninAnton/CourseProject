ghost commented on 12 Sep 2016
I am trying to train a model for regression. Basically I have an image and I take some 4 by 4 patches and make them into a vector of length 16 and target is i value. My code is -:
`batch_size = 1024
nb_epoch = 500
modelRed = Sequential()
modelRed.add(Dense(16 , input_shape=(red_rows,)))
modelRed.add(Activation('relu'))
modelRed.add(Dense(8))
modelRed.add(Activation('relu'))
modelRed.add(Dense(1))
modelRed.add(Activation('relu'))
modelRed.compile(optimizer='rmsprop', loss='mse', metrics=["accuracy"])
modelRed.fit(X_train_red, Y_train_red, batch_size=batch_size, nb_epoch=nb_epoch, validation_data=(X_test_red, Y_test_red), verbose=1)
scoreRed = modelRed.evaluate(X_test_red, Y_test_red , batch_size=batch_size)
print(scoreRed)
print("[INFO] dumping red weights to file...")
modelRed.save('models/'+date+'/modelRed.h5', overwrite=True)`
Now when the training starts , the loss is not changing significantly and accuracy is around 10%.
Train on 2064384 samples, validate on 1125000 samples Epoch 1/500 2064384/2064384 [==============================] - 7s - loss: 262.8366 - acc: 0.0716 - val_loss: 114.7868 - val_acc: 0.0843 Epoch 2/500 2064384/2064384 [==============================] - 7s - loss: 207.4097 - acc: 0.0775 - val_loss: 98.6670 - val_acc: 0.1329 Epoch 3/500 2064384/2064384 [==============================] - 7s - loss: 202.4491 - acc: 0.0793 - val_loss: 98.4252 - val_acc: 0.0983 Epoch 4/500 2064384/2064384 [==============================] - 7s - loss: 200.2928 - acc: 0.0801 - val_loss: 98.4661 - val_acc: 0.0862 Epoch 5/500 2064384/2064384 [==============================] - 7s - loss: 198.8120 - acc: 0.0808 - val_loss: 99.4978 - val_acc: 0.0674 Epoch 6/500 2064384/2064384 [==============================] - 7s - loss: 197.2105 - acc: 0.0830 - val_loss: 94.1958 - val_acc: 0.1027 Epoch 7/500 2064384/2064384 [==============================] - 7s - loss: 195.7770 - acc: 0.0853 - val_loss: 93.6606 - val_acc: 0.0991 Epoch 8/500 2064384/2064384 [==============================] - 7s - loss: 194.9638 - acc: 0.0862 - val_loss: 93.4946 - val_acc: 0.1038 Epoch 9/500 2064384/2064384 [==============================] - 7s - loss: 194.2256 - acc: 0.0865 - val_loss: 97.2228 - val_acc: 0.0847 Epoch 10/500 2064384/2064384 [==============================] - 7s - loss: 193.6435 - acc: 0.0871 - val_loss: 107.0747 - val_acc: 0.0539 Epoch 11/500 2064384/2064384 [==============================] - 7s - loss: 192.9196 - acc: 0.0874 - val_loss: 103.3168 - val_acc: 0.0975 Epoch 12/500 2064384/2064384 [==============================] - 7s - loss: 192.3347 - acc: 0.0885 - val_loss: 111.4804 - val_acc: 0.1041 Epoch 13/500 2064384/2064384 [==============================] - 7s - loss: 191.6973 - acc: 0.0891 - val_loss: 128.0778 - val_acc: 0.0753 Epoch 14/500 2064384/2064384 [==============================] - 7s - loss: 191.0240 - acc: 0.0894 - val_loss: 151.9250 - val_acc: 0.0944 Epoch 15/500 2064384/2064384 [==============================] - 7s - loss: 190.4836 - acc: 0.0904 - val_loss: 187.5526 - val_acc: 0.0815 Epoch 16/500 2064384/2064384 [==============================] - 7s - loss: 190.0552 - acc: 0.0909 - val_loss: 223.0900 - val_acc: 0.0900 Epoch 17/500 2064384/2064384 [==============================] - 7s - loss: 189.6594 - acc: 0.0926 - val_loss: 227.4159 - val_acc: 0.0877 Epoch 18/500 2064384/2064384 [==============================] - 7s - loss: 189.3446 - acc: 0.0915 - val_loss: 243.1507 - val_acc: 0.0798 Epoch 19/500 2064384/2064384 [==============================] - 7s - loss: 189.0191 - acc: 0.0936 - val_loss: 262.5395 - val_acc: 0.0663 Epoch 20/500 2064384/2064384 [==============================] - 7s - loss: 188.6804 - acc: 0.0935 - val_loss: 266.4030 - val_acc: 0.0579 Epoch 21/500 2064384/2064384 [==============================] - 7s - loss: 188.4249 - acc: 0.0942 - val_loss: 268.1881 - val_acc: 0.0972 Epoch 22/500 2064384/2064384 [==============================] - 7s - loss: 188.1592 - acc: 0.0952 - val_loss: 260.6266 - val_acc: 0.1124 Epoch 23/500 2064384/2064384 [==============================] - 7s - loss: 187.8753 - acc: 0.0959 - val_loss: 279.6210 - val_acc: 0.0869 Epoch 24/500 2064384/2064384 [==============================] - 7s - loss: 187.4796 - acc: 0.0964 - val_loss: 283.1497 - val_acc: 0.1053 Epoch 25/500 2064384/2064384 [==============================] - 7s - loss: 187.2783 - acc: 0.0967 - val_loss: 276.9925 - val_acc: 0.0775 Epoch 26/500 2064384/2064384 [==============================] - 7s - loss: 186.9355 - acc: 0.0981 - val_loss: 266.9071 - val_acc: 0.1050 Epoch 27/500 2064384/2064384 [==============================] - 8s - loss: 186.7448 - acc: 0.0985 - val_loss: 269.2414 - val_acc: 0.0933 Epoch 28/500 2064384/2064384 [==============================] - 7s - loss: 186.6203 - acc: 0.0978 - val_loss: 262.6495 - val_acc: 0.0975 Epoch 29/500 2064384/2064384 [==============================] - 7s - loss: 186.3543 - acc: 0.0988 - val_loss: 264.8819 - val_acc: 0.0759 Epoch 30/500 2064384/2064384 [==============================] - 7s - loss: 186.2142 - acc: 0.0992 - val_loss: 262.6092 - val_acc: 0.0884 Epoch 31/500 2064384/2064384 [==============================] - 7s - loss: 186.0984 - acc: 0.1000 - val_loss: 263.8414 - val_acc: 0.1082 Epoch 32/500 2064384/2064384 [==============================] - 7s - loss: 186.0365 - acc: 0.1008 - val_loss: 256.4330 - val_acc: 0.1009 Epoch 33/500 2064384/2064384 [==============================] - 7s - loss: 185.9146 - acc: 0.1004 - val_loss: 257.2521 - val_acc: 0.0964 Epoch 34/500 2064384/2064384 [==============================] - 7s - loss: 185.8332 - acc: 0.1010 - val_loss: 271.3592 - val_acc: 0.0807 Epoch 35/500 2064384/2064384 [==============================] - 7s - loss: 185.7249 - acc: 0.1005 - val_loss: 251.0919 - val_acc: 0.0930 Epoch 36/500 2064384/2064384 [==============================] - 8s - loss: 185.6835 - acc: 0.1011 - val_loss: 252.9707 - val_acc: 0.1133 Epoch 37/500 2064384/2064384 [==============================] - 7s - loss: 185.5578 - acc: 0.1016 - val_loss: 260.1523 - val_acc: 0.1063 Epoch 38/500 2064384/2064384 [==============================] - 7s - loss: 185.5426 - acc: 0.1017 - val_loss: 253.2548 - val_acc: 0.0689 Epoch 39/500 2064384/2064384 [==============================] - 7s - loss: 185.3982 - acc: 0.1025 - val_loss: 253.2336 - val_acc: 0.0864 Epoch 40/500 2064384/2064384 [==============================] - 7s - loss: 185.3686 - acc: 0.1023 - val_loss: 247.1919 - val_acc: 0.0930 Epoch 41/500 2064384/2064384 [==============================] - 7s - loss: 185.2903 - acc: 0.1026 - val_loss: 239.5486 - val_acc: 0.1145 Epoch 42/500 2064384/2064384 [==============================] - 7s - loss: 185.2027 - acc: 0.1029 - val_loss: 245.8559 - val_acc: 0.0954 Epoch 43/500 2064384/2064384 [==============================] - 7s - loss: 185.1857 - acc: 0.1027 - val_loss: 250.7422 - val_acc: 0.0686 Epoch 44/500 2064384/2064384 [==============================] - 7s - loss: 185.1402 - acc: 0.1037 - val_loss: 243.0395 - val_acc: 0.1130 Epoch 45/500 2064384/2064384 [==============================] - 7s - loss: 185.0607 - acc: 0.1032 - val_loss: 242.3247 - val_acc: 0.1022 Epoch 46/500 2064384/2064384 [==============================] - 7s - loss: 185.0244 - acc: 0.1031 - val_loss: 239.5981 - val_acc: 0.1052 Epoch 47/500 2064384/2064384 [==============================] - 7s - loss: 184.9727 - acc: 0.1036 - val_loss: 238.8083 - val_acc: 0.0927 Epoch 48/500 2064384/2064384 [==============================] - 7s - loss: 184.9499 - acc: 0.1037 - val_loss: 250.0885 - val_acc: 0.1135 Epoch 49/500 2064384/2064384 [==============================] - 7s - loss: 184.9076 - acc: 0.1030 - val_loss: 237.3578 - val_acc: 0.1087 Epoch 50/500 2064384/2064384 [==============================] - 7s - loss: 184.8728 - acc: 0.1034 - val_loss: 237.6239 - val_acc: 0.1136 Epoch 51/500 2064384/2064384 [==============================] - 7s - loss: 184.8032 - acc: 0.1032 - val_loss: 237.2164 - val_acc: 0.1144 Epoch 52/500 2064384/2064384 [==============================] - 7s - loss: 184.7657 - acc: 0.1033 - val_loss: 244.3095 - val_acc: 0.1076 Epoch 53/500
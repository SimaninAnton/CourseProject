bzhong2 commented on 21 Jun 2017
I am using keras with tensorflow as backend. I am trying to customize a loss function which weighted the cross entropy according to the prediction results and the true labels.
However, the y_true, y_pred, y_pred_max etc. are all tensors, and I want to weight all the individual samples but I am not familiar with tensor operations. It seems it cannot be done in the numpy way. Any help is appreciated. Below is the code:
def wccloss(y_true, y_pred):
  weights = np.matrix([   [1.0 ,0   ,0   ,0   ,0   ,0   ,0.2],\
       [0   ,1.0 ,0.1 ,0   ,0   ,0   ,0.2],\
       [0   ,0.1 ,1.0 ,0   ,0   ,0   ,0.2],\
       [0   ,0   ,0   ,1.0 ,0   ,0   ,0.2],\
       [0   ,0   ,0   ,0   ,1.0 ,0   ,0.2],\
       [0   ,0   ,0   ,0   ,0   ,1.0 ,0.2],\
       [0.2 ,0.2 ,0.2 ,0.2 ,0.2 ,0.2 ,1.0]])
 # scale preds so that the class probas of each sample sum to 1
 y_pred /= K.sum(y_pred, axis=-1, keepdims=True)
 # clip
 y_pred = K.clip(y_pred, K.epsilon(), 1)
 y_pred_max = K.max(y_pred, axis=1)
 y_true_max = K.max(y_true, axis=1)
 # calc
 print(y_pred)
 print(y_pred_max)
 weights_vector = K.ones_like(y_pred_max)
 for i in range(K.shape(y_pred_max)[0]):
  weights_vector[i] = 1-weights[y_pred_max[i],y_true_max[i]]
 loss = np.multiply(weights_vector,y_true*K.log(y_pred))
 loss =-K.sum(loss,-1)
 return loss
Add_layers.compile(optimizer=adam, loss=wccloss, metrics=['accuracy'])
A further question is: I would like to follow an adaboost style, that is reweight the loss according to how many times a certain sample has been misclassified. How can I do that ? Thanks!
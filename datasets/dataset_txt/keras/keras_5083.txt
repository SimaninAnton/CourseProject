daiwei89 commented on 27 May 2016
I notice that with Tensorflow backend, compiling the same model multiple times takes longer and longer in each successive compile call, with increasing memory footprint. This might be an issue with Tensorflow backend with GPU (Titan X), and does not manifest in Theano CPU mode. But I just want to bring it up here, to see if others have experienced this too, and if there's a solution.
This issue is important for model hyperparameter tuning, in which hundreds~thousands of models are compiled and tried.
Here's a simple program that produces the issue: https://gist.github.com/daiwei89/bb6a8963076138500283ed25422f34e3
Example output (time in seconds):
model 0 compiled in 1.85556578636
model 1 compiled in 0.991051197052
model 2 compiled in 1.09937405586
model 3 compiled in 1.2464530468
model 4 compiled in 1.58161401749
model 5 compiled in 1.83582210541
model 6 compiled in 2.23471999168
model 7 compiled in 2.43394994736
model 8 compiled in 2.57769298553
model 9 compiled in 3.01613497734
model 10 compiled in 3.31982398033
model 11 compiled in 3.57348203659
model 12 compiled in 3.65744900703
model 13 compiled in 3.92900300026
model 14 compiled in 4.41397094727
model 15 compiled in 4.44860506058
model 16 compiled in 5.58520293236
model 17 compiled in 5.06476783752
model 18 compiled in 5.5817258358
...
model 45 compiled in 12.4561269283
...
I'm using Tensorflow 0.8, keras 1.0.3.
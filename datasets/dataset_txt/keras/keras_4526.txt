HarisIqbal88 commented on 25 Aug 2016 â€¢
edited
I want to train a network with partially labelled data. For this, I use unsupervised loss for unlabeled data and supervised loss for labelled data. However, I noticed that the loss function definition in Keras require true labels and predicted labels as inputs. That is, the loss is supervised. I can work around it by labeling unlabeled data with y = -1 while labeled data as y =0...K and handling them properly in the function. But then, I don't know how the gradients will be computed as they are computed with T.grad() function. If I can define gradient for loss function myself, then this approach can work. Could you suggest me a work around it?
In addition, I would also want to write the (sub)-differential myself because the my loss function is not smooth/differentiable.
2
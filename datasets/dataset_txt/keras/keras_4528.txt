Contributor
tzachar commented on 25 Aug 2016
Hello.
Keras (nor any other library I know of) does not fully implement BatchNormalization: there is no mechanism to update the mean and variance statistics post train with the entire train set.
Users are expected to rely on the running mean and running variance calculated during the training phase.
In general, this approach works as long as you have enough data. However, in situations where the data is scarce (talking about thousands of data points here...), the running calculations seem to not be adequate when performing predictions.
I currently solve this issue as follows:
I have a new BatchNormalization layer in which the momentum is a tensor variable
After finishing the training phase, I manually change the momentum of all BN layers to 0.
I pass the entire train set through the model in a single batch
I was hoping someone had already encountered this problem, and maybe can come with a better solution. Preferably, one that fits nicely with Keras's framework; I would be really happy with something along the lines of model.post_train(...) and would be willing to implement it, but I need some guidance on where to start and how to integrate such a solution with Keras' overall architecture.
Cheers.
Contributor
icyblade commented on 17 Apr 2017
Activations from keras.layers.advanced_activations (e.g. LeakyReLU) are Layers, so typically we should do something like this:
model.add(LeakyReLU())
However, there're numbers of people who struggled model.add(Activation(LeakyReLU())) which doesn't work and will not raise a warning. (e.g. #3816)
I think maybe we can add some warnings?
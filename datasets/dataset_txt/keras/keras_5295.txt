PanWu commented on 2 May 2016
I am trying to run Keras with no hidden layer, and compare the result with a simple linear regression in sklearn. The data is generated with sklearn as below:
import matplotlib.pyplot as plt
%matplotlib inline
from sklearn import datasets, cross_validation
data_reg = datasets.make_regression(n_samples=10000, n_features=100, n_informative=100,
n_targets=1, noise=100, random_state=0)
The sklearn code & result is:
from sklearn import linear_model
lm_lr = linear_model.LinearRegression()
lm_lr.fit(data_reg[0], data_reg[1])
plt.scatter(data_reg[1], lm_lr.predict(data_reg[0]))
The Keras code & result is:
from keras.models import Sequential
from keras.layers import Input, Dense, Activation
model = Sequential()
model.add(Dense(1, input_dim=100))
model.compile(loss="mse", optimizer="rmsprop")
model.fit(data_reg[0], data_reg[1], nb_epoch=10, batch_size=16)
plt.scatter(data_reg[1], model.predict(data_reg[0]))
It is obvious that Keras result is has the incorrect scale from -70 to 70, while the original Y scale is from -2000 to 2000.
Could anyone help with understanding why Keras with no hidden layer does not recover the linear regression results?
oak-tree commented on 28 Mar 2017
This result with:
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 375.39                 Driver Version: 375.39                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla K80           Off  | 8CFB:00:00.0     Off |                    0 |
| N/A   58C    P0    58W / 149W |  10873MiB / 11439MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  Tesla K80           Off  | 9657:00:00.0     Off |                    0 |
| N/A   74C    P0    65W / 149W |  10873MiB / 11439MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   2  Tesla K80           Off  | A78F:00:00.0     Off |                    0 |
| N/A   42C    P0    71W / 149W |  10871MiB / 11439MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   3  Tesla K80           Off  | BB06:00:00.0     Off |                    0 |
| N/A   67C    P0   141W / 149W |  10941MiB / 11439MiB |     58%      Default |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|    0      4543    C   python                                       10869MiB |
|    1      4543    C   python                                       10869MiB |
|    2      4543    C   python                                       10867MiB |
|    3      4543    C   python                                       10937MiB |
+-----------------------------------------------------------------------------+
As can be seen above: Only 1 gpu is being used. But the memory has been allocated for all 4 gpu
Any idea how to prevent it?
8
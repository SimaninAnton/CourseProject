brunoklein99 commented on 29 Jun 2017
I'm trying to train with the following code:
generator = ImageDataGenerator(
    featurewise_center=True,
    rotation_range=90,
    horizontal_flip=True,
    vertical_flip=True,
    width_shift_range=.5,
    height_shift_range=.5,
    fill_mode='reflect'
)

batch_size = 2560

iterator = generator.flow(x_train, y_train[:, 0], batch_size=batch_size)

steps_per_epoch = math.ceil(len(x_train) / batch_size)

fit = model.fit_generator(iterator, steps_per_epoch, epochs=10000, verbose=True, workers=3, max_q_size=50)
But GPU usage is spiking:
This code has proper GPU usage, it only drops when calling generator.flow, as expected.
for x, y in generator.flow(x_train, y_train, batch_size=30720):
    fit = model.fit(x, y[:, 0],
                    batch_size=3072,
                    epochs=10,
                    verbose=1,
                    validation_split=.3,
                    shuffle=True,
                    callbacks=[checkpoint]
                    )
The images are 32x32x3 and x_train and y_train have 65k rows.
Is this behavior expected?
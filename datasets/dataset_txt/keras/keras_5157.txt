m-callahan commented on 18 May 2016 â€¢
edited
I've been working on a Neural Network to classify URLs and would like to be able to visualize the patterns that my convolutions are activating on. So far I've got the following code that gives me an error
ngram_output2 = K.function([model.layers[0].input, K.learning_phase()], [model.layers[2].layers[0].output])
Error:
An input of the graph, used to compute DimShuffle{0,1,2,x}(convolution1d_input_1), was not provided and not given a value.
My CNN model is as follows:
def sum_1d(X):
    return K.sum(X, axis=1)

def getconvmodel(filter_length,nb_filter):
    model = Sequential()
    model.add(Convolution1D(nb_filter=nb_filter,
                            input_shape=(100,32),
                            filter_length=filter_length,
                            border_mode='same',
                            activation='relu',
                            subsample_length=1))
    model.add(Lambda(sum_1d, output_shape=(nb_filter,)))
    model.add(BatchNormalization())
    model.add(Dropout(0.5))
    return model

def bag_of_convs_model(optimizer="sgd"):
    main_input = Input(shape=(100,), dtype='int32', name='main_input')
    embedding = Embedding(output_dim=32, input_dim=100, input_length=100,
        dropout=0)(main_input)

    conv1 = getconvmodel(2,256)(embedding)
    conv2 = getconvmodel(3,256)(embedding)
    conv3 = getconvmodel(4,256)(embedding)
    conv4 = getconvmodel(5,256)(embedding)

    merged = merge([conv1,conv2,conv3,conv4])

    middle = Dense(1024,activation='relu')(merged)
    middle = Dropout(0.5)(middle)
    middle = BatchNormalization()(middle)

    middle = Dense(1024,activation='relu')(middle)
    middle = Dropout(0.5)(middle)
    middle = BatchNormalization()(middle)

    output = Dense(1,activation='sigmoid')(middle)

    model = Model(input=main_input,output=output)
    model.compile(loss='binary_crossentropy', optimizer=optimizer)
    return model
and looks like
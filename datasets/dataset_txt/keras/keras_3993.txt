CCXD commented on 4 Nov 2016 â€¢
edited
Used a both a custom MLP model and the examples/mnist_mlp.py to test:
TF:
epoch time ~5s
real 1m20.077s
user 2m3.212s
sys 0m16.884s
Theano:
epoch time ~1s
real 0m38.972s
user 0m35.212s
sys 0m4.168s
On a Tesla K20c. The nvidia-smi gpu util is around 80% when using Theano. TF's gpu util is around 10-20%.
Using gpu device 0: Tesla K20c (CNMeM is enabled with initial size: 90.0% of memory, cuDNN 5005)
When I disable cnmem in .theanorc, theano performance becomes similar to TF: 20% gpu util, epoch time of ~4s:
real 1m51.123s
user 1m0.212s
sys 0m50.972s
Is there a way of customizing TF's memory allocation?
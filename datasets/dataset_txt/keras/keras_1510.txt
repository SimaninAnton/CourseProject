CloudResearch commented on 8 Nov 2017
Just done this guide -> https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html and the model saved successfully. Now i want to separate training phase from prediction. I know its possible to load a model again using load_model() function. In this tutorial you got on lstm for encoding, one for decoding, how to get the encoder/decoder again after successfully load the model?
In addition how to solve such a problem:
/usr/local/lib/python3.5/dist-packages/keras/engine/topology.py:2344: UserWarning: Layer lstm_2 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1/while/Exit_2:0' shape=(?, 366) dtype=float32>, <tf.Tensor 'lstm_1/while/Exit_3:0' shape=(?, 366) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).
So far i know it is necessary to have these weights/connection between encoder and decoder. Any idea?
3
kesinger commented on 21 Jun 2017
I've got a situation where I need a Conv3DTranspose, and am using the new tensorflow implementation wrapped inside a Lambda:
def tblock(self, sinput, skip, F=32):
u1 = Lambda(lambda x: tensorflow.layers.conv3d_transpose(x, kernel_size=3,
padding='SAME', strides=(2, 2, 2),
filters=F, activation=tensorflow.nn.relu,
use_bias=False))(sinput)
out = Add()([skip,u1])
return out
However, when I plumb layers like this into a Model, I'm seeing them show up with 0 trainable parameters, for example this .summary() putput:
lambda_70 (Lambda)               (None, 32, 16, 16, 64 0           add_17[0][0]                     
_____________
add_18 (Add)                     (None, 32, 16, 16, 64 0           conv3d_6[0][0]                   
                                                                                         lambda_70[0][0]                  
I'm hoping that everything's plumbed in ok underneath, but I don't want to spend a bunch of compute time to train up a big ugly model with a couple of these layers in the middle only to find out that I should have done something differently and had trainable parameters all along.
Am I doing something clearly wrong here?
thanks!
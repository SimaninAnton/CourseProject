s4chin commented on 17 Nov 2016
Hi,
I am trying to make a model of this. Here is the relevant code:
base_model = VGG16(weights='imagenet')
b_model = Model(input=base_model.input, output=[ base_model.get_layer('block4_conv3').output,
    base_model.get_layer('block3_conv3').output,
    base_model.get_layer('block2_conv2').output,
    base_model.get_layer('block1_conv2').output ])

conv4_3, conv3_3, conv2_2, conv1_2 = b_model.predict(x) # Here x should be a modified image

# Use the output of the layers of VGG16 on x in the model
conv1 = Convolution2D(256, 1, 1, border_mode='same')(BatchNormalization()(conv4_3))
conv1_scaled = resize(conv1, 56)
.
.
.
conv5 = Convolution2D(3, 3, 3, border_mode='same')(merge([ip_img, conv4], mode='sum'))
op = Convolution2D(2, 3, 3, border_mode='same')(conv5)

model = Model(input=base_model.input, output=op)
model.compile(optimizer='sgd', loss=custom_loss_fn)
Here, I want to train the model on a bunch of images in a directory where the input to the model is rgb2gray(image) and op should be close to rgb2uv(image). How do I do that?
Also, have I defined the models correctly?
cjnolet commented on 11 Sep 2016
I am getting the following when running the GloVE embedding example provided in the examples. I have made sure both Theano and Keras are up to date and I've copied the script ver-batim from your codebase (also based on the example from https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html).
Indexing word vectors.
Found 400000 word vectors.
Processing text dataset
Found 19997 texts.
Found 214909 unique tokens.
Shape of data tensor: (19997, 1000)
Shape of label tensor: (19997, 20)
Preparing embedding matrix.
Training model.
Train on 15998 samples, validate on 3999 samples
Epoch 1/50
15998/15998 [==============================] - 23s - loss: nan - acc: 0.0506 - val_loss: nan - val_acc: 0.0500
Epoch 2/50
15998/15998 [==============================] - 23s - loss: nan - acc: 0.0500 - val_loss: nan - val_acc: 0.0500
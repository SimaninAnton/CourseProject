FiReTiTi commented on 15 Jun 2016
Hi,
I have trained a CNN with Keras in order to segment specific patterns. It works really well, but now I have to start the "production phase", so my CNN must segment thousands of images.
So for a given image that the CNN has to segment, for each pixel into this image, I have to cut a patch around the pixel, and feed the CNN with all the patches. So far I used this solution:
WindowSize = 23 #patch size
ws2 = WindowSize / 2
image_data = ndimage.imread(image_file).astype(float)
dimensions = image_data.shape
SizeX = dimensions[1]
SizeY = dimensions[0]
imtest = np.ndarray(shape=(SizeX-2*ws2, 1, WindowSize, WindowSize), dtype=np.float32)
for y in range(ws2,SizeY-ws2):
    for x in range(ws2,SizeX-ws2):
        imtest[x-ws2,0] = image_data[y-ws2:y+ws2+1, x-ws2:x+ws2+1]
So I work row by row, like that I don't loose the patch coordinates. But this solution is really slow. Is there a faster way to do it?
I've also heard about the Generator in Keras, but it seems to be useful to train a generator with the fit_generator function, but not to test on an image and then to segment it because you it does not keep the patches coordinates.
Any idea?
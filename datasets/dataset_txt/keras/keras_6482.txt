Contributor
stephenroller commented on 5 Nov 2015
Writing this down so I don't forget, but I haven't got a patch or test yet (ICLR deadline approaching fast...)
The new .trainable parameter is very nice; I've found it particularly useful for settings where I want to keep my word embeddings fixed and learn a task-specific transformation of them, rather than backprop into them.
Currently, save_weights and load_weights are broken by these: one uses get_weights(), which returns weights for the frozen layers (desirable); however, load_weights fails, since it uses .params, which only returns trainable parameters.
MahdiKhodayar commented on 25 Feb 2017 â€¢
edited
I'm still confused about the TimeDistributedDense layer. If we add a LSTM layer in the Sequential model and then add the TimeDistributedDense layer, can we do mean pooling on all the "hidden states" of the LSTM for k time steps: t=0, t=1, ... , t=k-1 ?
I mean is this code doing mean pooling on all the hidden_state_size hidden states of LSTM ?
sequence = Input(shape=(max_sent_len,), dtype='int32')
embedded = Embedding(vocab_size, word_embedding_size)(sequence)
lstm = LSTM(hidden_state_size, activation='sigmoid', inner_activation='hard_sigmoid',
return_sequences=True)(embedded)
distributed = TimeDistributed(Dense(1))(lstm)
pool = AveragePooling1D()(distributed)
output = Dense(1, `activation='sigmoid')(pool)`
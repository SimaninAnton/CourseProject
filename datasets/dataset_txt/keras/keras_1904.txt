santient commented on 18 Jul 2017
Hi all,
I'm trying to train a sequence to sequence model to predict the next note (or full MIDI event if I add more functionality later) in a series of notes. So far, nothing has worked, the loss converges to around -0.4783 and the prediction is always all 4s padded with 0s on the left. Here's the code:
import tensorflow as tf
import numpy as np
import mido
from keras.preprocessing.text import Tokenizer
from keras.preprocessing.sequence import pad_sequences
from keras.models import Sequential
from keras.layers import Dense,Activation,Dropout,Embedding,SpatialDropout1D
from keras.layers import LSTM

def shift(seq, n):
    n = n % len(seq)
    return seq[n:] + seq[:n]

train = mido.MidiFile("training_data/train.mid")
test = mido.MidiFile("training_data/test.mid")
seq = "cdefgab"*100 #test sequence; will replace later with notes read from MIDI events

tk = Tokenizer(num_words=2000, lower=True, split=" ")
tk.fit_on_texts(seq)
x = tk.texts_to_sequences(seq)

#shifing to left
y = shift(x,1)
print(x)
print("\n")
print(y)

#padding sequence
max_len = 100
max_features=len(tk.word_counts)
X = pad_sequences(x, maxlen=max_len)
Y = pad_sequences(y, maxlen=max_len)
print(X)
print("\n")
print(Y)

#lstm model
model = Sequential()
model.add(Embedding(max_features + 1, 128, input_length=max_len))
model.add(SpatialDropout1D(0.2))
model.add(LSTM(128, recurrent_dropout=0.2, dropout=0.2))
model.add(Dense(max_len))
model.add(Activation('relu'))
model.compile(loss='binary_crossentropy', optimizer='rmsprop')
model.summary()

model.fit(X, Y, batch_size=200, epochs=10)

model.predict(X, batch_size=200)
Training:
Epoch 1/10
700/700 [==============================] - 1s - loss: 0.1733     
Epoch 2/10
700/700 [==============================] - 0s - loss: -0.0066    
Epoch 3/10
700/700 [==============================] - 0s - loss: -0.4747     
Epoch 4/10
700/700 [==============================] - 0s - loss: -0.4782     
Epoch 5/10
700/700 [==============================] - 0s - loss: -0.4783     
Epoch 6/10
700/700 [==============================] - 0s - loss: -0.4783     
Epoch 7/10
700/700 [==============================] - 0s - loss: -0.4783     
Epoch 8/10
700/700 [==============================] - 0s - loss: -0.4783     
Epoch 9/10
700/700 [==============================] - 0s - loss: -0.4783     
Epoch 10/10
700/700 [==============================] - 0s - loss: -0.4783
Prediction:
array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.        ,  4.26653194],
       [ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.        ,  4.26872206],
       [ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.        ,  4.26919842],
       ..., 
       [ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.        ,  4.27029228],
       [ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.        ,  4.26764679],
       [ 0.        ,  0.        ,  0.        , ...,  0.        ,
         0.        ,  4.26126671]], dtype=float32)
As you might be able to tell, I am new to machine learning. Can someone help point me in the right direction?
[ √] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps
[ √] If running on TensorFlow, check that you are up-to-date with the latest version. The installation instructions can be found here.
[ √] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps
[ √] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
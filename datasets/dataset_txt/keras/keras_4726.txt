cdicle commented on 24 Jul 2016
Hi,
I bet this problem has been addressed in another issue but I couldn't find it, so sorry for replicates.
I am trying to define a lambda layer which takes mean of the the input. I use two versions,
dim_data = 105
len_data = 21 
num_data = 7;
num_classes = 12;

X = np.empty((num_data,),dtype=object)

for i in range(0,num_data):
    X[i] = np.random.random((len_data,dim_data))

# version 1
def Kmean(x):
    return K.mean(x,axis=1)
def Kmean_output_shape(input_shape):
    return tuple(input_shape[0],1,input_shape[2])

x = input_data
x = Lambda(Kmean,output_shape=Ksum_output_shape)(x)
x = Dense(num_classes)(x)
x = Activation('softmax')(x)
pred = x

model = Model(input=input_data,output=pred)
model.summary()

# version 2
x = input_data
x = Lambda(lambda x: K.mean(x,axis=1))(x) 
x = Dense(num_classes)(x)
x = Activation('softmax')(x)
pred = x

model = Model(input=input_data,output=pred)
model.summary()
Both versions have problem. The first version returns the right output shape but dense layer gives an error. The second layer does not return the right dimensions, the input and the output have the same dimensions, which I believe should not be the case, because I take a mean along second axis.
I would appreciate any help, thanks.
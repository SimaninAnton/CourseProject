mbinkowski commented on 21 Nov 2016
Dear developers and users
I am working on stateful lstm and although I think I am able to train the network using fit_generator method, I am struggling to understand the required dimensions for the fit method.
Suppose I have n_seq training sequences of length n_time_steps and dimensionality dim. As the network is stateful, each of the batches contains several (say 10) time steps that follow the time steps from the previous batch. Therefore, I pass the argument
batch_input_shape=(n_seq, 10, dim)
and have my data stored in array X of the shape
X.shape = (n_seq, n_time_steps, dim).
Now, when I use the fit_generator method, with training generator yielding consecutive batches X[:, i*10: (i + 1)*10, :] (as presented in keras FAQ) the training seems to be working fine.
However, when I try to use the array X as an input to the fit method (provided that n_time_steps % 10 == 0) I got an error
Error when checking model input: expected lstm_8 to have shape (4, 10, 9) but got array with shape (4, 49000, 9)
The error seems to be raised by keras.engine.training.standardize_input_data function, which seems to require the input array to be of the shape passed by batch_input_shape parameter.
How to pass then more than one batch to the fit method?
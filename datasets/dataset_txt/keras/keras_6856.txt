Contributor
mikekestemont commented on 14 Jul 2015
I wanted to add an example for a character-level 1D convolution in the style of "Text Understanding from Scratch" (http://arxiv.org/pdf/1502.01710v3.pdf). For this, I wanted to reconstruct the original text from the Reuters topic classification dataset, which -- unlike the IMDB dataset? -- comes with a vocabulary index in keras.datasets. I thought the following would work, but it produces gibberish when I try to decode documents:
from keras.datasets import reuters
vocab_dict = reuters.get_word_index(path="reuters_word_index.pkl")
(X_train, y_train), (X_test, y_test) = reuters.load_data(nb_words=max(vocab_dict.values()), test_split=0.2)
print(vocab_dict["million"])
# inverse the dict for lookup via idx:
vocab_dict = dict((v, k) for k, v in vocab_dict.items())
print(vocab_dict[2124])
# reconstruct random document:
txt = [vocab_dict[idx] if idx in vocab_dict else "XXX" for idx in X_train[1000]]
print(txt)
Any thoughts? I might be missing something obvious here.
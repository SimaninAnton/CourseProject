Nimi42 commented on 4 Feb 2018 â€¢
edited
Hey there,
I stumbled across the definition of mse in Keras and I can't seem to find an explanation.
def mean_squared_error(y_true, y_pred):
    return K.mean(K.square(y_pred - y_true), axis=-1)
I was expecting the mean to be taken across the batches, which is axis=0, but instead it
is axis=-1.
I also played around with it a little to see if K.mean actually behaves like the numpy equivalent.
I must have misunderstood something. Can somebody please clarify?
I can't actually take a look inside the cost function at run time right?
As far as I know the function is called at compile time, which prevents me from
evaluating concrete values.
I mean... imagine doing regression and having a single output neuron and training with a batch size of ten.
>>> import numpy as np
>>> a = np.ones((10, 1))
>>> a
array([[ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.]])
>>> np.mean(a, axis=-1)
array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])
All it does is flatten the array instead of taking the mean of all the predictions.
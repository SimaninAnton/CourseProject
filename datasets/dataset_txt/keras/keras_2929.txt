redst4r commented on 19 Mar 2017 â€¢
edited
Hi,
I'm currently working on a problem where I need to have 2D convolutional filters shared over channels.
For example, for an RGB image (200x200x3), the first convolutional layer would have N filters (each of shape (5,5,1) ), each being applied to the three input channels separately -> outputshape = (200,200,3,N). Standard 2D conv would instead have a (5,5,3,N) W-matrix, yielding a 200x200xN output ). The overall goal here is to keep the input color-channels separate (no mixing of different channels, but sharing the filters). Note that I'm going to apply this to "images" with way more then 3 color-channels (more like ~100).
As far as I can tell there's 3 options to implement this in keras:
a Conv3D with kernel dimensions (1,5,5). Due to the 1 the kernel/filter is effectively shared across the first dimension
a TimeDistributed Conv2D layer, "time" being abused to share the 2D convolution across the 1st dimension
the Functional API of keras, i.e. splitting the input into different tensors (1 per color) and calling the same 2DConv-layers on them.
Could you guys maybe give any recommendation which option will do best (in terms of performance, mem-requirements)?
I played around with the parameters (imagesize, #inputchannels, #filters) on a CPU, but didnt really get any consistent winning strategy out of it.
I also wonder if a GPU would e.g. be able to "exploit" the 3Dconv operation in option 1) more then the implied RNN-structure of option 2) and hence be faster.
Here's some code for options 1) and 2) [dindt try 3) yet]
from keras.layers.wrappers import TimeDistributed
from keras.layers import  Convolution2D, Convolution3D
from keras.models import Sequential
import numpy as np

nfilter= 20
kernelsize = 5
space_dim = 200
channel_dim = 3   # like an RGB

inputshape = (10,channel_dim,space_dim,space_dim, 1)

# initialize the layers with the same filter to check if they actually do the same operation
convW = np.random.rand(kernelsize,kernelsize,1,nfilter)
convB = np.random.rand(nfilter,)

# option 1: TimeDistributed Conv2D
model_td = Sequential()
model_td.add(TimeDistributed(Convolution2D(nfilter, kernelsize, kernelsize, weights=(convW, convB)),
                          batch_input_shape=inputshape))

# option 2: Conv3D with 1xKxK kernels
model_3d = Sequential()
model_3d.add(Convolution3D(nfilter, 1 , kernelsize, kernelsize, weights=(np.stack([convW]), convB),
                           batch_input_shape=inputshape))

X = np.random.rand(*inputshape)

%time r = model_td.predict(X)
%time r2 = model_3d.predict(X)

assert np.all(r==r2)
Please make sure that the boxes below are checked before you submit your issue. If your issue is an implementation question, please ask your question on StackOverflow or join the Keras Slack channel and ask there instead of filing a GitHub issue.
Thank you!
Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps
If running on TensorFlow, check that you are up-to-date with the latest version. The installation instructions can be found here.
If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps
Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
5
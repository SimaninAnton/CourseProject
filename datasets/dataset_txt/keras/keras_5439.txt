3rduncle commented on 18 Apr 2016 â€¢
edited
I want to implement a semi-supervise model in this paper http://arxiv.org/abs/1603.06318
I try with steps below:
In my loss function, I pass a symbol x, representing unlabeled data, into the network to get the tensor of whole net.
computation of such tensor is combined with the original loss function. then the affected gradient will be computed automatically and go backward to tune the weight.
In training, I assign some unlabeled data to symbol x.
code like this:
def semi_loss(y_true, y_pred):
    labeled_loss = K.mean(K.binary_crossentropy(y_pred, y_true), axis=-1)
    unlabeled_x = T.matrix('unlabeled_x')
    unlabeled_tensor = net(unlabeled_x)
    unlabeled_loss = regulation(unlabeled_tensor)
    return 0.9 * labeled_loss + 0.1 * unlabeled_loss
But I don't know how to get such tensor about unlabeled_x.
Any suggestions?
5
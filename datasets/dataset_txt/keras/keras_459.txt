sekti92 commented on 15 Jan 2019
Hello guys, i would like to know why i cannot use 'categorical_crossentropy'.
I have 12 class both in training and validation folder.
the structure of the class like this
database/validation/P1
database/validation/...
database/validation/P12
How to make this model should be able to compile with 'categorical_crossentropy'? Thanks
This is my actual code:
from keras import applications, optimizers
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential, Model
from keras.layers import Conv2D, MaxPooling2D
from keras.layers import Activation, Dropout, Flatten, Dense, ZeroPadding2D
from keras import backend as K
import matplotlib.pyplot as plt

# dimensions of our images.
img_width, img_height = 224, 224

train_data_dir = 'database/train'
validation_data_dir = 'database/validation'
nb_train_samples = 46
nb_validation_samples = 26
epochs = 50
batch_size = 2


if K.image_data_format() == 'channels_first':
    input_shape = (3, img_width, img_height)
else:
    input_shape = (img_width, img_height, 3)

# build the VGG16 network
vgg_conv = applications.VGG16(weights='imagenet', include_top=False, input_shape=input_shape)
print('VGG Pretrained Model loaded.')

vgg_conv.summary()

# Freeze the layers except the last 4 layers
# for layer in vgg_conv.layers[:-4]:
#     layer.trainable = False

# Check the trainable status of the individual layers
for layer in vgg_conv.layers:
    print(layer, layer.trainable)

# Create the model
model = Sequential()

# Add the vgg convolutional base model
model.add(vgg_conv)

# First
model.add(Flatten())
model.add(Dense(12))
model.add(Activation('relu'))
model.add(Dropout(0.5))
model.add(Dense(1))
model.add(Activation('softmax'))

model.summary()


# this is the augmentation configuration we will use for training
train_datagen = ImageDataGenerator(
    rescale=1. / 224,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True)

# this is the augmentation configuration we will use for testing:
# only rescaling
test_datagen = ImageDataGenerator(rescale=1. / 224)

train_generator = train_datagen.flow_from_directory(
    train_data_dir,
    target_size=(img_width, img_height),
    batch_size=batch_size,
    class_mode='binary')

validation_generator = test_datagen.flow_from_directory(
    validation_data_dir,
    target_size=(img_width, img_height),
    batch_size=batch_size,
    class_mode='binary')

# compile model
# model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizers.RMSprop(lr=2e-4), metrics=['accuracy'])
model.compile(loss='categorical_crossentropy',
              optimizer=optimizers.RMSprop(lr=2e-4),
              metrics=['accuracy'])

# Train the model
history = model.fit_generator(
    train_generator,
    steps_per_epoch=nb_train_samples / batch_size,
    epochs=epochs,
    validation_data=validation_generator,
    validation_steps=nb_validation_samples / batch_size)

# Save the model
model.save('vgg16_pretrained_2.h5')



# Check Performance
acc = history.history['acc']
val_acc = history.history['val_acc']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(acc))

plt.plot(epochs, acc, 'b', label='Training acc')
plt.plot(epochs, val_acc, 'r', label='Validation acc')
plt.title('Training and validation accuracy')
plt.legend()

plt.figure()

plt.plot(epochs, loss, 'b', label='Training loss')
plt.plot(epochs, val_loss, 'r', label='Validation loss')
plt.title('Training and validation loss')
plt.legend()

plt.show()
The terminal output:
VGG Pretrained Model loaded.
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         (None, 224, 224, 3)       0
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0
=================================================================
Total params: 14,714,688
Trainable params: 14,714,688
Non-trainable params: 0
_________________________________________________________________
<keras.engine.topology.InputLayer object at 0x000001C834ABD0F0> False
<keras.layers.convolutional.Conv2D object at 0x000001C848B69828> True
<keras.layers.convolutional.Conv2D object at 0x000001C848319A20> True
<keras.layers.pooling.MaxPooling2D object at 0x000001C8482E72E8> True
<keras.layers.convolutional.Conv2D object at 0x000001C848C00CC0> True
<keras.layers.convolutional.Conv2D object at 0x000001C848C0E0F0> True
<keras.layers.pooling.MaxPooling2D object at 0x000001C848C18DD8> True
<keras.layers.convolutional.Conv2D object at 0x000001C848C305F8> True
<keras.layers.convolutional.Conv2D object at 0x000001C848C38EB8> True
<keras.layers.convolutional.Conv2D object at 0x000001C848C40EF0> True
<keras.layers.pooling.MaxPooling2D object at 0x000001C848C4CC50> True
<keras.layers.convolutional.Conv2D object at 0x000001C848C62710> True
<keras.layers.convolutional.Conv2D object at 0x000001C848C629B0> True
<keras.layers.convolutional.Conv2D object at 0x000001C848C7B5C0> True
<keras.layers.pooling.MaxPooling2D object at 0x000001C848C86DA0> True
<keras.layers.convolutional.Conv2D object at 0x000001C848C99860> True
<keras.layers.convolutional.Conv2D object at 0x000001C848CA4D68> True
<keras.layers.convolutional.Conv2D object at 0x000001C848CAD710> True
<keras.layers.pooling.MaxPooling2D object at 0x000001C848CB8EB8> True
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
vgg16 (Model)                (None, 7, 7, 512)         14714688
_________________________________________________________________
flatten_1 (Flatten)          (None, 25088)             0
_________________________________________________________________
dense_1 (Dense)              (None, 12)                301068
_________________________________________________________________
activation_1 (Activation)    (None, 12)                0
_________________________________________________________________
dropout_1 (Dropout)          (None, 12)                0
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 13
_________________________________________________________________
activation_2 (Activation)    (None, 1)                 0
=================================================================
Total params: 15,015,769
Trainable params: 15,015,769
Non-trainable params: 0
_________________________________________________________________
Found 46 images belonging to 12 classes.
Found 26 images belonging to 12 classes.
Epoch 1/50
Traceback (most recent call last):
  File "C:/Users/w024029h/PycharmProjects/keras_pretrained/vgg16_2.py", line 92, in <module>
    validation_steps=nb_validation_samples / batch_size)
  File "C:\Users\w024029h\AppData\Local\Programs\Python\Python36\lib\site-packages\keras\legacy\interfaces.py", line 91, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\w024029h\AppData\Local\Programs\Python\Python36\lib\site-packages\keras\models.py", line 1315, in fit_generator
    initial_epoch=initial_epoch)
  File "C:\Users\w024029h\AppData\Local\Programs\Python\Python36\lib\site-packages\keras\legacy\interfaces.py", line 91, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\w024029h\AppData\Local\Programs\Python\Python36\lib\site-packages\keras\engine\training.py", line 2230, in fit_generator
    class_weight=class_weight)
  File "C:\Users\w024029h\AppData\Local\Programs\Python\Python36\lib\site-packages\keras\engine\training.py", line 1877, in train_on_batch
    class_weight=class_weight)
  File "C:\Users\w024029h\AppData\Local\Programs\Python\Python36\lib\site-packages\keras\engine\training.py", line 1493, in _standardize_user_data
    self._feed_output_shapes)
  File "C:\Users\w024029h\AppData\Local\Programs\Python\Python36\lib\site-packages\keras\engine\training.py", line 256, in _check_loss_and_target_compatibility
    ' while using as loss `categorical_crossentropy`. '
ValueError: You are passing a target array of shape (2, 1) while using as loss `categorical_crossentropy`. `categorical_crossentropy` expects targets to be binary matrices (1s and 0s) of shape (samples, classes). If your targets are integer classes, you can con
vert them to the expected format via:

from keras.utils import to_categorical
y_binary = to_categorical(y_int)


Alternatively, you can use the loss function `sparse_categorical_crossentropy` instead, which does expect integer targets.
mostlymetalman commented on 16 Dec 2015
GRU has a self.activation that appears to be unused.
I would have expected it to be applied when computing hh (like it was) (Or alternatively removed from the init signature to avoid confusion.)
hh = self.inner_activation(x_h + K.dot(r * h_tm1, self.U_h)
was, and probably should be
hh = self.activation(x_h + K.dot(r * h_tm1, self.U_h)
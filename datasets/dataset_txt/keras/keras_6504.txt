sergeyf commented on 30 Oct 2015
Howdy,
I'd like to implement this paper: http://arxiv.org/pdf/1504.03410v1.pdf
The inputs are triplets of images, so my plan is to use Graph to create three identical networks and then tie their weights/params together for every layer, like Francois describes in #783. So first question is: is that the most efficient way to create a shared pipeline that 3 different images will go through?
If so, the final layer would be a merge (concatenate) layer that would emit the three final encodings.
Now, the loss function doesn't need a Y - it uses the information inherent in the ordering of the 3 concatenated outputs. The training data is ordered such that the first of the 3 images should be closer to the second than the third.
So let's say the output is 3 rows of embeddings/hashes as follows:
[embedding_1, 
embedding_2, 
embedding_3]
The loss function would then be just like eq (2) in the paper:
T.maximum(0 , ||embedding_1 - embedding_2||**2 - ||embedding_1 - embedding_2||**2 + 1)
Interestingly, there is no need for a Y. Is there a natural way to make a loss function that doesn't need a Y, or will Keras always require some Y, even if it is a dummy one?
Thanks.
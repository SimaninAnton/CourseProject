ChrisSwinchatt commented on 3 Sep 2018 â€¢
edited
Hi all,
I've found that the problem doesn't occur when TensorFlow is forced to use the CPU -- (I think) this implies that it's a TensorFlow bug and not a Keras bug, so maybe this issue can be closed.
First off, I'm using the Keras that's distributed with TensorFlow 1.10.0 so let me know if I should have opened the issue on their repo instead.
I'm using a sequence-to-sequence model based on the Keras blogpost which I've wrapped into a fairly complicated object (although the issue also occurs with a simplified version linked below). When I create a new model (which I have to do for gridsearch and for clearing the TF session when the graph gets too big and slows down training) it starts with accuracy of either 0% or 70%.
Here are a pair of screenshots that show what I mean:
Good: https://i.imgur.com/7mT5Siv.png
Bad: https://i.imgur.com/MZ3NdCB.png
You can see that in the first screenshot, the accuracy is low but trending upwards. In the second, the accuracy of two models starts at 70% and doesn't increase (another model starts at 3% and also doesn't increase).
This happens whether I create new, blank models or load pretrained weights into new models with model.load_weights().
Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/keras-team/keras.git --upgrade --no-deps
If running on TensorFlow, check that you are up-to-date with the latest version. The installation instructions can be found here.
If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps
Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
Here is a minimal Gist which reproduces the problem: https://gist.github.com/ChrisSwinchatt/97304761e9f875dfd34e3339891a5475
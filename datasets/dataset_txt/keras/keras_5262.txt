iheo commented on 4 May 2016 â€¢
edited
Hello,
I am pretty new to using Keras and it has been quite nice to use.
I tried to find a solution to my issue here but couldn't.
Some issues were about handling different length of timesteps in training and their solutions seem to use batchsize=1, using mask or padding zero to maxlen.
Suppose I have trained an LSTM using return_sequences=True like this:
model = Sequential()
model.add(LSTM(10, return_sequences=True, input_shape = [3, 2]))
model.add(TimeDistributedDense(4))
Then, I want to predict sequences using my real-time X_test which look like this:
timestep        0 1 2 3 4 5 6 7 8 9......
data(dim-1)     2 1 4 3 6 1 2 5 6 3 4 ....
data(dim-2)     5 2 3 1 5 3 4 4 2 2 3 ....
so the dimension of X_test = (1, T, 2) == as (nb_samples, timesteps, input_dim)
where T is the number of timesteps, say T is a very large number like 100000 (because my data is real-time)
But it seems to be that the dimension of X_test must be the same as X_train (except nb_samples) when I predict something from X_test using
mypredict = model.predict(X_test)    # X_test[0].shape == X_train[0].shape
otherwise it throws error messages about dimension mismatch.
As a sub-solution, I could predict an output at every timestep using a series of overlapping blocks like this:
for t in range(0, T)
   t1 = t
   t2 = t+3
   X_test_block = X_test[0][t1:t2].reshape(1, 3, 2)  # the prediction requires 3D Tensor input as well
   X_pred_block = model.predict(X_test_block)
   X_pred[t2] = X_pred_block[-1]
then the problem in my mind is that the hidden units in the model from one time to the next are not connected - reset every next block. Furthermore, if I trained the model using a large number of timesteps(=1000) it will be very inefficient - it has to have 1000 samples to predict one output at every timestep.
My understanding of this model (using TimeDistributedDense) is that
once a model is trained, then the model gives me an output for an input at each timestep so that any X_test with arbitrary timesteps would seem to work.
If I am missing something, please let me know I would really appreciate it!
Thanks!
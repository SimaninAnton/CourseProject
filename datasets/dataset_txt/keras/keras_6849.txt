Contributor
anayebi commented on 16 Jul 2015
I was wondering if there was a straightforward way in Keras (or would I have to write my own layer?) to combine a convolutional network which extracts features and then feeds it to an LSTM (or GRU, MUT1, etc) network (similar to Figure 1 of this paper: http://arxiv.org/pdf/1411.4389v3.pdf)?
Specifically, I want the input i_t to the convolutional network at a given timestep t to consist of n frames (in the case of Figure 1, n = 1), so i_t would be of dimension (num_rows, num_cols, n), from which the features of i_t are extracted and fed into an LSTM network, which produces a prediction y_t and a hidden state h_t. Then the next input i_{t+1} of dimension (num_rows, num_cols, n) is fed into the same convolutional network which outputs the features of i_{t+1} to the LSTM layer at timestep t+1, and h_t is fed to the LSTM layer at timestep t+1 from the LSTM layer at timestep t, from which the prediction y_{t+1} and hidden state h_{t+1} are produced, and so on.
I'm aware of #129; however, in this case, I believe the original poster wanted it so that the convolutional layer does not accept new inputs across timesteps (so something like Figure 3, pg. 4 of this paper: http://arxiv.org/pdf/1411.4555v2.pdf), which is not what I want.
Thanks in advance!
2
2
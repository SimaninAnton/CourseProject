jt827859032 commented on 8 Nov 2017
Hi,
I got an error when using my own loss function. My net is to produce an RGB image. So I wanna use the pretrained VGG-16 net to extract feature map and compute the 'mse' between predicted image and target image.
Here is my code:
def VGGloss(y_pred, y_true):  
     vggmodel = VGG16(include_top=False)  
     f_p = vggmodel.predict(y_pred)  
     f_t = vggmodel.predict(y_true)  
     return K.mean(K.square(f_p - f_t)) 
and the error logs:
  File "K:/codes/code_demo/demo.py", line 241, in VGGloss
    f_p = vggmodel.predict(y_pred)
  File "I:\ProgramData\Anaconda3\lib\site-packages\keras\engine\training.py", line 1748, in predict
    verbose=verbose, steps=steps)
  File "I:\ProgramData\Anaconda3\lib\site-packages\keras\engine\training.py", line 1290, in _predict_loop
    batches = _make_batches(num_samples, batch_size)
  File "I:\ProgramData\Anaconda3\lib\site-packages\keras\engine\training.py", line 384, in _make_batches
    num_batches = int(np.ceil(size / float(batch_size)))
TypeError: unsupported operand type(s) for /: 'Dimension' and 'float'
could someone tell me how to use pre-trained model to compute a custom loss ?
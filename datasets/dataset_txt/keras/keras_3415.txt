sun-peach commented on 20 Jan 2017
Hi, I am building a end-to-end speech recognition with attention model. I use keras also a keras-based tool seq2seq
My network architecture is like:
Softmax layer
Dense part
LSTM part
Attention Model
LSTM part
Dense part
For the parts lower than Attention Model is the "encoder" and the upper part is the "decoder". I think all the LSTM layers should return sequence(return_sequence=True), and all the Dense layers should be TimeDistributed(because they should do processing for every time step). Now I have a problem is that the input length is not equal to the output length (all the input have the same length with zero padding; all the output also have the same length).
How should I fix this problem? Also a extra problem I have right now is when I have the LSTM layer in the "decoder" to return sequence and connect to TimeDistributed(Dense), error always occurs. How should I fix this problem?
Thank you very much!
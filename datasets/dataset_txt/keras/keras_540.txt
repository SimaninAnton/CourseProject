husmen commented on 13 Dec 2018
Hi,
I noticed some weird behaviour when training a sequential model using FP16, mse as loss function and adam as optimizer; the loss can't be calculated and I get an output similar to:
Epoch 1/10
1381/1381 [==============================] - 1033s 748ms/step - loss: nan
There is no issue when using FP32, or changing the optimizer with FP16 (I tried both adamax and sgd). Am I missing something or is there something wrong with the implementation of adam?
It is worth noting that I'm using an RTX 2080 which does support FP16.
[ * ] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/keras-team/keras.git --upgrade --no-deps
done
[ * ] Check that your version of TensorFlow is up-to-date. The installation instructions can be found here.
done
[ * ] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
gist link with code snippet here
link for the original full code (before adding FP16) here
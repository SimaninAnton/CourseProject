Chaoste commented on 7 Dec 2018
Keras==2.2.4
Hi guys,
Setup:
I'm currently working with the sklearn implementation of a MLPClassifier. Since I want to have one interface for all further (custom) models I decided to start from your interface KerasClassifier. So I created my own class which extends KerasClassifier but __call__ returns an instance of sklearn.neural_network.MLPClassifier. I use this model for a multi-classification task with three classes [-1, 0, 1].
Issue:
When my classifier calls the interface method super().fit(X, y, **kwargs) the labels are transformed into [0, 1, 2]. At first I suspected the sklearn class since it transforms the data using sklearn.preprocessing.LabelBinarizer but I finally found the cause of this behaviour here:
elif (len(y.shape) == 2 and y.shape[1] == 1) or len(y.shape) == 1:
            self.classes_ = np.unique(y)
            y = np.searchsorted(self.classes_, y)
The np.searchsorted function returns the indizes of the labels so my labels are changing from [-1, 0, 1] to [0, 1, 2] before the model can train on it. Actually it sounds very reasonable to do this if the model is missing this functionality but I have two suggestions so n other people struggle need to explore this behaviour looking bewildered at their results:
As the sklearn.neural_network.MLPClassifier the classes should be stored and the predict output should be translated back to the original classes.
If you don't want to change the behaviour of the predict method (since it might affect a lot of already implemented code). You should start with a warning or add it to the documentation. That predict() returns other classes as I fed in with fit() is very confusing.
Greetings,
Thomas
phdowling commented on 4 Jul 2016 â€¢
edited
Hey! So I saw that masking for merge layers was recently introduced, however I'm getting an error when I try it:
merged_aux_and_text = merge([title_encoded_repeat, text_embedding], mode="concat")
  File "/usr/local/lib/python2.7/dist-packages/Keras-1.0.5-py2.7.egg/keras/engine/topology.py", line 1461, in merge
    name=name)
  File "/usr/local/lib/python2.7/dist-packages/Keras-1.0.5-py2.7.egg/keras/engine/topology.py", line 1123, in __init__
    self.add_inbound_node(layers, node_indices, tensor_indices)
  File "/usr/local/lib/python2.7/dist-packages/Keras-1.0.5-py2.7.egg/keras/engine/topology.py", line 543, in add_inbound_node
    Node.create_node(self, inbound_layers, node_indices, tensor_indices)
  File "/usr/local/lib/python2.7/dist-packages/Keras-1.0.5-py2.7.egg/keras/engine/topology.py", line 154, in create_node
    output_masks = to_list(outbound_layer.compute_mask(input_tensors, input_masks))
  File "/usr/local/lib/python2.7/dist-packages/Keras-1.0.5-py2.7.egg/keras/engine/topology.py", line 1330, in compute_mask
    masks = [K.ones_like(inputs[i][:-1]) if m is None else m for i, m in zip(inputs, mask)]
TypeError: list indices must be integers, not TensorVariable
This is the relevant part of the model:
text_input = Input((self.text_maxlen,), dtype="int32")
title_input = Input((self.title_maxlen,), dtype="int32")
embed = Embedding(
    input_dim=self.vocab_size, output_dim=self.text_embedding_size, mask_zero=True,
    name="word_embeddings",
    weights=init_weights
)
title_embedding = embed(title_input)
title_encoded = LSTM(self.title_lstm_size, return_sequences=False)(title_embedding)
title_encoded = Dropout(0.3)(title_encoded)
title_encoded_repeat = RepeatVector(self.text_maxlen)(title_encoded)
text_embedding = embed(text_input)
merged_aux_and_text = merge([title_encoded_repeat, text_embedding], mode="concat")
merged_text_lstm = LSTM(self.text_lstm_size, return_sequences=False)(merged_aux_and_text)
I'm trying to merge the encoded representation of some text input into each timestep of another input (usually a longer text which the first text occurs in). The behavior I'd like from the merging is to ignore those timesteps where the longer text is masked, even though the representation of the short text was merged in here. Should this work? Is there a way to do this?
Contributor
mihirparadkar commented on 9 Jan 2018
The current ZCA whitening implementation does two things that can unnecessarily worsen numerical stability and computation cost.
It explicitly forms the covariance matrix of the data before computing eigenvalues/vectors, even though all of these values can be readily calculated from the SVD of the data itself.
It explicitly forms the eigenvalues as a diagonal matrix using np.diag, while broadcasting division has the same effect and is much faster. For ImageNet images cropped to size 224x224x3 each (as an example), this means unnecessarily forming a matrix with ~22 billion elements when a ~150,000 element vector suffices and doing ~150,000 times the floating-point operations.
Linked PR: #9025
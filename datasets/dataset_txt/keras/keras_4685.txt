bkj commented on 29 Jul 2016
There's a great blog post from @fchollet that covers using pre-trained VGG16 weights in Keras here. In that post, the images are rescaled so that pixel values are in [0, 1], and do not have the VGG16 mean subtracted.
In the snippet that the vgg16_weights.h5 file is taken from, the images have pixel values in the range [0, 255] and have the VGG16 mean subtracted.
Feeding the images through at different scales and with/without centering yields different fc7 features. Is this a mistake on one side or the other? The model as used in the blog post obviously performs well despite seeming to use a different input format.
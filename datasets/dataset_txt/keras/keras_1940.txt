xcszbdnl commented on 12 Jul 2017
Hi, guys.
I'd like to train a recurrent network. However, they input and output orders are determined in real time. Also, they have different length for each sequence. For example, I have training data like this:
      y1 y2 y3 y4 y5
x1 = [1, 0, 1]
x2 = [0, 1, 0, 1]
x3 = [1, 1, 0, 0, 1]
x4 = [1, 0, 1, 1]
....
When I train a LSTM, the first input, target is determined by a function determineFirstOrder(), (e.g.x1->(y1,y2) x2->(y2,y1), x3->(y4,y5), x4->(y1,y2)...). Therefore, the input vector will be1 1 0 1..., target vector will be 0 0 1 0
The next input and output is also determined by a function determineNextOrder(), but this will take the output of the LSTM into consideration.
The question is:
How to deal with the variable length in the training data? (This may be done by mask layers. Padding the sequence is also an option, but in my case, the padding zeros will effect the LSTM state. Therefore, I'd like to use the mask layers.)
How to feed the real-time inputs and outputs into LSTM? The t-th inputs and outputs are determined by the output of the LSTM (at time t-1).
If I am missing something, please let me know I would really appreciate it!
Thanks!
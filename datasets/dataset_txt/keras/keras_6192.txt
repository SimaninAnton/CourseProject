Contributor
PiranjaF commented on 28 Dec 2015
For my current classification problem using a deep ConvNet I have a dataset of roughly 20 gb. Therefore, I need to train the ConvNet batchwise (see this example). Each observation has quite low dimensions, causing a batch of 1024 observations to only be ~100 mb. My GPU can therefore hold roughly 40 batches at the same time as it has 4gb memory.
I suspect that it would significantly reduce training time if I moved 40 batches at a time to the GPU rather than just 1 batch as done in the example. Is such functionality implemented in Keras/Theano?
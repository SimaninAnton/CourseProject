jingweimo commented on 16 Nov 2016 â€¢
edited
I am using LSTM in keras on top of theaon that is running in a desktop to train MINIST data. I post the mod.fit code:
 hist1 = model.fit(X_train, Y_train, 
              batch_size=batch_size, 
              nb_epoch=nb_epochs,
              verbose=1, 
              validation_data=(X_test, Y_test), callbacks=[earlystopper, lrate])
Implementing the code leads to the error message as follows:
Traceback (most recent call last):
File "", line 5, in
validation_data=(X_test, Y_test), callbacks=[earlystopper, lrate])
File "C:\Users\user\Anaconda2\lib\site-packages\keras\models.py", line 620, in fit
raise Exception('The model needs to be compiled before being used.')
File "C:\Users\user\Anaconda2\lib\site-packages\keras\engine\training.py", line 1104, in fit
File "C:\Users\user\Anaconda2\lib\site-packages\keras\engine\training.py", line 822, in _fit_loop
for epoch in range(nb_epoch):
File "C:\Users\user\Anaconda2\lib\site-packages\keras\backend\theano_backend.py", line 672, in call
input_shape[2] + top_pad + bottom_pad,
File "C:\Users\user\Anaconda2\lib\site-packages\theano\compile\function_module.py", line 871, in call
storage_map=getattr(self.fn, 'storage_map', None))
File "C:\Users\user\Anaconda2\lib\site-packages\theano\gof\link.py", line 314, in raise_with_op
reraise(exc_type, exc_value, exc_trace)
File "C:\Users\user\Anaconda2\lib\site-packages\theano\compile\function_module.py", line 859, in call
outputs = self.fn()
ValueError: operands could not be broadcast together with shapes (195,100) (32,100) (195,100) 
Apply node that caused the error: IncSubtensor{InplaceInc;int64}(Alloc.0, Dot22.0, Constant{-1})
Toposort index: 143
Inputs types: [TensorType(float32, 3D), TensorType(float32, matrix), Scalar(int64)]
Inputs shapes: [(784L, 195L, 100L), (32L, 100L), ()]
Inputs strides: [(78000L, 400L, 4L), (400L, 4L), ()]
Inputs values: ['not shown', 'not shown', -1]
Outputs clients: [[InplaceDimShuffle{0,1,2}(IncSubtensor{InplaceInc;int64}.0)]]
Backtrace when the node is created(use Theano flag traceback.limit=N to make it longer):
File "C:\Users\user\Anaconda2\lib\site-packages\theano\gradient.py", line 561, in grad
grad_dict, wrt, cost_name)
File "C:\Users\user\Anaconda2\lib\site-packages\theano\gradient.py", line 1324, in _populate_grad_dict
rval = [access_grad_cache(elem) for elem in wrt]
File "C:\Users\user\Anaconda2\lib\site-packages\theano\gradient.py", line 1279, in access_grad_cache
term = access_term_cache(node)[idx]
File "C:\Users\user\Anaconda2\lib\site-packages\theano\gradient.py", line 973, in access_term_cache
output_grads = [access_grad_cache(var) for var in node.outputs]
File "C:\Users\user\Anaconda2\lib\site-packages\theano\gradient.py", line 1279, in access_grad_cache
term = access_term_cache(node)[idx]
File "C:\Users\user\Anaconda2\lib\site-packages\theano\gradient.py", line 973, in access_term_cache
output_grads = [access_grad_cache(var) for var in node.outputs]
File "C:\Users\user\Anaconda2\lib\site-packages\theano\gradient.py", line 1279, in access_grad_cache
term = access_term_cache(node)[idx]
File "C:\Users\user\Anaconda2\lib\site-packages\theano\gradient.py", line 1113, in access_term_cache
input_grads = node.op.grad(inputs, new_output_grads)
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
Please make sure that the boxes below are checked before you submit your issue. Thank you!
Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps
If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps
Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
joaospinto commented on 26 Jul 2017
Hi everyone,
I hope this is an appropriate place for my question/proposal - please close this otherwise.
I've started using Keras recently at work, and for my particular use-case it seems to make more sense to use stateless RNNs during the training stage, essentially because the sequences I feed into my network are of an episodic nature; when a sequence is over, sharing its state to the first element of the next sequence would not make much sense and would introduce noise. Therefore, I implemented a generator for batches, which makes sure that separate episodes are never mixed together.
However, in the prediction stage, there is a single continuous episode (I guess because I'm using this network for a real-time problem); my intuition is that this is quite a common setting, rather than a project-specific one. Since I made my RNN stateless, I need to buffer lookahead-many inputs into a 3-dimensional numpy array with dimension (batchsize=1, lookahead, inputdim). It seems to me that it would be quite useful to have an option to change the statefulness of the RNN between these two stages (if nothing else is feasible, maybe by simply padding the tensor that is fed into the network). Would that make sense, or is it too specific a feature? I would be glad to help with it if it does.
Regards
2
How can I save and load the whole model for offline inference with examples/lstm_seq2seq.py
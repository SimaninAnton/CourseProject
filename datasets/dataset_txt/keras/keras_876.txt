stabgan commented on 19 Jul 2018
Take imdb_lstm.py from the examples folder . Can we add an attention layer and extract attention weights ? I've checked the machine translation paper an how they are doing it but that is different . I only have X-test as sentences and 1 label for each input , unlike seq2seq in nmt
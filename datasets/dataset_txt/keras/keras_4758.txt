madeofwin commented on 18 Jul 2016
Here is a simple version of what I do:
model.fit(x,y)
Epoch 1/5
60000/60000 [==============================] - 4s - loss: 0.3943 - acc: 0.8805 - val_loss: 0.0989 - val_acc: 0.9684
Epoch 2/5
60000/60000 [==============================] - 4s - loss: 0.1484 - acc: 0.9561 - val_loss: 0.0660 - val_acc: 0.9799
Epoch 3/5
60000/60000 [==============================] - 4s - loss: 0.1114 - acc: 0.9672 - val_loss: 0.0519 - val_acc: 0.9824
Epoch 4/5
60000/60000 [==============================] - 4s - loss: 0.0933 - acc: 0.9722 - val_loss: 0.0464 - val_acc: 0.9837
Epoch 5/5
60000/60000 [==============================] - 4s - loss: 0.0810 - acc: 0.9761 - val_loss: 

for layer in model.layers:
   layer.build(layer.input_shape)

model.fit(x,y)
Epoch 1/5
60000/60000 [==============================] - 4s - loss: 0.0723 - acc: 0.9782 - val_loss: 0.0372 - val_acc: 0.9858
Epoch 2/5
60000/60000 [==============================] - 4s - loss: 0.0660 - acc: 0.9810 - val_loss: 0.0376 - val_acc: 0.9874
Epoch 3/5
60000/60000 [==============================] - 4s - loss: 0.0626 - acc: 0.9818 - val_loss: 0.0349 - val_acc: 0.9878
Epoch 4/5
60000/60000 [==============================] - 4s - loss: 0.0563 - acc: 0.9831 - val_loss: 0.0336 - val_acc: 0.9885
Epoch 5/5
60000/60000 [==============================] - 4s - loss: 0.0547 - acc: 0.9838 - val_loss: 0.0311 - val_acc: 0.9901
So my expectation was that the loss starts again at approx. 0.4, but it doesn't. Instead it looks like the trained weights are still used ALTHOUGH I can compare the weights (using model.layers[i].get_weights()) from before and after applying .build() to the layers and they are clearly different (e.g. the bias vector is re-set to 0).
I'm confused about this behaviour, I guess I just have a misunderstanding of the functions I have used. Can someone please enlighten me and maybe explain how I can re-initialize the weights of my model without re-compiling it?
joelkuiper commented on 19 May 2017
I have two embedding spaces, a 128 dimensional Word2Vec embedding, and a 64 dimensional DeepWalk embedding. Both encode for some latent space of some training set. I would like to create a function that maps one space onto the other, using a data set where I know both embeddings. I have tried a MLP approach using Keras,
encode = Input(shape=(params["word_dim"], ), name="word")
encoded = Dense(64, activation="relu")(encode)
decode = Dense(params["walk_dim"], activation="sigmoid", name="walk")(encoded)

model = Model(input=encode,
              output=decode)

loss = {"walk": "mean_absolute_error"}

model.compile(loss=loss,
              optimizer="adam",
              metrics=[metrics.mae, metrics.mse])

return model
``` 

At test time, I only know the input embedding and the goal is to predict the output embedding. However, the performance is not great (stuck at mean_absolute_error: 0.5613 - mean_squared_error: 0.4970). Is this the right approach to map two spaces, or is there a better way to approach this problem?
abhijit-mudigonda commented on 1 Jun 2017
The code here:
https://github.com/tensorflow/models/tree/master/inception
trains Inceptionv3 (encoded using TF-slim) on imagenet data in tfrecords format.
In particular, it uses batch splitting to speed up training over multiple GPUs
I'm trying to modify this to accept a generic Keras model, based on
https://blog.keras.io/keras-as-a-simplified-interface-to-tensorflow-tutorial.html#calling-keras-layers-on-tensorflow-tensors
However, it seems like the logits outputted via processing through a Keras net are not quite the same format as those output by TF-slim, as I'm getting the following dimension error at the gradient computation step
ValueError: Dimension size must be evenly divisible by 1000 but is 32 for 'vgg16tower_0/gradients/vgg16tower_0/Reshape_grad/Reshape' (op: 'Reshape') with input shapes: [1,32], [2].
I don't understand why this should divide 1000 (the number of output classes), nor why the format of the output of the Keras net is different from the output of their implementation.
My code is here: https://gist.github.com/abhijit-mudigonda/2d32e2353072deeabcef1d560d56e413
To run, change data_dir in imagenet_train.py from '' to a directory containing imagenet in tfrecords format.
Contributor
sadeghmir commented on 27 Jul 2016
I'm training a single-layer LSTM with batch size 1, and the last epoch has the following output:
Epoch 1/1 22439/22439 [==============================] - 28s - loss: 902.9773
Right after this epoch (training is done), I run model.evaluate on the same data and labels and get a completely different loss value. Here is the output:
22418/22439 [============================>.] - ETA: 0s3694.0894752540389
This happens only when I set shuffle=False. Otherwise the two loss values are very close. Why is this happening? Right after evaluating, I ran fit again for a single epoch and got loss close to 900 again.
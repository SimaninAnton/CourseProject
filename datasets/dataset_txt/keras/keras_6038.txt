d07RiV commented on 29 Jan 2016
I'm training a model with Theano/CUDA, and if I attempt to specify a large batch_size (1024 in my case), it reports an out of memory error, which is understandable. However, if I change it back to a size that previously worked (I'm doing it in a notebook), it will still be out of memory, as if it didn't attempt to free whatever it allocated for the previous attempt, so I'm forced to restart the Python process (and reload all data/recompile models).
I can provide model code if needed, its on a laptop that does not have internet access currently.
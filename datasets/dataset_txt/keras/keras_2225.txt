konstantint commented on 5 Jun 2017 â€¢
edited
Consider the following example:
seq_len = 5
seq_of_int = Input((seq_len,))
seq_of_3vec = Embedding(10, 3)(seq_of_int)
seq_of_1vec = Flatten()(Embedding(10, 1)(seq_of_int))
out = Dot((0,0))([seq_of_1vec, seq_of_3vec])
m = Model(seq_of_int, out)

print(m.output_shape)
# Outputs (5,3)

print(m.predict(np.arange(5).reshape(1,-1)).shape)
# Outputs (1,3)
This seems to cause confusing bugs downstream:
other = concatenate([m(seq_of_int), Input((3,))])
# ValueError: `Concatenate` layer requires inputs with matching
#     shapes except for the concat axis. Got inputs shapes: [(5, 3), (None, 3)]
The concatenation problem occurs without using an intermediate model:
other = concatenate([out, Input((3,))])
# `Concatenate` layer requires inputs with matching shapes 
#   except for the concat axis. Got inputs shapes: [(5, 3), (None, 3)]
However if we just examine the size of out all seems fine:
out.get_shape()
# TensorShape([Dimension(None), Dimension(3)])
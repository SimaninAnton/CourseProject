siavash9000 commented on 1 Jun 2016
Hello,
I would like to create a sequence of word embeddings on character level by the usage of LSTMs and then feed this embeddings into another LSTM.
Take the String 'I want to create an embedding' as example. I want first generate a seqeuence of tokens
['I', 'want', 'to', 'create', 'an', 'embedding'], then a sequence of sequences
[ ['I'], ['w','a','n','t'], ['t','o'], ['c','r','e','a','t','e'], ['a','n'], ['e','m','b','e','d','d','i','n','g']]
Then I want to create with a LSTM a sequence of vectors
[vector_i, vector_want, vector_to, vector_create, vector_an, vector_embedding]
by feeding each word character for character into a LSTM.
Any ideas how to implement this in keras? My problem is that I dont know how to create a sequence from sequences of sequences. I thought about using the Reshape Layer, but skipped this since reshaping at batch level is not allowed.
Thanks,
Siavash
shyamupa commented on 16 Feb 2016
I am trying to implement the model specified by eqn. 7,8,9 in this paper. The idea is to encode a sequence (say x) with an LSTM having return sequences=True (call it x-encoder), then let its final hidden output initialized another LSTM which encodes another sequence y. Also, use all the sequences returned by the x-encoder in a attention model.
I think I will need to share the output of the x-encoder into two nodes (one for initializing the y-decoder, and another for the attention model). Is this possible?
MahdiKhodayar commented on 17 Apr 2017 â€¢
edited
I have implemented some layers of VGG16 applying TimeDistributed for each layer. my input shape of the first TimeDistributed is (30, 224, 224, 3). VGG16 layers are used up to the Flatten layer and after that I have Normalization layer which I expected to normalize the features of every sample (each time step) alone...but it doesn't do that !
I have 30 time steps, and each time step is a 224 * 224 image with 3 channels
Here is my code:
`
timesteps=30;
model.add(TimeDistributed(Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1'), input_shape=(timesteps,224,224,3) ))
model.add(TimeDistributed(Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')))
model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')))model.add(TimeDistributed(Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')))
model.add(TimeDistributed(Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')))
model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')))
(SOME CONV AND MAX POOLING LAYERS ... )
model.add(TimeDistributed(Flatten(name='flatten')))
model.add(TimeDistributed(Dense(3000, activation='relu')))
model.add(LeakyReLU(alpha=0.1))
model.add(BatchNormalization(axis = -1));
`
lovecambi commented on 11 Jun 2016 â€¢
edited
from keras.layers.convolutional import Convolution1D
from keras.layers import Input, Activation

input_len = 100
input_dim = 10
output_dim = 20
filter_len = 5

x = Input(shape=(input_len, input_dim))
y = Convolution1D(output_dim, filter_len, activation='softmax', border_mode='same', subsample_length=1)(x)
Just run these lines in any interactive environment, you will get the error:
Exception                                 Traceback (most recent call last)
<ipython-input-9-242185710e90> in <module>()
----> 1 y = Convolution1D(output_dim, filter_len, activation='softmax', border_mode='same', subsample_length=1)(x)

/anaconda2/lib/python2.7/site-packages/keras/engine/topology.pyc in __call__(self, x, mask)
    483         if inbound_layers:
    484             # this will call layer.build() if necessary
--> 485             self.add_inbound_node(inbound_layers, node_indices, tensor_indices)
    486             input_added = True
    487

/anaconda2/lib/python2.7/site-packages/keras/engine/topology.pyc in add_inbound_node(self, inbound_layers, node_indices, tensor_indices)
    541         # creating the node automatically updates self.inbound_nodes
    542         # as well as outbound_nodes on inbound layers.
--> 543         Node.create_node(self, inbound_layers, node_indices, tensor_indices)
    544
    545     def get_output_shape_for(self, input_shape):

/anaconda2/lib/python2.7/site-packages/keras/engine/topology.pyc in create_node(cls, outbound_layer, inbound_layers, node_indices, tensor_indices)
    146
    147         if len(input_tensors) == 1:
--> 148             output_tensors = to_list(outbound_layer.call(input_tensors[0], mask=input_masks[0]))
    149             output_masks = to_list(outbound_layer.compute_mask(input_tensors[0], input_masks[0]))
    150             # TODO: try to auto-infer shape if exception is raised by get_output_shape_for

/anaconda2/lib/python2.7/site-packages/keras/layers/convolutional.pyc in call(self, x, mask)
    165         if self.bias:
    166             output += K.reshape(self.b, (1, self.nb_filter, 1, 1))
--> 167         output = self.activation(output)
    168         output = K.squeeze(output, 3)  # remove the dummy 3rd dimension
    169         output = K.permute_dimensions(output, (0, 2, 1))

/anaconda2/lib/python2.7/site-packages/keras/activations.pyc in softmax(x)
     13     else:
     14         raise Exception('Cannot apply softmax to a tensor that is not 2D or 3D. ' +
---> 15                         'Here, ndim=' + str(ndim))
     16
     17

Exception: Cannot apply softmax to a tensor that is not 2D or 3D. Here, ndim=4
Is the reason that the conv1d operator lifts the 3D to 4D first, then applies the activation function, and finally squeezes it back to 3D? So it works for the following two-step activation. Does it mean if I want to write customized activation function, I should consider it?
z = Convolution1D(output_dim, filter_len, activation='linear', border_mode='same', subsample_length=1)(x)
y = Activation('softmax')(z)
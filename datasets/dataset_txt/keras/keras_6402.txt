Contributor
dbonadiman commented on 23 Nov 2015
This has been pointed out different times in different threads. By default Theano at each iteration updates weights for all the weights in a shared matrix. That it is not a problem in the general case.
But there is a case in which this cause problem:
take as example for instance the Embedding layer. It is a Huge matrix of weight are filtered according to the input resulting in the case of words in the sentence representation (as a matrix).
Use a second order optimisation method (Adagrad, Adadelta, RMSprop) where updates are calculated accordingly to the history of the updates.
From an optimisation point of view a 0 update on a weight means that the weight do not contribute to the final loss. But there are rare words that most of the time are not updated so from the accumulators we obtain a series of 0 updates for this word using this information to adjust the embedding of rare words lead to a near to zero weight update. The fact that a rare words do not appear in a particular instance means that the some of the weight do not contribute to the final loss because they are not connected and not because they are ok.
This problem occurs in many cases where the upper layers uses only part of the output of the previous one. Masked output, Max_pooling and Embeddings are some that for me suffer of that problem.
What do you think? Shouldn't we pass the masks to the optimisers and by doing so updating the weight using the set_subtensor method?
To Highlight this issue try to use on the examples using Word Embeddings to use first order optimisers like Adam or SGD, you will notice a much faster convergence. In other cases when you set the word embedding weights (from word2vec for instance) and then you refine them on the specific problem using second order methods you will obtain results near to the one obtained if we set the Embedding layer as not trainable. Differently with Adam you tend to obtain better result.
What do you think guys i'm understanding in the wrong way? or there is an actual problem?
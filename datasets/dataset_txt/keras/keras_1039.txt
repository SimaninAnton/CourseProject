mikelane commented on 10 May 2018 â€¢
edited
I have the following in my model description:
    conv_1 = Conv2D(self.network_channel_sizes[0], kernel_size=self.down_conv_kernel, padding='same')(up_4)
    conv_2 = Conv2D(self.network_channel_sizes[0], kernel_size=self.down_conv_kernel, padding='same')(conv_1)
    outputs = Conv2D(filters=1, kernel_size=(1, 1), strides=1, padding='same')(conv_2)
    outputs = LeakyReLU(alpha=self.leaky_alpha)(outputs)
My model summary says this:
conv2d_17 (Conv2D)              (None, 512, 512, 8)  1160        concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 512, 512, 8)  584         conv2d_17[0][0]                  
__________________________________________________________________________________________________
conv2d_19 (Conv2D)              (None, 512, 512, 1)  9           conv2d_18[0][0]                  
__________________________________________________________________________________________________
leaky_re_lu_17 (LeakyReLU)      (None, 512, 512, 1)  0           conv2d_19[0][0]                  ```
When I run the training I get this:
ValueError: Error when checking target: expected leaky_re_lu_17 to have shape (512, 512, 1) but got array with shape (512, 512, 3)
As you can see, conv2d_19 is defined with 1 filter and the leaky_re_lu_17 takes that conv2d_19 as input. In the model summary, the output shape of conv2d_19 matches with this: (None, 512, 512, 1). But when the model is actually run (verified using debug), the shape is (3, 512, 512, 3). Have I done something incorrect in my description, or is this a bug?
EDIT: this is using TF backend if that isn't obvious.
liujxing commented on 21 Apr 2017
I am trying to understand the behavior of fit_generator so that I can use it with dataset too large to fit in my memory, so I use the following generator function to imitate the behavior of fit (keras version 1.2.0):
load x_data_train and y_data_train into the memory
create a simple sequential model
define the generator function in the following way:
def generateDataFromMemory(batch_size):
    ind_row = np.random.randint(0, x_data_train.shape[0], size=batch_size)
    while True:
        x_data = x_data_train[ind_row]
        y_data = y_data_train[ind_row].reshape(-1,1)
        yield (x_data, y_data)
use the generator function in fit_generator
The fit_generator works fine with my simple toy data, but for true data, the result is totally different from using fit with the same batch_size and the same dataset: the loss either does not get better at all or generates some crazy output. In addition, the fit_generator is faster even though I expect it to be slower. To make things more weird, fit_generator is faster than fit even if I am loading dataset from hard disk with similar generator function.
I do not see any difference between this fit_generator and fit expect my generator is sampling with replacement, but I do not think it will create such a big difference in behaviour.
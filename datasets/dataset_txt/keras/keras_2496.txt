Contributor
parag2489 commented on 2 May 2017 â€¢
edited
I want to implement a triplet based loss. My network will take a triplet of images as input and at the end, will output (say) three scalars, based on which I define some kind of triplet loss. Now, a single channel of my network is quite deep, so it consumes a lot of memory.
Previously, I had defined a pair-wise loss that takes image pairs as input. For that network itself, my GPU memory usage was ~ 11 GB. Now, if I extend it to a triplet i.e. three channels of the deep CNN, I think it will surely go out of memory.
However, say that we have 8 images (not triplets) in a mini-batch. We do a forward pass to get the output of last FC layer for all 8 images. Now, we can form triplets from these 8 feature vectors and compute a loss (e.g. distance between these features). We can then back-propagate this to update the shared weights of all three channels.
My question is, how can this be done with minimal memory usage. My understanding is that when we use Model class and call the same tensor twice with different inputs, it consumes additional memory.
Edit:
So here are some numbers:
      Three channels               |     Two channels
 memory -- batchSz -- memory increase from prev. batch size
--------------------------------------------------------
      342 -- 1                     |   284 -- 1
      530 -- 2 -- +188             |   412 -- 2 -- +128
      728 -- 3 -- +198             |   550 -- 3 -- +138
      904 -- 4 -- +176             |   670 -- 4 -- +120
      .                            |   .
      .                            |   .
      .                            |   .
      5875 -- 30                   |   4114 -- 30
      9688 -- 50                   |   6755 -- 50
      Out of memory -- 60          |   10710 -- 80
Now it is not as bad as I thought. A batch size of 50 should be enough for me. However, if we do forward passes only for 8 images and then construct triplets on our own, we could reduce on time, right? Since now we do not have to compute redundant forward passes? Any thoughts on should this be done, if yes, how?
1
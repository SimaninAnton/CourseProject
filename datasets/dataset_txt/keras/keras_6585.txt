Contributor
NickShahML commented on 8 Oct 2015
Hey Keras Dev's, really appreciate what you've done.
I was reading the guide on dropout, and I saw that they usually halve their weights when using a model if they use a dropout of 0.5. I'm strictly talking about when you have finished training and using the model.predict function.
Here is the guide:
http://neuralnetworksanddeeplearning.com/chap3.html
Here is a quote from the guide:
"By repeating this process over and over, our network will learn a set of weights and biases. Of course, those weights and biases will have been learnt under conditions in which half the hidden neurons were dropped out. When we actually run the full network that means that twice as many hidden neurons will be active. To compensate for that, we halve the weights outgoing from the hidden neurons."
Does Keras automatically half the weights (or the corresponding dropout you use) when you use the model.predict function? If not, I believe it could lead to overfitting.
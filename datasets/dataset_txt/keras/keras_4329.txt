abes975 commented on 22 Sep 2016 â€¢
edited
In the documentation regarding Convolutional2D there is and example for
128x128 RGB image (3 channels) and input size is specified as
input_shape=(3, 128, 128) for 128x128 RGB pictures.
But if the image is B/W and has only one channel according to de documentation the obvious input_shape should be
input_shape=(1, 128, 128)
But as soon as I instantiate a model
from keras.models import Sequential
from keras.layers.convolutional import Convolution2D

img_rows, img_cols = 128, 128
nb_filters = 64
nb_conv = 3

model = Sequential()
model.add(Convolution2D(nb_filters, nb_conv, nb_conv,
                        border_mode='valid',
                        input_shape=(1, img_rows, img_cols)))
I got
ValueError: Filter must not be larger than the input: Filter: (3, 3) Input: (1, 128)
So it seems that the number of channel cannot be specified as first dimension in the input_shape parameter unless it is equal to the size of the kernel.
2
tik0 commented on 10 Jan 2019
[x ] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/keras-team/keras.git --upgrade --no-deps
[ x] Check that your version of TensorFlow is up-to-date. The installation instructions can be found here.
[ x] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
Using the VAE example from Keras, one can easily reproduce the effect that any metric defined in the model.compile call will not be evaluated if the loss argument is None. For instance, substituting vae.compile(optimizer='adam') in line 188 with
    def kl_loss_fun(y_true, y_pred):
        return kl_loss
    def reconstruction_loss_fun(y_true, y_pred):
        return reconstruction_loss
    vae.compile(optimizer='adam', metrics=[kl_loss_fun, reconstruction_loss])
shows no output of the metrics when fit is called.
I found out that, if compile is called, that the metrics are just skipped if the corresponding loss per output is None in line 443. Removing the conditional fixes the issue!
So the main question is, why is the calculation of the metric conditioned on the losses at all? If the user demands it explicitly it should not depend on the loss which is given in the compile call.
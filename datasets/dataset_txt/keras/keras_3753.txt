ruanxt commented on 6 Dec 2016
I'm building a variational autoencoder with convolution and deconvolution, which is modified from https://github.com/fchollet/keras/blob/master/examples/variational_autoencoder_deconv.py
And the definition of the network in my code is:
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import norm

from keras.layers import Input, Dense, Lambda, Flatten, Reshape
from keras.layers import Convolution2D, Deconvolution2D, MaxPooling2D, UpSampling2D
from keras.models import Model
from keras import backend as K
from keras import objectives

# input image dimensions
img_rows, img_cols, img_chns = 104, 104, 1
# number of convolutional filters to use
nb_filters = 16
nb_filters_1 = 8
nb_filters_2 = 4
# convolution kernel size
nb_conv = 3

batch_size = 2
if K.image_dim_ordering() == 'th':
    original_img_size = (img_chns, img_rows, img_cols)
else:
    original_img_size = (img_rows, img_cols, img_chns)
latent_dim = 2
intermediate_dim = 32
epsilon_std = 1.0
nb_epoch = 5

x = Input(batch_shape=(batch_size,) + original_img_size)
conv_1 = Convolution2D(img_chns, 2, 2, border_mode='same', activation='relu')(x)
MP_1 = MaxPooling2D((2, 2), border_mode='same')(conv_1)
conv_2 = Convolution2D(nb_filters, 2, 2,
                       border_mode='same', activation='relu',
                       subsample=(2, 2))(MP_1)
MP_2 = MaxPooling2D((2, 2), border_mode='same')(conv_2)
conv_3 = Convolution2D(nb_filters_1, nb_conv, nb_conv,
                       border_mode='same', activation='relu',
                       subsample=(1, 1))(MP_2)
MP_3 = MaxPooling2D((2, 2), border_mode='same')(conv_3)
conv_4 = Convolution2D(nb_filters_2, nb_conv, nb_conv,
                       border_mode='same', activation='relu',
                       subsample=(1, 1))(MP_3)
flat = Flatten()(conv_4)
hidden = Dense(intermediate_dim, activation='relu')(flat)

z_mean = Dense(latent_dim)(hidden)
z_log_var = Dense(latent_dim)(hidden)


def sampling(args):
    z_mean, z_log_var = args
    epsilon = K.random_normal(shape=(batch_size, latent_dim),
                              mean=0., std=epsilon_std)
    return z_mean + K.exp(z_log_var) * epsilon

# note that "output_shape" isn't necessary with the TensorFlow backend
# so you could write `Lambda(sampling)([z_mean, z_log_var])`
z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])

# we instantiate these layers separately so as to reuse them later
decoder_hid = Dense(intermediate_dim, activation='relu')
decoder_upsample = Dense(nb_filters_2 * 7 * 7, activation='relu')

if K.image_dim_ordering() == 'th':
    output_shape = (batch_size, nb_filters_2, 7, 7)
else:
    output_shape = (batch_size, 7, 7, nb_filters_2)

decoder_reshape = Reshape(output_shape[1:])
decoder_deconv_1 = Deconvolution2D(nb_filters_2, nb_conv, nb_conv,
                                   output_shape=(batch_size, 14, 14, nb_filters_2),
                                   border_mode='same',
                                   subsample=(1, 1),
                                   activation='relu')
upsampling_1 = UpSampling2D((2, 2))
decoder_deconv_2 = Deconvolution2D(nb_filters_1, nb_conv, nb_conv,
                                   output_shape=(batch_size, 56, 56, nb_filters_1),
                                   border_mode='valid',
                                   subsample=(1, 1),
                                   activation='relu')
if K.image_dim_ordering() == 'th':
    output_shape = (batch_size, nb_filters, 105, 105)
else:
    output_shape = (batch_size, 105, 105, nb_filters)
decoder_deconv_3_upsamp = Deconvolution2D(nb_filters, 2, 2,
                                          output_shape,
                                          border_mode='valid',
                                          subsample=(2, 2),
                                          activation='relu')
decoder_mean_squash = Convolution2D(img_chns, 2, 2,
                                    border_mode='valid',
                                    activation='sigmoid')

hid_decoded = decoder_hid(z)
up_decoded = decoder_upsample(hid_decoded)
reshape_decoded = decoder_reshape(up_decoded)
deconv_1_decoded = upsampling_1(decoder_deconv_1(reshape_decoded))
deconv_2_decoded = decoder_deconv_2(deconv_1_decoded)
x_decoded_relu = decoder_deconv_3_upsamp(deconv_2_decoded)
x_decoded_mean_squash = decoder_mean_squash(x_decoded_relu)

def vae_loss(x, x_decoded_mean):
    # NOTE: binary_crossentropy expects a batch_size by dim
    # for x and x_decoded_mean, so we MUST flatten these!
    x = K.flatten(x)
    x_decoded_mean = K.flatten(x_decoded_mean)
    xent_loss = img_rows * img_cols * objectives.binary_crossentropy(x, x_decoded_mean)
    kl_loss = - 0.5 * K.mean(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)
    return xent_loss + kl_loss

vae = Model(x, x_decoded_mean_squash)
vae.compile(optimizer='adadelta', loss=vae_loss)
vae.summary()
However, I got error:
Using TensorFlow backend.
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
input_1 (InputLayer)             (2, 104, 104, 1)      0                                            
____________________________________________________________________________________________________
convolution2d_1 (Convolution2D)  (2, 104, 104, 1)      5           input_1[0][0]                    
____________________________________________________________________________________________________
maxpooling2d_1 (MaxPooling2D)    (2, 52, 52, 1)        0           convolution2d_1[0][0]            
____________________________________________________________________________________________________
convolution2d_2 (Convolution2D)  (2, 26, 26, 16)       80          maxpooling2d_1[0][0]             
____________________________________________________________________________________________________
maxpooling2d_2 (MaxPooling2D)    (2, 13, 13, 16)       0           convolution2d_2[0][0]            
____________________________________________________________________________________________________
convolution2d_3 (Convolution2D)  (2, 13, 13, 8)        1160        maxpooling2d_2[0][0]             
____________________________________________________________________________________________________
maxpooling2d_3 (MaxPooling2D)    (2, 7, 7, 8)          0           convolution2d_3[0][0]            
____________________________________________________________________________________________________
convolution2d_4 (Convolution2D)  (2, 7, 7, 4)          292         maxpooling2d_3[0][0]             
____________________________________________________________________________________________________
flatten_1 (Flatten)              (2, 196)              0           convolution2d_4[0][0]            
____________________________________________________________________________________________________
dense_1 (Dense)                  (2, 32)               6304        flatten_1[0][0]                  
____________________________________________________________________________________________________
dense_2 (Dense)                  (2, 2)                66          dense_1[0][0]                    
____________________________________________________________________________________________________
dense_3 (Dense)                  (2, 2)                66          dense_1[0][0]                    
____________________________________________________________________________________________________
lambda_1 (Lambda)                (2, 2)                0           dense_2[0][0]                    
                                                                  dense_3[0][0]                    
____________________________________________________________________________________________________
dense_4 (Dense)                  (2, 32)               96          lambda_1[0][0]                   
____________________________________________________________________________________________________
dense_5 (Dense)                  (2, 196)              6468        dense_4[0][0]                    
____________________________________________________________________________________________________
reshape_1 (Reshape)              (2, 7, 7, 4)          0           dense_5[0][0]                    
____________________________________________________________________________________________________
deconvolution2d_1 (Deconvolution (2, 14, 14, 4)        148         reshape_1[0][0]                  
____________________________________________________________________________________________________
upsampling2d_1 (UpSampling2D)    (2, 28, 28, 4)        0           deconvolution2d_1[0][0]          
____________________________________________________________________________________________________
deconvolution2d_2 (Deconvolution (2, 56, 56, 8)        296         upsampling2d_1[0][0]             
____________________________________________________________________________________________________
deconvolution2d_3 (Deconvolution (2, 105, 105, 16)     528         deconvolution2d_2[0][0]          
____________________________________________________________________________________________________
convolution2d_5 (Convolution2D)  (2, 104, 104, 1)      65          deconvolution2d_3[0][0]          
====================================================================================================
Total params: 15574
____________________________________________________________________________________________________
('x_train.shape:', (40, 104, 104, 1))
('x_test.shape:', (10, 104, 104, 1))
Traceback (most recent call last):
 File "/home/ruanxt/tests/code/conv_variational_autoencoder.py", line 159, in <module>
   validation_data=(x_test, x_test))
 File "/usr/local/lib/python2.7/dist-packages/keras/engine/training.py", line 1083, in fit
   self._make_train_function()
 File "/usr/local/lib/python2.7/dist-packages/keras/engine/training.py", line 696, in _make_train_function
   self.total_loss)
 File "/usr/local/lib/python2.7/dist-packages/keras/optimizers.py", line 310, in get_updates
   grads = self.get_gradients(loss, params)
 File "/usr/local/lib/python2.7/dist-packages/keras/optimizers.py", line 62, in get_gradients
   grads = K.gradients(loss, params)
 File "/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py", line 1121, in gradients
   return tf.gradients(loss, variables, colocate_gradients_with_ops=True)
 File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients.py", line 500, in gradients
   in_grad.set_shape(t_in.get_shape())
 File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py", line 405, in set_shape
   self._shape = self._shape.merge_with(shape)
 File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/tensor_shape.py", line 570, in merge_with
   (self, other))
ValueError: Shapes (2, 52, 52, 8) and (2, 56, 56, 8) are not compatible

Process finished with exit code 1
Does this mean we can not specify the output shape in the Deconvolution2D layer? could anyone tell me how to make it work? Thanks!
Please make sure that the boxes below are checked before you submit your issue. Thank you!
[X ] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps
[ X] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps
[X ] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
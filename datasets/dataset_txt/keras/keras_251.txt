Sawatdatta commented on 1 May 2019
Using following code to start training. 1st training and validation epoch completes successfully, but on second epoch it runs out of data and shows following error
the training is started using :
model.fit_generator(generator=datagen.next_train(), steps_per_epoch=datagen.samples_per_train//args.batch_size, epochs=nb_epoch,
                            validation_data=datagen.next_valid(), use_multiprocessing=False, workers=1,
                            validation_steps=datagen.samples_per_valid//args.batch_size, callbacks=[checkpointer, tbpointer])
** skipping intermediate output
Epoch 1/10
1/212 [..............................] - ETA: 1:21:20 - loss: 143.2768
2/212 [..............................] - ETA: 1:10:25 - loss: 93.7193
3/212 [..............................] - ETA: 1:06:34 - loss: 71.4400
4/212 [..............................] - ETA: 1:05:54 - loss: 58.9247
.
.
.
208/212 [============================>.] - ETA: 1:06 - loss: 2.9934
209/212 [============================>.] - ETA: 49s - loss: 2.9845
210/212 [============================>.] - ETA: 33s - loss: 2.9757
211/212 [============================>.] - ETA: 16s - loss: 2.9671
1/16 [>.............................] - ETA: 4:01 - loss: 1.3382
2/16 [==>...........................] - ETA: 3:16 - loss: 1.3387
3/16 [====>.........................] - ETA: 2:53 - loss: 1.3386
4/16 [======>.......................] - ETA: 2:35 - loss: 1.3387
5/16 [========>.....................] - ETA: 2:20 - loss: 1.3386
6/16 [==========>...................] - ETA: 2:06 - loss: 1.3387
7/16 [============>.................] - ETA: 1:52 - loss: 1.3387
8/16 [==============>...............] - ETA: 1:39 - loss: 1.3387
9/16 [===============>..............] - ETA: 1:26 - loss: 1.3388
10/16 [=================>............] - ETA: 1:14 - loss: 1.3388
11/16 [===================>..........] - ETA: 1:01 - loss: 1.3388
12/16 [=====================>........] - ETA: 49s - loss: 1.3388
13/16 [=======================>......] - ETA: 36s - loss: 1.3388
14/16 [=========================>....] - ETA: 24s - loss: 1.3388
15/16 [===========================>..] - ETA: 12s - loss: 1.3389
16/16 [==============================] - 196s 12s/step - loss: 1.3389
Epoch 00001: val_loss improved from inf to 1.33886, saving model to F:/Implementation/Rtip2r_Conference18/siamese/signet_distance/weights_ep10all_feat_MCYT75.hdf5
WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).
212/212 [==============================] - 3708s 17s/step - loss: 2.9584 - val_loss: 1.3389
Epoch 2/10
1/212 [..............................] - ETA: 57:44 - loss: 1.10902019-05-01 11:46:17.042840: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 455.84MiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-05-01 11:46:17.112554: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 455.84MiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
Traceback (most recent call last):
File "F:/Implementation/Rtip2r_Conference18/siamese/signet_distance/SigNet_stat_measures_more_MCYT.py", line 522, in
main(args)
File "F:/Implementation/Rtip2r_Conference18/siamese/signet_distance/SigNet_stat_measures_more_MCYT.py", line 482, in main
validation_steps=datagen.samples_per_valid//args.batch_size, callbacks=[checkpointer, tbpointer]) # KERAS 2
File "F:\stable\lib\site-packages\tensorflow\python\keras\engine\training.py", line 1426, in fit_generator
initial_epoch=initial_epoch)
File "F:\stable\lib\site-packages\tensorflow\python\keras\engine\training_generator.py", line 191, in model_iteration
batch_outs = batch_function(*batch_data)
File "F:\stable\lib\site-packages\tensorflow\python\keras\engine\training.py", line 1179, in train_on_batch
self, x, y, sample_weights=sample_weights)
File "F:\stable\lib\site-packages\tensorflow\python\keras\engine\training_eager.py", line 260, in train_on_batch
model, inputs, targets, sample_weights=sample_weights, training=True)
File "F:\stable\lib\site-packages\tensorflow\python\keras\engine\training_eager.py", line 214, in _process_single_batch
training=training)
File "F:\stable\lib\site-packages\tensorflow\python\keras\engine\training_eager.py", line 106, in _model_loss
outs, masks = model._call_and_compute_mask(inputs, **kwargs)
File "F:\stable\lib\site-packages\tensorflow\python\keras\engine\network.py", line 826, in _call_and_compute_mask
mask=masks)
File "F:\stable\lib\site-packages\tensorflow\python\keras\engine\network.py", line 1024, in _run_internal_graph
output_tensors = layer(computed_tensors, **kwargs)
File "F:\stable\lib\site-packages\tensorflow\python\keras\engine\base_layer.py", line 592, in call
outputs = self.call(inputs, *args, **kwargs)
File "F:\stable\lib\site-packages\tensorflow\python\keras\layers\core.py", line 743, in call
return self.function(inputs, **arguments)
File "F:/Implementation/Rtip2r_Conference18/siamese/signet_distance/SigNet_stat_measures_more_MCYT.py", line 211, in robust_embedding_all
iqr_list_a = tf.reshape(iqr_list_a, [args.batch_size, 1])
File "F:\stable\lib\site-packages\tensorflow\python\ops\gen_array_ops.py", line 8444, in reshape
tensor, shape, name=name, ctx=_ctx)
File "F:\stable\lib\site-packages\tensorflow\python\ops\gen_array_ops.py", line 8489, in reshape_eager_fallback
ctx=_ctx, name=name)
File "F:\stable\lib\site-packages\tensorflow\python\eager\execute.py", line 66, in quick_execute
six.raise_from(core._status_to_exception(e.code, message), None)
File "", line 3, in raise_from
tensorflow.python.framework.errors_impl.InvalidArgumentError: Input to reshape is a tensor with 18 values, but the requested shape has 64 [Op:Reshape]
datagen.samples_per_train =13650
batch size=64
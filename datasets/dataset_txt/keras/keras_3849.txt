cbdbdd commented on 23 Nov 2016
i know theano backend actually creates gradient function for the backpropogation mechamism and the forward pass is also a function for the gradient. the forward pas functions inputs are actually placeholders not really real numbers. so one can only get layers activations after training by k.function and inputs real numbers into it. however since on each training batch there must have real numbers inputs flows back and forth in the gpu calculations for the backpropogation to work then why cannot get the layers activations on traning using callback fuction in theano backend?
appreciates!
Please make sure that the boxes below are checked before you submit your issue. Thank you!
Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps
If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps
Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
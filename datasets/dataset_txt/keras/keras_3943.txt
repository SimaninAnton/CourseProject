jaromiru commented on 11 Nov 2016
I have a code with a dense layer as follows:
Dense(256, activation='relu')
Training over 60000 samples takes consistently 1 second on my CPU:
Epoch 1/50
60000/60000 [==============================] - 1s - loss: 0.5521 - acc: 0.8262 - val_loss: 0.3253 - val_acc: 0.8936
Epoch 2/50
60000/60000 [==============================] - 1s - loss: 0.2314 - acc: 0.9296 - val_loss: 0.1808 - val_acc: 0.9463
...
Epoch 26/50
60000/60000 [==============================] - 1s - loss: 0.0545 - acc: 0.9829 - val_loss: 0.0756 - val_acc: 0.9762
However, when I add an L2 regularizer as follows:
Dense(256, activation='relu', W_regularizer=l2(0.01))
the performance gradually drops, so one epoch takes 12 secods, as shown below:
Epoch 1/1000
60000/60000 [==============================] - 1s - loss: 2.6633 - acc: 0.7988 - val_loss: 0.3473 - val_acc: 0.9012
Epoch 2/1000
60000/60000 [==============================] - 1s - loss: 1.2643 - acc: 0.9043 - val_loss: 0.2925 - val_acc: 0.9180
Epoch 3/1000
60000/60000 [==============================] - 1s - loss: 0.8831 - acc: 0.9161 - val_loss: 0.2495 - val_acc: 0.9312
Epoch 4/1000
60000/60000 [==============================] - 1s - loss: 0.6981 - acc: 0.9213 - val_loss: 0.2421 - val_acc: 0.9341
Epoch 5/1000
60000/60000 [==============================] - 4s - loss: 0.6022 - acc: 0.9233 - val_loss: 0.2288 - val_acc: 0.9367
Epoch 6/1000
60000/60000 [==============================] - 4s - loss: 0.5395 - acc: 0.9274 - val_loss: 0.2283 - val_acc: 0.9334
Epoch 7/1000
60000/60000 [==============================] - 3s - loss: 0.4988 - acc: 0.9305 - val_loss: 0.2239 - val_acc: 0.9349
Epoch 8/1000
60000/60000 [==============================] - 3s - loss: 0.4696 - acc: 0.9318 - val_loss: 0.2563 - val_acc: 0.9171
Epoch 9/1000
60000/60000 [==============================] - 6s - loss: 0.4422 - acc: 0.9350 - val_loss: 0.1977 - val_acc: 0.9431
Epoch 10/1000
60000/60000 [==============================] - 10s - loss: 0.4252 - acc: 0.9360 - val_loss: 0.1866 - val_acc: 0.9490
Epoch 11/1000
60000/60000 [==============================] - 12s - loss: 0.4076 - acc: 0.9362 - val_loss: 0.2847 - val_acc: 0.9059
Epoch 12/1000
60000/60000 [==============================] - 12s - loss: 0.3934 - acc: 0.9393 - val_loss: 0.2038 - val_acc: 0.9373
Epoch 13/1000
60000/60000 [==============================] - 12s - loss: 0.3794 - acc: 0.9412 - val_loss: 0.2041 - val_acc: 0.9390
Epoch 14/1000
60000/60000 [==============================] - 11s - loss: 0.3694 - acc: 0.9419 - val_loss: 0.1956 - val_acc: 0.9395
Epoch 15/1000
60000/60000 [==============================] - 11s - loss: 0.3602 - acc: 0.9433 - val_loss: 0.2088 - val_acc: 0.9381
...
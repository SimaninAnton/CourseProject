MaxHoefl commented on 10 Aug 2016
Hi,
my problem is related to #1624.
I have the following model for a binary classification task.
The dataset has N observations of 40-dimensional inputs. They are first fed into 120-dim LSTM layer which in turn passes its hidden units on to several TimeDistributedDense layers until it reaches a sigmoid layer.
I present the training data X_train as N x 1 x 40 dimensional array and the labels (0/1) as
N x 1 x 1 array. This is my code (the dropout layers were neglected in the chart above):
model = Sequential()
model.add(LSTM(120, input_shape=(None, X_train.shape[2]), 
return_sequences=True, consume_less='gpu'))
model.add(TimeDistributed(Dense(50, activation='relu')))
model.add(Dropout(0.2))
model.add(TimeDistributed(Dense(20, activation='relu')))
model.add(Dropout(0.2))
model.add(TimeDistributed(Dense(10, activation='relu')))
model.add(Dropout(0.2))
model.add(TimeDistributed(Dense(3, activation='relu')))
model.add(TimeDistributed(Dense(1, activation='sigmoid')))
As the labels are highly imbalanced, I passed class weights to fit
model.fit(X_train, y_train, nb_epoch=num_epoch, batch_size=batch_size, verbose=0, shuffle=False, callbacks=[epochPrint], class_weight=class_weights)
where class_weights={0: 1, 1: 25}.
I am getting an error: class_weight not supported for 3+ dimensional targets.
Now @fchollet answered to the issues stated above that "The concept of 'class' is ill-defined is that case (3D labels)". But when I present the labels as a N x 1 array, e.g. [0,0,1,1,0,0,...], I get the exception Error when checking model target: expected timedistributed_5 to have 3 dimensions, but got array with shape (5932720, 1).
I have a bad feeling that I misunderstood how the LSTM layer works. I appreciate any help!
Best regards,
Max
3
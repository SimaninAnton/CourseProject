sjebbara commented on 15 Mar 2016
Hi,
I am currently experiencing the issue that I cannot use a Sequential() container as the argument to the TimeDistributed() layer. See the dummy script below:
 1: input_size = 2
 2: dense_size = 10
 3:
 4: model = Graph()
 5: model.add_input(name="input_sequence", input_shape=(0, input_size))
 6:
 7: scorer = containers.Sequential()
 8: scorer.add(Dense(dense_size, input_dim=input_size, activation="relu"))
 9:
10: distributed = TimeDistributed(scorer)
11: 
12: model.add_node(distributed, name="dense", input="input_sequence")
13: ...
An error is thrown when adding the TimeDistributed layer to the model (line 12 in this example):
Using Theano backend.
Traceback (most recent call last):
  File ".../src/KerasError.py", line 21, in <module>
    model.add_node(distributed, name="dense", input="input_sequence")
  File ".../keras/layers/containers.py", line 444, in add_node
    layer.set_previous(self.inputs[input])
  File ".../keras/layers/core.py", line 151, in set_previous
    self.build()
  File ".../keras/layers/wrappers.py", line 47, in build
    self.layer.set_input_shape(child_input_shape)
  File ".../keras/layers/core.py", line 222, in set_input_shape
    self.input = K.placeholder(shape=self._input_shape)
AttributeError: can't set attribute
However, it does work when I put the Dense() layer directly into the TimeDistributed Layer.
I guess the error has something to do with self.input of the Layer already being assigned (?!).
I have to note that I use a forked Keras repository with a few changes for my work but none at the relevant locations.
Simply switching to TimeDistributedDense() is not an option since I want to distribute more complicated combinations of layers than a simple Dense() layer.
Am I missing something about the order in which to add the models or about providing dimensionalities?
TillLindemann commented on 25 Jan 2018
environment:
   latest keras version,
   latest tensorflow version,
   python3.6,
   ubuntu17.10
problems:
I want to add a dropout layer to my functional model and I didn't see any examples,so I don't know how to do it.
below is my code:
house_input = Input(shape=(None,None,33),dtype='float32')
house_middle = LSTM(units,return_sequences = True,activation=self.activation_f,kernel_initializer=self.initializer)(house_input)
house_output = LSTM(units,return_sequences = True,activation=self.activation_f,kernel_initializer=self.initializer)(house_middle)
#dropout layer should be added here.
finale_output = Dense(1)(house_output)
model =Model(inputs=house_input,outputs=finale_output)
some explanations about my code:
I want to build a multi-layer RNN(LSTM Cell),the data coming in is the shape of (batch_size,timesteps,33).
where to add:
I want to add to the second LSTM layer BELOW,How I suppose to do it?
Any suggestions will be appreciated!
Thanks
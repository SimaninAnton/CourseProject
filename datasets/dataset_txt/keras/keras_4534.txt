Contributor
carlthome commented on 24 Aug 2016 â€¢
edited
I suppose I'm missing something obvious but the progress bar reports a much higher training loss than validation loss when the data is the same. Why is that? Shouldn't they be pretty much the same?
With split data (80/20, for example) everything looks fine, with a slightly worse validation loss than training loss, as expected.
jinpoon commented on 7 Mar 2017
Below is the code for model definition:
model = Sequential()
model.add(LSTM(200, return_sequences=True, input_shape=(timestep, n)))
model.add(LSTM(200))
model.add(Dense(output_dim=88, activation='sigmoid'))
sgd = SGD(lr=0.001, decay=1e-6, clipnorm=5., momentum=0.9)
model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['fmeasure'])
The model input x_train is a 3D matrix of shape (batch_number, timestep, n), where n is the dimension of the sequences. And I divided the ground truth label y_train into a 3D matrix of shape (batch_number, timestep, 88), where 88 is the dimension of the label. However it threw an execption:
Error when checking model target: expected dense_1 to have 2 dimensions, but got array with shape (batch_number, timestep, 88)
It's bit confusing because in my work, each sequence corresponds to a label vector, but in Keras, it seems no way to fit the label matrix into the LSTM layer.
Any help would be appreciated. Thank you.
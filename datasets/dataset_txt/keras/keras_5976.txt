AntreasAntoniou commented on 10 Feb 2016
Hello guys,
I've been trying to build an attention-based model using a CNN and an LSTM. Basically I want the LSTM to be able to select whichever slice it likes from the last layer of my CNN which is of size (512, 3, 3), so that each input will be of input 128, 3, 3 (using top 128 choices) transformed to 128, 9 for the LSTM. Now I thought of using an LSTM for the computations and one LSTM/Dense for selecting the slice and then sending the result as a softmax and the top results used as the slices. There is the possibility of using a Merge layer with mode='mul' but then I would have to have a matrix of the same dimensions which would not be very efficient. Is there any other ways around this in keras? Please let me know.
Edit: I have looked into LamdaLayers, which may help. And also I thought of sending a node with 128 outputs as an input to my LSTM along with the conv outputs in hope that it will learn what each corresponds to. However I am open to any other hacks you guys may have come accross.
7
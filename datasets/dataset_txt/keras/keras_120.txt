amitgupta911 commented on 15 Jul 2019 â€¢
edited
I am trying to create a sequence to sequence model using keras. Here is the architecture which we are following.I am Running my code on Google Colab.
number of samples =1000
input_vocab_size=2347
target_vocab_size=2376
This is the code I'm running:
## create an encoder architecture
encoder_input=Input(shape=(None,))
encoder_embeddings=Embedding(input_dim=input_vocab_size,output_dim=128,name='encoder_embedding')
encoder_gru_1=GRU(512,name="encoder_gru_1",return_sequences=True)
encoder_gru_2=GRU(512,name="encoder_gru_2",return_sequences=True)
encoder_gru_3=GRU(512,name="encoder_gru_3",return_sequences=False)

def Create_Encoder():
  #Here we will use functional api of keras
  net=encoder_input
  net=encoder_embeddings(net)
  ## not need to connect GRU units
  net=encoder_gru_1(net)
  net=encoder_gru_2(net)
  net=encoder_gru_3(net)
  return net

  
##Now create decoder architecture
decoder_initial_state=Input(shape=(512,),name="decoder_initial_state")
decoder_input=Input(shape=(None,),name="decoder_input")
decoder_embeddings=Embedding(input_dim=target_vocab_size,output_dim=128,name='decoder_embedding')
decoder_gru_1=GRU(512,name="decoder_gru_1",return_sequences=True)
decoder_gru_2=GRU(512,name="decoder_gru_2",return_sequences=True)
decoder_gru_3=GRU(512,name="decoder_gru_3",return_sequences=True)
decoder_dense=Dense(target_vocab_size,activation="linear")

def Create_Decoder(initial_state):
  #Here we will use functional api of keras
  net=decoder_input
  net=decoder_embeddings(net)
  ## not need to connect GRU units
  net=decoder_gru_1(net,initial_state=initial_state)
  net=decoder_gru_2(net,initial_state=initial_state)
  net=decoder_gru_3(net,initial_state=initial_state)
  net=decoder_dense(net)  
  return net
  
##Create a Training Model
encoder_output=Create_Encoder()
decoder_output=Create_Decoder(encoder_output)
model_train=Model(inputs=[encoder_input,decoder_input],outputs=[decoder_output])
Then i tried compiling the model
model_train.compile(optimizer=optimizer, loss=KL.sparse_categorical_crossentropy,metrics=['acc'],target_tensors=[decoder_target])
model_train.summary()
And this is the summary i got:
But Getting this error while fitting it.
model_train.fit([encoder_input_data, decoder_input_data],np.expand_dims(decoder_target_data, -1),
          batch_size=32,
          epochs=20,
          validation_split=0.3,callbacks=callbacks)
InvalidArgumentError: 2 root error(s) found.
(0) Invalid argument: Incompatible shapes: [6560] vs. [32,206]
[[{{node metrics/acc/Equal}}]]
[[loss/mul/_123]]
(1) Invalid argument: Incompatible shapes: [6560] vs. [32,206]
[[{{node metrics/acc/Equal}}]]
0 successful operations.
0 derived errors ignored.
But if change the batch size as 640 i am getting other issue as-
ResourceExhaustedError: 2 root error(s) found.
(0) Resource exhausted: OOM when allocating tensor with shape[640,206,2376] and type bool on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
[[{{node training_1/RMSprop/gradients/loss_1/dense_2_loss/clip_by_value/Minimum_grad/LessEqual}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
metrics_1/acc/Mean/_251
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
(1) Resource exhausted: OOM when allocating tensor with shape[640,206,2376] and type bool on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
[[{{node training_1/RMSprop/gradients/loss_1/dense_2_loss/clip_by_value/Minimum_grad/LessEqual}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
0 successful operations.
0 derived errors ignored.
If anyone is having solution,please help on the same.
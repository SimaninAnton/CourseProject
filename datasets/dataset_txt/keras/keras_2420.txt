diwadd commented on 11 May 2017
Hi,
I'm not sure but the documentation about categorical_crossentropy seems to be not compatible with the tensorflow one.
I mean just had a look at the documentation about loss functions i. e.
https://keras.io/losses/#available-loss-functions
and at the end there is a note about the categorical_crossentropy.
There is such a sentence:
"Note: when using the categorical_crossentropy loss, your targets should be in categorical format (e.g. if you have 10 classes, the target for each sample should be a 10-dimensional vector that is all-zeros expect for a 1 at the index corresponding to the class of the sample)."
So I understand that the only possible target is e.g. [0, 0, 1, 0, 0]?
But in the tensorflow documentation about softmax_cross_entropy_with_logits we have (https://www.tensorflow.org/api_docs/python/tf/nn/softmax_cross_entropy_with_logits)
"While the classes are mutually exclusive, their probabilities need not be. All that is required is that each row of labels is a valid probability distribution."
which I understand means that such a target is possible [0.0, 0.75, 0.25, 0.0, 0.0]?
categorical_crossentropy is defined in https://github.com/tensorflow/tensorflow/blob/r1.1/tensorflow/contrib/keras/python/keras/backend.py and indeed returns softmax_cross_entropy_with_logits.
Am I missing something (if yes then I'm really sorry)?
Best wishes
Dawid
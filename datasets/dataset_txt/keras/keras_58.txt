maurera commented on 19 Sep 2019 â€¢
edited
System information
Have I written custom code (as opposed to using example directory): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
TensorFlow backend (yes / no): yes
TensorFlow version: 1.14.0
Keras version: 2.2.5
Python version: 3.7.3
CUDA/cuDNN version: unknown
GPU model and memory: unknown
Describe the current behavior
I run mnist_cnn.py from the examples folder and save the model at the end using model.save('model_mnist.h5') . I then sequentially load the model and run model.predict() on a test set. Each sequential call takes longer than the previous and total memory usage increases.
Describe the expected behavior
I would expect each sequential call to take a similar amount of time and memory to remain approximately the same.
Code to reproduce the issue
Start with keras/examples/mnist_cnn.py and append the following:
model.save('model_mnist.h5')

from keras.models import load_model
from time import time
import os, psutil
def print_memory_usage():
    process = psutil.Process(os.getpid())
    print(process.memory_info().rss)  # in bytes

for _ in range(10):

    # load model from file
    model = load_model('model_mnist.h5')

    # get predictions
    start = time()
    y_pred = model.predict(x_test)
    print(f'Predict timing: {time()-start:.2f}s')
    print_memory_usage()

    # clean up
    del model
aluminumbox commented on 28 Sep 2018 â€¢
edited
If I only have keras layer, I know that I can use layer.trainable=False. However, I also have a pretrained tensorflow model, and I don't want to change the parameter. What I want to achieve is as follows:
g = tf.Graph()
with g.as_default()

    ## this is the pretrain tensorflow model, and I don't want to change the parameters
    with tf.variable_scope('pretrain'):
        saver = tf.train.import_meta_graph(xxxx)
        saver.restore(sess, tf.train.latest_checkpoint(xxxx))
    tf_input = g.get_tensor_by_name('input')
    tf_output = g.get_tensor_by_name('output')

    ## this is my keras model that I want to optimize
    with tf.variable_scope('train'):
        keras_output = Dense(xxx)(tf_output)

## how to specify the trainable variable in Keras?
## I don't want to use sess.run(opt) because I want to save it as a keras model, 
## which is easier to use in inference stage.
opt = tf.train.AdamOptimizer().minimize(var_list='train')
model = Model(tf_input, keras_output)
model.compile(xxx, optimizer = opt)
How to specify the trainable variable when I have a pretrain model?
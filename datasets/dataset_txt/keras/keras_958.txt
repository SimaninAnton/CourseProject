captain-pool commented on 15 Jun 2018 â€¢
edited
The issue is posted on StackOverflow. Can anyone help me solve the problem?? Thank You.
GRU Network in keras as GAN Throws Value Error
Issue:
I am trying to build a GAN network using 2 Layers of GRU as Discriminator and Generator. I have built my code based on the following codes of https://github.com/keras-team/keras-contrib/blob/master/examples/improved_wgan.py for GAN and https://github.com/keras-team/keras/blob/master/examples/lstm_text_generation.py. However am running into a problem as soon as I initiate the training process of discriminator.
The error is thrown on this line.
https://github.com/captain-pool/Deep_GRU_GAN/blob/master/IWRNNGAN.py#L129
Traceback (most recent call last):
  File "/home/rick/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 2327, in get_attr
    c_api.TF_OperationGetAttrValueProto(self._c_op, name, buf)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Operation 'loss_1/sequential_2_loss_2/gradients/sequential_2_3/gru_3/while/TensorArrayReadV3/Enter_1_grad/b_acc_3' has no attr named '_XlaCompile'.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/rick/.local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py", line 380, in _MaybeCompile
    xla_compile = op.get_attr("_XlaCompile")
  File "/home/rick/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 2331, in get_attr
    raise ValueError(str(e))
ValueError: Operation 'loss_1/sequential_2_loss_2/gradients/sequential_2_3/gru_3/while/TensorArrayReadV3/Enter_1_grad/b_acc_3' has no attr named '_XlaCompile'.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "train.py", line 3, in <module>
    from IWRNNGAN import RNNGAN
  File "/home/rick/Desktop/Deep_GRU_GAN/IWRNNGAN.py", line 137, in <module>
    r.train()
  File "/home/rick/Desktop/Deep_GRU_GAN/IWRNNGAN.py", line 129, in train
    d_loss=self.discriminator.train_on_batch([y,np.random.uniform(size=[self.batch_size,self.d.X.shape[1],self.d.X.shape[2]])],[positive_y,negs,dummy])
  File "/home/rick/.local/lib/python3.6/site-packages/keras/engine/training.py", line 1219, in train_on_batch
    self._make_train_function()
  File "/home/rick/.local/lib/python3.6/site-packages/keras/engine/training.py", line 497, in _make_train_function
    loss=self.total_loss)
  File "/home/rick/.local/lib/python3.6/site-packages/keras/legacy/interfaces.py", line 91, in wrapper
    return func(*args, **kwargs)
  File "/home/rick/.local/lib/python3.6/site-packages/keras/optimizers.py", line 445, in get_updates
    grads = self.get_gradients(loss, params)
  File "/home/rick/.local/lib/python3.6/site-packages/keras/optimizers.py", line 78, in get_gradients
    grads = K.gradients(loss, params)
  File "/home/rick/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py", line 2703, in gradients
    return tf.gradients(loss, variables, colocate_gradients_with_ops=True)
  File "/home/rick/.local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py", line 494, in gradients
    gate_gradients, aggregation_method, stop_gradients)
  File "/home/rick/.local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py", line 636, in _GradientsHelper
    lambda: grad_fn(op, *out_grads))
  File "/home/rick/.local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py", line 385, in _MaybeCompile
    return grad_fn()  # Exit early
  File "/home/rick/.local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py", line 636, in <lambda>
    lambda: grad_fn(op, *out_grads))
  File "/home/rick/.local/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_grad.py", line 155, in _ExitGrad
    raise TypeError("Second-order gradient for while loops not supported.")
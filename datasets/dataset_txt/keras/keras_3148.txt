daynebatten commented on 23 Feb 2017 â€¢
edited
Suppose I want to train a stateful RNN and I have two samples. For the first, I have 100 observations - 100 X values and 100 Y values to train on. For the second, I have 200 observations - 100 X values and 100 Y values to train on.
I set up a stateful RNN with a batch size of 2. I start training on batches of 2. All is well and good for the first 100 batches. But what happens on the 101st? My batch size really needs to be 1 at this point, but I don't believe I can just change the batch size mid-training.
Is masking intelligent enough to handle this situation? So, suppose I pad my first observation with 100 sets of zeros at the beginning of my X series. I also pad its Y series with 100 zeros. I use a masking layer to mask zeros from the input data. I know masking will prevent information from the X series from being used, but will it also prevent the model from doing anything with the dummy Y values?
I suppose it would also be possible to use a batch size of 1 throughout and simply reset the model state when I'm ready to switch samples. Is there any downside to doing so (other than a little more coding overhead)?
Is there another best practice for this?
I hope I have explained this well.
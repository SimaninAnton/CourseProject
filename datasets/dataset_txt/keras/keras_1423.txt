UsoHolger commented on 7 Dec 2017
Yes I know sounds like I did not do my research but I really tried during the last two days and still did not find the answer myself.
I am using a simple train_test_split to train a model with validation_fit (keras model.fit parameter) of 0.2. With my current understanding that should mean keras holds the last 20% of the training data back for validation at the end of every epoch. The validation data should not be used for training.
What I am encountering is, the validation accuracy is consistently higher than the accuracy during training. Well that might be because parts of the network are disabled for training. At the end of training val_acc reaches close to 1. But after the training is done I am testing the model on my test data from train_test_split which gives me a much worse accuracy of about 0.65. How can the validation accuracy be so much better, if the model does not use the validation data for training? I have even seen examples where people use the test data for validation, which in my case would give completely wrong results of close to 1 while the real generalized accuracy is around 0.65.
What am I missing here? Would love to show my code but that's not too easy because it is all wrapped in my own classes for database access and image manipulation. So before I rewrite that to make it presentable I'd like to know if there is some obvious mistake in my train of thought first.
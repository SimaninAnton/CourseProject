dnola commented on 20 Nov 2016 â€¢
edited
I have tried to reproduce several of Caffe's example codes, but the accuracy in Keras consistently seems to fall a few percent behind with the convolutional architectures. For example, here is a slightly modified version of Caffe's cifar10_quick prototxt, with the lr_mult stuff removed, and a step lr function:
https://gist.github.com/dnola/459e0ab043b22e8dd93234b26eb66e24
I use the CIFAR data that Caffe downloads for you, and I use Caffe's compute_image_mean script to generate a mean file - just like in their example.
And here is Keras code that, near as I can tell, is identical:
https://gist.github.com/dnola/538aa2cba85a20287dd68d1a5333674f
The Caffe code consistently gets above a 76% accuracy (typically around 76.5%), while the Keras code consistently gets below a 76% accuracy. In fact, in about a dozen trials, the best Keras result I got fell short of the worst Caffe result I got.
It is admittedly a small difference, but very important when trying to reproduce or beat the state of the art. I have had this same issue with a reproduction of the Caffe example cifar10_full code, and the network in network example code - every time falling a few percent shy.
One thought might be that Caffe rolls its softmax and loss into a single layer (http://caffe.berkeleyvision.org/doxygen/classcaffe_1_1SoftmaxWithLossLayer.html#details), but I doubt numerical instability is the issue. Any ideas what might be going on? Alternatively, any Keras code that can reliably reproduce any of Caffe's CIFAR-10 examples would be appreciated, if there is something I am missing.
I am on the latest development version of Keras, and I am using the Tensorflow backend (version 0.11.0rc1), though I get the same sub-76% results with Theano.
Thanks!
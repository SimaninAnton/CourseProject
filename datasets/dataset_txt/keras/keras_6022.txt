dragon271828 commented on 1 Feb 2016
I'm trying to replicate Alex Graves' paper: http://arxiv.org/pdf/1308.0850v5.pdf
The part with handwriting generation, I'm having trouble defining the objective function as a function of y_true and y_pred. In the paper, y_true takes the form of a 3-tuple and y_pred takes the form of a (e, {w_i, mu_i, sigma_i, rho_i}) where w_i, mu_i, sigma_i, and rho_i are the parameterization of the Gaussian mixture and e_i is the probability of whether the pen is down or not.
First off, y_true and y_pred have different dimensions, is that allowed?
Secondly, the different elements of y_pred must be treated individually in the custom loss function. So for instance let's say that there's two Gaussians in the mixture so that the dimension of y_pred is 9. Then the loss function will use all these individual components and do something different with each of them as shown on page 20 of the reference paper above
e = y_pred[0]
w1 = y_pred[1]
mu1 = y_pred[2]
sigma1 = y_pred[3]
rho1 = y_pred[4]
w2 = y_pred[5]
mu2 = y_pred[6]
sigma2 = y_pred[7]
rho2 = y_pred[8]
Is splitting up the components of y_pred a permitted operation in the custom loss function? I've written an implementation of the function but seem to be getting NaNs for the loss. I'm not sure whether I am doing something wrong or whether they are simply not allowed in keras or theano.
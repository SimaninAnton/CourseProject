ying9309 commented on 24 Jul 2018
I am a newbie for CNN, I followed and build my own model from scratch.
When I run my model, the validation accuracy fluatuate I have 10 classes with me. I tried to play around with the learning rate, but not much different. It seems like the model always overfitting
For my model, I tried to follow NiN model, but I am not sure whether this is the right code since nothing to refer to. Since I am using this data generator, I couldn't do k-fold cross validation.
Is there any suggestion I can used to increase my validation and testing accuracy?
Thank you very much.
`from numpy.random import seed
seed(1)
from tensorflow import set_random_seed
set_random_seed(2)
img_width, img_height = 200, 200
nb_train_samples = 8804
nb_validation_samples = 2512
nb_test_samples = 1263
batch_size = 128
epochs = 100
train_data_dir = 'C:/Users/Z/Documents/Python Scripts/10 species dataset TVT/Training Dataset'
validation_data_dir = 'C:/Users/Z/Documents/Python Scripts/10 species dataset TVT/Validation Dataset'
test_data_dir = 'C:/Users/Z/Documents/Python Scripts/10 species dataset TVT/Testing Dataset'
if K.image_data_format() == 'channels_first':
input_shape = (3, img_width, img_height)
else:
input_shape = (img_width, img_height, 3)
if K.image_data_format() == 'channels_first':
input_shape = (3, img_width, img_height)
else:
input_shape = (img_width, img_height, 3)
model = Sequential()
model.add(Conv2D(192, (5, 5), input_shape=input_shape,strides=4))
model.add(Activation('relu'))
model.add(Conv2D(160, (1, 1)))
model.add(Activation('relu'))
model.add(Conv2D(96, (1, 1)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.5))
model.add(Conv2D(192, (5, 5)))
model.add(Activation('relu'))
model.add(Conv2D(192, (1, 1)))
model.add(Activation('relu'))
model.add(Conv2D(192, (1, 1)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.5))
model.add(Conv2D(192, (3, 3)))
model.add(Activation('relu'))
model.add(Conv2D(192, (1, 1)))
model.add(Activation('relu'))
model.add(Conv2D(10, (1, 1)))
model.add(Activation('relu'))
model.add(GlobalAveragePooling2D(data_format=None))
model.add(Dense(64))
model.add(Activation('relu'))
model.add(Dropout(0.5))
model.add(Dense(10))
model.add(Activation('softmax'))
learning_rate = 0.00001
decay_rate = learning_rate / epochs
adam = Adam(lr=learning_rate, decay=decay_rate)
model.compile(loss='categorical_crossentropy',
optimizer='adam',
metrics=['accuracy'])
train_datagen = ImageDataGenerator(
rescale=1. / 255,
shear_range=0.2,
zoom_range=0.2,
horizontal_flip=True)
validation_datagen = ImageDataGenerator(rescale=1. / 255)
test_datagen = ImageDataGenerator(rescale=1. / 255)
train_generator = train_datagen.flow_from_directory(
train_data_dir,
target_size=(img_width, img_height),
batch_size=batch_size,
class_mode='categorical')
validation_generator = validation_datagen.flow_from_directory(
validation_data_dir,
target_size=(img_width, img_height),
batch_size=batch_size,
class_mode='categorical', shuffle=False)
test_generator = test_datagen.flow_from_directory(
test_data_dir,
target_size=(img_width, img_height),
batch_size=batch_size,
class_mode='categorical', shuffle=False)
history = model.fit_generator(
train_generator,
steps_per_epoch=nb_train_samples // batch_size,
epochs=epochs,
validation_data=validation_generator,
validation_steps=nb_validation_samples // batch_size)`
Epoch 81/100 - loss: 0.5721 - acc: 0.8063 val_loss: 0.9529 - val_acc: 0.7196
Epoch 82/100 - loss: 0.5614 - acc: 0.8076 val_loss: 0.9202 - val_acc: 0.7335
Epoch 83/100 - loss: 0.5359 - acc: 0.8115 val_loss: 0.9232 - val_acc: 0.7344
Epoch 84/100 - loss: 0.5340 - acc: 0.8127 val_loss: 0.9260 - val_acc: 0.7279
Epoch 85/100 - loss: 0.5502 - acc: 0.8080 val_loss: 1.0026 - val_acc: 0.7183
Epoch 86/100 - loss: 0.5328 - acc: 0.8161 val_loss: 0.9267 - val_acc: 0.7348
Epoch 87/100 - loss: 0.5429 - acc: 0.8095 val_loss: 0.9420 - val_acc: 0.7322
Epoch 88/100 - loss: 0.5222 - acc: 0.8143 val_loss: 0.9440 - val_acc: 0.7305
Epoch 89/100 - loss: 0.5115 - acc: 0.8200 val_loss: 0.9106 - val_acc: 0.7339
Epoch 90/100 - loss: 0.5127 - acc: 0.8219 val_loss: 0.9231 - val_acc: 0.7335
Epoch 91/100 - loss: 0.5050 - acc: 0.8228 val_loss: 0.9582 - val_acc: 0.7253
Epoch 92/100 - loss: 0.5065 - acc: 0.8213 val_loss: 0.9467 - val_acc: 0.7509
Epoch 93/100 - loss: 0.5502 - acc: 0.8093 val_loss: 0.9302 - val_acc: 0.7491
Epoch 94/100 - loss: 0.5025 - acc: 0.8201 val_loss: 0.9208 - val_acc: 0.7331
Epoch 95/100 - loss: 0.4827 - acc: 0.8309 val_loss: 0.8994 - val_acc: 0.7452
Epoch 96/100 - loss: 0.5100 - acc: 0.8268 val_loss: 0.9476 - val_acc: 0.7383
Epoch 97/100 - loss: 0.4812 - acc: 0.8271 val_loss: 0.9493 - val_acc: 0.7322
Epoch 98/100 - loss: 0.4903 - acc: 0.8325 val_loss: 0.8881 - val_acc: 0.7413
Epoch 99/100 - loss: 0.4638 - acc: 0.8401 val_loss: 0.9888 - val_acc: 0.7352
Epoch 100/100 - loss: 0.4852 - acc: 0.8311 val_loss: 0.9508 - val_acc: 0.7339
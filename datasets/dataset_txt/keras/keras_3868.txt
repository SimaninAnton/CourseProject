longma307 commented on 22 Nov 2016 â€¢
edited
I am using the mnist_siamese_graph.py as an example for my own data, but the loss (below) in each epoch was not decreased. My data is different from the data being used in the mnist_siamese_graph example, the data in x[:, 0] looks like: [0,12,24,31...], but the data in x[:, 1] looks like [12343, 789273, 9872,...].
model.fit([x[:, 0],x[:, 1]], y, batch_size=64, nb_epoch=10)
The training data (two branches in Siamese NN) are really different. If the Siamese NN shared weights for both of two branches, I think that would be a issue for training due to my training loss was "not correct".
If two branches share weights in Siamese NN, how can I fix that according to my data?
I could do normalize two branches, this should work.
Epoch 1/10
20000/20000 [==============================] - 3s - loss: 26157091.5761
Epoch 2/10
20000/20000 [==============================] - 1s - loss: 26103.3771
Epoch 3/10
20000/20000 [==============================] - 1s - loss: 66322.9797
Epoch 4/10
20000/20000 [==============================] - 1s - loss: 33068.0571
Epoch 5/10
20000/20000 [==============================] - 1s - loss: 3271.2368
Epoch 6/10
20000/20000 [==============================] - 1s - loss: 124758.9755
Epoch 7/10
20000/20000 [==============================] - 1s - loss: 11452.0805
Epoch 8/10
20000/20000 [==============================] - 1s - loss: 31291.7847
Epoch 9/10
20000/20000 [==============================] - 1s - loss: 2562.3131
Epoch 10/10
20000/20000 [==============================] - 1s - loss: 0.4973
* Accuracy on training set: 50.00%
Epoch 1/10
20000/20000 [==============================] - 3s - loss: 23972822.8330
Epoch 2/10
20000/20000 [==============================] - 1s - loss: 31353.3295
Epoch 3/10
20000/20000 [==============================] - 1s - loss: 33149.6620
Epoch 4/10
20000/20000 [==============================] - 1s - loss: 22481.5665
Epoch 5/10
20000/20000 [==============================] - 1s - loss: 103161.4879
Epoch 6/10
20000/20000 [==============================] - 1s - loss: 11121.0753
Epoch 7/10
20000/20000 [==============================] - 1s - loss: 122371.6265
Epoch 8/10
20000/20000 [==============================] - 1s - loss: 49855.2024
Epoch 9/10
20000/20000 [==============================] - 1s - loss: 41485.7752
Epoch 10/10
20000/20000 [==============================] - 1s - loss: 2243.4557
* Accuracy on training set: 50.05%
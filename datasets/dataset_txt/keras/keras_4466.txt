kevkid commented on 1 Sep 2016
Please make sure that the boxes below are checked before you submit your issue. Thank you!
Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps
If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps
Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
I am performing batch learning and after a few batches I get this error from this line of code:
model.fit(Xtrain, Ytrain, batch_size=128, nb_epoch=1,
                  verbose=1,validation_split=0.01,
                  callbacks=[ModelCheckpoint(weightStr, monitor='val_loss', verbose=0, save_best_only=True, mode='auto')])

Traceback (most recent call last):

  File "<ipython-input-1-0ab90ed05873>", line 321, in <module>
    callbacks=[ModelCheckpoint(weightStr, monitor='val_loss', verbose=0, save_best_only=True, mode='auto')])

  File "/home/kevin/.local/lib/python2.7/site-packages/keras/models.py", line 620, in fit
    sample_weight=sample_weight)

  File "/home/kevin/.local/lib/python2.7/site-packages/keras/engine/training.py", line 1104, in fit
    callback_metrics=callback_metrics)

  File "/home/kevin/.local/lib/python2.7/site-packages/keras/engine/training.py", line 842, in _fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)

  File "/home/kevin/.local/lib/python2.7/site-packages/keras/callbacks.py", line 40, in on_epoch_end
    callback.on_epoch_end(epoch, logs)

  File "/home/kevin/.local/lib/python2.7/site-packages/keras/callbacks.py", line 196, in on_epoch_end
    self.progbar.update(self.seen, self.log_values, force=True)

AttributeError: 'ProgbarLogger' object has no attribute 'log_values'
I have no idea why I get this error, It seems to happen randomly, can anyone point me in the right direction?
Here is the module of code that I am running:
for e in range(numEpoch):
    numOfImgToLoad = 50000#we can tune this
    totalNumberOfImages = len(imagesAndClass)
    runningTotal = 0
    startingPoint = 0
    endingPoint = numOfImgToLoad
    while totalNumberOfImages > 0:
        print "StartingPoint: {}, endingPoint {}".format(startingPoint, endingPoint)
        totalNumberOfImages = totalNumberOfImages - numOfImgToLoad#subtract the number of images loaded into mem
        if totalNumberOfImages < 0:
            remainder = totalNumberOfImages + numOfImgToLoad
            (Xtrain, Ytrain) = loadImages(imagesAndClass[startingPoint:remainder])
            Xtrain = np.array(Xtrain).reshape(len(Xtrain), 1, 106, 106)#np.array(Xtrain).reshape(4415, 1, 106, 106)
            runningTotal += remainder
        else:
            (Xtrain, Ytrain) = loadImages(imagesAndClass[startingPoint:endingPoint])
            Xtrain = np.array(Xtrain).reshape(len(Xtrain), 1, 106, 106)
            runningTotal += numOfImgToLoad
            startingPoint = endingPoint+1
            endingPoint = startingPoint + numOfImgToLoad - 1

        Xtrain /= 255#change pixel value to between 0 and 1
        Xtrain = Xtrain.astype('float32')
        Ytrain = np_utils.to_categorical(Ytrain, len(classes)+1)
        Ytrain = np.array(Ytrain)
        print "Starting epoch {}".format(e)
        model.fit(Xtrain, Ytrain, batch_size=128, nb_epoch=1,
                  verbose=1,validation_split=0.01,
                  callbacks=[ModelCheckpoint(weightStr, monitor='val_loss', verbose=0, save_best_only=True, mode='auto')])
                  #callbacks=[EarlyStopping(monitor='val_loss', patience=2)])
        #print "Starting epoch {} on image {}".format(e, runningTotal)
        print "Killing Xtrain and resetting"
        del Xtrain
        del Ytrain
9
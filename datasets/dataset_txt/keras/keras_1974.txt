enricopal commented on 7 Jul 2017
Hello,
I am running a server application that uses Keras and I have noticed that the memory allocated to the process is increasing with the number of calls to the API, significantly increasing the response time. I am using Ubuntu 16.04, python 3.6.0, Tensorflow as a backend.
I have created a small experiment to measure the size of the allocated memory when loading a model multiple times (I am using Ubuntu 16.04, python 3.6.0, Tensorflow as a backend):
from keras.models import load_model
import time
from pympler import asizeof
model_file = 'model.h5'
for i in range(10):
model = load_model(model_file)
print(asizeof.asizeof(model))
del model
time.sleep(2)
The output is:
8847736
17060064
25370520
33237832
41498512
49956848
58217816
66084752
74674104
82541328
You can get the model file here to reproduce the experiment: https://drive.google.com/file/d/0B0f321vV55z9T3gzV0ZLWTRBa3c/view?usp=sharing.
It seems that, even deleting the model variable, not all the memory is deallocated.
6
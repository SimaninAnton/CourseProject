MikeShlis commented on 6 Jul 2018
There is an issue that when loading weights of a model it overwrites the weight names.
Scenario:
you have a 3 models: A, B, C
model A and model B have the same architecture but are given different layer names.
model A is trained and saved
A.save_weights('A.h5')
model B loads the optmiized weights from A's training
B.load_weights('A.h5', by_name=False)
C is a different architecture but shares some of the same layers/layer-names as B
Model B saves its weights so C can soon load them
B.save_weights('B.h5')
Model C now tries to take them
C.load_weights('B.h5', by_name=True)
End Result: C gets a random initialization rather than the trained upon weights.
This can be then seen equivalently by checking the accuracy difference of just saving and reloading into the same model:
B.save_weights('B.h5')
B.load_weights('B.h5', by_name=True) ### This B is as good as random init.
[ v] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/keras-team/keras.git --upgrade --no-deps
[ v] If running on TensorFlow, check that you are up-to-date with the latest version. The installation instructions can be found here.
[N/A ] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps
[ N/A] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
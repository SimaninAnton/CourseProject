RubenZazo commented on 9 May 2017 â€¢
edited
I have seen different implementations of the fourth architecture. In that topology the first LSTM layer sees the whole sequence, gets an output and using that output (repeated with RepeatVector) you feed a second LSTM of any size and you get the actual output.
The problem I am trying to tackle is signal cleaning, so I have the following:
X_train = n sequences of the signal + noise, frame by frame.
Y_train = same as X_train but with no noise.
The "easy" solution for this problem is to use the last architecture in the figure, but if we do this we are forcing the LSTM to get the cleaned signal of the first frame seeing only that first frame. The LSTM benefits from the context so what I want is a mix between the fourth and the fifht architecture so:
The LSTM sees n frames (let's say 20), once the LSTM gets the frame 21 it outputs the cleaned version of the frame 1 and the network keeps getting one output for every frame it receives.
This is the architecture I am trying to train:
Is this possible in Keras?
1
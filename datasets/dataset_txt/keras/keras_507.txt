SebiSebi commented on 25 Dec 2018
Hello!
For a multi-GPU model built using multi_gpu_model, the function parallel_model.summary() outputs incorrect information. More precisely, for the following code:
with tf.device('/cpu:0'):
    model = Model(inputs=[...], outputs=[...])
parallel_model = multi_gpu_model(model, gpus=3)
parallel_model.summary()
The output is:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
text_input (InputLayer)         (None, 1)            0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 1)            0           text_input[0][0]                 
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 1)            0           text_input[0][0]                 
__________________________________________________________________________________________________
lambda_3 (Lambda)               (None, 1)            0           text_input[0][0]                 
__________________________________________________________________________________________________
model_1 (Model)                 (None, 2)            134326      lambda_1[0][0]                   
                                                                 lambda_2[0][0]                   
                                                                 lambda_3[0][0]                   
__________________________________________________________________________________________________
dense_3 (Concatenate)           (None, 2)            0           model_1[1][0]                    
                                                                 model_1[2][0]                    
                                                                 model_1[3][0]                    
==================================================================================================
Total params: 134,326
Trainable params: 134,326
Non-trainable params: 0
__________________________________________________________________________________________________
However, calling summary() on the original model (e.g. model.summary()) outputs the correct architecture:
Layer (type)                 Output Shape              Param #   
=================================================================
text_input (InputLayer)      (None, 1)                 0         
_________________________________________________________________
elmo_embedding_layer_1 (Elmo (None, 450, 1024)         4         
_________________________________________________________________
gru_1 (GRU)                  (None, 40)                127800    
_________________________________________________________________
dense_1 (Dense)              (None, 70)                2870      
_________________________________________________________________
dense_2 (Dense)              (None, 50)                3550      
_________________________________________________________________
dense_3 (Dense)              (None, 2)                 102       
=================================================================
Total params: 134,326
Trainable params: 134,326
Non-trainable params: 0
_________________________________________________________________
Is this the expected behaviour? Is it related to the same issue as calling save() on the parallel model?
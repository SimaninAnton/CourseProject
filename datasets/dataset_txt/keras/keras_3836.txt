phdowling commented on 25 Nov 2016 â€¢
edited
I defined the following merge:
def MatchScore(left, right):
    return merge(
        [left, right],
        mode=lambda l_r:
            1. /
            (
                1. +
                K.sqrt(K.dot(l_r[0], l_r[0].T) - 2. * K.dot(l_r[0], l_r[1].T) + K.dot(l_r[1], l_r[1].T))
            ),
        output_shape=(left._keras_shape[1], right._keras_shape[1])
    )

# calling like this:
left_input = Input(shape=(left_seq_len,))
right_input = Input(shape=(right_seq_len,))
left_embed = Embedding(input_dim=vocab_size, output_dim=embed_dimensions, dropout=dropout)(left_input)
right_embed = Embedding(input_dim=vocab_size, output_dim=embed_dimensions, dropout=dropout)(right_input)

match_score = MatchScore(left_embed, right_embed)
This should compute a score based on pairwise euclidean distances of the rows of two matrices, thus have output shape (num_samples_left, num_samples_right) as manually specified in the output_shape argument - however, Keras gives the resulting TensorVariable an ndim of 4, this it's not compatible with e.g. a TimeDistributed(Dense(...)) as expected.
Is this a possible bug in Keras or am I missing something?
EDIT: Okay, seems that this is Theano doing this, not Keras, and that the output of that lambda really is 4-dimensional (forgot about the num_samples dimension). I guess my question now becomes: how can I use Keras to "broadcast" the above function for each sample in my two inputs?
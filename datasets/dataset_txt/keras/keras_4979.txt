vabatista commented on 13 Jun 2016
Here is my code:
from keras.models import Sequential
from keras.layers import Dense, Activation, Dropout

model2 = Sequential()
model2.add(Dense(64, input_dim=2, activation='sigmoid', init='uniform'))
model2.add(Dense(3, activation='sigmoid'))

model2.compile(loss='categorical_crossentropy', optimizer='sgd')
model2.fit(X_train, y_train_cat, nb_epoch=1, batch_size=10000,
           show_accuracy=True, validation_data=(X_valid, y_valid_cat), verbose=1)
My X have two features, both with scores from 1 to 5, and Y have 3 encoded labels.
When I run the code above, it returns:
Train on 33679 samples, validate on 8420 samples
Epoch 1/1
33679/33679 [==============================] - 0s - loss: nan - val_loss: nan
Out[37]:
<keras.callbacks.History at 0x211f8b70>
Then all the predictions return nan:
preds = model2.predict_proba(X_valid)
print preds[:10]
array([[ nan,  nan,  nan],
       [ nan,  nan,  nan],
       [ nan,  nan,  nan],
       [ nan,  nan,  nan],
       [ nan,  nan,  nan],
       [ nan,  nan,  nan],
       [ nan,  nan,  nan],
       [ nan,  nan,  nan],
       [ nan,  nan,  nan],
       [ nan,  nan,  nan]])
I tried all combinations of optimizers, activation functions, etc. None of them worked.
Any Help?
Another question is how to combine this simple MLP to a CNN for text classification? My actual input is like this:

"Nota Questão X" are my categorical (ordinal values) features and "Comentário" is a free text comment. "Manifestação do Atendimento" is the class I want to learn.
Using the cnn for text classification over "Comentário" field yelds to good results, but I think it can be improved with the scores, since they have a strong meaning here.
Can anybody suggest a good approach? My CNN implementation is based on this: https://github.com/alexander-rakhlin/CNN-for-Sentence-Classification-in-Keras
Thanks, Vitor
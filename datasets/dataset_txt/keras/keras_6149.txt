around1991 commented on 9 Jan 2016
Hi all
I think I've found a really strange bug in weight regularization. Basically, I'm pretraining some autoencoder layers with l2 regularization of 0.001, and then adding the pretrained layers to my network. At this point, I'd like to change the l2 regularization weight to 0.01.
I thought I'd start by changing the l2 reg value to the same value it currently is, to see if that would affect anything. Adding the following lines of code
for r in model.regularizers:
    tmp = regularizer.l2
    regularizer.l2 = tmp
before model compilation dramatically affects the resulting training loss. In fact, the following code
for r in model.regularizers:
    tmp = regularizer.l2
    print(tmp)
    regularizer.l2 = tmp
gets a different training loss yet again.
What could be the cause of this non-determinism? Is there some Theano trickery going on behind the scenes?
Thanks
Kris
Contributor
zo7 commented on 19 Apr 2016 â€¢
edited
This small toy convolutional network compiles and trains as you would expect:
vis_in = Input(shape=VIS_SHAPE, name='vis_in_singleframe')
x = ZeroPadding2D((1,1))(vis_in)
x = Convolution2D(64, 3, 3, activation='relu')(x)
x = ZeroPadding2D((1,1))(x)
x = Convolution2D(64, 3, 3, activation='relu')(x)
x = MaxPooling2D((2,2), strides=(2,2))(x)

x = Flatten()(x)
x = Dense(512, activation='relu')(x)
x = Dropout(0.5)(x)
x = Dense(10, activation='sigmoid')(x)

model = Model(input=vis_in, output=x)
However, when you want to wrap it in TimeDistributed to make it evaluate a video sequence,
vis_input = Input(shape=(MAX_FRAMES,)+VIS_SHAPE, name='vis_in')

x = TimeDistributed(model)(vis_input)
# Let's say we want to do a simple regression over everything
x = Flatten()(x)
x = Dense(1, activation='sigmoid')(x)
model = Model(input=vis_input, output=x)
the model will compile fine, but Theano will throw an error when you try to train:
theano.gof.fg.MissingInputError: An input of the graph, used to compute DimShuffle{x,x}(keras_learning_phase), was not provided and not given a value.
However, getting rid of the dropout layer,
#x = Dropout(0.5)(x)
will allow it to work. I'm not familiar enough with Theano to understand its message :/
This does seem to work with TensorFlow, although on my Macbook it gobbles up memory to the point where the disk space gets full, presumably from all that sweet swap (I'm surprised the OS doesn't stop that from happening... I walked away for a few minutes while it was compiling and I came back to find ~50GB of disk space gone and a warning on my screen. Not sure if that's related or just a TF problem.)
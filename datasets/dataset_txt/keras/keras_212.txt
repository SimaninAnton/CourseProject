palatos commented on 24 May 2019 â€¢
edited
OS Platform and Distribution: Linux Debian 9
TensorFlow backend (yes / no): yes
TensorFlow version: 1.13.1
Keras version: 2.2.4
Python version: 3.6.6
I'm using an .h5 file containing the weights of a model trained by someone else. I can successfully load the model through model.load_weights(). However once I do some predictions I get awful accuracy as the model basically predicts only the same class every time. Originally this model had 90% accuracy, and it was trained on the same machine I'm using.
After loading the saved weights it literally just predicts "1" for every image in the training/val/test sets.
I can't find the reason why the same model with same weights is performing differently on two different sessions on the same machine. Shouldn't it load normally and just perform the same predictions on the same images?
The code is very simple. I'm using the same image pre-processing function used before. Is there some mistake in how I'm loading the weights?
input_tensor = Input((96, 96, 3))
base_model = VGG19(include_top=False, pooling='avg', input_tensor=input_tensor, weights = None)
x = base_model(input_tensor)
out = Dense(1, activation="softmax")(x)
model = Model(input_tensor, out)

model.load_weights("../model_trained.h5")
I have seen people reporting this same behavior before with more complex models, stateful LSTMs and custom layers, but my model is simple and it's still giving me this same issue.
Anyone found a solution for this yet?
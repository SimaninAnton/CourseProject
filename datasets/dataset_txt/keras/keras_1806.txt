xcszbdnl commented on 4 Aug 2017 â€¢
edited
I want to map the embedding vector back by using like this: x = v * A.T. v is the embedding vector and A is the embedding matrix. How could I do it in keras? like this?
embedding_dim = 10
voc_size = 5
seq_length = 10
x = Input(shape=(seq_length))
embedding_layer = Embedding(voc_size, embedding_dim)
x = embedding_layer(x)
x = TimeDistributed(Dense(voc_size, ...))     # weights may be embedding_layer.embeddings.T
giladdiv commented on 21 Nov 2016
I have a large dataset(>1M images) and I am trying to work with fit_generator.
The problem is i think it train only on the first batch and not work on all the data that fit_generator give me
def generate_batch_data_new(batch_size=32):
list_all = get_path_to_all_1M_images()
while 1:
for i in range(len(list_all)/batch_size):
x, y = load_image_batch(list_all,batch_idx=i, batch_size)
yield (x, y)
model.fit_generator(
generate_batch_data_new(batch_size=64),
samples_per_epoch=10000, nb_epoch=40,
validation_data=(x_val,y_val))`
what i think happen is i get only one batch of 64 that is used 1000/64 times
how can i fix it?
I think that this is my problem because the model over fit very fast and if i load (x,y) at the size of 10,000 without using the generator it work well
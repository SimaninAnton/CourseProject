cburgdorf commented on 16 Sep 2016 â€¢
edited
I'm testing different models on the same dataset. Somehow I observed that val_acc is quite unpredictable and I wonder if I'm just doing it wrong.
Let's say I pass val_input_data and val_darget_data to validation_data when I call model.fit(...)
 history = model.fit(training_data,
                     target_data,
                     nb_epoch=1000,
                     batch_size=32,
                     shuffle='batch',
                     verbose=2,
                     validation_data = (val_input_data, val_target_data),
                     callbacks=[model_checkpoint])
And let's say I see this:
Model 1
Epoch 72/1000
2s - loss: 0.0070 - acc: 0.4003 - val_loss: 2.5762e-06 - val_acc: 0.3583
This one has a super low val_loss but the val_acc doesn't actually seem so good.
And then on a different model with the same dataset I see this
Model 2
Epoch 99/1000
2s - loss: 0.0212 - acc: 0.4094 - val_loss: 0.0109 - val_acc: 0.6667
The val_acc seems to be much better. However, if I run model.predict(val_input_data); with the saved weights of Model 1 and the same val_input_data that is passed to validation_data during mode.fit(...) I notice that the Model 1 (which only had a val_acc of 0.3583) actually performs much better than Model 2 which has a much higher val_acc. Am I misinterpreting what val_acc actually is supposed to be?
Right now it seems to me that I can't reliably measure the performance of my model because the number of val_acc doesn't actually make much sense.
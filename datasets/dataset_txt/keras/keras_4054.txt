jingweimo commented on 28 Oct 2016 â€¢
edited
In using keras to implement a deep neural network, how to set up a learning rate that is exponentially decayed with respect to cost, that is:
       eta = eta0*exp(CostFunction)
where eta is learning rate at the current epoch, eta0 is the initial learning rate, and CostFunct is the cost associated with each epoch.
With such learning rate schedule, a larger learning rate is used when the cost is large, vice versa, which is likely to improve training performance. How to achieve this in Keras?
Please make sure that the boxes below are checked before you submit your issue. Thank you!
Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps
If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps
Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
alsoltani commented on 21 Jun 2016 â€¢
edited
I am implementing a Deep Convolutional Neural Network for multiclass classification.
My loss is the categorical_crossentropyand my metrics are the Keras accuracy as well as an in-house implementation of the Cohen-Kappa coefficient ckm.
model.compile(loss='categorical_crossentropy',
              optimizer="adadelta",
              metrics=[ckm, "accuracy"])
early_stopping = EarlyStopping(monitor='val_acc', patience=2, mode="max")
Quite similarly to #1364, when training my model, training loss and metrics are pretty normal.
When evaluating them on the validation set (by setting validation_split=0.1, shuffle=True), loss and accuracy are finite but Cohen-Kappa coefficient goes to nan.
Using gpu device 0: GeForce GTX TITAN X (CNMeM is disabled, cuDNN 5005)
Using Theano backend.
Train on 8789 samples, validate on 977 samples
Epoch 1/10
8789/8789 [==============================] - 12s - loss: 1.4828 - ckm: 0.0591 - acc: 0.3949 - val_loss: 1.2536 - val_ckm: 1.6025e-08 - val_acc: 0.3204
Epoch 2/10
8789/8789 [==============================] - 12s - loss: 1.3158 - ckm: 0.1047 - acc: 0.4208 - val_loss: 1.1424 - val_ckm: nan - val_acc: 0.5026
Epoch 3/10
8789/8789 [==============================] - 12s - loss: 1.1722 - ckm: 0.1894 - acc: 0.4717 - val_loss: 1.1458 - val_ckm: nan - val_acc: 0.5251
...
When evaluating my model on a distinct test set using model.evaluate, everything works fine :
('Evaluation on validation set:', [1.0822346006198775, 0.2739806798530029, 0.52856054829443488])
Setting shuffle=False turns the Cohen-Kappa metric into nan both for train and validation sets.
The data is directly loaded from a HDF5 file (i.e. as a dictionary of numpy objects).
Any thoughts ? I simply cannot find where the problem comes from.
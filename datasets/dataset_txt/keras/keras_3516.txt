samsinai commented on 9 Jan 2017 â€¢
edited
I'm running the vae and vae_deconv (in keras examples) with the loss function as provided (no changes done to code logic, but different data). However, I sometimes get both training and validation loss to be negative, which means the variable kl_loss is negative. As I understand, we are minimizing log (p(x))-D_kl(p(x)||q(x)), we know the D_kl is non-negative, it means D_kl(p(x)||q(x))> log(p(x)), or the information in p(x) is less than the distance between the two distributions. Is this statement correct? I'm basically trying to understand what the function vae_loss is exactly computing, and why it would be negative.
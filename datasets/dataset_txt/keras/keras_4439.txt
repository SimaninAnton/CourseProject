cryo111 commented on 5 Sep 2016
I am trying to reproduce the value of the loss that is due to weight regularization.
According to https://github.com/fchollet/keras/blob/master/keras/regularizers.py#L80, the regularized loss is given as
regularized_loss += K.sum(self.l1 * K.abs(self.p))
or, taking into account how regularized_loss is initialized,
regularized_loss = loss + K.sum(self.l1 * K.abs(self.p))
with loss, self.l1, and K.sum(K.abs(self.p)) denoting the loss without regularization, the L1-type weight regularization coefficient, and the sum over all absolute values of all weights, respectively.
Now, when I train the model on one epoch, I can access the loss (I use categorical cross-entropy) with and without regularization via the returned history object via
hist.history['loss'][0] and hist.history['categorical_crossentropy'][0], respectively.
The difference is
hist.history['loss'][0]-hist.history['categorical_crossentropy'][0]
#0.18749386072158813
However, when I manually calculate K.sum(self.l1 * K.abs(self.p)), this gives 921.879 which is orders of magnitude larger than 0.187....
Please see the code in the attached gist for a reproducible example that also shows how I manually calculate the regularization term.
I am clearly missing something here.
Any help appreciated!
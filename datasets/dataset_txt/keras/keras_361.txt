mangohero1985 commented on 4 Mar 2019 •
edited
Hi all, I am trying to implement the google wide&deep model in Keras.
From the original paper and the official TF implementation, the optimization was done by two optimizers parallel.
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/learn/python/learn/estimators/dnn_linear_combined.py#L328
Can the model be compiled by optimizer dictionary like {branch1: “optimizer1”, branch2:“optimizer2"}? and the loss can be computed separately.
Thanks in advance.
JamesAllingham commented on 7 Aug 2017 â€¢
edited
Hello all,
I have run into an issue with Keras embedding layers. The issue arose when I upgraded to the latest versions of Keras and Tensorflow (GPU) but unfortunately I do not know what versions I was using before. When I try and include and embedding layer I get the following error:
InvalidArgumentError (see above for traceback): Incompatible shapes: [128,100] vs. [10]
         [[Node: gradients/batch_normalization_1/batchnorm/mul_1_grad/BroadcastGradientArgs = BroadcastGradientArgs[T=DT_INT32, _class=["loc:@batch_normalization_1/batchnorm/mul_1"], _device="/job:localhost/replica:0/task:0/gpu:0"](gradients/batch_normalization_1/batchnorm/mul_1_grad/Shape, gradients/batch_normalization_1/batchnorm/mul_1_grad/Shape_1)]]
I am up to date with both Keras and Tensorflow (GPU) as described in the guidelines for contributing. The versions are tensorflow-gpu (1.2.1) and Keras (2.0.6).
Here is a short python 3 script that can reproduce the issue on my Laptop with a GTX960m, Ubuntu 16.04, Cuda V8.0.61, and CuDNN 5.1.10:
import keras
from keras.datasets import mnist
from keras.models import Model
from keras.layers import Dense, Embedding, Input, Flatten, BatchNormalization
from keras.optimizers import RMSprop

batch_size = 128
num_classes = 10
epochs = 20

# the data, shuffled and split between train and test sets
(x_train, y_train), (x_test, y_test) = mnist.load_data()

x_train = x_train.reshape(60000, 784)
x_test = x_test.reshape(10000, 784)
x_train = x_train.astype('float32')
x_test = x_test.astype('float32')
x_train /= 255
x_test /= 255

# convert class vectors to binary class matrices
y_train = keras.utils.to_categorical(y_train, num_classes)
y_test = keras.utils.to_categorical(y_test, num_classes)

inp = Input(shape = (10,))
out = Embedding(input_dim = 10, output_dim = 10, input_length=1)(inp)
out = Flatten()(out)
out = BatchNormalization()(out)
out = Dense(200, activation='relu')(out)
out = BatchNormalization()(out)
out = Dense(400, activation='relu')(out)
out = BatchNormalization()(out)
out = Dense(784, activation='relu')(out)

model = Model(inputs = inp, outputs = out)

model.compile(loss='mse',
              optimizer="rmsprop")

model.fit(x = y_train,
          y =  x_train,
          epochs=20,
          batch_size=128,
          validation_split=0.2)
Please let me know if I should supply any additional information to assist in solving this issue.
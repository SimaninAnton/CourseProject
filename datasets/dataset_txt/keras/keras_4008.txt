CCXD commented on 2 Nov 2016 â€¢
edited
A dataset that I'm trying to fit my model on results in a too large memory allocation for the GPU, so I'm trying to resolve this by fitting on batches of the dataset.
What is the difference between using
model.fit(self, batch_X, batch_y, batch_size=128, nb_epoch=1, verbose=1, callbacks=[], validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None)
and
model.train_on_batch(self, batch_X, batch_y, class_weight=None, sample_weight=None)
for training a single step? The latter lacks a lot of features such as callbacks and validation split. So am I missing something, or is the former always better to use?
Can I just use model.fit with a section of the training set as if I were training normally, and just chain this on the remaining training set sections?
1
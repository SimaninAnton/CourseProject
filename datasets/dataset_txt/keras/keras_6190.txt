icemansina commented on 28 Dec 2015
Currently, I am using Bidirectional RNN/LSTM(BRNN/BLSTM) for sequence classification (return_sequence= True, i.e., classification of each time-step). According to the official provided example, the BRNN is required to implemented by Graph (while the BidirectionalRNN API does not support mask input). Besides, before mini-batch input, I do a preprocessing (pad with 0) to make the input to (batch_size, input_length, input_features), but it seems that no explicit mask input for keras. So I listed my implementation as
modellstm = Graph()
modellstm.add_input(name='input', input_shape=(MAX_SEQ_LENGTH, input_dim), dtype='float')
modellstm.add_node(Masking(mask_value=0), name='masked_input', input='input')
modellstm.add_node(LSTM(10, return_sequences=True), name='forward', input='masked_input')
modellstm.add_node(LSTM(10, go_backwards= True, return_sequences=True), name='backward', input='masked_input')
modellstm.add_node(Dropout(0.5), name='dropout', inputs=['forward', 'backward'])
modellstm.add_node(TimeDistributedDense(N_CLASSES, activation='softmax'), name='dense', input='dropout')
modellstm.add_output(name='output', input='dense')
modellstm.compile('Adadelta', {'output': 'categorical_crossentropy'})
As no show_accuracy=True for modellstm.fit (fit of Graph does not support), the accuracy
acc = accuracy((y_train_accuracy), np.argmax(np.array(modellstm.predict({'input': X_train}, batch_size=BATCH_SIZE)['output']), axis=-1)) doesn't take the input_mask into consideration. Besides, for example, without explicit input_mask, the output result of classification np.argmax([0 0 0 0])=0 (i.e., class=1) for input np.array([0 0 ... 0]), which is indeed wrong. Actually input_mask for input np.array([0 0 ... 0]) should be 0, which means all 0 input and output should not be calculated for accuracy. How could I modify me code to accomplish this code. Thanks a lot for your nice assistance. @fchollet @farizrahman4u
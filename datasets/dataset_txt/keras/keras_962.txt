cpphoo commented on 15 Jun 2018
I am playing around with Keras' BatchNormalization layer with the following code.
`bn_layer = keras.Sequential()
bn_layer.add(keras.layers.BatchNormalization(momentum=0,
moving_mean_initializer=keras.initializers.constant(0),
moving_variance_initializer=keras.initializers.constant(0),
input_shape=(1,)))
bn_layer.compile('sgd', loss='mean_squared_error')
X = np.array([1,2,3,4])[:, np.newaxis] # with mean 2.5 and variance 1.25
y = 2*X
bn_layer.fit(X, y)
`
When look at bn_layer.layers[0].get_weights(), I get [array([1.0247195], dtype=float32), array([0.09999999], dtype=float32), array([2.5], dtype=float32), array([1.6672224], dtype=float32)]
Since I set momentum = 0, then the moving average and moving variance should be the mean and variance of the X. However, the moving variance I get is 1.6672224 instead of 1.25. Any idea why this is happening?
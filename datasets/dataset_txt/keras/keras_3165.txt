Contributor
datumbox commented on 20 Feb 2017 â€¢
edited
The fit_generator() on models.py forces the nb_worker to be equal to 1 if the pickle_safe is False (same applies for predict and evaluate). At the same time the actual implementation of fit_generator() in training.py does not do the same. I think the initial check was introduced by @fchollet and later updated by @tdeboissiere.
I believe this policy should not be enforced. I understand that if the generator is not pickle_safe we will use threads instead of processes, but Python's Global Interpreter Lock can be turned off in C plugins. As a result if the generator is performing a CPU intensive operation in C code, we can still speed up the training using threads. Here are some references:
https://docs.python.org/3/c-api/init.html
http://stackoverflow.com/questions/651048/concurrency-are-python-extensions-written-in-c-c-affected-by-the-global-inter
https://mfitzp.io/article/why-are-numpy-calculations-not-affected-by-the-global-interpreter-lock/
I checked also the keras-2 branch and as far as I can see this policy is no longer enforced. Can someone from the main contributors confirm that Keras 2.0 will not have this policy?
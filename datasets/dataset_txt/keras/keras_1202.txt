wenbotse commented on 2 Mar 2018
I implement a callback , override on_epoch_endï¼Œ when save the model and decode_model ,there is a warning mag:
UserWarning: Layer lstm_2 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'input_5:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'input_6:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).
str(node.arguments) + '. They will not be included '
it means some weight can't save to disk, when inference
How can I save the model , encoder_model, decoder_model for offline test & application
save the model:
print('save s2s h5')
model.save('s2s.h5.'+str(epoch))
model_json = model.to_json()
with open("model.json."+str(epoch), "w") as json_file:
print('save s2s json')
json_file.write(model_json)
    encoder_model = Model(encoder_inputs, encoder_states)
    decoder_state_input_h = Input(shape=(latent_dim,))
    decoder_state_input_c = Input(shape=(latent_dim,))
    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]
    decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)
    decoder_states = [state_h, state_c]
    decoder_outputs = decoder_dense(decoder_outputs)
    decoder_model = Model([decoder_inputs] + decoder_states_inputs,[decoder_outputs] + decoder_states)

    #save encoder model
    print('save encoder h5')
    encoder_model.save('encoder_model.h5.'+str(epoch))
    encoder_model_json = encoder_model.to_json()
    with open("encoder_model.json."+str(epoch), "w") as json_file:
        print('save encoder json')
        json_file.write(encoder_model_json)

    #save decoder model
    print('save decoder h5')
    decoder_model.save('decoder_model.h5.'+str(epoch))
    decoder_model_json = decoder_model.to_json()
    with open("decoder_model.json."+str(epoch), "w") as json_file:
        print('save decoder json')
        json_file.write(decoder_model_json)
1
Contributor
EderSantana commented on 7 Dec 2015
Reproduce error with
model = Sequential()
model.add(LSTM(128, return_sequences=True, input_dim=128))  # try using a GRU instead, for fun
model.compile('sgd', 'mse')

X = np.random.randn(100, 10, 128)
model.train_on_batch(X, X, sample_weight=np.ones_like(X))
We used to be able to weight batch and time dimensions. Now we can only weight batch dim? How do we consider which points in time should go out? This used to be key to the Neural Turing Machines.
It does not crash if use fit:
model.fit(X, X, sample_weight=np.ones_like(X))
train_on_batch and fit used to have similar APIs. What changed? I can write the tests and possible fixes if I get some guidance.
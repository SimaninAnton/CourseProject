ajdaling commented on 19 Oct 2016 â€¢
edited
I apologize if this is the wrong place to post this, but I need some guidance in interpreting the results of my attempt at generating convolutional filter visualization. I took your VGG visualization code and adjusted it to work with your MNIST_CNN, just for my own education. Link to python code here: https://github.com/ajdaling/KerasAu16/blob/master/KerasTest/src/Visualization/visualize.py
It seems to work well, the images generated from the final dense classification layer look like I would expect, with clearly discernible digits.
My confusion is in the convolutional layers. When I run the code using a 28x28 input image on the first convolutional layer (not the input layer), the look like this:
The only variation is on the very edges, with one or multiple edges being either light or dark.
The second convolutional layer is a bit more interesting, with more complicated features:
So my first question was why are the results from the first convolutional layer so unremarkable? I have a fairly solid understanding of the process of convolving images, but I am still new to neural nets so I get lost in trying to reason about what I'm seeing. When I thought about it some more, I though that maybe I would get a better understanding if I input a 3x3 image (the size of the kernels) instead. This is what I got:

Not clear features but certainly more interesting that what I got using 28x28.
But then I realized that I have no idea how that even works, in terms of the dimensions.
So here are my questions, and note that any and all help is extremely appreciated:
What should I expect to see in trying to visualize the first convolutional layer? I though that I would see basic features like edges or corners, but I don't seem to get that or at least don't know how to interpret what I am getting.
Should I use images that are the dimension of the input image (28x28) or the dimensions of the kernels (3x3) to view the filters of the convolutional layers? If the latter, how does it work (qualitatively or quantitatively) if the dimensions of the filter are 26x26 or 24x24 depending on the layer.
How should I interpret the results from the conv layers as opposed to those from the classification layer? For example, are the results from the classification layer sort of like the culmination of all of the network's knowledge of what a specific digit looks like, whereas the conv layer results just showing the specific local features that the network thinks are important?
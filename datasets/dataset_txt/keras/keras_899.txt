vmarceau commented on 11 Jul 2018
Summary:
Optimizing the learning rate decay schedule is a very common task when training deep learning models. Currently, the LearningRateScheduler callback parameter schedule must be a function that takes only two input arguments: epoch index and current learning rate. When testing different learning rate annealing schemes, it would be very useful to have the possibility of using parameterizable schedule functions that takes other various keyword arguments as inputs. The change request described in this document aims at improving the LearningRateScheduler callback API with this functionality.
https://docs.google.com/document/d/1bZRouQ21UA1x-wKUWMAeQJJqwc1zt1bM3QK03BvuVpI/edit?usp=sharing
birolkuyumcu commented on 13 Aug 2017
Tokenizer failed with unicode text
d = [u'ali veli kırk dokuz elli',u'ali veli kırk dokuz elli veli kırk dokuz']
tokenizer.fit_on_texts(d)
TypeError Traceback (most recent call last)
in ()
----> 1 tokenizer.fit_on_texts(d)
C:\Anaconda2\lib\site-packages\keras-2.0.3-py2.7.egg\keras\preprocessing\text.pyc in fit_on_texts(self, texts)
117 self.filters,
118 self.lower,
--> 119 self.split)
120 for w in seq:
121 if w in self.word_counts:
C:\Anaconda2\lib\site-packages\keras-2.0.3-py2.7.egg\keras\preprocessing\text.pyc in text_to_word_sequence(text, filters, lower, split)
36 if lower:
37 text = text.lower()
---> 38 text = text.translate(maketrans(filters, split * len(filters)))
39 seq = text.split(split)
40 return [i for i in seq if i]
TypeError: character mapping must return integer, None or unicode
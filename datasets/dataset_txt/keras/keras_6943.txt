civiskdonahue commented on 20 Jun 2015
I'm trying to get access to the loss history in a nicer format than the printed out version. I'm using the method described here: https://github.com/fchollet/keras/blob/master/docs/sources/callbacks.md. The exact code I'm using is
class LossHistory(keras.callbacks.Callback):
def on_train_begin(self):
self.losses = []
def on_batch_end(self, batch, logs={}):
self.losses.append(logs.get('loss'))
Followed by:
model = Sequential()#make our first model
model.add(Dense(X_train.shape[1], HiddenUnits, init='uniform', activation='sigmoid'))
model.add(Dense(HiddenUnits, X_train.shape[1], init='uniform', activation='sigmoid'))
sgd = SGD(lr=LearningRate, decay=1e-6, momentum=Momentum, nesterov=True)
model.compile(loss='categorical_crossentropy', optimizer=sgd)
history=LossHistory()
model.fit(X_train, X_train, batch_size=BatchSize, nb_epoch=NumEpochs, callbacks=[history])
However, when I run this, I keep getting an error:
TypeError: on_train_begin() takes exactly 1 argument (2 given)
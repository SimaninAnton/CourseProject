asturkmani commented on 22 Jul 2017 â€¢
edited
I have a vector that represents the distribution of time, over a 5-minute period, a user spent on a set of apps. This could be the entire 5 minutes (300 seconds) on one app, the time (300 seconds) distributed across multiple apps, or less than 300 seconds on one or multiple apps. These vectors are time-series data where each element represents the distribution of time spent over the apps, and I would like to use an RNN to predict the next elements based on the previous N.
The output could look like:
[ 0.,  0.,  0.,  0.,  0., 0.,  0.,  0.,  0.,  0., 0.,  0.,  0.,  0.,  0.21666667]
OR
[ 0.03333333,  0.,  0.,  0.,  0., 0.96666667,  0.,  0.,  0.,  0., 0.,  0.,  0.,  0.,  0.]
OR
[ 1.,  0.,  0.,  0.,  0., 0.,  0.,  0.,  0.,  0., 0.,  0.,  0.,  0.,  0.]
and my model, so far, looks like this:
N_HIDDEN = 16
N_DENSE = 64
LEARNING_RATE = 0.005
BATCH_SIZE = 16
EPOCHS = 50


model = Sequential()
model.add(GRU(N_HIDDEN, input_shape=(INPUT_LENGTH, INPUT_DIM), return_sequences=True))

model.add(TimeDistributed(Dense(N_DENSE)))
model.add(TimeDistributed(Activation('relu'))) 

model.add(TimeDistributed(Dense(INPUT_DIM)))  # Add another dense layer with the desired output size.
model.add(TimeDistributed(Activation('softmax')))

model.compile(loss='mse', optimizer=RMSprop(lr=LEARNING_RATE), metrics=['mae'])
print(model.summary())
I have 2 questions
Which activation layer should I use at the output? In a sense, these vectors crudely represent a distribution although they don't always sum to 1 (but can never exceed a sum of 1). The softmax seems decent for this kind of problem, however, it will force the sum of elements to equal 1
Which loss layer in Keras would be good for this? Since the vector is quite sparse, I wonder whether the MSE would be good enough, would perhaps the Cosine Proximity or KL divergence do a better job?
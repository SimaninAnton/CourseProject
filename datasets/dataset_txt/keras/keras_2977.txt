Derek-Gong commented on 15 Mar 2017 â€¢
edited
Please make sure that the boxes below are checked before you submit your issue. If your issue is an implementation question, please ask your question on StackOverflow or join the Keras Slack channel and ask there instead of filing a GitHub issue.
Thank you!
Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps
If running on TensorFlow, check that you are up-to-date with the latest version. The installation instructions can be found here.
If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps
Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
script:
keras.models.load_model(filename)
the model file contained recurrent layer which had argument input_dim.
then I got:
TypeError: ('Keyword argument not understood:', u'input_dim')
I checked keras/layers/recurrent.py in keras2 and keras1, and found a difference that I thought which is not intended:
keras2:
class Recurrent(Layer):
def init(self, return_sequences=False,
go_backwards=False,
stateful=False,
unroll=False,
implementation=0,
**kwargs):
super(Recurrent, self).init(**kwargs)
keras1:
class Recurrent(Layer):
def init(self, weights=None,
return_sequences=False, go_backwards=False, stateful=False,
unroll=False, consume_less='cpu',
input_dim=None, input_length=None, **kwargs):
......................... some initiating code for other arguments
if self.input_dim:
kwargs['input_shape'] = (self.input_length, self.input_dim)
super(Recurrent, self).init(**kwargs)
which means you will not handle input_dim in Recurrent layer in keras2.
however, doc string said in keras2:
input_dim: dimensionality of the input (integer).
This argument (or alternatively, the keyword argument input_shape)
is required when using this layer as the first layer in a model.
Meanwhile, this may cause a compatibility problem, which I have encountered.
meanmee commented on 22 Jan 2016
I have serached the old issuesï¼Œbut did not get the idea.
I tried to implement it like this(two tasks for individual label):
def multi_tasks_block(input_shape):
    from keras.models import Graph
    g = Graph()
    g.add_input('input',input_shape)
    g.add_node(Dense(5, activation='relu'), 'dense','input')
    g.add_node(Dense(5, activation='softmax'),'output_dense1','dense')
    g.add_node(Dense(5, activation='softmax'),'output_dense2','dense')
    g.add_output('output1','output_dense1')
    g.add_output( 'output2','output_dense2')
    return g
nb_classes = 5
nb_epoch = 100

X_train, y_train_one, y_train_two = generate_data()
print('X_train shape:', X_train.shape)
print(X_train.shape[0], 'train samples')

Y_train_one = np_utils.to_categorical(y_train_one, nb_classes)
Y_train_two = np_utils.to_categorical(y_train_two, nb_classes)

model = Sequential()
model.add(Dense(5, input_shape=(10,), activation='relu'))
model.add(multi_tasks_block((5,)))
model.summary()

model.compile(loss = {'output1': 'categorical_crossentropy', 'ouput2': 'categorical_crossentropy'}, optimizer='adam')

print('Not using data augmentation or normalization')
model.fit(X_train, Y_train_one, batch_size=X_train.shape[0], nb_epoch=nb_epoch)
but I failed
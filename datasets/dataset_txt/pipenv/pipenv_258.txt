stefanoborini commented on 4 Mar 2019 â€¢
edited
Hello, I have a question on the usage pattern of pipenv within the following context. Unfortunately I am limited in what I can paste due to company secrecy, but I'll try to give as much information as possible. I scouted the documentation searching for a solution, but both a colleague and I were not sure on how to proceed.
The problem is the following: we are developing my-application. This python app has external dependencies (e.g. requests and its sub-deps) and internal (in house developed) dependencies (ex. my-internal-library). Currently we know that we want e.g. 2.21.0 of requests and we don't want that to change, however my-internal-library is currently being developed and is therefore a moving target. Of course, as we develop my application, we always want to run against the develop branch, or potentially a feature branch, of my-internal-library.
In the old days, using requirements.txt generated from a pip freeze invocation, one could do for example
requests==2.21.0
requests_subdependency=3.14.15
my-internal-library==<git URL>@develop#egg<yada yada>
the @develop basically allowed the virtualenv generated by this requirements.txt to have a fixed, deterministic target for what concern requests, but a moving target that kept moving forward as the my-internal-library team pushed new changes. When my-application made a release, we would also have a stable release of my-internal-library, and the appropriate version would go in the requirements.txt.
With pipenv, I am not sure how to solve this workflow. The reason is the following. Our current Pipfile is:
[packages]
requests = "*"
my-internal-library = {git = "git+ssh://<git url>", editable = true, ref = 'develop'}
my-application = {path = "."}
I however found out that the generated Pipfile.lock contains, for the ref, the git hashes at which develop is currently pointing to.
Now, in order to follow develop as it moves forward, we would have to recreate the .lock file every time, but this has the unintended consequence of also bumping forward not only requests, but also any sub-dependency of requests, which we would not want to specify in the Pipfile. Once we have a working environment, we don't want it to accidentally upgrade on the whims of pypi.
What is the recommended pipenv usage strategy to address this workflow pattern?
For now, we have selectively reverted the patches to upgraded libraries, but this is tedious for developers and problematic with CI.
Thanks
Stripped to the bare minimum for IP concerns.
pipenv==2018.11.26. Invoked through tox as
pipenv install --dev --deploy
{'implementation_name': 'cpython',
 'implementation_version': '3.6.7',
 'os_name': 'posix',
 'platform_machine': 'x86_64',
 'platform_python_implementation': 'CPython',
 'platform_release': '4.15.0-45-generic',
 'platform_system': 'Linux',
 'platform_version': '#48-Ubuntu SMP Tue Jan 29 16:28:13 UTC 2019',
 'python_full_version': '3.6.7',
 'python_version': '3.6',
 'sys_platform': 'linux'}
BeyondEvil commented on 22 Oct 2018 â€¢
edited
I'm looking for a best practice on how to use pipenv when developing a package that is later going to be distributed by pypi.
Background:
At my company we have a CLI that is developed using javascript. In that project, in the package.json, we have a postinstall hook that installs a couple of python helpers (simply because the python libs for dealing with AWS are awesome).
These helpers are installed system-wide using the --user flag.
So when working on the helpers, devs want to do that in a virtual env, as to not interfere with the system-wide installation.
Hence, we use pipenv, and the Pipfile looks as follows:
[[source]]
url = "https://pypi.org/simple"
verify_ssl = true
name = "pypi"

[packages]

[dev-packages]
click = "===7.0"
"boto3" = "===1.9.28"
requests = "===2.19.1"
moment = "===0.8.2"
tabulate = "===0.8.2"
tox = "*"
The problem:
Well, apart from tox, the deps are a carbon copy from what's contained in the install_requires key in setup.py:
    install_requires=[
        'click==7.0',
        'boto3==1.9.28',
        'requests==2.19.1',
        'moment==0.8.2',
        'tabulate==0.8.2'
    ],
From a maintenance standpoint, this is less than optimal, so we would like to just work with a single-source-of-truth.
The question:
What's the best practice when it comes to avoiding defining the same deps in multiple places.
The solution I could come up with is:
[dev-packages]
dpo-python-helpers = {editable = true, path = "."}
tox = "*"
Is this good or is there a better way?
TIA!
tzickel commented on Oct 20, 2018 â€¢
edited
I am sending huge amounts of data in a request via a POST (gigabytes) where I know the data length, and would like to send it to the other side in the http headers (so it can do some optimization on allocation).
Since this data it generated itself via a stream (in chunks of lots of megabytes each), I am implementing my own class that I send to the data parameter.
My options today are (all bad):
A. Don't implement a __len__/len, and implement __Iter__, this way I can control how much data is send per iteration (I can even send it all in one shot), but the data is sent as chunked and the other side doesn't know how big the request is.
B. Implement __len__/len, but then I need to implement read, which defaults to 8196 size reads (because of httplib) which I have to fake and return more (since 8196 kills performance).
C. Use toolbelt's StreamingIterator which returns to the performance issues of B (it implements read).
A side issue as well, I don't understand why a class with __len__/len and read, needs to modify __len__/len to what is left after read if it's passed as a files (multipart) parameter, but not if it's sent as a data parameter (confusing).
Expected Result
I should be able to send a object with a known length, and only __iter__ implemented so it won't be limited to 8192 cases in B, and C above.
tzickel commented on Aug 24, 2016 â€¢
edited
This is an performance issue, especially when passing large objects. This can be easily triggered with a data post body:
bigdata = 'a' * 100000000
stream = io.BytesIO(bigdata)
a = requests.post('http://localhost', data=stream)
will call super_len on stream, which will call stream.getvalue() which will actually copy the 100MB in memory, get it's length, and discard the copy.
we should check first if the object has 'seek' and 'tell' and use them (much quicker) to get the length instead.
https://github.com/kennethreitz/requests/blob/52b15f811f8ef52a144c96b8b742d734dd39d693/requests/utils.py#L59
Contributor
zackw commented on Mar 14, 2014
I said in #1957 that I would like a guarantee that
try:
    resp = requests.get("...")
except requests.exceptions.RequestException as e:
    # recover
is sufficient to trap all exceptions that may occur as a result of "Weird Shit coming off the network" -- this should be understood broadly: anything other than a successful DNS lookup followed by a successful connection to a server that actually speaks HTTP(S) on that port and returns (a chain of valid redirections culminating in) a valid HTTP response. #1957 covers one class of problems in that area. This is the other: urllib3 is supposed to be just an implementation detail to the user of Requests, but under some conditions, some of its exceptions can "leak" out to the user. I have observed urllib3.exceptions.MaxRetryError and urllib3.exceptions.LocationParseError. Unfortunately, I do not have enough information to pin down exactly what causes these.
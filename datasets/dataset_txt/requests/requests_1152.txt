geckon commented on Feb 16, 2016
It might be beneficial to unite the behavior with other tools (including browsers) and start ignoring whitespaces surrounding a URL. See the examples:
$ curl -s "https://github.com/ " -o /dev/null -w "%{http_code}"; echo
200

$ python -c 'import urllib2; print(urllib2.urlopen("https://github.com/ ").getcode())'
200

$ python -c 'import requests; print(requests.get("https://github.com/ ").status_code)'
404
Also, W3C defines the a tag's href attribute as...
The href attribute on a and area elements must have a value that is a valid URL potentially surrounded by spaces.
Where URL potentially surrounded by spaces is defined as...
A string is a valid non-empty URL potentially surrounded by spaces if, after stripping leading and trailing whitespace from it, it is a valid non-empty URL.
I know this is not a killer argument for the requests library but it would be beneficial if it behaved the same way as the other approaches. It would also make HTML processing with requests (and e.g. beautifulsoup4) easier.
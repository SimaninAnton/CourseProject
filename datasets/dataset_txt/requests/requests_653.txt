astrofrog commented on May 23, 2017
I am trying to send a very large file (100Gb) using a POST request, with a call that looks like:
 r = requests.post(url, data={'filename': filename}, files={'file': f})
but the issue is that internally, requests tries to read the whole file before sending:
  File "upload.py", line 19, in <module>
    files=files)
  File "/home/robitaille/anaconda/lib/python2.7/site-packages/requests/api.py", line 88, in post
    return request('post', url, data=data, **kwargs)
  File "/home/robitaille/anaconda/lib/python2.7/site-packages/requests/api.py", line 44, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/robitaille/anaconda/lib/python2.7/site-packages/requests/sessions.py", line 349, in request
    prep = self.prepare_request(req)
  File "/home/robitaille/anaconda/lib/python2.7/site-packages/requests/sessions.py", line 287, in prepare_request
    hooks=merge_hooks(request.hooks, self.hooks),
  File "/home/robitaille/anaconda/lib/python2.7/site-packages/requests/models.py", line 290, in prepare
    self.prepare_body(data, files)
  File "/home/robitaille/anaconda/lib/python2.7/site-packages/requests/models.py", line 427, in prepare_body
    (body, content_type) = self._encode_files(files, data)
  File "/home/robitaille/anaconda/lib/python2.7/site-packages/requests/models.py", line 140, in _encode_files
    rf = RequestField(name=k, data=fp.read(),
MemoryError
For other libraries, there are solutions that involve e.g. mmap:
https://stackoverflow.com/a/2504133
but this doesn't work for requests due to the hard-coded f.read() which will force loading the whole file into memory. Is there a way to avoid this, and if not can support for mmap be implemented? (for mmap, f.read has to take an argument).
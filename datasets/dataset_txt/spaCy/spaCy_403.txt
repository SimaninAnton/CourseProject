Contributor
F0rge1cE commented on 22 Aug 2019
How to reproduce the behaviour
I try to call python -m spacy convert <path> ./ -t json -c iob with this labeled NER training corpus:
https://github.com/EuropeanaNewspapers/ner-corpora/blob/master/enp_DE.onb.bio/enp_DE.onb.bio
After the conversion, you can get a json file with content:
[
  {
    "id":0,
    "paragraphs":[
      {
        "sentences":[
          {
            "tokens":[
              {
                "orth":"November",
                "tag":"-",
                "ner":"O"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "id":0,
    "paragraphs":[
      {
        "sentences":[
          {
            "tokens":[
              {
                "orth":"Heute",
                "tag":"-",
                "ner":"O"
              }
            ]
          }
        ]
      }
    ]
  },
......
Such behavior is really weired. Seems that every separate token is considered as a whole sentence and a paragraph.
Another issue has already mentioned here: #4111 , which will cause exception when the token contains any non-word char ("[^\w-]" in the regex scope).
Your Environment
Operating System: OSX 10.13.6
Python Version Used: 3.7.3
spaCy Version Used: 2.1.8
Environment Information: N/A
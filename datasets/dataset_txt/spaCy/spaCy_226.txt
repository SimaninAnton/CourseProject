davidbren commented on 21 Oct 2019
How to reproduce the behaviour
from spacy.tokenizer import Tokenizer
tokens = tokenizer(sample)
result = len(tokens.text)

print("tokens length " + str(result))

totalTokenSize = 0

for i in tokens:
    totalTokenSize = totalTokenSize + len(i.text)

print("totalTokenSize " + str(totalTokenSize))
Output is
tokens length 34,980
totalTokenSize 30,034
So I am missing 4.946 when I loop vs when I take length
Your Environment
Operating System: Windows 10
Python Version Used: 3.6
spaCy Version Used: 2.1.8
1
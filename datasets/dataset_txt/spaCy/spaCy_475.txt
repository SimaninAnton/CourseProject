erotavlas commented on 29 Jul 2019 â€¢
edited
using genism I created custom word vectors Word2Vec(vocab=28964, size=100, alpha=0.025) using a larger corpus from which my NER training dataset was derived. (In case it's relevant, I lower cased all the words and removed words with numerics and special characters before training the word2vec model )
Then I trained my NER model using an empty English model en and the vectors I created and I got the following scores
Final model average score... (blank en model - with custom word vectors)
Recall: 69.63350785340315
Precision: 77.32558139534885
FScore: 73.27823691460055
Training an NER model with no word embeddings - just the blank English model en and I got the following scores
Final model average score... (Blank en model)
Recall: 73.82198952879581
Precision: 83.67952522255193
FScore: 78.44228094575799
What does this mean? I didn't expect the score to drop so much after introducing my custom word embeddings.
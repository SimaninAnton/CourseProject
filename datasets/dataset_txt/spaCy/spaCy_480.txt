imsaiful commented on 29 Jul 2019
I have tried the following code to retrain the spacy model:
import spacy
import random
from sklearn.externals import joblib
nlp = spacy.load('en')
nlp.entity.add_label('Brand')
nlp.entity.add_label('Celebrity')
nlp.entity.add_label('Community')
nlp.entity.add_label('GPE')
nlp.entity.add_label('Publisher')
nlp.entity.add_label('Show')
TRAIN_DATA = l[0:1800]
print(len(TRAIN_DATA))
try:
    optimizer = nlp.begin_training()
    for text, annotations in TRAIN_DATA:
        nlp.update([text], [annotations],drop=0.3, sgd=optimizer)
    nlp.to_disk("./model")
except Exception as e:
    print(e)
nlp = spacy.load('./model')
text = "Google is a Company.Elon Musk is world number one innovator.WordPress is good for SEO website. I live in America"
doc = nlp(text)
for ent in doc.ents:
    print(ent.text,ent.label_)
I have 1817 sentance in my test data. There is no prediction after training for the test data.However when I try to retrain the model using slicing i.e. first I train the model for the slice l[0:200] and then l[200:500],l[500:800],l[800:1000],l[1000:1300],l[1200:1600],l[1600:1817] for all slice then I got the prediction output. It means my dataset is correct. However when I take data size l[0:1800] I am not getting any prediction result. What is the reason of this issue?
romlatron commented on 8 Jul 2019
I have a model with different NER categories, which I want to separate to optimize training results. To do so, I thought about having one Spacy model with different custom components, one for each category. The problem is, I then have to load the same vocabulary for each one of my NER components, which is pretty heavy because we use custom word vectors which take a lot of memory space (> 1Gb). I tried to load the NER models without the vectors, which raises an error. I also tried to load them with very few vocabulary, and then assign them the vocab of the original NLP model:
ner = spacy.load(“path/to/ner”)
nlp = spacy.load(“path/to/nlp”)
ner.vocab = nlp.vocab
But it didn’t seem to work so well as the last line did not affect the NER results.
Is there a way to assign the same vocabulary to every component, without loading it multiple times which takes considerably too much space in memory? I thought about redefining the EntityRecognizer object, but is it a good approach, as it won’t let me load the model without the vectors?
Your Environment
spaCy version: 2.0.18
Platform: Windows-10-10.0.17134-SP0
Python version: 3.6.6
1
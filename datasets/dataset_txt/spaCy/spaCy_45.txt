Contributor
AlJohri commented on 29 Dec 2019
I'm using nlp.pipe (with multiple processes) in the latest spaCy (master branch) and having trouble doing proper error handling in a generator.
I have a custom pipeline component which occasionally errors on some documents with ValueError: [E103] Trying to set conflicting doc.ents: '(1387, 1388, 'PERSON')' and '(1387, 1388, 'PERSON')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap..
Issue
I can't easily figure out which document ID caused the issue since my custom pipeline components doesn't have access to the context. The context is provided to nlp.pipe via the as_tuples=True argument.
gen = tqdm(
    nlp.pipe(zip(df.text, df.id), as_tuples=True, batch_size=10, n_process=16),
    total=len(df),
)
I can't figure out how to ignore the exception and continue processing since it doesn't seem like there's an easy way to catch the error and continue the generator, especially in a multiprocessing setting.
Potential Solution
Can we add an ignore_exceptions=True, error_handler=callable which allows ignoring exceptions and running some error handler function that has access to the handler(error, doc, context)?
Info about spaCy
spaCy version: 2.2.3
Platform: Darwin-18.7.0-x86_64-i386-64bit
Python version: 3.7.5
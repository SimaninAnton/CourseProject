pramodith commented on 3 Dec 2019 â€¢
edited
Description
I seem to be facing a memory leak when I try to use beam_parse on a large number of documents.
The below code is a function that's called hundreds of times, each call to the function will pass in a dataframe containing around 5000 documents.
I obeserve that there's a spike in memory when I call beam_parse and it continues to spike despite leaving the function and being called again. I've tried using the del command to delete my dataframe before I leave the function, using gc.collect() and even reloading the spacy model at the end of every call to the function but the problem persists.
I've seen the thread over here (#3618) discussing the same issue but none of them seemed to mention beam_parse.
Also this is how I load the model :
nlp = spacy.load("en_core_web_lg", disable=['tagger', 'parser'])
How to reproduce the behaviour
`
def ner(nlp, df, threshold=0.8):
'''
:param nlp: Spacy object
:param df: Dataframe that contains the documents.
:param threshold: Threshold score for an entity to be deemed to be a positive.
:return:
'''
try:
 print(f'Creating pipe : memory , {psutil.virtual_memory().percent}')
 docs = list(nlp.pipe(df['text'],batch_size=64,n_threads=4,disable=['ner']))
 print(f'Creating beam : memory , {psutil.virtual_memory().percent}')
 beams = nlp.entity.beam_parse(docs, beam_width=4, beam_density=0.0001)
 print(f'Processing beam : memory , {psutil.virtual_memory().percent}')
 for i, doc_beam in enumerate(zip(docs, beams)):
  doc, beam = doc_beam
  for score, ents in nlp.entity.moves.get_beam_parses(beam):
   if score > threshold:
    for start, end, label in ents:
     print(label)
 print(f'Done : memory , {psutil.virtual_memory().percent}')
except Exception as e:
 raise e
`
Log Statements:
Below are the logs for the first 5 iterations. As it goes on longer I see the continued increase in consumption of memory.
Processing 5000 documents.
Entered NER : memory , 26.0
Creating pipe : memory , 26.0
Creating beam : memory , 26.2
Processing beam : memory , 28.9
Done : memory , 28.9
Processing 5000 documents.
Entered NER : memory , 28.6
Creating pipe : memory , 28.6
Creating beam : memory , 28.6
Processing beam : memory , 30.8
Done : memory , 30.8
Processing 5001 documents.
Entered NER : memory , 30.5
Creating pipe : memory , 30.5
Creating beam : memory , 30.5
Processing beam : memory , 32.4
Done : memory , 32.3
Processing 5003 documents.
Entered NER : memory , 33.9
Creating pipe : memory , 33.9
Creating beam : memory , 33.9
Processing beam : memory , 36.0
Done : memory , 36.0
Processing 5004 documents.
Entered NER : memory , 35.7
Creating pipe : memory , 35.7
Creating beam : memory , 35.7
Processing beam : memory , 37.8
Done : memory , 37.8
Processing 5001 documents.
Entered NER : memory , 37.4
Creating pipe : memory , 37.4
Creating beam : memory , 37.4
Processing beam : memory , 39.5
Done : memory , 39.5
Environment
Operating System: Linux
Python Version Used: 3.6.9
spaCy Version Used: 2.2.3
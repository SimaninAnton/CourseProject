MrEricL commented on 24 Jun 2019
I'm updating the NER with new data (about 2k more sentences) using existing tags. However when examining what the model missed with the manual annotation, there are a few ORGs that the model consistently seems to miss despite multiple examples in those sentences. Similar looking ORGs don't seem to suffer from the same issue.
Is there a way for me to fix this without going into the over fitting territory?
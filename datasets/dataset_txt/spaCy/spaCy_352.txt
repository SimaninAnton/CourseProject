smiles3983 commented on 6 Sep 2019
I have been using the nlp.from_bytes method with the large english model version 1. We upgraded to the 2.1.0 model, and now im getting an error stating that it cant find the en_model.vectors. See below how I load the model. When I do the to_bytes, am I supposed to also save the en_model.vectors separately?
with open(os.path.join(filepath, "large_2.1.0.txt"), 'rb') as file:
modelContent = file.read()
nlp = spacy.blank(meta["lang"])
for pipe_name in meta["pipeline"]:
pipe = nlp.create_pipe(pipe_name)
nlp.add_pipe(pipe)
nlp.from_bytes(modelContent)
Your Environment
Operating System:
Python Version Used:
spaCy Version Used:
Environment Information:
easonla commented on 1 Aug 2019 â€¢
edited
I am trying to exercise intent classifier data with spacy example code with minimal modification. Similar to previous solved issue, I've set
random.seed(0)
np.random.seed(0)
and did not use gpu training. From my experiments, I was able to recreate identical model with the the same machine. But failed to reproduce results across different platform even with exact same code, same environment, same glove vector and random number seed. I've test it on Ubuntu 18.04, Mac 10.14.5 and docker ubuntu:latest with python 3.6, spacy 2.0.11, thinc 6.10.1. Also tested on spacy 2.1.6 and thinc 7.0.8 with other pretrained vector (en-web-small) but nothing different, the model cannot be reproduce across platform/ machine. The model performance is comparable just I expect to get exact the same model with everything controlled.
# Load the data (training data for utterance to intent mappings) - internal count
import sys
import pandas as pd
import numpy as np
import random
import time
import spacy
from spacy.util import minibatch
from pathlib import Path
random.seed(0)
np.random.seed(0)

training = pd.read_csv('data/train.csv', keep_default_na=False, na_values=[""]
                       , usecols = ['utterance', 'intent', 'weight'], encoding="latin-1")
#Sort the input by intent alphabetically then index
training = training.reset_index().sort_values(['intent','index']).drop(columns='index').reset_index(drop=True)

#testing_new = pd.read_csv('data/test.csv', usecols = ['utterance', 'intent'])

# Create duplicate rows based on the weight column 
training = pd.DataFrame(np.repeat(training.values, training['weight'].values, axis=0)
                        , columns=['utterance', 'intent', 'weight'])[['utterance', 'intent']]


print("Data read in")
sys.stdout.flush()

# Load NLP model
nlp1 = spacy.load('en')
# Add text classification to pipeline
textcat = nlp1.create_pipe('textcat')
nlp1.add_pipe(textcat, last=True)

print("Spacy and model loaded")
sys.stdout.flush()

# Get unique intents to add to possible classes
intents_unique = training['intent'].unique()
intents_unique = [str("".join(i for i in a if ord(i)<128)) for a in intents_unique]
for intent in intents_unique:
    textcat.add_label(intent)


# Process data for modeling
training_raw = [tuple(x) for x in training.to_records(index=False)]
training_raw = [(str("".join(i for i in a if ord(i)<128)), 
                 str("".join(j for j in b if ord(j)<128))) 
                for a,b in training_raw]


# Construct training data and convert to unicode for input into spaCy
texts, labels = zip(*training_raw)
cats = []
intent_cat_dict = {}
for intent in intents_unique:
    intent_cat_dict[intent] = {}
    for intent1 in intents_unique:
        if intent == intent1:
            intent_cat_dict[intent][intent1] = 1
        else:
            intent_cat_dict[intent][intent1] = 0
for label in labels:
    cats.append({'cats': intent_cat_dict[label]})
train_data = list(zip(texts, cats))

random.shuffle(train_data)
texts, _ = zip(*train_data)

# Import spaCy utilities needed and get names of other pipes to disable them during training
other_pipes = [pipe for pipe in nlp1.pipe_names if pipe != 'textcat']

print("Data processed and ready for modeling")
sys.stdout.flush()

start = time.time()
# Train categorization model
n_iter = 5
with nlp1.disable_pipes(*other_pipes):
    optimizer = nlp1.begin_training()
    for i in range(n_iter):
        losses = {}
        batches = minibatch(train_data, size=256)
        for batch in batches:
            texts, annotations = zip(*batch)
            nlp1.update(texts, annotations, sgd=optimizer, drop=0.2, losses=losses)
        current_time = time.time()
        time_esclape = current_time - start
        print(i, losses['textcat'], time_esclape)
        sys.stdout.flush()


print("Modeling finished")
sys.stdout.flush()

# Output model to disk
output_dir = 'model/output_intent_clf_docker'
output_dir = Path(output_dir)
if not output_dir.exists():
    output_dir.mkdir()
nlp1.to_disk(output_dir)
print("Saved model to", output_dir)

print("Output to disk finished")
sys.stdout.flush()
Your Environment
Operating System: Mac 10.14.5/ Ubuntu 18.04 / Docker ubuntu:latest runs on Mac
Python Version Used: 3.6
spaCy Version Used: 2.0.11
Environment Information:
absl-py==0.7.1
aniso8601==6.0.0
astor==0.7.1
Click==7.0
cymem==1.31.2
cytoolz==0.8.2
dill==0.2.9
duckling==1.8.0
Flask==1.0.2
Flask-RESTful==0.3.6
gast==0.2.2
gevent==1.2.2
greenlet==0.4.15
grpcio==1.19.0
gunicorn==19.8.1
h5py==2.9.0
itsdangerous==1.1.0
Jinja2==2.10.1
JPype1==0.6.3
jsonschema==2.6.0
Keras-Applications==1.0.7
Keras-Preprocessing==1.0.9
Markdown==3.1
MarkupSafe==1.1.1
mock==2.0.0
msgpack==0.6.1
msgpack-numpy==0.4.3.2
msgpack-python==0.5.6
murmurhash==0.28.0
nltk==3.3
numpy==1.16.2
pandas==0.23.4
pathlib==1.0.1
pbr==5.1.3
plac==0.9.6
preshed==1.0.1
protobuf==3.7.1
python-dateutil==2.8.0
pytz==2019.1
regex==2017.4.5
six==1.12.0
spacy==2.0.11
tensorboard==1.13.1
tensorflow==1.13.1
tensorflow-estimator==1.13.0
termcolor==1.1.0
thinc==6.10.1
toolz==0.9.0
tqdm==4.31.1
ujson==1.35
Werkzeug==0.15.1
wrapt==1.11.1
1
attenton commented on 12 Dec 2019
I'm using spacy to do customized tokenizer. I want to take the api name as one token. Such as srcs[offset].remaining() in sentence:Up to the first srcs[offset].remaining() bytes of this sequence are written from buffer srcs[offset].
I have added a token_match to tokenizer, however it was overridedd by suffixes.
The code is shown below:
import re
import spacy
from spacy.tokenizer import Tokenizer

def customize_tokenizer_api_name_recognition(nlp):
    # add api_name regex, such aaa.bbb(cccc) or aaa[bbb].ccc(ddd)
    api_name_match = re.compile("(\w+(\[[\w+-]+\])?\.)+\w+\(.*?\)", re.UNICODE).match
    nlp.tokenizer.token_match = api_name_match

if __name__ == '__main__':
    nlp = spacy.load('en_core_web_sm')
    customize_tokenizer_api_name_recognition(nlp)
    sentence = "Up to the first srcs[offset].remaining() bytes of this sequence are written from buffer srcs[offset]."
    doc = nlp(sentence)
    print([token.text for token in doc])
    # output:  ['Up', 'to', 'the', 'first', 'srcs[offset].remaining', '(', ')', 'bytes', 'of', 'this', 'sequence', 'are', 'written', 'from', 'buffer', 'srcs[offset', ']', '.']
    # expected output: ['Up', 'to', 'the', 'first', 'srcs[offset].remaining()', 'bytes', 'of', 'this', 'sequence', 'are', 'written', 'from', 'buffer', 'srcs[offset', ']', '.']
I have read some related issues #4573, #4645 and the doc. However all the examples are simple regex, and they were solved by removing some prefixes_search. what about the complex regex? How to solve this type of problem?
Your Environment
Operating System: Windows 10 18362.476
Python Version Used: python 3.7.3
spaCy Version Used: spacy 2.2.3
Environment Information:
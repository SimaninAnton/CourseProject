swicaksono commented on 22 Oct 2019 â€¢
edited
I successfully created the KB model by using my own dataset. Well, when I'm gonna try to train and add the EL component into the pipeline alongside with NER, I've had always encountered the error segmented fault (core dump), although the vocab is the one I used to create the KB model. I trace it and it's always when load_bulk the KB model.
KnowledgeBase(vocab=nlp.vocab)

# here I've always get segmented fault
kb.load_bulk(os.path.join(path_kb, lang))
Any helps?
Thanks.
Your Environment
Operating System: Ubuntu 19
Python Version Used: 3.6.6
spaCy Version Used: 2.2.1
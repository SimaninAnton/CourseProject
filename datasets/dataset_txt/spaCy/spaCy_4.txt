lingvisa commented 8 days ago â€¢
edited
I loaded 300000 line of Chinese texts, each line is like a tweet length. The compared the batch and non-batch mode to compare its speed:
Batch:
def process_text_with_batch(text_lines):
    line_number = 0
    print("Start to process: ")
    for doc in nlp.pipe(text_lines):
        line_number += 1
        print(line_number)
Non batch:
def process_text(text_lines):
    line_number = 0
    print("Start to process: ")
    for text in text_lines:
        doc = nlp(text)
        line_number += 1
        print(line_number)
Where 'text_lines' is an array. The two ways finish almost the same time consumed: 2.5 and 2.6 minutes. why doesn't it speed up? spaCy is using Jieba segmentation. Is possible that Jieba doesn't speed up?
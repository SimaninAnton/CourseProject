kbmlcoding commented on 5 Dec 2019 â€¢
edited
I am trying to run spacy similarity on bunch of documents on machine which has GPU tesla card
and using python3 multiprocessing to run in parallel but running into below issue
"""
Traceback (most recent call last):
File "/usr/lib64/python3.6/multiprocessing/pool.py", line 119, in worker
result = (True, func(*args, **kwds))
File "/usr/lib64/python3.6/multiprocessing/pool.py", line 44, in mapstar
return list(map(*args))
File "gpu.py", line 35, in chan_similarity
df['sim_measure'] = df.apply(lambda x : run_sim(x), axis=1)
File "/home/kadu/venv/lib/python3.6/site-packages/pandas/core/frame.py", line 6913, in apply
return op.get_result()
File "/home/kadu/venv/lib/python3.6/site-packages/pandas/core/apply.py", line 186, in get_result
return self.apply_standard()
File "/home/kadu/venv/lib/python3.6/site-packages/pandas/core/apply.py", line 292, in apply_standard
self.apply_series_generator()
File "/home/kadu/venv/lib/python3.6/site-packages/pandas/core/apply.py", line 321, in apply_series_generator
results[i] = self.f(v)
File "gpu.py", line 35, in
df['sim_measure'] = df.apply(lambda x : run_sim(x), axis=1)
File "gpu.py", line 23, in run_sim
return (nlp_glob(x['all_train_data_with_desc_trim_100_null_removed.mov_chan_desc']).similarity(nlp_glob(x['all_train_data_with_desc_trim_100_null_removed.proj_chan_desc'])))
File "doc.pyx", line 395, in spacy.tokens.doc.Doc.similarity
File "doc.pyx", line 464, in spacy.tokens.doc.Doc.vector_norm.get
File "doc.pyx", line 312, in iter
File "cupy/core/core.pyx", line 935, in cupy.core.core.ndarray.add
File "cupy/core/_kernel.pyx", line 828, in cupy.core._kernel.ufunc.call
File "cupy/core/_kernel.pyx", line 90, in cupy.core._kernel._preprocess_args
TypeError: ("Unsupported type <class 'numpy.ndarray'>", 'occurred at index 2')
"""
The above exception was the direct cause of the following exception:
Traceback (most recent call last):
File "gpu.py", line 78, in
dt = parallelize(chunk, chan_similarity)
File "gpu.py", line 54, in parallelize
data = pd.concat(pool.map(func, data_split))
File "/usr/lib64/python3.6/multiprocessing/pool.py", line 266, in map
return self._map_async(func, iterable, mapstar, chunksize).get()
File "/usr/lib64/python3.6/multiprocessing/pool.py", line 644, in get
raise self._value
TypeError: ("Unsupported type <class 'numpy.ndarray'>", 'occurred at index 2')
Your Environment
Operating System: Centos
Python Version Used: python 3.6.8
spaCy Version Used: spacy 2.2.3
Environment Information: Running on Tesla GPU card
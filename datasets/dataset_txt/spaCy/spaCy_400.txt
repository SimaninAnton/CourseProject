jameszlj commented on 22 Aug 2019 â€¢
edited
Your Environment
Operating System:
Python Version Used:
spaCy Version Used:
Environment Information:
spacy 2.0.18
text = """Start traveling like a local! Book Trip Guru with Mastercard and get 20% off all tour experiences and adventures in many South East Asian destinations."""
doc = nlp(text)
taxonomys_list = OrderedDict(doc.cats)
taxonomys_list = OrderedDict(sorted(taxonomys_list.items(), key=lambda t: t[1], reverse=True))
print(taxonomys_list)
OrderedDict([('Services', 0.991990864276886), ('Travel Services', 0.9888597726821899), ('Holiday', 0.9870848059654236), ('Booking services', 0.9758071303367615), ('Travel', 0.9735677242279053), ('Vacations', 0.9703308343887329), ('Adventure Activities', 0.9638486504554749), ('Entertainment', 0.9459176659584045), ('Holidays', 0.8224777579307556), ('Vacation', 0.7244226932525635), ('Booking Service', 0.08504372835159302), ('Booking', 0.06343142688274384), ('Attractions', 0.046378690749406815), ('Car Rentals', 0.03734173625707626), ('Experiences', 0.03500397875905037), ('Family Vacations', 0.033907972276210785), ('Tickets', 0.02211538888514042), ('Hotels', 0.02100328728556633), ('Movies', 0.019198477268218994), ('Vacation Rentals', 0.018203062936663628), ('Personal Care', 0.0152616947889328), ('Weekend Getaways', 0.015231739729642868), ('Museums', 0.013910885900259018), ('Jewish', 0.01270236074924469), ('Arts and Crafts', 0.011866671964526176), ('Sports and Fitness', 0.010706927627325058), ('Teas', 0.009054446592926979), ('Meats', 0.009014514274895191), ('Restaurants', 0.008879509754478931), ('Champagne', 0.008256825618445873), ('Buffets', 0.00780327757820487), ('Desserts', 0.007737184874713421), ('Cooking', 0.007576660718768835), ('Sports Fan', 0.005898750387132168), ('Cuisine', 0.005667830351740122), ('Dining', 0.00557311624288559), ('Health Care', 0.005544014275074005), ('Barbecue', 0.005424442235380411), ('Food & Beverage', 0.005325845908373594), ('Golf', 0.004812314175069332), ('Healthcare', 0.0047915480099618435), ('Beauty', 0.0039006059523671865), ('Luxury', 0.00378055521287024), ('Spas', 0.0037371967919170856), ('Games', 0.003526924178004265), ('Airports', 0.0034586999099701643), ('Resorts', 0.003405642230063677), ('Bakeries', 0.0033209563698619604), ('Seafood', 0.003297787392511964), ('Travel Insurance', 0.0026215368416160345), ('Exhibitions', 0.0022796255070716143), ('Islands', 0.002163636265322566), ('Souvenir', 0.0021531537640839815), ('Shopping', 0.002134014619514346), ('Muslim', 0.0018916900735348463), ('Cruises', 0.0018594496650621295), ('Wineries', 0.0017661957535892725), ('Fruit', 0.0016967753181234002), ('Michelin', 0.0016406797803938389), ('Celebrity Chef', 0.001576813287101686), ('Parks', 0.0015764206182211637), ('Gambling', 0.0015523636247962713), ('Accessories', 0.0015489469515159726), ('Coffee', 0.0015304710250347853), ('Household', 0.001439731102436781), ('Grocery', 0.0013601784594357014), ('Theme', 0.0012071426026523113), ('Concerts and Music', 0.001160294166766107), ('Department Stores', 0.001099713845178485), ('Hindu', 0.0010434803552925587), ('Clubs/Nightclubs', 0.0009954808047041297), ('Buddhist', 0.0009882946033030748), ('Sushi', 0.0009507693466730416), ('Clothes', 0.0009361709235236049), ('Bars', 0.0008493054774589837), ('Fishing', 0.0008431627647951245), ('Market Places', 0.0007646719459444284), ('Weddings', 0.0006306252907961607), ('Honeymoons', 0.0005952748470008373), ('Fast Food', 0.0005368471029214561), ('Fashion Trends', 0.00039127955096773803), ('Breakfast', 0.0003885205078404397), ('Gold Beach', 0.00038597179809585214), ('Electronics', 0.0003595442685764283), ('Health Foods', 0.0003307793813291937), ('Nightlife', 0.0002483692951500416), ('Beverages', 0.00024224855587817729), ('Airlines', 0.00021940836450085044), ('Alcoholic Beverages', 0.00017127700266428292)])
but spacy 2.1.8
OrderedDict([('Experiences', 0.2224183976650238), ('Vacations', 0.18968799710273743), ('Holiday', 0.18574681878089905), ('Vacation', 0.15565261244773865), ('Holidays', 0.1445891559123993), ('Food & Beverage', 0.06648927927017212), ('Travel', 0.03541579842567444), ('Services', 0.0), ('Fashion Trends', 0.0), ('Entertainment', 0.0), ('Luxury', 0.0), ('Hotels', 0.0), ('Resorts', 0.0), ('Family Vacations', 0.0), ('Islands', 0.0), ('Honeymoons', 0.0), ('Weekend Getaways', 0.0), ('Personal Care', 0.0), ('Spas', 0.0), ('Sports and Fitness', 0.0), ('Accessories', 0.0), ('Adventure Activities', 0.0), ('Airlines', 0.0), ('Airports', 0.0), ('Arts and Crafts', 0.0), ('Attractions', 0.0), ('Beauty', 0.0), ('Booking services', 0.0), ('Car Rentals', 0.0), ('Clothes', 0.0), ('Clubs/Nightclubs', 0.0), ('Concerts and Music', 0.0), ('Cruises', 0.0), ('Department Stores', 0.0), ('Electronics', 0.0), ('Exhibitions', 0.0), ('Fishing', 0.0), ('Gambling', 0.0), ('Games', 0.0), ('Gold Beach', 0.0), ('Golf', 0.0), ('Grocery', 0.0), ('Health Care', 0.0), ('Household', 0.0), ('Market Places', 0.0), ('Movies', 0.0), ('Museums', 0.0), ('Nightlife', 0.0), ('Parks', 0.0), ('Shopping', 0.0), ('Souvenir', 0.0), ('Sports Fan', 0.0), ('Theme', 0.0), ('Tickets', 0.0), ('Travel Insurance', 0.0), ('Travel Services', 0.0), ('Vacation Rentals', 0.0), ('Weddings', 0.0), ('Michelin', 0.0), ('Celebrity Chef', 0.0), ('Restaurants', 0.0), ('Cuisine', 0.0), ('Cooking', 0.0), ('Dining', 0.0), ('Beverages', 0.0), ('Alcoholic Beverages', 0.0), ('Wineries', 0.0), ('Champagne', 0.0), ('Bars', 0.0), ('Teas', 0.0), ('Coffee', 0.0), ('Bakeries', 0.0), ('Desserts', 0.0), ('Barbecue', 0.0), ('Breakfast', 0.0), ('Buffets', 0.0), ('Fast Food', 0.0), ('Fruit', 0.0), ('Health Foods', 0.0), ('Meats', 0.0), ('Seafood', 0.0), ('Sushi', 0.0), ('Hindu', 0.0), ('Muslim', 0.0), ('Buddhist', 0.0), ('Jewish', 0.0), ('Booking', 0.0), ('Booking Service', 0.0), ('Healthcare', 0.0)])
code
`def auto_training(model="en_core_web_lg", output_dir=None, split=0.8, n_iter=20, init_tok2vec=None, get_data=get_data_from_database):
nlp = spacy.load(model)
if "textcat" not in nlp.pipe_names:
    # architecture in ["ensemble", "simple_cnn", "bow"]
    textcat = nlp.create_pipe(
        "textcat", config={"exclusive_classes": True, "architecture": "simple_cnn"})
    nlp.add_pipe(textcat, last=True)
else:
    textcat = nlp.get_pipe("textcat")

texts, annotations, labels = get_data()

# add label to text classifier
for label in labels:
    textcat.add_label(label)

logger.info("Loading training data...")
n_texts = int(len(texts) * split)
train_texts = texts[:n_texts]
train_cats = annotations[:n_texts]
dev_texts = texts[n_texts:]
dev_cats = annotations[n_texts:]
logger.info("Using {} examples ({} training, {} evaluation)".format(len(texts), len(train_texts), len(dev_texts)))

train_data = list(zip(train_texts, train_cats))

# get names of other pipes to disable them during training
other_pipes = [pipe for pipe in nlp.pipe_names if pipe != "textcat"]
with nlp.disable_pipes(*other_pipes):  # only train textcat
    optimizer = nlp.begin_training()
    if init_tok2vec is not None:
        with init_tok2vec.open("rb") as file_:
            textcat.model.tok2vec.from_bytes(file_.read())
    logger.info("Training the model...")
    logger.info("{:^5}\t{:^5}\t{:^5}\t{:^5}".format("LOSS", "P", "R", "F"))
    batch_sizes = compounding(4.0, 32.0, 1.001)
    for _ in range(n_iter):
        losses = {}
        # batch up the examples using spaCy's minibatch
        random.shuffle(train_data)
        batches = minibatch(train_data, size=batch_sizes)
        # batches_len = len(batches)
        batch_p = 0
        for batch in batches:
            batch_p += 1
            texts, annotations = zip(*batch)
            nlp.update(texts, annotations, sgd=optimizer, drop=0.2, losses=losses)
        with textcat.model.use_params(optimizer.averages):
            # evaluate on the dev data split off in load_data()
            scores = evaluate(nlp.tokenizer, textcat, dev_texts, dev_cats)
        logger.info("{0:.3f}\t{1:.3f}\t{2:.3f}\t{3:.3f}".format(losses["textcat"], scores["textcat_p"], scores["textcat_r"], scores["textcat_f"]))

if output_dir is not None:
    output_dir = Path(output_dir)
    if not output_dir.exists():
        output_dir.mkdir()
    with nlp.use_params(optimizer.averages):
        nlp.to_disk(output_dir)
    logger.info("Saved model to %s" % output_dir)`
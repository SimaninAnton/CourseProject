PROgramJEDI commented on 11 Oct 2019
I don't really familiar with the spaCy library, but I don't think the way spaCy manipulate the 'text' is correct. Those are supportive reasons:
The 're' (regular expression) module
aldo the 're' module offers the best ways to manipulate text in High-Performance speed, it's written that spaCy don't take advantage of it.
Performance
only by writing this code takes spaCy 1sec in 'intel i5 k8' computer, which is bad:
nlp = spacy.load('en_core_web_sm')
doc = nlp('this is my text')
After that, you need to iterate in 'doc' to get the tokens or token attributes.
I think the Dictionary is a much better way to accomplish that.
Something like this:
import re
from functools import wraps


def load(model):
 # process the model...
 @wraps(model)
 def wrapper(text):
  # wrapper: process the 'text' with the given 'model'...

  # initialize before loop (assign new memory to the objects)
  ptt = None
  mchs = None
  position = None
  # FIX: fix the split method to split it to only letters, dots, and columns
  #  with no new lines ('\n') or tabs...
  for word in text.split(' '):
   ptt = re.compile(word)
   # find the mchs which are the positions of the given pattern
   mchs = re.finditer(ptt, text)

   for mch in mchs:
    # the position of the word
    position = (mch.start(), mch.end())

    yield {
     (position): 
      {   'name': text[mch.start():mch.end()],
       'head': '',
       'pos': '',
      }
     }
 return wrapper


nlp = load('en')
doc = nlp('this is my text')

for obj in doc:
 print(obj)
NOT IN THE EXAMPLE (extra functionality):
After that, any time user requests to access an attribute of a token, the program would add it to the dictionary in the token index inside the head filed.
>>> Please tell me if it's a good idea so I can pull new commit to the library...
2
Contributor
aaronkub commented on 28 Sep 2019
How to reproduce the behaviour
Hello and thank you very much for this beautiful library. :)
I am using spaCy in a PySpark application and am finding that the PhraseMatcher behaves differently than when I test locally. I believe the root cause is that I'm pickling the Language (nlp) object and deserializing on the workers.
From what I can tell this is the same issue raised in #1939 and #3248.
The below code fails with python 3.6.9 and spaCy 2.1.8
import pickle
import spacy
from spacy.matcher import PhraseMatcher

nlp = spacy.load('en_core_web_sm')

matcher = PhraseMatcher(nlp.vocab, attr="LOWER")
matcher.add("test_words", None, *[nlp.make_doc("random")])

test_doc = nlp("This is a Random phrase.")

print("Original Matcher Found {} matches."
 .format(len(matcher(test_doc)))) # 1 match

with open("matcher.pickle", 'wb') as tmp:
    pickle.dump(matcher, tmp)
    
with open("matcher.pickle", 'rb') as tmp:
    unpickled_matcher = pickle.load(tmp)

print("Unpickled Matcher Found {} matches."
 .format(len(unpickled_matcher(test_doc)))) # 0 matches
Your Environment
Info about spaCy
spaCy version: 2.1.8
Platform: Darwin-18.7.0-x86_64-i386-64bit
Python version: 3.6.9
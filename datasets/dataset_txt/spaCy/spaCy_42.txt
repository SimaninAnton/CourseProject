kormilitzin commented on 30 Dec 2019
How to reproduce the behaviour
Being inspired by: https://explosion.ai/blog/sense2vec-reloaded example with custom hyper parameters with spacy pretrain, I wanted to train a larger (than the default) model, namely:
$ python -m spacy pretrain ./data/data_pretrain.jsonl en_vectors_web_lg ./tokens_expr -lstm 3 -uv -er 5000 -sa 4 -cw 128 -cd 8 -i 1
all finished nicely. However, when I wanted to use the pertained weights with spaCy NER model:
$ token_vector_width=128 embed_size=5000 hidden_width=128 python -m spacy train en ./med7_128_5000_v00_shuffle ./data/train_test/train/_med7_train_shuffle.json ./data/train_test/test/_med7_test_shuffle.json -t2v ./tokens_expr/model0.bin -v en_vectors_web_lg -p ner -n 200 -ne 5 -g 0
It crashed with:
Training pipeline: ['ner']
Starting with blank model 'en'
Loading vector from model 'en_vectors_web_lg'
Counting training words (limit=0)
Traceback (most recent call last):
File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
"main", mod_spec)
File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
exec(code, run_globals)
File "/mnt/sdf/andrey_work/spacy/lib/python3.6/site-packages/spacy/main.py", line 33, in
plac.call(commands[command], sys.argv[1:])
File "/mnt/sdf/andrey_work/spacy/lib/python3.6/site-packages/plac_core.py", line 367, in call
cmd, result = parser.consume(arglist)
File "/mnt/sdf/andrey_work/spacy/lib/python3.6/site-packages/plac_core.py", line 232, in consume
return cmd, self.func(*(args + varargs + extraopts), **kwargs)
File "/mnt/sdf/andrey_work/spacy/lib/python3.6/site-packages/spacy/cli/train.py", line 244, in train
components = _load_pretrained_tok2vec(nlp, init_tok2vec)
File "/mnt/sdf/andrey_work/spacy/lib/python3.6/site-packages/spacy/cli/train.py", line 551, in _load_pretrained_tok2vec
component.tok2vec.from_bytes(weights_data)
File "/mnt/sdf/andrey_work/spacy/lib/python3.6/site-packages/thinc/neural/_classes/model.py", line 367, in from_bytes
for dim, value in weights[i][b"dims"].items():
TypeError: byte indices must be integers or slices, not bytes
Is there any workaround to introduce a larger model for spaCy NER? Thanks.
Info about spaCy
spaCy version: 2.2.3
Platform: Linux-4.15.0-70-generic-x86_64-with-Ubuntu-18.04-bionic
Python version: 3.6.8
Models: en
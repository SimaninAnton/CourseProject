chikubee commented on 4 Sep 2019 â€¢
edited
How to reproduce the behaviour
Your Environment
Operating System: Built on Google Colab
Python Version Used: python 3
spaCy Version Used: 2.1.8
spacy-pytorch-transformers verison: 2.1.1
I was wondering if you could help me understand why there is extremely low similarity for some genuinely similar cases.
Sentence1: I am a salaried person
Sentence2: I am a person who gets salary
The similarity between the tokens salaried and salary is extremely less.
While Sentence2 actually matches with other sentences in the corpora relevant to salary, Sentence1 does not.
Does it have something to do with the word-pieces as salaried gets broken into sal ##ari ##ed?
And how exactly is the final vector constructed from wordpieces for a particular token?
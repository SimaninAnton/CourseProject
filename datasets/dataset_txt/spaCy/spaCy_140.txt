engrsfi commented on 18 Nov 2019 â€¢
edited
The BERT model for the German language works fine if I use it in the main process or use it in a multi-threaded way. However, as soon as, I use the model in a multi-processing mode, it gets stuck at the model inference time.
Normal usage which works fine:
import spacy

# Load model (German language)
bert_model = spacy.load('de_trf_bertbasecased_lg')

# Run model 
result = bert_model("This is just a test input")
Usage in multiprocessing mode which does not work:
import spacy

bert_model = None

def worker(text):
    # Load model (German language)
    if not bert_model:
       bert_model = spacy.load('de_trf_bertbasecased_lg')

    # Run model 
    result = bert_model(text) #It just gets stuck here.

from multiprocessing import Pool

list_of_text_strings = ["this is test 1", "this is test 2", "this is test 3"]

with Pool(2) as p:
    p.map(worker, list_of_text_strings)
In the multiprocessing model, the model loading statement is executed but then it gets stuck at inference time. Any ideas what is going wrong here? Is it a bug or am I doing something really wrong? or could it be that its a problem only with German-language Bert?
Your Environment
spaCy version: 2.2.2
Platform: Darwin-18.7.0-x86_64-i386-64bit
Python version: 3.6.9
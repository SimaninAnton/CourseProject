tnmcneil commented on 19 Oct 2019
How to reproduce the behaviour
I created a phrasematcher to match titles (eg: queen, manager, mayor, etc.) and it fails when applied to a document containing out of vocabulary tokens.
The error it throws is:
ERROR:root:error: "[E018] Can't retrieve string for hash '4332798303416328849'."
I got around this by creating a "clean doc" from the original doc to feed through the phrase matcher like so:
if any([t.is_oov for t in doc]):
        clean_toks = [t.text_with_ws if not t.is_oov else 'OOV ' if t.text_with_ws != t.text or re.match('\s', t.text) else 'OOV' for t in doc]
        clean_doc = nlp(''.join(clean_toks))
matches = phrase_matcher(clean_doc)
spans = [doc[start:end] for match_id, start, end in matches]
(I added string 'OOV' to replace the oov tokens because I needed the token indices to match the original doc)
I am wondering if there is a better way around this or a way for the phrase matcher code to inherently ignore oov tokens rather than trying to process them
Info about spaCy
Models: en
Python version: 3.5.1
spaCy version: 2.1.6
Platform: Darwin-18.6.0-x86_64-i386-64bit
Operating System: Mac OS
chunyat commented on 23 Aug 2019 â€¢
edited
How to reproduce the behaviour
I have been using spaCy v2.0.18 (which was downloaded as a package when I installed Fastai) to train a custom NER model to detect a set of custom entity types for my own purposes.
I was able to get really good results with v2.0.18:
nlp.entity_tagger|train_entity_tagger|INFO| Training model...
nlp.entity_tagger|train_entity_tagger|INFO| Losses {'ner': 0.15672576857688614}
nlp.entity_tagger|train_entity_tagger|INFO| Losses {'ner': 0.12927774898755265}
nlp.entity_tagger|train_entity_tagger|INFO| Losses {'ner': 0.10086585149922489}
nlp.entity_tagger|train_entity_tagger|INFO| Losses {'ner': 0.11106154029696236}
nlp.entity_tagger|train_entity_tagger|INFO| Losses {'ner': 0.08540124149758303}
nlp.entity_tagger|train_entity_tagger|INFO| Losses {'ner': 0.0679294809260213}
nlp.entity_tagger|train_entity_tagger|INFO| Losses {'ner': 0.08455457622118247}
nlp.entity_tagger|train_entity_tagger|INFO| Losses {'ner': 0.11117098736776775}
nlp.entity_tagger|train_entity_tagger|INFO| Losses {'ner': 0.09019838208963762}
nlp.entity_tagger|train_entity_tagger|INFO| Losses {'ner': 0.08187232735047828}
(This evaluation script was written myself, making use of the seqeval package for sequence evaluation tasks)
nlp.spacy_tools|evaluate_spacy|INFO|
                  precision    recall  f1-score   support

        PRODUCT    0.95686   0.93487   0.94574       783
ATTRIBUTE_VALUE    0.97315   0.99315   0.98305       146
       HOSPITAL    0.96644   0.98630   0.97627       146
  ATTRIBUTE_KEY    0.88889   0.88889   0.88889        18

      micro avg    0.95930   0.94876   0.95400      1093
      macro avg    0.95920   0.94876   0.95386      1093
This result was achieved using the "en_core_web_md" model as the base that was then trained on a dataset containing only the custom entity types that I wish to detect. Recently, I have been trying to add in the EntityRuler pipeline to augment the custom NER model. Since it is only available from v2.1 onward, I tried upgrading to the latest version (v2.1.8) and updated all 3 pre-trained "en_core_web" models to the corresponding v2.1.0. I was able to run the training again on a fresh "en_core_web_md" model, but the results became significantly poorer:
nlp.entity_tagger|train_entity_tagger|INFO| Training model...
nlp.entity_tagger|train_entity_tagger|INFO| Losses {'ner': 38476.7237200737}
nlp.entity_tagger|train_entity_tagger|INFO| Losses {'ner': 30793.436396598816}
nlp.entity_tagger|train_entity_tagger|INFO| Losses {'ner': 29513.01201248169}
nlp.entity_tagger|train_entity_tagger|INFO| Losses {'ner': 28433.613090991974}
nlp.entity_tagger|train_entity_tagger|INFO| Losses {'ner': 28227.99483013153}
nlp.entity_tagger|train_entity_tagger|INFO| Losses {'ner': 27747.527606010437}
nlp.entity_tagger|train_entity_tagger|INFO| Losses {'ner': 27771.533205986023}
nlp.entity_tagger|train_entity_tagger|INFO| Losses {'ner': 27399.654321193695}
nlp.entity_tagger|train_entity_tagger|INFO| Losses {'ner': 27462.22469186783}
nlp.entity_tagger|train_entity_tagger|INFO| Losses {'ner': 27126.22325849533}

nlp.spacy_tools|evaluate_spacy|INFO|
                  precision    recall  f1-score   support

        PRODUCT    0.64179   0.65900   0.65028       783
  ATTRIBUTE_KEY    0.00000   0.00000   0.00000        18
       HOSPITAL    0.00000   0.00000   0.00000       146
ATTRIBUTE_VALUE    0.16667   0.02055   0.03659       146

      micro avg    0.63139   0.47484   0.54204      1093
      macro avg    0.48203   0.47484   0.47074      1093
The model seemed to become entirely incapable of picking out some of the custom entities even though the only difference was the spaCy version and the pre-trained model's version. Does anyone have a clue as to what may be wrong or if I have missed something out?
Your Environment
spaCy version: 2.1.8
Platform: Linux-4.4.0-18362-Microsoft-x86_64-with-debian-stretch-sid
Python version: 3.7.3
Models: en_core_web_lg, en_core_web_md, en_core_web_sm
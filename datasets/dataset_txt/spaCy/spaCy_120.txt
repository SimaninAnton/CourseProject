kevingeng commented on 24 Nov 2019 â€¢
edited
I am training a TextCategories Pipeline by reference to spacy-transformers/blob/master/examples/train_textcat.py. The training process has been successfully completed and passed the test on the nlp object for training.
I used nlp.to_disk("mydir") to save the model and then use spacy.load("mydir") to loaded it as nlp2 and encountered an error.
AttributeError Traceback (most recent call last)
Pipes.pyx in spacy.pipeline.pipes.Pipe.from_disk.load_model()
E:\G\Anaconda3\lib\site-packages\thinc\neural\_classes\model.py in from_bytes(self, bytes_data)
    374 name = name.decode("utf8")
--> 375 dest = getattr(layer, name)
    376 copy_array(dest, param[b"value"])

AttributeError: 'FeedForward' object has no attribute 'W'
....
....
Pipes.pyx in spacy.pipeline.pipes.Pipe.from_disk.load_model()

ValueError: [E149] Error deserializing model. Check that the config used to create the component matches the model being loaded.
The code I used during training was as follows:
    Textcat = nlp.create_pipe("trf_textcat")#,config={"architecture": "softmax_last_hidden", "words_per_batch": max_wpb},)
    For v in labels: textcat.add_label(v)
    Nlp.add_pipe(textcat, last=True)
I tried both config and default without using config, which is the same as loading.
I saw something similar in another issue, but I didn't understand the solution.
How can I try to solve this problem?
Thank you.
ADDING:
this train is based on 'en_trf_xlnetbasecased_lg' model
tsoernes commented on 27 Nov 2019 â€¢
edited
I've mimicked the example in the docs, and for a binary classification problem used two output neurons with exclusive_classes=True and labels as such:
{
        'cats': {
            'POS': False,
            'NEG': True
        }
    }
.. and architecture either bow or ensemble. I observe a strange issue:
After training 80k examples for an epoch, the loss, as reported by Spacy (from nlp.update), is 0.0000, while the accuracy, as reported by scikit-learn's accuracy_score tends toward 0.5000 exactly and the log_loss just keeps increasing.
from sklearn.metrics import accuracy_score, log_loss

docs = nlp.pipe(valid_texts, batch_size=256)
pred_probs = []
for doc in docs:
    pred_probs.append(list(doc.cats.values()))
y_pred_probs = np.array(pred_probs)

avg_log_loss = log_loss(y_true, y_pred_probs)
y_pred = y_pred_probs > 0.5
acc = accuracy_score(y_true, y_pred)
I've made sure the the order of Spacy's internal labels (as given by doc.cats.keys()) is the same as the one-hot encoded numpy array y_true, and that y_pred and y_true are the same shape, that is, (n_examples, 2). Evaluations are done using with nlp.use_params(optimizer.averages).
These results seems highly suspect to me and I'm not sure where I've stepped wrong. I'm using the en_core_web_lg model; disabling any pipes besides textcat, and training from scratch (i.e. nlp.begin_training()) without word vectors.
The label distribution is exactly 50-50 for both the training and the test set.
Thanks for any advice,
Your Environment
spaCy version: 2.2.3
Platform: Linux-4.4.0-1098-aws-x86_64-with-debian-stretch-sid
Python version: 3.7.4
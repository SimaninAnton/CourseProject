seljaseppala commented on 20 Dec 2019
How to reproduce the behaviour
I have the following function to process lists of terms with the PhraseMatcher:
def add_patterns_to_phrasematcher(nlp, term_list, attr=None):
 
    if attr is None:
        nlp = English()

    matcher = PhraseMatcher(nlp.vocab, attr, validate=True)
    
    # If default PhraseMatcher (i.e., attr='ORTH')
    if attr is None:
        term_patterns_list = [nlp.make_doc(term) for term in term_list]

    # If attribute is specified
    else:
        term_patterns_list = [nlp(term) for term in term_list]

    # Add term patterns in list to PhraseMatcher
    term_label = 'USE_' + str(attr)
    matcher.add(term_label, None, *term_patterns_list)

    return matcher
The idea is to call the function with different attributes to create different matchers, and then combine and filter the matches output by matchers.
However, when using the PhraseMatcher with attr=LEMMA and nlp = spacy.load('en_core_web_md', disable=['ner']), the returned matches are the same as when using it without any attributes (with the default ORTH) and nlp = English().
This seems to be confirmed by the warning message that is displayed when running the PhraseMatcher with attr=LEMMA:
UserWarning: [W012] A Doc object you're adding to the PhraseMatcher for pattern 'USE_LEMMA' is parsed and/or tagged, but to match on 'ORTH', you don't actually need this information. This means that creating the patterns is potentially much slower, because all pipeline components are applied. To only create tokenized Doc objects, try using `nlp.make_doc(text)` or process all texts as a stream using `list(nlp.tokenizer.pipe(all_texts))`.
Similar issues were already reported on the issue tracker, the closest one being #4100, but the solutions don't seem to be working in my case.
Would this be an issue with the PhraseMatcher or with the way I am using it?
Your Environment
spaCy version: 2.2.3
Platform: Darwin-19.2.0-x86_64-i386-64bit
Python version: 3.7
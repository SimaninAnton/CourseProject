pratapaprasanna commented on 26 Jul 2019 •
edited
Hi all ,
I have tried my traning data with spacy with the following cli command
python -m spacy train en spacy_exam_clean_tag train.json valid.json --pipeline ner -G -v <vectors_path> -g 1 -n 400
My training data set has around 130K records
and while saving the best model i get this weird error can any one suggest me as to what might be the possible issue?
398       0.000      15.070    0.000    1.247    1.943    1.519  100.000  100.000    45155    66339
399       0.000      14.969    0.000    1.248    1.943    1.520  100.000  100.000    45008    66389
✔ Saved model to output directory
spacy_exam_clean_tag/model-final
Traceback (most recent call last):
  File "/home/vz/miniconda3/envs/gp/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/home/vz/miniconda3/envs/gp/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/vz/miniconda3/envs/gp/lib/python3.6/site-packages/spacy/__main__.py", line 35, in <module>
    plac.call(commands[command], sys.argv[1:])
  File "/home/vz/miniconda3/envs/gp/lib/python3.6/site-packages/plac_core.py", line 328, in call
    cmd, result = parser.consume(arglist)
  File "/home/vz/miniconda3/envs/gp/lib/python3.6/site-packages/plac_core.py", line 207, in consume
    return cmd, self.func(*(args + varargs + extraopts), **kwargs)
  File "/home/vz/miniconda3/envs/gp/lib/python3.6/site-packages/spacy/cli/train.py", line 367, in train
    with msg.loading("Creating best model..."):
  File "/home/vz/miniconda3/envs/gp/lib/python3.6/contextlib.py", line 81, in __enter__
    return next(self.gen)
  File "/home/vz/miniconda3/envs/gp/lib/python3.6/site-packages/wasabi/printer.py", line 192, in loading
    t.start()
  File "/home/vz/miniconda3/envs/gp/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/home/vz/miniconda3/envs/gp/lib/python3.6/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/vz/miniconda3/envs/gp/lib/python3.6/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/vz/miniconda3/envs/gp/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/vz/miniconda3/envs/gp/lib/python3.6/multiprocessing/popen_fork.py", line 66, in _launch
    self.pid = os.fork()
OSError: [Errno 12] Cannot allocate memory
Segmentation fault (core dumped)
is there anything wrong about my method of starting the training?
I have ample amount of resources in my machine. But donno why im landing into this error
Any way forward will be of great use.
Thanks in advance
Your Environment
Operating System:
Python Version Used: 3.6.8
spaCy Version Used: 2.1.4
Environment Information:
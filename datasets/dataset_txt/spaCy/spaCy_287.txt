luispsantos commented on 4 Oct 2019
Hello, this may be a rookie question but I need to know the answer for my use case of an email booking system. I want to train from scratch the EntityRecognizer and TextCategorizer models with annotated texts from my domain, and we don't have a lot of annotated data. While I don't need to load the pre-built components, I would like to use the pre-trained embeddings. My understanding is that if I call nlp = spacy.blank('en') and train the models using the training recipes, I wouldn't get the benefits of transfer learning from the embeddings. So if I were to call nlp = spacy.load('en_core_web_md', disable=['parser', 'tagger', 'ner']) or just spacy.load('en_vectors_web_lg'), would I get the benefit of the pre-trained embeddings on the first layer of the NN when training from scratch the NER and Textcat models?
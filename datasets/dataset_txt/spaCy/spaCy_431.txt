AbhishekKargawal commented on 14 Aug 2019 â€¢
edited
I am training a model from scratch to predict food items from the text. I have tagged around 500 sentences to train my model and the accuracy is pretty good. But, I am a bit worried about the unseen real-world data so I have come up with an interesting idea. So I wanted to know some experienced person thought in this interesting idea.
So the idea is to convert the 500 sentences into maybe 10000 sentences. For that, I have first I replaced the actual entity with tag and then filled with possible entities. Example of this as follows:
Original training Sentences:
"Tesco sold fifty thousand pizza last year. " --- Food = pizza
"He loves to eat pudding when he is alone." --- Food = pudding
Generic Sentences:
"Tesco sold fifty thousand last year. "
"He loves to eat when he is alone."
Food List:
pizza
pudding
New training sentences:
"Tesco sold fifty thousand pizza last year. " --- Food = pizza
"Tesco sold fifty thousand pudding last year. " --- Food = pudding
"He loves to eat pizza when he is alone." --- Food = pizza
"He loves to eat pudding when he is alone." --- Food = pudding
So is this a good to generate training sentences like this.
Benefits which I think:
More sentences.
The single entity will have more example instead of one or two.
May be high accuracy.
Issues could be:
Training data full of similar sentence pattern.
Thanks, Please let me know thoughts on this approach.
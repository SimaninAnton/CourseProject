Contributor
ZhuoruLin commented 23 days ago â€¢
edited
I trained a custom textcat pipeline where the model is replaced by a custom PyTorch module (very simple CBOW model) wrapped by thinc wrapper. When I tried to evaluate the model using nlp.evaluate the process would crash.
My dev_docs consist of around 90000 documents (of over 6000 mutual exclusive classes), they are not preprocessed and therefore are in the base string type. I suspect whether in line 673-675 in language.py
    docs = [
        self.make_doc(doc) if isinstance(doc, basestring_) else doc for doc in docs
    ]
the storages of these docs are creating the memory issue? (Although I don't think it is very likely to be the case).
Your Environment
spaCy version: 2.0.18
Platform: Linux-4.9.0-8-amd64-x86_64-with-debian-9.7
Python version: 3.7.2
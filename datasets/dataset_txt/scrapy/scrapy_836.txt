shahidkarimi commented on Aug 25, 2016
When I run the crawl command, this error comes. It was working fine before I write the pipline
Traceback (most recent call last): File "c:\python27\lib\site-packages\scrapy\cmdline.py", line 150, in _run_command cmd.run(args, opts) File "c:\python27\lib\site-packages\scrapy\commands\crawl.py", line 57, in run self.crawler_process.crawl(spname, **opts.spargs) File "c:\python27\lib\site-packages\scrapy\crawler.py", line 153, in crawl d = crawler.crawl(*args, **kwargs) File "c:\python27\lib\site-packages\twisted\internet\defer.py", line 1274, in unwindGenerator return _inlineCallbacks(None, gen, Deferred()) --- <exception caught here> --- File "c:\python27\lib\site-packages\twisted\internet\defer.py", line 1128, in _inlineCallbacks result = g.send(result) File "c:\python27\lib\site-packages\scrapy\crawler.py", line 71, in crawl self.engine = self._create_engine() File "c:\python27\lib\site-packages\scrapy\crawler.py", line 83, in _create_engine return ExecutionEngine(self, lambda _: self.stop()) File "c:\python27\lib\site-packages\scrapy\core\engine.py", line 69, in __init__ self.scraper = Scraper(crawler) File "c:\python27\lib\site-packages\scrapy\core\scraper.py", line 70, in __init__ self.itemproc = itemproc_cls.from_crawler(crawler) File "c:\python27\lib\site-packages\scrapy\middleware.py", line 56, in from_crawler return cls.from_settings(crawler.settings, crawler) File "c:\python27\lib\site-packages\scrapy\middleware.py", line 32, in from_settings mwcls = load_object(clspath) File "c:\python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object mod = import_module(module) File "c:\python27\lib\importlib\__init__.py", line 37, in import_module __import__(name) exceptions.ImportError: No module named pipelies 2016-08-25 22:53:42 [twisted] CRITICAL:
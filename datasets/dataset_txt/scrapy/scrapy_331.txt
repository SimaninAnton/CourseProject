Contributor
BurnzZ commented on Jul 31, 2018
There's this log message that was popping up when we intended to export data via S3:
Disabled feed storage scheme: s3.
The problem was that the existing code is catching the NotConfigured exceptions:
https://github.com/scrapy/scrapy/blob/master/scrapy/extensions/feedexport.py#L272
This occurs when either of botocore or boto libs aren't installed and the user is attempting to export via S3 (set via FEED_URI scheme): https://github.com/scrapy/scrapy/blob/master/scrapy/utils/boto.py#L19
This leads to a few hour of head scratching figuring out why it was disabled. A better error log would be along the lines of:
Disabled feed storage scheme: s3. Reason: missing botocore library
Steps to Reproduce:
Open a new shell without botocore installed/declared in it
Run: scrapy shell -s FEED_URI='s3://test.com'
2018-07-31 18:56:20 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: scrapybot)
2018-07-31 18:56:20 [scrapy.utils.log] INFO: Versions: lxml 4.2.3.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 2.7.15 (default, May  1 2018, 16:44:37) - [GCC 4.2.1 Compatible Apple LLVM 9.0.0 (clang-900.0.39.2)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Darwin-16.7.0-x86_64-i386-64bit
2018-07-31 18:56:20 [scrapy.crawler] INFO: Overridden settings: {'FEED_URI': 's3://test.com', 'LOGSTATS_INTERVAL': 0, 'EDITOR': 'vim', 'DUPEFILTER_CLASS': 'scrapy.dupefilters.BaseDupeFilter'}
2018-07-31 18:56:20 [scrapy.extensions.feedexport] ERROR: Disabled feed storage scheme: s3

<more output truncated>
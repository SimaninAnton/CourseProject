thiagof commented on Mar 24, 2015
Programming a Crawler from ipython notebook is causing boto to raise an error
ERROR:boto:Caught exception reading instance data
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/boto/utils.py", line 219, in retry_url
    r = opener.open(req)
  File "/usr/lib/python2.7/urllib2.py", line 404, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 422, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 382, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1214, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1184, in do_open
    raise URLError(err)
URLError: <urlopen error timed out>
ERROR:boto:Unable to read instance data, giving up
2015-03-24 00:58:54-0300 [fipe-periodo] INFO: Closing spider (finished)
2015-03-24 00:58:54-0300 [fipe-periodo] INFO: Dumping Scrapy stats:
        {'downloader/request_bytes': 308,
         'downloader/request_count': 1,
         'downloader/request_method_count/GET': 1,
         'downloader/response_bytes': 124031,
         'downloader/response_count': 1,
         'downloader/response_status_count/200': 1,
         'finish_reason': 'finished',
         'finish_time': datetime.datetime(2015, 3, 24, 3, 58, 54, 646566),
         'item_scraped_count': 171,
         'response_received_count': 1,
         'scheduler/dequeued': 1,
         'scheduler/dequeued/memory': 1,
         'scheduler/enqueued': 1,
         'scheduler/enqueued/memory': 1,
         'start_time': datetime.datetime(2015, 3, 24, 3, 58, 53, 978029)}
2015-03-24 00:58:54-0300 [fipe-periodo] INFO: Spider closed (finished)
We solved the problem by removing boto from scrapy.optional_packages
Here is the code
from twisted.internet import reactor
from scrapy.crawler import Crawler
from scrapy import log, signals
from scrapy.utils.project import get_project_settings

from fipe_spiders.spiders.automoveis import FipePeriodo

from scrapy import optional_features
# uncommented fixes my issue
# optional_features.remove('boto')

def setup_crawler(Spider):
    spider = Spider()
    settings = get_project_settings()

    crawler = Crawler(settings)
    crawler.signals.connect(reactor.stop, signal=signals.spider_closed)
    crawler.configure()
    crawler.crawl(spider)
    crawler.start()

setup_crawler(FipePeriodo)

log.start()
reactor.run()
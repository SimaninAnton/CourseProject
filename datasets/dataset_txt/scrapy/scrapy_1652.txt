Member
shaneaevans commented on Sep 9, 2011
Reported by binarybug on Trac http://dev.scrapy.org/ticket/325
If a website is using a session to maintain the client's state than resuming a crawl doesn't work when cache is enabled. If we can instruct scrapy not to cache some requests than resuming a crawl would create a session when those requests are encountered and subsequent requests wouldn't fail e.g.
yield Request(' http://www.example.com', meta={'dont_cache': True}) 
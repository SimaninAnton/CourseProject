thecpdubguy commented on Apr 22, 2018
I've seen variations of this issue but no "solution" I've seen has worked for me.
The crawler was working for me at least a month ago. It stopped working (when I was still using scrapy 1.4) no code change, now I'm getting the issue below. I've tried upgrading to scrapy 1.5 but still hasn't fixed the problem.
I have also tried updating twisted but that caused other errors, I've tried downgrading cryptography to version 1.9 and that has not worked either. (Those are the only suggestions I've seen in other closed threads.)
2018-04-21 18:17:31 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: GatherRecipes)
2018-04-21 18:17:31 [scrapy.utils.log] INFO: Versions: lxml 3.8.0.0, libxml2 2.9.4, cssselect 1.0.1, parsel 1.2.0, w3lib 1.18.0,Twisted 16.0.0, Python 2.7.10 (default, Oct 23 2015, 19:19:21) - [GCC 4.2.1 Compatible Apple LLVM 7.0.0 (clang-700.0.59.5)], pyOpenSSL 0.13.1 (OpenSSL 0.9.8zh 14 Jan 2016), cryptography 2.2.2, Platform Darwin-15.6.0-x86_64-i386-64bit
2018-04-21 18:17:31 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'GatherRecipes.spiders', 'LOG_LEVEL': 'INFO', 'CONCURRENT_REQUESTS': 1, 'SPIDER_MODULES': ['GatherRecipes.spiders'], 'BOT_NAME': 'GatherRecipes', 'DOWNLOAD_DELAY': 3}
2018-04-21 18:17:31 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-04-21 18:17:31 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-04-21 18:17:31 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-04-21 18:17:31 [scrapy.middleware] INFO: Enabled item pipelines:
['GatherRecipes.pipelines.ValidatePipeline',
 'GatherRecipes.pipelines.DedupePipeline',
 'GatherRecipes.pipelines.FormatPipeline',
 'GatherRecipes.pipelines.PostPipeline']
2018-04-21 18:17:31 [scrapy.core.engine] INFO: Spider opened
2018-04-21 18:17:31 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-04-21 18:17:38 [scrapy.core.scraper] ERROR: Error downloading <GET http://allrecipes.com/>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2018-04-21 18:17:39 [scrapy.core.engine] INFO: Closing spider (finished)
2018-04-21 18:17:39 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 3,
 'downloader/request_bytes': 639,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 4, 21, 22, 17, 39, 1797),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'memusage/max': 53305344,
 'memusage/startup': 53305344,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 4, 21, 22, 17, 31, 770852)}
2018-04-21 18:17:39 [scrapy.core.engine] INFO: Spider closed (finished)
This is the results of running scrapy version -v
Scrapy       : 1.5.0
lxml         : 3.8.0.0
libxml2      : 2.9.4
cssselect    : 1.0.1
parsel       : 1.2.0
w3lib        : 1.18.0
Twisted      : 16.0.0
Python       : 2.7.10 (default, Oct 23 2015, 19:19:21) - [GCC 4.2.1 Compatible Apple LLVM 7.0.0 (clang-700.0.59.5)]
pyOpenSSL    : 0.13.1 (OpenSSL 0.9.8zh 14 Jan 2016)
cryptography : 2.2.2
Platform     : Darwin-15.6.0-x86_64-i386-64bit
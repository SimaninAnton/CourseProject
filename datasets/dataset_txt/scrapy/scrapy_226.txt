MarcWarrior commented on Jan 12, 2019
I got the error when I run a spider with command 'scrapy crawl spider'
This is the trace:
2019-01-12 22:22:11 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: )
2019-01-12 22:22:11 [scrapy.utils.log] INFO: Versions: lxml 4.3.0.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.7.1 (v3.7.1:260ec2c36a, Oct 20 2018, 14:57:15) [MSC v.1915 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j 20 Nov 2018), cryptography 2.4.2, Platform Windows-8.1-6.3.9600-SP0
2019-01-12 22:22:11 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': '', 'CONCURRENT_REQUESTS': 2, 'CONCURRENT_REQUESTS_PER_DOMAIN': 2, 'CONCURRENT_REQUESTS_PER_IP': 2, 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 3, 'HTTPCACHE_ENABLED': True, 'HTTPCACHE_EXPIRATION_SECS': 3600, 'HTTPCACHE_GZIP': True, 'HTTPCACHE_IGNORE_HTTP_CODES': [301, 302, 303, 401, 403, 404, 500, 502, 503, 504], 'NEWSPIDER_MODULE': '.spiders', 'SPIDER_MODULES': ['.spiders']}
2019-01-12 22:22:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
'scrapy.extensions.telnet.TelnetConsole',
'scrapy.extensions.logstats.LogStats']
2019-01-12 22:22:11 [py.warnings] WARNING: ...\venv\lib\site-packages\scrapy\utils\deprecate.py:156: ScrapyDeprecationWarning: scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware class is deprecated, use scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware instead
ScrapyDeprecationWarning)
2019-01-12 22:22:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['.middlewares.RandomUserAgentMiddleware',
'.middlewares.ProxyMiddleware',
'.downloadermiddlewares.httpauth.HttpAuthMiddleware',
'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
'scrapy.downloadermiddlewares.retry.RetryMiddleware',
'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
'scrapy.downloadermiddlewares.stats.DownloaderStats',
'scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware']
2019-01-12 22:22:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
'scrapy.spidermiddlewares.referer.RefererMiddleware',
'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-01-12 22:22:13 [scrapy.middleware] INFO: Enabled item pipelines:
['.pipelines.****Pipeline']
2019-01-12 22:22:13 [scrapy.core.engine] INFO: Spider opened
2019-01-12 22:22:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-01-12 22:22:13 [scrapy.extensions.httpcache] DEBUG: Using filesystem cache storage in ....scrapy\httpcache
2019-01-12 22:22:13 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2019-01-12 22:22:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET ****> (referer: None) ['cached']
2019-01-12 22:22:14 [scrapy.core.scraper] ERROR: Spider error processing <GET ****> (referer: None)
Traceback (most recent call last):
File "...\Python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
current.result = callback(current.result, *args, **kw)
File "...\spiders\novel.py", line 21, in parse
novel_item['introduction'] = response.folllow(
AttributeError: 'HtmlResponse' object has no attribute 'folllow'
As you see,I had update the scrapy to ver.1.5.1.But I still got the error,I had no idea.
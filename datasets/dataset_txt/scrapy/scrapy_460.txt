Anderson-Liu commented on Jan 19, 2018 â€¢
edited
Hi. I meet a problem after compare the source code in this Github repo with the code installed inside my machine's site-packages directory when I try to custom aws S3 endpoint url in setting file . I found that the code relate this feature had been commit about 11 months ago in master branch and you can check this one or this one for more detail.
My installed scrapy is the latest one(1.5.0) and I also run pip show to confirm that.
Name: Scrapy
Version: 1.5.0
Summary: A high-level Web Crawling and Web Scraping framework
Home-page: https://scrapy.org
Author: Pablo Hoffman
Author-email: pablo@pablohoffman.com
License: BSD
Location: /home/liuhongda1/.pyenv/versions/3.6.4/lib/python3.6/site-packages
Requires: queuelib, pyOpenSSL, lxml, Twisted, PyDispatcher, w3lib, six, service-identity, parsel, cssselect
And in my installed package's code(which under site-packages/scrapy) I found code like this:
class S3FilesStore(object):

    AWS_ACCESS_KEY_ID = None
    AWS_SECRET_ACCESS_KEY = None

    POLICY = 'private'  # Overriden from settings.FILES_STORE_S3_ACL in
                        # FilesPipeline.from_settings.
    HEADERS = {
        'Cache-Control': 'max-age=172800',
    }

    def __init__(self, uri):
        self.is_botocore = is_botocore()
        if self.is_botocore:
            import botocore.session
            session = botocore.session.get_session()
            self.s3_client = session.create_client(
                's3', aws_access_key_id=self.AWS_ACCESS_KEY_ID,
                aws_secret_access_key=self.AWS_SECRET_ACCESS_KEY)
        else:
            from boto.s3.connection import S3Connection
            self.S3Connection = S3Connection
        assert uri.startswith('s3://')
        self.bucket, self.prefix = uri[5:].split('/', 1)
rather than the code inside Github repo's master branch:
class S3FilesStore(object):
    AWS_ACCESS_KEY_ID = None
    AWS_SECRET_ACCESS_KEY = None
    AWS_ENDPOINT_URL = None
    AWS_REGION_NAME = None
    AWS_USE_SSL = None
    AWS_VERIFY = None

    POLICY = 'private'  # Overriden from settings.FILES_STORE_S3_ACL in
                        # FilesPipeline.from_settings.
    HEADERS = {
        'Cache-Control': 'max-age=172800',
    }

    def __init__(self, uri):
        self.is_botocore = is_botocore()
        if self.is_botocore:
            import botocore.session
            session = botocore.session.get_session()
            self.s3_client = session.create_client(
                's3',
                aws_access_key_id=self.AWS_ACCESS_KEY_ID,
                aws_secret_access_key=self.AWS_SECRET_ACCESS_KEY,
                endpoint_url=self.AWS_ENDPOINT_URL,
                region_name=self.AWS_REGION_NAME,
                use_ssl=self.AWS_USE_SSL,
                verify=self.AWS_VERIFY
            )
        else:
            from boto.s3.connection import S3Connection
            self.S3Connection = S3Connection
        assert uri.startswith('s3://')
        self.bucket, self.prefix = uri[5:].split('/', 1)
     ......
    @classmethod
    def from_settings(cls, settings):
        s3store = cls.STORE_SCHEMES['s3']
        s3store.AWS_ACCESS_KEY_ID = settings['AWS_ACCESS_KEY_ID']
        s3store.AWS_SECRET_ACCESS_KEY = settings['AWS_SECRET_ACCESS_KEY']
        s3store.AWS_ENDPOINT_URL = settings['AWS_ENDPOINT_URL']
        s3store.AWS_REGION_NAME = settings['AWS_REGION_NAME']
        s3store.AWS_USE_SSL = settings['AWS_USE_SSL']
        s3store.AWS_VERIFY = settings['AWS_VERIFY']
        s3store.POLICY = settings['FILES_STORE_S3_ACL']

        gcs_store = cls.STORE_SCHEMES['gs']
        gcs_store.GCS_PROJECT_ID = settings['GCS_PROJECT_ID']

        store_uri = settings['FILES_STORE']
        return cls(store_uri, settings=settings)
So, my problem is why not add those code into release version package ? @kmike
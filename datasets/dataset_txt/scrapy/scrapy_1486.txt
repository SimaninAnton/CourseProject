ghost commented on Nov 2, 2013
When using the example from http://doc.scrapy.org/en/latest/topics/practices.html "Run Scrapy from a script" using Windows XP and Python 2.7 it seems the item_scraped passed signal is not fired. The scraping works and shows in its stats that "item_scraped_count" is 60, yet not a single time the associated function gets called.
I connected it using
crawler.signals.connect(self._item_passed, signal=signals.item_scraped)
I also tried
crawler.signals.connect(self._item_passed, signal=signals.item_passed)
dispatcher.connect(self._item_passed_2, signals.item_scraped)
dispatcher.connect(self._item_passed_2, signals.item_passed)
which didn't get called either.
item_dropped isn't called either.
I have no explicit pipelines defined, just a single basic spider which works fine as seen in the debug logs.
Connecting other signals like
crawler.signals.connect(self._spider_opened, signal=signals.spider_opened)
works on the other hand.
The main call is:
def _item_passed(self, item, response, spider):
    print "PASSED"

def _item_passed_2(self, item, response, spider):
    print "PASSED-DISP"

def _item_dropped(self, item, spider, exception):
    print "dropped"

def _spider_opened(spider):
    print "spider opened"

def run(self):
    spider = TestSpider()
    settings = get_project_settings()
    crawler = Crawler(settings)
    crawler.install()
    crawler.signals.connect(reactor.stop, signal=signals.spider_closed)
    crawler.signals.connect(self._item_passed, signal=signals.item_scraped)
    crawler.signals.connect(self._item_passed, signal=signals.item_passed)
    crawler.signals.connect(self._item_dropped, signal=signals.item_dropped)
    crawler.signals.connect(self._spider_opened, signal=signals.spider_opened)
    crawler.configure()
    crawler.crawl(spider)
    dispatcher.connect(self._item_passed_2, signals.item_passed)
    dispatcher.connect(self._item_passed_2, signals.item_scraped)

    crawler.start()

    log.start(loglevel=log.INFO)
    reactor.run()
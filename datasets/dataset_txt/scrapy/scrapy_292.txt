baby5 commented on Sep 26, 2018
i run scrapy example try to yield Deferred to sleep and not block, and i got this log output:
[scrapy.core.scraper] ERROR: Spider must return Request, BaseItem, dict or None, got 'Deferred' in <GET http://quotes.toscrape.com/tag/humor/>
think about this situation:
i got url from redis in start_requests function, the redis return error for the moment, i do not want to hit redis and block thread, so i can yield a Deferred to let cpu do other things
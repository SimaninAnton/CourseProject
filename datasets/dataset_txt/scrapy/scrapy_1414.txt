WilliamKinaan commented on Apr 30, 2014
I am using scrapy 0.20 with python 2.7
I deployed my project, which contains one spider, on scrapyd server.
When I run my spider from cmd, I can see the output file in the root of the project, but when I run my spider from the scrapyd server, I can't see my output file.
I am using windows 7. I created this scrapyd.conf file inside scrapyd folder in the c drive. and I put these values inside it.
[scrapyd]
eggs_dir = eggs
logs_dir = logs
items_dir = items
jobs_to_keep = 5
dbs_dir = dbs
max_proc = 0
max_proc_per_cpu = 4
finished_to_keep = 100
poll_interval = 5
http_port = 6800
debug = off
runner = scrapyd.runner
application = scrapyd.app.application
launcher = scrapyd.launcher.Launcher
[services]
schedule.json = scrapyd.webservice.Schedule
cancel.json = scrapyd.webservice.Cancel
addversion.json = scrapyd.webservice.AddVersion
listprojects.json = scrapyd.webservice.ListProjects
listversions.json = scrapyd.webservice.ListVersions
listspiders.json = scrapyd.webservice.ListSpiders
delproject.json = scrapyd.webservice.DeleteProject
delversion.json = scrapyd.webservice.DeleteVersion
listjobs.json = scrapyd.webservice.ListJobs
I can see that the items_dir is set to "Item", but when I can't see the output file.
In my setting I do this:
FEED_EXPORTERS = {
'jsonlines': 'scrapy.contrib.exporter.JsonLinesItemExporter',
}
FEED_FORMAT = 'jsonlines'
FEED_URI = 'ourput.json'
Could u help please, Thanks in advance
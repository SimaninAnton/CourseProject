Contributor
nyov commented on Mar 28, 2015
$ scrapy shell 'http://[::1]/'
2015-03-28 14:03:46+0000 [scrapy] INFO: Scrapy 0.25.0-270-gc9d7386 started (bot: scrapybot)
2015-03-28 14:03:46+0000 [scrapy] INFO: Optional features available: ssl, http11, boto, django
2015-03-28 14:03:46+0000 [scrapy] INFO: Overridden settings: {'LOGSTATS_INTERVAL': 0}
2015-03-28 14:03:46+0000 [scrapy] INFO: Enabled extensions: TelnetConsole, CloseSpider, CoreStats, SpiderState
2015-03-28 14:03:47+0000 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, HttpProxyMiddleware, ChunkedTransferMiddleware, DownloaderStats
2015-03-28 14:03:47+0000 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2015-03-28 14:03:47+0000 [scrapy] INFO: Enabled item pipelines: 
2015-03-28 14:03:47+0000 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2015-03-28 14:03:47+0000 [default] INFO: Spider opened
Traceback (most recent call last):
  File "/usr/bin/scrapy", line 9, in <module>
    load_entry_point('Scrapy==0.25.0-270-gc9d7386', 'console_scripts', 'scrapy')()
  File "/usr/lib/pymodules/python2.7/scrapy/cmdline.py", line 143, in execute
    _run_print_help(parser, _run_command, cmd, args, opts)
  File "/usr/lib/pymodules/python2.7/scrapy/cmdline.py", line 89, in _run_print_help
    func(*a, **kw)
  File "/usr/lib/pymodules/python2.7/scrapy/cmdline.py", line 150, in _run_command
    cmd.run(args, opts)
  File "/usr/lib/pymodules/python2.7/scrapy/commands/shell.py", line 65, in run
    shell.start(url=url)
  File "/usr/lib/pymodules/python2.7/scrapy/shell.py", line 44, in start
    self.fetch(url, spider)
  File "/usr/lib/pymodules/python2.7/scrapy/shell.py", line 87, in fetch
    reactor, self._schedule, request, spider)
  File "/usr/lib/python2.7/dist-packages/twisted/internet/threads.py", line 122, in blockingCallFromThread
    result.raiseException()
  File "/usr/lib/pymodules/python2.7/scrapy/utils/defer.py", line 39, in mustbe_deferred
    result = f(*args, **kw)
  File "/usr/lib/pymodules/python2.7/scrapy/core/downloader/handlers/__init__.py", line 41, in download_request
    return handler(request, spider)
  File "/usr/lib/pymodules/python2.7/scrapy/core/downloader/handlers/http11.py", line 42, in download_request
    return agent.download_request(request)
  File "/usr/lib/pymodules/python2.7/scrapy/core/downloader/handlers/http11.py", line 209, in download_request
    d = agent.request(method, url, headers, bodyproducer)
  File "/usr/lib/python2.7/dist-packages/twisted/web/client.py", line 1510, in request
    _URI.fromBytes(uri), headers,
  File "/usr/lib/python2.7/dist-packages/twisted/web/client.py", line 617, in fromBytes
    host, port = host.split(b':')
ValueError: too many values to unpack
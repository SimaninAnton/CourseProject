jacob1237 commented on Nov 24, 2014
Greetings!
During the making of my current scrapy project, I've found some interesting 'request_scheduled' signal behavior: it fires always, even if a request has been rejected by dupefilter or something else.
So for example, I can't count the number of scheduled requests by value increment, but only by crawler stats values.
I think there is a need to split this signal in two pieces: 'request_scheduled' and 'request_dropped', like in pipeline items.
Thank you!
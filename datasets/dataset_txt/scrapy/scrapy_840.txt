Contributor
pawelmhm commented on Aug 23, 2016 â€¢
edited
I have bunch of spiders in project that consume lists of urls. It seems like currently lots of websites are moving from http to https. This means that all my outdated url are now redirecting to https. This is somewhat annoying because spider gets huge amount of redirects and it gets slower. It also leads to unexpected issues when downloading images (image pipeline doesn't follow redirects as explained here #2191 so if I have http://image.png and it gets redirected to https://image.png I get error). I know I can update my urls but it's not always easy or possible (I dont have easy access to those urls, some of them are generated by user).
I was thinking about adding some downloader middleware that would replace protocol to https from http on all requests flowing from spider, it would be really trivial to implement (process_request method on downloader middleware object) and could be enabled by some setting key, e.g. HTTPS_EVERYWHERE = True/False.
Does it sound like useful addition to Scrapy or should I limit it to my project?
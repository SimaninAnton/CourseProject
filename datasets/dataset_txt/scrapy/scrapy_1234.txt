aldarund commented on May 4, 2015
If scrapy found a link that outputs not an html but pdf or something else it fails with exception.
Here is stracktrace:
2015-05-03 18:16:28+0000 [external_link_spider] ERROR: Spider error processing <GET http://www.chanel.com/en_AS/Watches/print?popup=1&ref=H0451>
        Traceback (most recent call last):
          File "/opt/webapps/link_crawler/local/lib/python2.7/site-packages/twisted/internet/base.py", line 824, in runUntilCurrent
            call.func(*call.args, **call.kw)
          File "/opt/webapps/link_crawler/local/lib/python2.7/site-packages/twisted/internet/task.py", line 638, in _tick
            taskObj._oneWorkUnit()
          File "/opt/webapps/link_crawler/local/lib/python2.7/site-packages/twisted/internet/task.py", line 484, in _oneWorkUnit
            result = next(self._iterator)
          File "/opt/webapps/link_crawler/local/lib/python2.7/site-packages/scrapy/utils/defer.py", line 57, in <genexpr>
            work = (callable(elem, *args, **named) for elem in iterable)
        --- <exception caught here> ---
          File "/opt/webapps/link_crawler/local/lib/python2.7/site-packages/scrapy/utils/defer.py", line 96, in iter_errback
            yield next(it)
          File "/opt/webapps/link_crawler/local/lib/python2.7/site-packages/scrapy/contrib/spidermiddleware/offsite.py", line 26, in process_spider_output
            for x in result:
          File "/opt/webapps/link_crawler/local/lib/python2.7/site-packages/scrapy/contrib/spidermiddleware/referer.py", line 22, in <genexpr>
            return (_set_referer(r) for r in result or ())
          File "/opt/webapps/link_crawler/local/lib/python2.7/site-packages/scrapy/contrib/spidermiddleware/offsite.py", line 26, in process_spider_output
            for x in result:
          File "/opt/webapps/link_crawler/local/lib/python2.7/site-packages/scrapy/contrib/spidermiddleware/urllength.py", line 33, in <genexpr>
            return (r for r in result or () if _filter(r))
          File "/opt/webapps/link_crawler/local/lib/python2.7/site-packages/scrapy/contrib/spidermiddleware/depth.py", line 50, in <genexpr>
            return (r for r in result or () if _filter(r))
          File "/opt/webapps/link_crawler/local/lib/python2.7/site-packages/scrapy/contrib/spiders/crawl.py", line 69, in _parse_response
            for requests_or_item in iterate_spider_output(cb_res):
          File "build/bdist.linux-x86_64/egg/ex_link_crawl/spiders/external_link_spider.py", line 28, in parse_obj

          File "/opt/webapps/link_crawler/local/lib/python2.7/site-packages/scrapy/contrib/linkextractors/lxmlhtml.py", line 96, in extract_links
            html = Selector(response)
          File "/opt/webapps/link_crawler/local/lib/python2.7/site-packages/scrapy/selector/unified.py", line 80, in __init__
            _root = LxmlDocument(response, self._parser)
          File "/opt/webapps/link_crawler/local/lib/python2.7/site-packages/scrapy/selector/lxmldocument.py", line 27, in __new__
            cache[parser] = _factory(response, parser)
          File "/opt/webapps/link_crawler/local/lib/python2.7/site-packages/scrapy/selector/lxmldocument.py", line 13, in _factory
            body = response.body_as_unicode().strip().encode('utf8') or '<html/>'
        exceptions.AttributeError: 'Response' object has no attribute 'body_as_unicode'
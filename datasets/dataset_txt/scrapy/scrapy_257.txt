HelloEdit commented on Nov 20, 2018
Hi,
I am working on a project that is divided into two parts:
Retrieve a specific page
Once the ID of this page is extracted,
Send requests to an API to obtain additional information on this page
For the second point, and to follow Scrapy's asynchronous philosophy, where should such a code be placed? (I hesitate between in the spider or in a pipeline).
Do we have to use different libraries like asyncio & aiohttp to be able to achieve this goal asynchronously? (I <3 aiohttp so this is not a problem)
I think that updating the documentation to give an example of this case could be used by someone other than me.
Thanks you ^^
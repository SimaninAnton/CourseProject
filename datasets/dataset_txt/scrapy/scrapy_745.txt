nathanielford commented on Dec 8, 2016 ‚Ä¢
edited by redapple
When executing scrapy version on the command line inside a scrapy project, an ImportError: No module named 'spiders' can occur if the settings.py file that is found by scrapy contains, in this case SPIDER_MODULES = ['spiders'] and there is no spiders module in the project.
Essentially, any execution of scrapy picks up the settings file, which will report a rather generic error (googling for it will return a number of unrelated issues) if there is an issue in that file.
I created a StackOverflow question about this that can be found here with a bit more detail:
http://stackoverflow.com/questions/41028605/importerror-no-module-named-spiders/41028628?noredirect=1#comment69264795_41028628
Sample traceback:
$ scrapy version
Traceback (most recent call last):
  File "/Users/nathanielford/virtualenvironments/crawler/bin/scrapy", line 11, in <module>
    sys.exit(execute())
  File "/Users/nathanielford/virtualenvironments/crawler/lib/python3.5/site-packages/scrapy/cmdline.py", line 141, in execute
    cmd.crawler_process = CrawlerProcess(settings)
  File "/Users/nathanielford/virtualenvironments/crawler/lib/python3.5/site-packages/scrapy/crawler.py", line 238, in __init__
    super(CrawlerProcess, self).__init__(settings)
  File "/Users/nathanielford/virtualenvironments/crawler/lib/python3.5/site-packages/scrapy/crawler.py", line 129, in __init__
    self.spider_loader = _get_spider_loader(settings)
  File "/Users/nathanielford/virtualenvironments/crawler/lib/python3.5/site-packages/scrapy/crawler.py", line 325, in _get_spider_loader
    return loader_cls.from_settings(settings.frozencopy())
  File "/Users/nathanielford/virtualenvironments/crawler/lib/python3.5/site-packages/scrapy/spiderloader.py", line 33, in from_settings
    return cls(settings)
  File "/Users/nathanielford/virtualenvironments/crawler/lib/python3.5/site-packages/scrapy/spiderloader.py", line 20, in __init__
    self._load_all_spiders()
  File "/Users/nathanielford/virtualenvironments/crawler/lib/python3.5/site-packages/scrapy/spiderloader.py", line 28, in _load_all_spiders
    for module in walk_modules(name):
  File "/Users/nathanielford/virtualenvironments/crawler/lib/python3.5/site-packages/scrapy/utils/misc.py", line 63, in walk_modules
    mod = import_module(path)
  File "/Users/nathanielford/virtualenvironments/crawler/lib/python3.5/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 986, in _gcd_import
  File "<frozen importlib._bootstrap>", line 969, in _find_and_load
  File "<frozen importlib._bootstrap>", line 956, in _find_and_load_unlocked
ImportError: No module named 'spiders'
üëç 1
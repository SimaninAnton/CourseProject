Contributor
redapple commented on Mar 23, 2014
Currently, scrapy/templates/project/module/settings.py.tmpl is rather succint.
# Scrapy settings for $project_name project
#
# For simplicity, this file contains only the most important settings by
# default. All the other settings are documented here:
#
#     http://doc.scrapy.org/en/latest/topics/settings.html
#
BOT_NAME = '$project_name'

SPIDER_MODULES = ['$project_name.spiders']
NEWSPIDER_MODULE = '$project_name.spiders'

# Crawl responsibly by identifying yourself (and your website) on the user-agent
#USER_AGENT = '$project_name (+http://www.yourdomain.com)'
It would be nice to have many common and useful settings in the generated settings.py, probably commented.
The current file redirects the reader to http://doc.scrapy.org/en/latest/topics/settings.html
but useful settings like AUTOTHROTTLE or HTTPCACHE_xxx settings are not explained in this page
settings.py could include something like this:
# The amount of time (in secs) that the downloader should wait
# before downloading consecutive pages from the same website. 
#3 seconds corresponds to roughly 20 request/sec maximum
# Default value is 0 so the downloader will ask for pages as fast as it can
# within the constraints of CONCURRENT_REQUESTS_PER_DOMAIN
#DOWNLOAD_DELAY=3
#CONCURRENT_REQUESTS_PER_DOMAIN=16
#CONCURRENT_REQUESTS_PER_IP=16

# Enables the AutoThrottle extension. (Default: False)
# See http://doc.scrapy.org/en/latest/topics/autothrottle.html
#AUTOTHROTTLE_ENABLED=True
# The initial download delay (in seconds). Default: 60.0 (Default: 5.0)
#AUTOTHROTTLE_START_DELAY=3
# The maximum download delay (in seconds) to be set in case of high latencies.
#AUTOTHROTTLE_MAX_DELAY=90
#AUTOTHROTTLE_DEBUG=True

#HTTPCACHE_ENABLED=True
#HTTPCACHE_EXPIRATION_SECS=3600
#HTTPCACHE_DIR='httpcache'
#HTTPCACHE_IGNORE_HTTP_CODES=[404]
...
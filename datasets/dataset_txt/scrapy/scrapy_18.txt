abtisam commented on Dec 8, 2019
I am trying to run demo project for the first time but it will not executed successfully.
I got given below error.
(base) 192:tutorial air$ scrapy crawl quotes
2019-12-08 19:30:17 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: tutorial)
2019-12-08 19:30:17 [scrapy.utils.log] INFO: Versions: lxml 4.4.1.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.4 (default, Aug 13 2019, 15:17:50) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 19.0.0 (OpenSSL 1.1.1d 10 Sep 2019), cryptography 2.7, Platform Darwin-18.7.0-x86_64-i386-64bit
2019-12-08 19:30:17 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'tutorial', 'NEWSPIDER_MODULE': 'tutorial.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['tutorial.spiders']}
2019-12-08 19:30:17 [scrapy.extensions.telnet] INFO: Telnet Password: f1a7db4605320b1e
2019-12-08 19:30:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
'scrapy.extensions.telnet.TelnetConsole',
'scrapy.extensions.memusage.MemoryUsage',
'scrapy.extensions.logstats.LogStats']
Unhandled error in Deferred:
2019-12-08 19:30:17 [twisted] CRITICAL: Unhandled error in Deferred:
Traceback (most recent call last):
File "/Users/air/opt/anaconda3/lib/python3.7/site-packages/scrapy/crawler.py", line 184, in crawl
return self._crawl(crawler, *args, **kwargs)
File "/Users/air/opt/anaconda3/lib/python3.7/site-packages/scrapy/crawler.py", line 188, in _crawl
d = crawler.crawl(*args, **kwargs)
File "/Users/air/opt/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 1613, in unwindGenerator
return _cancellableInlineCallbacks(gen)
File "/Users/air/opt/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 1529, in _cancellableInlineCallbacks
_inlineCallbacks(None, g, status)
--- ---
File "/Users/air/opt/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 1418, in _inlineCallbacks
result = g.send(result)
File "/Users/air/opt/anaconda3/lib/python3.7/site-packages/scrapy/crawler.py", line 86, in crawl
self.engine = self._create_engine()
File "/Users/air/opt/anaconda3/lib/python3.7/site-packages/scrapy/crawler.py", line 111, in _create_engine
return ExecutionEngine(self, lambda _: self.stop())
File "/Users/air/opt/anaconda3/lib/python3.7/site-packages/scrapy/core/engine.py", line 69, in init
self.downloader = downloader_cls(crawler)
File "/Users/air/opt/anaconda3/lib/python3.7/site-packages/scrapy/core/downloader/init.py", line 86, in init
self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
File "/Users/air/opt/anaconda3/lib/python3.7/site-packages/scrapy/middleware.py", line 53, in from_crawler
return cls.from_settings(crawler.settings, crawler)
File "/Users/air/opt/anaconda3/lib/python3.7/site-packages/scrapy/middleware.py", line 35, in from_settings
mw = create_instance(mwcls, settings, crawler)
File "/Users/air/opt/anaconda3/lib/python3.7/site-packages/scrapy/utils/misc.py", line 142, in create_instance
return objcls.from_crawler(crawler, *args, **kwargs)
File "/Users/air/opt/anaconda3/lib/python3.7/site-packages/scrapy/downloadermiddlewares/robotstxt.py", line 39, in from_crawler
return cls(crawler)
File "/Users/air/opt/anaconda3/lib/python3.7/site-packages/scrapy/downloadermiddlewares/robotstxt.py", line 35, in init
self._parserimpl.from_crawler(self.crawler, b'')
File "/Users/air/opt/anaconda3/lib/python3.7/site-packages/scrapy/robotstxt.py", line 120, in from_crawler
o = cls(robotstxt_body, spider)
File "/Users/air/opt/anaconda3/lib/python3.7/site-packages/scrapy/robotstxt.py", line 112, in init
from protego import Protego
builtins.ModuleNotFoundError: No module named 'protego'
2019-12-08 19:30:17 [twisted] CRITICAL:
Traceback (most recent call last):
File "/Users/air/opt/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 1418, in _inlineCallbacks
result = g.send(result)
File "/Users/air/opt/anaconda3/lib/python3.7/site-packages/scrapy/crawler.py", line 86, in crawl
self.engine = self._create_engine()
File "/Users/air/opt/anaconda3/lib/python3.7/site-packages/scrapy/crawler.py", line 111, in _create_engine
return ExecutionEngine(self, lambda _: self.stop())
File "/Users/air/opt/anaconda3/lib/python3.7/site-packages/scrapy/core/engine.py", line 69, in init
self.downloader = downloader_cls(crawler)
File "/Users/air/opt/anaconda3/lib/python3.7/site-packages/scrapy/core/downloader/init.py", line 86, in init
self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
File "/Users/air/opt/anaconda3/lib/python3.7/site-packages/scrapy/middleware.py", line 53, in from_crawler
return cls.from_settings(crawler.settings, crawler)
File "/Users/air/opt/anaconda3/lib/python3.7/site-packages/scrapy/middleware.py", line 35, in from_settings
mw = create_instance(mwcls, settings, crawler)
File "/Users/air/opt/anaconda3/lib/python3.7/site-packages/scrapy/utils/misc.py", line 142, in create_instance
return objcls.from_crawler(crawler, *args, **kwargs)
File "/Users/air/opt/anaconda3/lib/python3.7/site-packages/scrapy/downloadermiddlewares/robotstxt.py", line 39, in from_crawler
return cls(crawler)
File "/Users/air/opt/anaconda3/lib/python3.7/site-packages/scrapy/downloadermiddlewares/robotstxt.py", line 35, in init
self._parserimpl.from_crawler(self.crawler, b'')
File "/Users/air/opt/anaconda3/lib/python3.7/site-packages/scrapy/robotstxt.py", line 120, in from_crawler
o = cls(robotstxt_body, spider)
File "/Users/air/opt/anaconda3/lib/python3.7/site-packages/scrapy/robotstxt.py", line 112, in init
from protego import Protego
ModuleNotFoundError: No module named 'protego'
Steps to Reproduce
scrapy startproject tutorial
Versions
Scrapy : 1.8.0
lxml : 4.4.1.0
libxml2 : 2.9.9
cssselect : 1.1.0
parsel : 1.5.2
w3lib : 1.21.0
Twisted : 19.10.0
Python : 3.7.4 (default, Aug 13 2019, 15:17:50) - [Clang 4.0.1 (tags/RELEASE_401/final)]
pyOpenSSL : 19.0.0 (OpenSSL 1.1.1d 10 Sep 2019)
cryptography : 2.7
Platform : Darwin-18.7.0-x86_64-i386-64bit
(base) 192:tutorial air$
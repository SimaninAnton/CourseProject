kgrvamsi commented on Apr 14, 2016
I'm being trying to iterate a loop of urls in which i have three layers of scraping done
1)Scrapy the first URL and get the respective data
2)Based upon the data use that in one of the for loop range
3)Run the Scraping and fetch new urls and append it to a variable and then again parse them
Here is the example code that i'm looking out for
from scrapy.spider import BaseSpider
from scrapy.http import Request

class TestSpider(BaseSpider):
    name = "test_spider"
    allowed_domains=["amazon.com"]
    some_value=0
    data=[]
    def start_requests(self):
        yield Request(first-url,callback=self.parse)
       ''' this is the place the some_value is not replaced with the new value '''
        for i in range(2, some_value):
            url = 'http://www.amazon.com/dp/%i/' % i
            yield Request(url,callback=self.somefunction)

         for site in data:
           yield Request(site,callback=self.somefunction)

    def parse(self, response):
        '''does nothing'''
        if self.some_value == 0:
              self.some_value = int(response.xpath(somexpath).extract())
        url =  response.xpath(somexpath).extract()[0]
        self.data.append(str(url))
        print 'parse'
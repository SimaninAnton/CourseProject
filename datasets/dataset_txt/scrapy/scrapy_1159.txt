vincentlaucy commented on Aug 5, 2015
It's seems to me that such behaviour is undocumented - scraper will be in back out state once there is over 5M requests, as in
scrapy/scrapy/core/scraper.py
Line 29 in 342cb62
 self.max_active_size = max_active_size 
where the default value is always used.
scrapy/scrapy/core/scraper.py
Line 79 in 342cb62
 self.slot = Slot() 
I am reaching a deadlock scenario that I have over 5M requests in the slot, then since enqueue request will check for backout, new request can never be completed.
I can submit a PR if it make sense to extract to settings, say SCRAPER_SLOT_MAX_ACTIVE_SIZE
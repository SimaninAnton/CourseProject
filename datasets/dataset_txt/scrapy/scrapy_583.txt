ru1996 commented on Jul 19, 2017 â€¢
edited
Hi, there.I am in trouble when trying scrapy, I hope you can help me.
Scrapy (1.4.0)
scrapy-redis (0.6.8)
I set CONCURRENT_REQUESTS=200.And when it run, I use telnet to find len(crawler.engine.slot.inprogress)=134.
I guess this may be related to the memory(but my memory is a lot of surplus).Can someone explain this?Thanks.
Then, when it has being running for a while(about one hour).I find thelen(crawler.engine.slot.inprogress)=80.I read the document and get that is beacuse python memory management.
But how can i solve this?Because its reduction affected the crawler rate.
Here is my thought:
Add an extensions: When the number drops to the half, call CrawlerProcess()._graceful_stop_reactor.And use supervisor restart it.
Is there any other solutions?
xpacket commented on May 3, 2015
issue is running a schedule spider in scrapyd using curl schedule.json
scrapy-0.24.6 and scrapyd 1.0
File "/usr/lib/python2.7/runpy.py", line 162, in _run_module_as_main
"main", fname, loader, pkg_name)
File "/usr/lib/python2.7/runpy.py", line 72, in _run_code
exec code in run_globals
File "/usr/lib/pymodules/python2.7/scrapyd/runner.py", line 39, in
main()
File "/usr/lib/pymodules/python2.7/scrapyd/runner.py", line 36, in main
execute()
File "/usr/local/lib/python2.7/dist-packages/scrapy/cmdline.py", line 143, in execute
2015-05-02 14:24:49-0700 [Launcher,11085/stderr] _run_print_help(parser, _run_command, cmd, args, opts)
File "/usr/local/lib/python2.7/dist-packages/scrapy/cmdline.py", line 89, in _run_print_help
func(_a, *_kw)
File "/usr/local/lib/python2.7/dist-packages/scrapy/cmdline.py", line 150, in _run_command
cmd.run(args, opts)
File "/usr/local/lib/python2.7/dist-packages/scrapy/commands/crawl.py", line 58, in run
spider = crawler.spiders.create(spname, *_opts.spargs)
File "/usr/local/lib/python2.7/dist-packages/scrapy/spidermanager.py", line 46, in create
return spcls.from_crawler(self.crawler, *_spider_kwargs)
TypeError: from_crawler() got an unexpected keyword argument '_job'
Running in
scrapy 0.25.1 and scrapyd 1.0.2
problem just moved to another module
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/Scrapy-0.25.1-py2.7.egg/scrapy/cmdline.py", line 150, in _run_command
    cmd.run(args, opts)
  File "/usr/local/lib/python2.7/dist-packages/Scrapy-0.25.1-py2.7.egg/scrapy/commands/crawl.py", line 57, in run
    self.crawler_process.crawl(spname, **opts.spargs)
  File "/usr/local/lib/python2.7/dist-packages/Scrapy-0.25.1-py2.7.egg/scrapy/crawler.py", line 152, in crawl
    d = crawler.crawl(*args, **kwargs)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1253, in unwindGenerator
    return _inlineCallbacks(None, gen, Deferred())
--- <exception caught here> ---
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1107, in _inlineCallbacks
    result = g.send(result)
  File "/usr/local/lib/python2.7/dist-packages/Scrapy-0.25.1-py2.7.egg/scrapy/crawler.py", line 69, in crawl
    self.spider = self._create_spider(*args, **kwargs)
  File "/usr/local/lib/python2.7/dist-packages/Scrapy-0.25.1-py2.7.egg/scrapy/crawler.py", line 79, in _create_spider
    return self.spidercls.from_crawler(self, *args, **kwargs)
exceptions.TypeError: from_crawler() got an unexpected keyword argument '_job'
appears to be passing 2 arguments although method only takes in crawler
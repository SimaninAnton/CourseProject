Six-wars commented on Apr 9, 2018
I'm new to scrapy, I've been able to crawl one page but expect it to also crawl specific new pages. Started with an attempt to crawl stackoverflow like so
# -*- coding: utf-8 -*-
import scrapy
from scrapy.spiders import CrawlSpider, Rule
from scrapy.linkextractors import LinkExtractor
from items import QuestionItem


class FirstSpider(CrawlSpider):
    name = 'first'
    allowed_domains = ['stackoverflow.com']
    start_urls = ['https://stackoverflow.com/questions']

    rules = (
            Rule(LinkExtractor(allow=['/questions/\?page=\d&sort=newest']), callback='parse'),
    )

    def parse(self, response):

        selector_list = response.css('.question-summary')

        for selector in selector_list:
            item = QuestionItem()
            item['question'] = selector.css('h3 a::text').extract()
            item['votes'] = selector.css('.vote-count-post strong::text').extract()
            item['answers'] = selector.css('.status strong::text').extract()
            item['views'] = selector.css('.views ::text').extract()[0].replace('\n','').replace('\r','').lstrip()
            item['username'] = selector.css('.user-details a::text').extract()
            item['userlink'] = selector.css('.user-details a::attr(href)').extract()

            yield item
pages to "pages" of questions on stackoverflow have this format /questions?page=2&sort=newest and the way I've setup my regex
rules = (
        Rule(LinkExtractor(allow=['/questions/\?page=\d&sort=newest']), callback='parse'),
)
doesn't seem to lead to any new pages being discovered. I've asked this on stackoverflow and slack group for python without getting any response so any help would be appreciated.
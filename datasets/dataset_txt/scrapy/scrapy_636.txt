MalikRumi commented on May 5, 2017
I wanted to get a deeper understanding of the inner workings of the Scrapy pipeline. However, when I looked at the github repo, I found file, image, and media pipeline code that talked about network connections and downloads. But the Item Pipeline, as the docs say, is for
After an item has been scraped by a spider, it is sent to the Item Pipeline which processes it through several components that are executed sequentially.
Where is that code? Is some of this code not open sourced? I see an issue #2633
suggesting a base class. Is the entire pipeline implementation wholly up to the programmer? Then why are we required to use process_item()? What about the Item Pipelines setting that sets the sequence in which the components are called? Where is that code and how does it work? What about scoping, state, and variables?
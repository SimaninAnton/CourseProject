Contributor
bagratte commented on Apr 19, 2015
Microsoft Windows [Version 6.3.9600]
(c) 2013 Microsoft Corporation. All rights reserved.

C:\Users\bagratte>scrapy shell
2015-04-19 16:15:13+0400 [scrapy] INFO: Scrapy 0.24.5 started (bot: scrapybot)
2015-04-19 16:15:13+0400 [scrapy] INFO: Optional features available: ssl, http11
, django
2015-04-19 16:15:13+0400 [scrapy] INFO: Overridden settings: {'LOGSTATS_INTERVAL
': 0}
2015-04-19 16:15:13+0400 [scrapy] INFO: Enabled extensions: TelnetConsole, Close
Spider, WebService, CoreStats, SpiderState
2015-04-19 16:15:13+0400 [scrapy] INFO: Enabled downloader middlewares: HttpAuth
Middleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, Def
aultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, Redirec
tMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2015-04-19 16:15:13+0400 [scrapy] INFO: Enabled spider middlewares: HttpErrorMid
dleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddlew
are
2015-04-19 16:15:13+0400 [scrapy] INFO: Enabled item pipelines:
2015-04-19 16:15:13+0400 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6
026
2015-04-19 16:15:13+0400 [scrapy] DEBUG: Web service listening on 127.0.0.1:6083

[s] Available Scrapy objects:
[s]   crawler    
[s]   item       {}
[s]   settings   
[s] Useful shortcuts:
[s]   shelp()           Shell help (print this help)
[s]   fetch(req_or_url) Fetch request (or URL) and update local objects
[s]   view(response)    View response in a browser

In [1]: fetch('http://scrapy.org/')
2015-04-19 16:15:40+0400 [default] INFO: Spider opened
2015-04-19 16:15:41+0400 [default] DEBUG: Redirecting (302) to  from 
2015-04-19 16:15:41+0400 [default] DEBUG: Crawled (200) 
 (referer: None)
[s] Available Scrapy objects:
[s]   crawler    
[s]   item       {}
[s]   request    
[s]   response   <200 http://scrapy.org/>
[s]   settings   
[s]   spider     
[s] Useful shortcuts:
[s]   shelp()           Shell help (print this help)
[s]   fetch(req_or_url) Fetch request (or URL) and update local objects
[s]   view(response)    View response in a browser

In [2]: response

In [3]: response is None
Out[3]: True

In [4]:
Do you really want to exit ([y]/n)?


C:\Users\bagratte>scrapy shell http://scrapy.org/
2015-04-19 16:16:05+0400 [scrapy] INFO: Scrapy 0.24.5 started (bot: scrapybot)
2015-04-19 16:16:05+0400 [scrapy] INFO: Optional features available: ssl, http11
, django
2015-04-19 16:16:05+0400 [scrapy] INFO: Overridden settings: {'LOGSTATS_INTERVAL
': 0}
2015-04-19 16:16:05+0400 [scrapy] INFO: Enabled extensions: TelnetConsole, Close
Spider, WebService, CoreStats, SpiderState
2015-04-19 16:16:05+0400 [scrapy] INFO: Enabled downloader middlewares: HttpAuth
Middleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, Def
aultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, Redirec
tMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2015-04-19 16:16:05+0400 [scrapy] INFO: Enabled spider middlewares: HttpErrorMid
dleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddlew
are
2015-04-19 16:16:05+0400 [scrapy] INFO: Enabled item pipelines:
2015-04-19 16:16:05+0400 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6
026
2015-04-19 16:16:05+0400 [scrapy] DEBUG: Web service listening on 127.0.0.1:6083

2015-04-19 16:16:05+0400 [default] INFO: Spider opened
2015-04-19 16:16:06+0400 [default] DEBUG: Crawled (200) 
 (referer: None)
[s] Available Scrapy objects:
[s]   crawler    
[s]   item       {}
[s]   request    
[s]   response   <200 http://scrapy.org/>
[s]   settings   
[s]   spider     
[s] Useful shortcuts:
[s]   shelp()           Shell help (print this help)
[s]   fetch(req_or_url) Fetch request (or URL) and update local objects
[s]   view(response)    View response in a browser

In [1]: response
Out[1]: <200 http://scrapy.org/>

In [2]: fetch('http://www.python.org/')
2015-04-19 16:16:41+0400 [default] DEBUG: Redirecting (301) to  from 
2015-04-19 16:16:41+0400 [default] DEBUG: Crawled (200)  (referer: None)
[s] Available Scrapy objects:
[s]   crawler    
[s]   item       {}
[s]   request    
[s]   response   <200 https://www.python.org/>
[s]   settings   
[s]   spider     
[s] Useful shortcuts:
[s]   shelp()           Shell help (print this help)
[s]   fetch(req_or_url) Fetch request (or URL) and update local objects
[s]   view(response)    View response in a browser

In [3]: response
Out[3]: <200 http://scrapy.org/>

In [4]:
Do you really want to exit ([y]/n)?


C:\Users\bagratte>scrapy version -v
Scrapy  : 0.24.5
lxml    : 3.4.2.0
libxml2 : 2.9.0
Twisted : 15.1.0
Python  : 2.7.9 (default, Dec 10 2014, 12:28:03) [MSC v.1500 64 bit (AMD64)]
Platform: Windows-8-6.2.9200

C:\Users\bagratte>ipython --version
3.1.0

C:\Users\bagratte>
is this an expected behavior?
Contributor
starrify commented on May 16, 2017 â€¢
edited
Sample code of Here is an example that runs multiple spiders simultaneously: is believed to be out-dated and now not working.
Here's a minimal example:
import scrapy
from scrapy.crawler import CrawlerProcess

class MySpider1(scrapy.Spider):
    # Your first spider definition
    name = 'spider1'

class MySpider2(scrapy.Spider):
    # Your second spider definition
    name = 'spider2'

process = CrawlerProcess()
process.crawl(MySpider1)
process.crawl(MySpider2)
process.start() # the script will block here until all crawling jobs are finished
And here's the stack trace when invoking it using scrapy runspider test.py (using Scrapy v1.3.3):
Traceback (most recent call last):
  File "/usr/sbin/scrapy", line 11, in <module>
    sys.exit(execute())
  File "/usr/lib/python2.7/site-packages/scrapy/cmdline.py", line 142, in execute
    _run_print_help(parser, _run_command, cmd, args, opts)
  File "/usr/lib/python2.7/site-packages/scrapy/cmdline.py", line 88, in _run_print_help
    func(*a, **kw)
  File "/usr/lib/python2.7/site-packages/scrapy/cmdline.py", line 149, in _run_command
    cmd.run(args, opts)
  File "/usr/lib/python2.7/site-packages/scrapy/commands/runspider.py", line 89, in run
    self.crawler_process.start()
  File "/usr/lib/python2.7/site-packages/scrapy/crawler.py", line 280, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "/usr/lib/python2.7/site-packages/twisted/internet/base.py", line 1242, in run
    self.startRunning(installSignalHandlers=installSignalHandlers)
  File "/usr/lib/python2.7/site-packages/twisted/internet/base.py", line 1222, in startRunning
    ReactorBase.startRunning(self)
  File "/usr/lib/python2.7/site-packages/twisted/internet/base.py", line 730, in startRunning
    raise error.ReactorNotRestartable()
twisted.internet.error.ReactorNotRestartable
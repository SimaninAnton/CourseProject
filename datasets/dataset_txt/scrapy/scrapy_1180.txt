ileodo commented on Jul 10, 2015
Under the following setting up:
in setting.py:
LOG_ENABLED = False
in script to start the crawler:
configure_logging()
process = CrawlerProcess(get_project_settings())
process.crawl('retriever')
process.start()
in crawler:
logging.debug("PC get page [%s]:- %s" % (item['id'], item['url']))
There are still a lot of logging info.
even:
2015-07-09 23:29:20 [scrapy] DEBUG: Scraped from <200 http://www.example.com>
Is is a bug?
ghost commented on Jan 30, 2012
In scrapy shell, when fetch() is run for the second time, it crashes with the following exception:
exceptions.AssertionError: No free spider slots when opening 'default'
Traceback:
2012-01-29 23:45:01-0600 [-] ERROR: Unhandled error in Deferred:
2012-01-29 23:45:01-0600 [-] Unhandled Error
Traceback (most recent call last):
File "/usr/lib/python2.7/dist-packages/twisted/internet/threads.py", line 113, in _callFromThread
result = defer.maybeDeferred(f, _a, *_kw)
File "/usr/lib/python2.7/dist-packages/twisted/internet/defer.py", line 133, in maybeDeferred
result = f(_args, *_kw)
File "/usr/lib/pymodules/python2.7/scrapy/shell.py", line 64, in _schedule
self.crawler.engine.open_spider(spider, close_if_idle=False)
File "/usr/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1141, in unwindGenerator
return _inlineCallbacks(None, f(_args, *_kwargs), Deferred())
--- ---
File "/usr/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1020, in _inlineCallbacks
result = g.send(result)
File "/usr/lib/pymodules/python2.7/scrapy/core/engine.py", line 214, in open_spider
spider.name
exceptions.AssertionError: No free spider slots when opening 'default'
Traceback (most recent call last):
File "", line 1, in
File "/usr/lib/pymodules/python2.7/scrapy/shell.py", line 80, in fetch
self._schedule, request, spider)
File "/usr/lib/python2.7/dist-packages/twisted/internet/threads.py", line 118, in blockingCallFromThread
result.raiseException()
File "/usr/lib/python2.7/dist-packages/twisted/python/failure.py", line 338, in raiseException
raise self.type, self.value, self.tb
AssertionError: Spider 'default' not opened when crawling: <GET http://www.economist.com/blogs/freeexchange/2011/10/generational-warfare>
loveghost commented on Jul 29, 2016
hello
I custom spiders start_requests method.
 def start_requests(self):
        response_encoding = "utf-8"
        driver = webdriver.PhantomJS(executable_path=phantomjs_path)

        driver.get(self.start_url)

        WebDriverWait(driver, 30).until(EC.presence_of_element_located((By.CLASS_NAME, "hottrends-trends-list-video-container")))
        divs = driver.find_elements_by_class_name("hottrends-trends-list-video-container")`
        for div in divs:
               ..........
            request = scrapy.Request(url, callback=self.parse_detail)
            request.meta['item'] = item
            yield request
       driver.close()

def parse_detail(self, response):
            ......
I need the crawler can perform all the time, in other words, the crawler start automatically after the stop
how to do
thanks
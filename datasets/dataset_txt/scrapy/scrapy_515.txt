kingname commented on Oct 27, 2017 â€¢
edited
I am crawling 100 urls in scrapy. I have found that if I start scrapy - crawl 1 url - kill scrapy, then I can crawl every url in a short time. However, if I crawl all the 100 url in the same scrapy process, then the website will find me and refuse me.
Therefore, the website must write some datas to my spider, so the latter request will fail. Is there some method to reset the status of spider just like restart the scrapy process? So that I can reset the status of spider as soon as I finish crawling every url.
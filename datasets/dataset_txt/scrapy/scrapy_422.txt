newthis commented on Mar 13, 2018 •
edited
When I execute "scrapy shell scrapy shell https://crates.io/api/v1/crates?page=1&per_page=100"，exception occured as below:
2018-03-13 21:00:15 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6024
2018-03-13 21:00:15 [scrapy.core.engine] INFO: Spider opened
2018-03-13 21:00:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://crates.io/api/v1/crates?page=1> (failed 1 times): [<twisted.python.failure.Failure <class 'OpenSSL.SSL.Error'>>]
2018-03-13 21:00:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://crates.io/api/v1/crates?page=1> (failed 2 times): [<twisted.python.failure.Failure <class 'OpenSSL.SSL.Error'>>]
2018-03-13 21:00:17 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://crates.io/api/v1/crates?page=1> (failed 3 times): [<twisted.python.failure.Failure <class 'OpenSSL.SSL.Error'>>]
Traceback (most recent call last):
File "/usr/local/bin/scrapy", line 11, in
sys.exit(execute())
File "/usr/local/lib/python2.7/dist-packages/scrapy/cmdline.py", line 150, in execute
_run_print_help(parser, _run_command, cmd, args, opts)
File "/usr/local/lib/python2.7/dist-packages/scrapy/cmdline.py", line 90, in _run_print_help
func(*a, **kw)
File "/usr/local/lib/python2.7/dist-packages/scrapy/cmdline.py", line 157, in _run_command
cmd.run(args, opts)
File "/usr/local/lib/python2.7/dist-packages/scrapy/commands/shell.py", line 73, in run
shell.start(url=url, redirect=not opts.no_redirect)
File "/usr/local/lib/python2.7/dist-packages/scrapy/shell.py", line 48, in start
self.fetch(url, spider, redirect=redirect)
File "/usr/local/lib/python2.7/dist-packages/scrapy/shell.py", line 115, in fetch
reactor, self._schedule, request, spider)
File "/usr/local/lib/python2.7/dist-packages/twisted/internet/threads.py", line 122, in blockingCallFromThread
result.raiseException()
File "", line 2, in raiseException
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure <class 'OpenSSL.SSL.Error'>>]
And the pip freeze result is:
adium-theme-ubuntu==0.3.4
apt-xapian-index==0.45
asn1crypto==0.24.0
attrs==17.4.0
Automat==0.6.0
cffi==1.11.5
chardet==2.0.1
colorama==0.2.5
command-not-found==0.3
constantly==15.1.0
cryptography==2.1.4
cssselect==1.0.3
debtagshw==0.1
defer==1.0.6
dirspec==13.10
duplicity==0.6.23
enum34==1.1.6
html5lib==0.999
httplib2==0.8
hyperlink==18.0.0
idna==2.6
incremental==17.5.0
ipaddress==1.0.19
lockfile==0.8
lxml==3.3.3
oauthlib==0.6.1
oneconf==0.3.7.14.4.1
PAM==0.4.2
parsel==1.4.0
pexpect==3.1
Pillow==2.3.0
piston-mini-client==0.7.5
pyasn1==0.4.2
pyasn1-modules==0.2.1
pycparser==2.18
pycrypto==2.6.1
pycups==1.9.66
PyDispatcher==2.0.5
pygobject==3.12.0
pymongo==3.6.0
pyOpenSSL==17.4.0
pyserial==2.6
pysmbc==1.0.14.1
python-apt===0.9.3.5ubuntu2
python-debian===0.1.21-nmu2ubuntu2
pyxdg==0.25
queuelib==1.5.0
reportlab==3.0
requests==2.2.1
Scrapy==1.5.0
service-identity==17.0.0
sessioninstaller==0.0.0
six==1.5.2
software-center-aptd-plugins==0.0.0
system-service==0.1.6
Twisted==13.1.0
Twisted-Core==13.2.0
Twisted-Web==13.2.0
unity-lens-photos==1.0
urllib3==1.7.1
w3lib==1.19.0
xdiagnose===3.6.3build2
zope.interface==4.0.5
openssl version on ubuntu is OpenSSL 1.0.2g 1 Mar 2016，
on windows ,the same openssl exception occured, "scrapy shell scrapy shell https://crates.io/api/v1/crates?page=1&per_page=100"
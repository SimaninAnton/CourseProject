ghost commented on Nov 4, 2015
I recently tried to use scrapy to crawl my blog. Everything worked well until I came to rules. It didn't work and I did not know what was wrong. I followed the doc in scrapy crawlspider rules doc
Here is the code:
# -*- coding: utf8 -*-
from scrapy.spiders import CrawlSpider, Rule
from scrapy.linkextractors import LinkExtractor


class BlogSpider(CrawlSpider):
    name = 'leonard-peng.blog'
    allowed_domains = ['leonard-peng.github.io']
    start_urls = ['http://leonard-peng.github.io/']
    rules = (
        # try to match '/2015/09/04/regex/'
        Rule(LinkExtractor(allow=('/2015/09/04/regex/', )), callback="parse_item"),
        Rule(LinkExtractor(allow=('2015/09/04/regex/', )), callback="parse_item"),
        Rule(LinkExtractor(allow=(r'/\d{4}/\d{2}/\d{2}/.*', )), callback="parse_item"),
    )

    def parse(self, response):
        print 'get root url data'

    def parse_item(self, response):
        print 'get article url data'
üëç 2
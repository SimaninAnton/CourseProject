mike-athene commented on Oct 24, 2012
Hi,
I store parsed data in database on remote machine and don't need to have items feed on same server as scrapyd. According to docs this can be done by setting "items_dir" to empty value, which doesn't seem to work when launching scrapyd with "scrapy server":
items_dir would be set anyway in https://github.com/scrapy/scrapy/blob/master/scrapyd/script.py#L32
If I remove items_dir from script.py I still get "Items" link in web admin which leads me to root of scrapy project due to wrong static files configuration (which is definitely bad thing as I can download any file from it)
I can see "Items" link for every spider in web admin
Same thing for logs_dir
Am I doing something wrong, or is this an actual bug? If so, would be happy to provide a patch.
$scrapy version -v
Scrapy  : 0.17.0
lxml    : 3.0.1.0 
libxml2 : 2.7.8 
Twisted : 12.2.0
Python  : 2.6.6 (r266:84292, Dec 26 2010, 22:31:48) - [GCC 4.4.5] 
Platform: Linux-2.6.32-12-pve-x86_64-with-debian-6.0.4
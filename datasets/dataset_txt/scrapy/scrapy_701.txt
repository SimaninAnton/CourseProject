p8a commented on Feb 11, 2017 â€¢
edited
Crawling of authenticated urls ( http://:@domain.com) fails with DNS lookup failure:
2017-02-10 14:48:37 [scrapy] INFO: Spider opened
2017-02-10 14:48:37 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-02-10 14:48:37 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2017-02-10 14:48:37 [scrapy] DEBUG: Retrying <GET http://user:password@foobar.com/context/latest.txt> (failed 1 times): DNS lookup failed: address 'user:password@foobar.com' not found: [Errno 8] nodename nor servname provided, or not known.
2017-02-10 14:48:37 [scrapy] DEBUG: Retrying <GET http://user:password@foobar.com/context/latest.txt> (failed 2 times): DNS lookup failed: address 'user:password@foobar.com' not found: [Errno 8] nodename nor servname provided, or not known.
2017-02-10 14:48:37 [scrapy] DEBUG: Gave up retrying <GET http://user:password@foobar.com/context/latest.txt> (failed 3 times): DNS lookup failed: address 'user:password@foobar.com' not found: [Errno 8] nodename nor servname provided, or not known.
2017-02-10 14:48:37 [scrapy] ERROR: Error downloading <GET http://user:password@foobar.com/context/latest.txt>: DNS lookup failed: address 'user:password@foobar.com' not found: [Errno 8] nodename nor servname provided, or not known.
2017-02-10 14:48:37 [scrapy] INFO: Closing spider (finished)
I'm using scrapy 1.1.2
Is there a different way/option to make this kind of URLs work ?
Thanks
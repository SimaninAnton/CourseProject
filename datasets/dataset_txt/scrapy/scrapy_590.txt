Pac23 commented on Jul 12, 2017
PS C:\Windows\system32> scrapy shell
2017-07-12 09:30:40 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: scrapybot)
2017-07-12 09:30:40 [scrapy.utils.log] INFO: Overridden settings: {'DUPEFILTER_CLASS': 'scrapy.dupefilters.BaseDupeFilte
r', 'LOGSTATS_INTERVAL': 0}
2017-07-12 09:30:40 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
'scrapy.extensions.telnet.TelnetConsole']
Traceback (most recent call last):
File "c:\program files (x86)\python36-32\lib\runpy.py", line 193, in _run_module_as_main
"main", mod_spec)
File "c:\program files (x86)\python36-32\lib\runpy.py", line 85, in run_code
exec(code, run_globals)
File "C:\Program Files (x86)\Python36-32\Scripts\scrapy.exe_main.py", line 9, in
File "c:\program files (x86)\python36-32\lib\site-packages\scrapy\cmdline.py", line 149, in execute
_run_print_help(parser, _run_command, cmd, args, opts)
File "c:\program files (x86)\python36-32\lib\site-packages\scrapy\cmdline.py", line 89, in _run_print_help
func(*a, **kw)
File "c:\program files (x86)\python36-32\lib\site-packages\scrapy\cmdline.py", line 156, in _run_command
cmd.run(args, opts)
File "c:\program files (x86)\python36-32\lib\site-packages\scrapy\commands\shell.py", line 67, in run
crawler.engine = crawler._create_engine()
File "c:\program files (x86)\python36-32\lib\site-packages\scrapy\crawler.py", line 102, in create_engine
return ExecutionEngine(self, lambda : self.stop())
File "c:\program files (x86)\python36-32\lib\site-packages\scrapy\core\engine.py", line 69, in init
self.downloader = downloader_cls(crawler)
File "c:\program files (x86)\python36-32\lib\site-packages\scrapy\core\downloader_init.py", line 88, in init
self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
File "c:\program files (x86)\python36-32\lib\site-packages\scrapy\middleware.py", line 58, in from_crawler
return cls.from_settings(crawler.settings, crawler)
File "c:\program files (x86)\python36-32\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
mwcls = load_object(clspath)
File "c:\program files (x86)\python36-32\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
mod = import_module(module)
File "c:\program files (x86)\python36-32\lib\importlib_init.py", line 126, in import_module
return _bootstrap._gcd_import(name[level:], package, level)
File "", line 978, in _gcd_import
File "", line 961, in _find_and_load
File "", line 950, in _find_and_load_unlocked
File "", line 655, in _load_unlocked
File "", line 678, in exec_module
File "", line 205, in _call_with_frames_removed
File "c:\program files (x86)\python36-32\lib\site-packages\scrapy\downloadermiddlewares\retry.py", line 20, in <module
from twisted.web.client import ResponseFailed
File "c:\program files (x86)\python36-32\lib\site-packages\twisted\web\client.py", line 42, in
from twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS
File "c:\program files (x86)\python36-32\lib\site-packages\twisted\internet\endpoints.py", line 41, in
from twisted.internet.stdio import StandardIO, PipeAddress
File "c:\program files (x86)\python36-32\lib\site-packages\twisted\internet\stdio.py", line 30, in
from twisted.internet import _win32stdio
File "c:\program files (x86)\python36-32\lib\site-packages\twisted\internet_win32stdio.py", line 9, in
import win32api
ModuleNotFoundError: No module named 'win32api'
Scrapy was working fine on win 7,ever since i switched to win 10 this error pop's up.
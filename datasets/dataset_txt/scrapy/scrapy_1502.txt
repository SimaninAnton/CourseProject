em-cliqz commented on Sep 30, 2013
I'm unable to get the spider.log function to produce any output when the LOG_FILE is specified on the command line.
/usr/local/bin/scrapy crawl web -a job_name=test_job -a input_file=/tmp/test_job.json -s "LOG_FILE=/tmp/test.log" -s 'FEED_URI=/tmp/test.jl'
I have a Filter with this function:
def process_start_requests(self, start_requests, spider):
print( "HERE" )
spider.log( "HERE" )
return start_requests
"HERE" is written to stdout but not to the logfile. The Logfile is generated, it has the basic stats. A log statement in the spider as well is not recording any data.
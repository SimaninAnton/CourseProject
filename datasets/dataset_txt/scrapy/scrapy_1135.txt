eyurtsev commented on Sep 8, 2015
I apologize in advance if I misunderstood the API, but I suspect that there's a bug with passing meta information to the FTPClient.
I was successful in following this post for crawling a public ftp server: http://stackoverflow.com/questions/27770610/using-scrapy-to-crawl-a-public-ftp-server
In this post, the spider uses start_requests. So this kind of construction works:
    def start_requests(self):
        urls = self.start_urls
        for url in urls:
            yield Request(url, meta={'ftp_user': 'anonymous', 'ftp_password': ''})
(That works successfully.)
However, if instead of using start_requests, I use make_request_from_url:
    def make_request_from_url(self, url):
        yield Request(url, meta={'ftp_user': 'anonymous', 'ftp_password': ''})
Then, I get the following error message:
'''
python2.7/site-packages/scrapy/core/downloader/handlers/ftp.py", line 72, in download_request
creator = ClientCreator(reactor, FTPClient, request.meta["ftp_user"],
KeyError: 'ftp_user'
'''
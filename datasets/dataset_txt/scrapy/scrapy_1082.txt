Monk-Liu commented on Nov 14, 2015
I dont't know why, my spider just stop after
2015-11-14 10:26:39 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
and when I forced to stop it , it raise :gevent.hub.LoopExit: This operation would block forever
all debug info just like that:
2015-11-14 10:24:14 [scrapy] INFO: Scrapy 1.0.3 started (bot: TCspider)
2015-11-14 10:24:14 [scrapy] INFO: Optional features available: ssl, http11
2015-11-14 10:24:14 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'TCspider.spiders', 'SPIDER_MODULES': ['TCspider.spiders'], 'LOGSTATS_INTERVAL': 0, 'BOT_NAME': 'TCspider'}
2015-11-14 10:24:14 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, CoreStats, SpiderState
2015-11-14 10:24:14 [py.warnings] WARNING: /home/liuqifan/Virtualenv/PY2/lib/python2.7/site-packages/scrapy/utils/deprecate.py:155: ScrapyDeprecationWarning: scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware class is deprecated, use scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware instead
ScrapyDeprecationWarning)
2015-11-14 10:24:23 [scrapy] INFO: Enabled downloader middlewares: HostMiddleware, UserAgentMiddleware, ProxyMiddleware, UserAgentMiddleware, HttpAuthMiddleware, DownloadTimeoutMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2015-11-14 10:24:23 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2015-11-14 10:24:23 [scrapy] INFO: Enabled item pipelines: TcspiderPipeline
2015-11-14 10:24:23 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
^C2015-11-14 10:24:53 [scrapy] INFO: Received SIGINT, shutting down gracefully. Send again to force
Traceback (most recent call last):
File "/home/liuqifan/Virtualenv/PY2/bin/scrapy", line 11, in
sys.exit(execute())
File "/home/liuqifan/Virtualenv/PY2/lib/python2.7/site-packages/scrapy/cmdline.py", line 143, in execute
_run_print_help(parser, _run_command, cmd, args, opts)
File "/home/liuqifan/Virtualenv/PY2/lib/python2.7/site-packages/scrapy/cmdline.py", line 89, in _run_print_help
func(_a, *_kw)
File "/home/liuqifan/Virtualenv/PY2/lib/python2.7/site-packages/scrapy/cmdline.py", line 150, in _run_command
cmd.run(args, opts)
File "/home/liuqifan/Virtualenv/PY2/lib/python2.7/site-packages/scrapy/commands/shell.py", line 63, in run
shell.start(url=url)
File "/home/liuqifan/Virtualenv/PY2/lib/python2.7/site-packages/scrapy/shell.py", line 44, in start
self.fetch(url, spider)
File "/home/liuqifan/Virtualenv/PY2/lib/python2.7/site-packages/scrapy/shell.py", line 87, in fetch
reactor, self._schedule, request, spider)
File "/home/liuqifan/Virtualenv/PY2/lib/python2.7/site-packages/twisted/internet/threads.py", line 120, in blockingCallFromThread
result = queue.get()
File "/usr/lib64/python2.7/Queue.py", line 168, in get
self.not_empty.wait()
File "/usr/lib64/python2.7/threading.py", line 340, in wait
waiter.acquire()
File "gevent/_semaphore.pyx", line 112, in gevent._semaphore.Semaphore.acquire (gevent/gevent._semaphore.c:3386)
File "/home/liuqifan/Virtualenv/PY2/lib/python2.7/site-packages/gevent/hub.py", line 338, in switch
return greenlet.switch(self)
gevent.hub.LoopExit: This operation would block forever
Appreciated if anysome tell me what's wrong with the program
geekan commented on Jan 31, 2014
I'm a newbie to scrapy, and when I crawl some web with utf-8 encoding, I see the log messages contain lots of \uxx. I don't like showing unicode code, so I hack log.py, now it shows the right utf-8 character.
Here's the code, repr(kw).decode("unicode-escape"): is the only modification.
def msg(message=None, _level=INFO, **kw):
    kw['logLevel'] = kw.pop('level', _level)
    kw.setdefault('system', 'scrapy')
    if message is None:
        # log.msg(**kw)
        print repr(kw).decode("unicode-escape")
    else:
        # log.msg(message, **kw)
        print message, repr(kw).decode("unicode-escape")
The method I use may be crude, not a twisted-style log, but I'm not familier with twisted too. So is there any configuration I could use to make utf-8 log correct, or any better way to do it?
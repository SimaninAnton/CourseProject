kedizhou commented on Jan 15, 2016
i have a spider youtube script,example, use command 'scrapy crawl youtube' by manual in linux command terminal, return 1000line json data file,but use crontab call following script return 950 line json data file,missing 50 line data,why does this?
from multiprocessing import Pool
import os, sys

def _crawl(spider_name=None):
    if spider_name:
        path = os.path.dirname(os.path.abspath(sys.argv[0]))
        os.chdir(path + '/' + spider_name)
        os.environ["PATH"] = os.environ["PATH"] + ':/usr/local/bin/'
        os.system('scrapy crawl %s' % spider_name)
    return None


def run_crawler(list):
    pool = Pool(processes=len(list))
    pool.map(_crawl, list)


list = ['youtube']
run_crawler(list)
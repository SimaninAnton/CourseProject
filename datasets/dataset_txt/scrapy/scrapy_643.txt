vionemc commented on Apr 16, 2017
So I run Scrapy inside a Thread object, like this:
class myThread(threading.Thread):
    #omitted
    
 def start(self, spiders):
  settings = get_project_settings()
  settings['LOG_ENABLED'] = False
  process = CrawlerProcess(settings)
  for spider in spiders:
   process.crawl(spider)

  process.start()
But the log becomes like this:
2017-04-16 07:13:48 [scrapy] INFO: Spider opened
2017-04-16 07:13:48 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-16 07:13:48 [root] INFO: Using crawlera at http://proxy.crawlera.com:8010?noconnect (user: ae3151d...)
2017-04-16 07:13:48 [root] INFO: CrawleraMiddleware: disabling download delays on Scrapy side to optimize delays introduced by Crawlera. To avoid this behaviour you can use the CRAWLERA_PRESERVE_DELAY setting but keep in mind that this may slow down the crawl significantly
2017-04-16 07:13:48 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2017-04-16 07:13:48 [scrapy] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2017-04-16 07:13:48 [scrapy] INFO: Enabled downloader middlewares:
Please notice [scrapy] instead of [scrapy.middlewares] etc. It makes it hard for me to filter the log.
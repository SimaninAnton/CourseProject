ssbb commented on Nov 2, 2015
Hi!
I want to download first 100-200kb of file for each scraped item (normal size is much bigger) and run subprocess call. Now I have this logic (inside celery): downloading X bytes of file (with requests/urllib), call ffprobe via subprocess, stop if file can be parsed. If not - get more X bytes and check again... Loop here.
So what you think if I will move this logic to Scrapy pipeline? I will have blocks?
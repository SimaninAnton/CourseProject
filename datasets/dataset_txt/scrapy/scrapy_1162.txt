aldarund commented on Aug 2, 2015
Stacktrace (most recent call last):

  File "scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "scrapy/spidermiddlewares/offsite.py", line 28, in process_spider_output
    for x in result:
  File "scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "scrapy/spidermiddlewares/offsite.py", line 28, in process_spider_output
    for x in result:
  File "scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "scrapy/spidermiddlewares/depth.py", line 54, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "scrapy/spiders/crawl.py", line 69, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "ex_link_crawl/spiders/external_link_spider.py", line 45, in parse_obj
    for link in LxmlLinkExtractor(allow=(), deny=self.allowed_domains).extract_links(response):
  File "scrapy/linkextractors/lxmlhtml.py", line 108, in extract_links
    links = self._extract_links(doc, response.url, response.encoding, base_url)
  File "scrapy/linkextractors/__init__.py", line 103, in _extract_links
    return self.link_extractor._extract_links(*args, **kwargs)
  File "scrapy/linkextractors/lxmlhtml.py", line 50, in _extract_links
    for el, attr, attr_val in self._iter_links(selector._root):
  File "scrapy/linkextractors/lxmlhtml.py", line 38, in _iter_links
    for el in document.iter(etree.Element):
My use of extractor is following:
def parse_obj(self, response):
        if not isinstance(response, HtmlResponse):
            return
        for link in LxmlLinkExtractor(allow=(), deny=self.allowed_domains).extract_links(response):
            if not link.nofollow:
                yield LinkCrawlItem(domain=link.url)
Contributor
pawelmhm commented on Dec 10, 2015
this is partly bug, partly feature but you can do something like this:
scrapy crawl dmoz -a start_requests="this"
and it will effectively overwrite spider start_requests with string "this" so that you will get
2015-12-10 14:19:05 [twisted] CRITICAL: Unhandled error in Deferred:


Traceback (most recent call last):
  File "/home/pawel//src/scrapy/scrapy/cmdline.py", line 150, in _run_command
    cmd.run(args, opts)
  File "/home/pawel/scrapy/scrapy/commands/crawl.py", line 57, in run
    self.crawler_process.crawl(spname, **opts.spargs)
  File "/home/pawelsrc/scrapy/scrapy/crawler.py", line 153, in crawl
    d = crawler.crawl(*args, **kwargs)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1274, in unwindGenerator
    return _inlineCallbacks(None, gen, Deferred())
--- <exception caught here> ---
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1128, in _inlineCallbacks
    result = g.send(result)
  File "/home/pawel/src/scrapy/scrapy/crawler.py", line 72, in crawl
    start_requests = iter(self.spider.start_requests())
exceptions.TypeError: 'str' object is not callable
2015-12-10 14:19:05 [twisted] CRITICAL: 
I discovered this when client asked to add option to pass download_delay when scheduling. Turns out you can do this without any updates to spider, but the type will be invalid.
I think it could be dangerous though, it allows lots of control over spider settings and can cause mysterious bugs, imagine you have some spider attribute that is string and someone passes this attribute from command line too. It would be unexpected for most users that command line argument can overwrite object attribute. The line responsible for this is here: https://github.com/scrapy/scrapy/blob/master/scrapy/spiders/__init__.py#L30
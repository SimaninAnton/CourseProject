Member
kmike commented on Dec 27, 2013
Hi,
Scrapy uses shelve-based cache by default; this could lead to a bad experience with scrapy because shelve databases can become corrupted if spider is stopped forcefully.
What do you think about the following?
Check if it can be fixed - for example, by closing databases at certain points;
if it can't be fixed, then switch to an another cache backend.
This ticket could be related: #491 - I haven't looked at that ticket in details, but user mentions close_spider is not called on middleware - this could cause DB corruption for dbm backend. Any ideas?
File-based cache doesn't seem to have this issue. Another option is sqlite - in my experience it is much harder to get sqlite database corrupted, compared to dbm.
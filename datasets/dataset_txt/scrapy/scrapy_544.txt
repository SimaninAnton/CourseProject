treemore commented on Sep 11, 2017 â€¢
edited
this is my scrapy file
# -*- coding: utf-8 -*-
import scrapy


class Bug1Spider(scrapy.Spider):
    name = 'bug1'
    allowed_domains = ['google.com']
    start_urls = ['https://www.google.com/search?q=scrapy' for x in range(0, 20, 1)]

    def parse(self, response):
        self.log("*" * 100)
        pass
settings.py
DOWNLOAD_DELAY = 10
# The download delay setting will honor only one of:
CONCURRENT_REQUESTS_PER_DOMAIN = 20
# here AUTOTHROTTLE_ENABLED set True or False not affect the result
AUTOTHROTTLE_ENABLED = False
when i execute the shell below
scrapy crawl bug1
i notice that the start_urls not CONCURRENT request.
i set CONCURRENT_REQUESTS_PER_DOMAIN=20. i assume will fetch 20 request at the same time, but the console look like the request is fetch one by one . request one and than wait 10 seconds and start the next one.
maybe DOWNLOAD_DELAY>0 -> CONCURRENT_REQUES TS_PER_DOMAIN=1 ?
just like https://stackoverflow.com/questions/37461327/scrapy-concurrent-requests-ignored-when-download-delay-set
but i can not find that in any document.
my scrapy version is Version: 1.4.0
Twisted version is Version: 17.5.0
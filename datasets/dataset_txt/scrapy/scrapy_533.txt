Chratho commented on Sep 23, 2017
I am in a situation where a single item gets defined over a sequence of multiple pages, passing values between the particular callbacks using the meta-dict. I believe this is a common approach among scrapy-users.
However, it feels like this approach is difficult to get right. With the default implementation of RFPDupefilter, my callback-chain is teared apart quite easy, as fingerprints don't take the meta-dict into account. The corresponding requests are thrown away, the information in the meta-dict which made this request unique is lost.
I have currently implemented by own meta-aware DupeFilter, but I am still facing the problem that it lacks access to the specific spider in use - and only the Spider really knows the meta-attributes that make a request unique. I could now take it a step further and implement my own scheduler, but I'm afraid that all these custom extensions make my code very brittle wrt future versions of scrapy.
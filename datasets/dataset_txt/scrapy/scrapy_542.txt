xiaoyuan1998 commented on Sep 17, 2017 â€¢
edited
Hello Guys,
To solve the problem of proxy, i programmed spider A in project A which helps to crawl free proxy ip in a website and then put them in a csv file:
scrapy runspider getproxy_inmyfile.py -o proxylist.csv
Then i did my spider B in project B to crawl the information.
Spider B will check and get a proxy ip in my customised download middware. if the proxy ip is invalid, middware will delete this ip in the proxy csv file. if it is effective, i will use this ip as a proxy,
My issue is that:
when the proxy csv file is empty (all proxy ip are invalid and deleted)
i would like to run spider A again to provisioning the csv file.
I only find the tutorial of running multiple spiders in one project in the site of doc https://docs.scrapy.org/en/latest/ but i do not know how to run another spider in another project.
Thanks in advance for your help.
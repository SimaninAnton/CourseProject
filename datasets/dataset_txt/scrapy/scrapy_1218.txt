1a1a11a commented on May 20, 2015
I am writing the following spider, but has the error "error downloading, Couldn't bind: 24: Too many open files. ", can you help me?
class Spider(scrapy.Spider):
    name = “***”
    def __init__(self, url='http://example.com/', **kw):
        super(Spider,self).__init__(**kw)
        self.url = url 
        self.allowed_domains = [re.sub(r'^www\.', '', urlparse(url).hostname)]

    def start_requests(self):
        return [Request(self.url, callback=self.find_all_url, dont_filter=False)]

    def find_all_url(self,response):
        if ***:
             self.parse(response)
        links = LinkExtractor().extract_links(response)
        for link in links:
             if len(link.url) < 50:
                   yield Request(link.url, callback = self.find_all_url, dont_filter=False)

    def parse(self, response):
        dept = deptItem()
        dept['deptName'] = response.xpath('//title/text()').extract()[0].strip()
        dept['url'] = response.url
        log.msg('find an item: '+ str(response.url) +'\n going to return item' , level = log.INFO)
        return dept        
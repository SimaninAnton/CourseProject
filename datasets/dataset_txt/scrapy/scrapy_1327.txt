wangeguo commented on Nov 19, 2014
I wrote this code:
import scrapy
from scrapy.contrib.spiders import CrawlSpider, Rule
from scrapy.contrib.linkextractors import LinkExtractor
from bot.items import Product

class RevolveclothingSpider(CrawlSpider):
    name = "revolveclothing"
    allowed_domains = ["www.revolveclothing.com"]
    start_urls = ('http://www.revolveclothing.com/daydreamer-rolling-stones-flag-tongue-sweatshirt-in-black/dp/DDRE-WO8/')
    rules = (Rule(LinkExtractor(allow=('dp/[a-zA-Z0-9\-]+/')), callback='parse_item'),)

    def parse_item(self, response):
        product = Product()

        brand = response.xpath('//div[@class="designer_brand"]/h2/a/text()').extract()
        title = response.xpath('//div[@class="product_name"]/h1/text()').extract()
        product['name'] = '%s %s' % (brand[0], title[0].strip())

        product['price'] = response.xpath('//div[@class="price_box"]/span[@class="price"]/text()').extract()[0]
        product['link'] = response.url
        #product['description'] = response.xpath('').extract()[0].strip()
        product['image_urls'] = response.xpath('//div[@class="pdp_zoomed_product"]/div/img/@src').extract()

        yield product
and here is result:
scrapy crawl revolveclothing
2014-11-19 21:54:17+0800 [scrapy] INFO: Scrapy 0.24.4 started (bot: bot)
2014-11-19 21:54:17+0800 [scrapy] INFO: Optional features available: ssl, http11, django
2014-11-19 21:54:17+0800 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'bot.spiders', 'SPIDER_MODULES': ['bot.spiders'], 'BOT_NAME': 'bot'}
2014-11-19 21:54:17+0800 [scrapy] INFO: Enabled extensions: LogStats, TelnetConsole, CloseSpider, WebService, CoreStats, SpiderState
2014-11-19 21:54:17+0800 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2014-11-19 21:54:17+0800 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2014-11-19 21:54:17+0800 [scrapy] INFO: Enabled item pipelines: MyImagesPipeline
2014-11-19 21:54:17+0800 [revolveclothing] INFO: Spider opened
2014-11-19 21:54:17+0800 [revolveclothing] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2014-11-19 21:54:17+0800 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2014-11-19 21:54:17+0800 [scrapy] DEBUG: Web service listening on 127.0.0.1:6080
2014-11-19 21:54:17+0800 [revolveclothing] ERROR: Obtaining request from start requests
    Traceback (most recent call last):
      File "/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/twisted/internet/base.py", line 1169, in run
        self.mainLoop()
      File "/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/twisted/internet/base.py", line 1178, in mainLoop
        self.runUntilCurrent()
      File "/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/twisted/internet/base.py", line 800, in runUntilCurrent
        call.func(*call.args, **call.kw)
      File "/Library/Python/2.7/site-packages/scrapy/utils/reactor.py", line 41, in __call__
        return self._func(*self._a, **self._kw)
    --- <exception caught here> ---
      File "/Library/Python/2.7/site-packages/scrapy/core/engine.py", line 112, in _next_request
        request = next(slot.start_requests)
      File "/Library/Python/2.7/site-packages/scrapy/spider.py", line 50, in start_requests
        yield self.make_requests_from_url(url)
      File "/Library/Python/2.7/site-packages/scrapy/spider.py", line 53, in make_requests_from_url
        return Request(url, dont_filter=True)
      File "/Library/Python/2.7/site-packages/scrapy/http/request/__init__.py", line 26, in __init__
        self._set_url(url)
      File "/Library/Python/2.7/site-packages/scrapy/http/request/__init__.py", line 61, in _set_url
        raise ValueError('Missing scheme in request url: %s' % self._url)
    exceptions.ValueError: Missing scheme in request url: h

2014-11-19 21:54:17+0800 [revolveclothing] INFO: Closing spider (finished)
2014-11-19 21:54:17+0800 [revolveclothing] INFO: Dumping Scrapy stats:
    {'finish_reason': 'finished',
     'finish_time': datetime.datetime(2014, 11, 19, 13, 54, 17, 958055),
     'log_count/DEBUG': 2,
     'log_count/ERROR': 1,
     'log_count/INFO': 7,
     'start_time': datetime.datetime(2014, 11, 19, 13, 54, 17, 953648)}
2014-11-19 21:54:17+0800 [revolveclothing] INFO: Spider closed (finished)
ENV
scrapy version -v
Scrapy  : 0.24.4
lxml    : 3.4.0.0
libxml2 : 2.9.0
Twisted : 12.2.0
Python  : 2.7.5 (default, Mar  9 2014, 22:15:05) - [GCC 4.2.1 Compatible Apple LLVM 5.0 (clang-500.0.68)]
Platform: Darwin-13.4.0-x86_64-i386-64bit
Who can tell me how to modify the problem?
tombka commented on Jun 4, 2019 â€¢
edited
Hello everybody,
I have a problem with running my spider through a worker who is listening for new job(RQ) :
class Scraper:
    def __init__(self):
        self.process = CrawlerProcess(get_project_settings())
        self.spider = mySpider

    def run_spiders(self, url):
        print(self.process.crawlers) # <= output : set()
        self.process.crawl(self.spider[0], url=url)
        print(self.process.crawlers) # <= output : {<scrapy.crawler.Crawler object at 0x7f2d9419e6a0>}
        self.process.start()  # the script will block here until the crawling is finished
While i run my spider with python3 crawl_site.py everything seems to be ok as you can see above.
BUT, when i try to perform a crawl through my worker my self.process.crawlers remains the same : an empty set()
It doesn't make any sense for me...
Feel free to ask for more informations if needed.
EDIT :
It's weird the self.process.start() seems to be absolutely useless : nothing if performed while i executed it within my worker, but as always it's working perfectly while being run in command line
eadebruijn commented on Mar 1, 2016
So my code (pasted) below almost does what I want. Instead, it covers 29/30 pages, and then leaves out the last. Furthermore, I would preferably have it go beyond, but the website has no button for it (the pages actually do work when you manually fill in page=31 in the link). When Depth_Limit is 29 it's all fine, but on 30 I get the following error in the command prompt:
File "C:\Users\Ewald\Scrapy\OB\OB\spiders\spider_OB.py", line 23, in parse
next_link = 'https://zoek.officielebekendmakingen.nl/' + s.xpath('//a[@Class="volgende"]/@href').extract()[0]
IndexError: list index out of range
I've tried variious approaches, but they all seem to fail me... Also, I can't for the life of me format this post properly :(.
class OB_Crawler(CrawlSpider):
name = 'OB5'
allowed_domains = ["https://www.officielebekendmakingen.nl/"]
start_urls = ["https://zoek.officielebekendmakingen.nl/zoeken/resultaat/?zkt=Uitgebreid&pst=Tractatenblad|Staatsblad|Staatscourant|BladGemeenschappelijkeRegeling|ParlementaireDocumenten&vrt=Cybersecurity&zkd=InDeGeheleText&dpr=Alle&sdt=DatumPublicatie&ap=&pnr=18&rpp=10&_page=1&sorttype=1&sortorder=4"]
custom_settings = {
'BOT_NAME': 'OB-crawler',
'DEPTH_LIMIT': 30,
'DOWNLOAD_DELAY': 0.1
}
def parse(self, response):
    s = Selector(response)
    next_link = 'https://zoek.officielebekendmakingen.nl/' + s.xpath('//a[@class="volgende"]/@href').extract()[0]
    if len(next_link):
        yield self.make_requests_from_url(next_link)
    posts = response.selector.xpath('//div[@class = "lijst"]/ul/li')
    for post in posts:
        i = TextPostItem()
        i['title'] = ' '.join(post.xpath('a/@href').extract()).replace(';', '').replace('  ', '').replace('\r\n', '')
        i['link'] = ' '.join(post.xpath('a/text()').extract()).replace(';', '').replace('  ', '').replace('\r\n', '')
        i['info'] = ' '.join(post.xpath('a/em/text()').extract()).replace(';', '').replace('  ', '').replace('\r\n', '').replace(',', '-')
        yield i       
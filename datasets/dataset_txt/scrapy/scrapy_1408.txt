hxu commented on May 23, 2014
I've been working on a deployment of a spider that uses the FilesPipeline, and encountered a sort of 'gotcha' with respect to where files get downloaded when it gets deployed to scrapyd.
When developing, I can set the FILES_STORE to whatever suits my development environment. However, when I deploy this to scrapyd, this setting gets deployed with my project and spider. If the path of FILES_STORE isn't already created on the scrapyd server, then the files will fail to save.
It seems like where the FilesPipeline stores files should be overridden by the settings in the scrapyd server. In the current situation, I have to make sure to set the FILES_STORE setting to something that works for the deployment server before I deploy, then switch it back when I'm in my dev environment. Is there a better way to do this?
(I wasn't sure if this ticket was better suited for scrapy or scrapyd)
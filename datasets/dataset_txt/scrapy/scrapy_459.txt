zinyosrim commented on Jan 19, 2018
I'm trying to use scrapy with splash and rotating proxies. Here's my settings.py:
ROBOTSTXT_OBEY = False
BOT_NAME = 'mybot'
SPIDER_MODULES = ['myproject.spiders']
NEWSPIDER_MODULE = 'myproject.spiders'
LOG_LEVEL = 'INFO'
USER_AGENT = 'Mozilla/5.0'

# JSON file pretty formatting
FEED_EXPORT_INDENT = 4

# Suppress dataloss warning messages of scrapy downloader
DOWNLOAD_FAIL_ON_DATALOSS = False 
DOWNLOAD_DELAY = 1.25  

# Enable or disable spider middlewares
SPIDER_MIDDLEWARES = {
    'scrapy_splash.SplashDeduplicateArgsMiddleware': 100,
}

# Enable or disable downloader middlewares
DOWNLOADER_MIDDLEWARES = {
    'rotating_proxies.middlewares.RotatingProxyMiddleware': 610,
    'rotating_proxies.middlewares.BanDetectionMiddleware': 620,
    'scrapy_splash.SplashCookiesMiddleware': 723,
    'scrapy_splash.SplashMiddleware': 725,
    'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware': 810,
    'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware': None,
}

# Splash settings
HTTPCACHE_STORAGE = 'scrapy_splash.SplashAwareFSCacheStorage'
DUPEFILTER_CLASS = 'scrapy_splash.SplashAwareDupeFilter'
SPLASH_URL = 'http://localhost:8050'
I'm setting the ROTATING_PROXY_LIST in my spider:
proxy_list = re.findall(r'(\d*\.\d*\.\d*\.\d*\:\d*)\b', requests.get("https://raw.githubusercontent.com/clarketm/proxy-list/master/proxy-list.txt").text)
custom_settings = {'ROTATING_PROXY_LIST': proxy_list}
I started splash with
docker run -p 8050:8050 scrapinghub/splash
But, when running the crawler I don't see any requests going through Splash. How can I fix this?
Thanks
Zin
seozed commented on Sep 27, 2017 â€¢
edited
i need start a spider from a running spider.
but show this error.
what should I do
myspider.py
import scrapy
from twisted.internet import reactor
from scrapy.crawler import CrawlerRunner

class MySpider1(scrapy.Spider):
    name = "myspider1"
    allowed_domains = []
    start_urls = ['http://cn.bing.com/']

    def parse(self, response):
        # Some run conditions
        if 'Bing' in response.text:

            runner = CrawlerRunner()
            runner.crawl(MySpider2)
            d = runner.join()
            d.addBoth(lambda _: reactor.stop())
            reactor.run()


class MySpider2(scrapy.Spider):
    """do someting"""
    pass
error info
['base.pipelines.BasePipeline']
2017-09-27 13:40:54 [scrapy.core.engine] INFO: Spider opened
2017-09-27 13:40:54 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-09-27 13:40:54 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2017-09-27 13:40:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://cn.bing.com/> (referer: None)
2017-09-27 13:40:55 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats']
Unhandled error in Deferred:
2017-09-27 13:40:55 [twisted] CRITICAL: Unhandled error in Deferred:

2017-09-27 13:40:55 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "C:\Program Files\Python35\lib\site-packages\twisted\internet\defer.py", line 1301, in _inlineCallbacks
    result = g.send(result)
  File "C:\Program Files\Python35\lib\site-packages\scrapy\crawler.py", line 71, in crawl
    self.spider = self._create_spider(*args, **kwargs)
  File "C:\Program Files\Python35\lib\site-packages\scrapy\crawler.py", line 94, in _create_spider
    return self.spidercls.from_crawler(self, *args, **kwargs)
  File "C:\Program Files\Python35\lib\site-packages\scrapy\spiders\__init__.py", line 50, in from_crawler
    spider = cls(*args, **kwargs)
  File "C:\Program Files\Python35\lib\site-packages\scrapy\spiders\__init__.py", line 29, in __init__
    raise ValueError("%s must have a name" % type(self).__name__)
ValueError: MySpider2 must have a name
2017-09-27 13:40:55 [scrapy.core.scraper] ERROR: Spider error processing <GET http://cn.bing.com/> (referer: None)
Traceback (most recent call last):
  File "C:\Program Files\Python35\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\scripts\spider\SpiderBase\base\spiders\testsMyspider.py", line 19, in parse
    reactor.run()
  File "C:\Program Files\Python35\lib\site-packages\twisted\internet\base.py", line 1242, in run
    self.startRunning(installSignalHandlers=installSignalHandlers)
  File "C:\Program Files\Python35\lib\site-packages\twisted\internet\base.py", line 1222, in startRunning
    ReactorBase.startRunning(self)
  File "C:\Program Files\Python35\lib\site-packages\twisted\internet\base.py", line 728, in startRunning
    raise error.ReactorAlreadyRunning()
twisted.internet.error.ReactorAlreadyRunning
2017-09-27 13:40:55 [scrapy.core.engine] INFO: Closing spider (shutdown)
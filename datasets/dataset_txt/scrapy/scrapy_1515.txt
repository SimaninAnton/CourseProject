Contributor
nyov commented on Sep 1, 2013
scrapy check fails in a project with more than one spider, that have a 'name' property.
$ scrapy check
Unhandled Error
Traceback (most recent call last):
  File "[...]/scrapy.git/scrapy/core/engine.py", line 247, in _spider_idle
    self.close_spider(spider, reason='finished')
  File "[...]/scrapy.git/scrapy/core/engine.py", line 259, in close_spider
    dfd.addBoth(lambda _: self.downloader.close())
  File "/usr/lib/python2.7/dist-packages/twisted/internet/defer.py", line 327, in addBoth
    callbackKeywords=kw, errbackKeywords=kw)
  File "/usr/lib/python2.7/dist-packages/twisted/internet/defer.py", line 293, in addCallbacks
    self._runCallbacks()
--- <exception caught here> ---
  File "/usr/lib/python2.7/dist-packages/twisted/internet/defer.py", line 575, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "[...]/scrapy.git/scrapy/core/engine.py", line 259, in <lambda>
    dfd.addBoth(lambda _: self.downloader.close())
  File "[...]/scrapy.git/scrapy/core/downloader/__init__.py", line 180, in close
    self._slot_gc_loop.stop()
  File "/usr/lib/python2.7/dist-packages/twisted/internet/task.py", line 181, in stop
    assert self.running, ("Tried to stop a LoopingCall that was "
exceptions.AssertionError: Tried to stop a LoopingCall that was not running.
This was introduced by commit af5c13f.
scrapy check also hangs forever in a (new) project without any spiders,
but this already seemed to be the case in 0.16
edit: tested with Twisted 12.0 and 13.0
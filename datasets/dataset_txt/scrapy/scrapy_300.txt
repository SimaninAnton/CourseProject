FinnFrotscher commented on Sep 20, 2018 â€¢
edited
My Goal I want to keep track of multiple twitter profiles over time (say, 12 weeks).
What I want to build: A SpiderMother class that interfaces with some Database (holding CrawlJobs) to spawn and manage many small spiders.
Each spider will crawl 1 user-profile on twitter at an irregular interval (the jobs will be added to the database according to some algorithm).
The Spiders get spawned as subprocesses by SpiderMother and depending on the success of the crawl, the database job get removed.
Is this a good (the right) architecture?
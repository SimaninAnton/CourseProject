shadowing commented on Nov 11, 2012
Hi,
I've been working on a complicated data scraping project for several months, the development are mainly based on 0.14.x stable and 0.15.x unstable. Last time I run it's around early Oct, all spiders ran flawlessly.
But after I upgraded to 0.16.x, it just printed endless ERROR, not doing anything. The only thing I can do is actually to kill -9. Then I tried downgrading to 0.14.4, it runs back to normal.
the error msg is like follows:
2012-11-09 00:39:33+0800 [scrapy] INFO: Scrapy 0.16.1 started (bot: mybot)
2012-11-09 00:39:33+0800 [scrapy] DEBUG: Enabled extensions: LogStats, TelnetConsole, CloseSpider, CoreStats, SpiderState, FailLogger
2012-11-09 00:39:33+0800 [scrapy] DEBUG: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, RandomUserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, RedirectMiddleware, HttpCompressionMiddleware, ChunkedTransferMiddleware, DownloaderStats
2012-11-09 00:39:33+0800 [scrapy] DEBUG: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2012-11-09 00:39:33+0800 [scrapy] DEBUG: Enabled item pipelines: sanitizePipeline
2012-11-09 00:39:34+0800 [-] ERROR: 2012-11-09 00:39:34+0800 [-] ERROR: 2012-11-09 00:39:34+0800
message like [-] ERROR: 2012-11-09 00:39:34+0800 just went on forever with the same timestamp, and ^C cannot stop it.
So, I start a new project using scrapy startproject mybot, copied one spider class, scrapy crawl spider, runs great; copy another, great; then one by one, until one, it started to print all these messages again. BTW, I run the same spider all the time.
Thought it could be some problem in my __init__() implementation, I brutally commented it, still wont work
So, you see, here I got a perfect running project and some spiders under scrapy 0.15.1/0.14.x, but in 0.16.x, all of the spiders won't work because of some certain spiders. My best guess is, is there some aggressive mechanism for spider initiation in 0.16.x?
Contributor
DharmeshPandav commented on Oct 4, 2019
I have been trying to run a scrapy crawl in a time constrained envrionment where we want to make sure that scrapy stops after fixed run time limit.
We have set the following CLOSESPIDER_TIMEOUT as 60 seconds and DOWNLOAD_TIMEOUT as 30 seconds.
We have set the forceful termination (kill the subprocess) at 90 seconds to cover the edge case scenario if page request is made at 59 seconds and twisted fails to download page and download timeout signal is triggred. ( 59 + 30 = 89 < 90 seconds)
but still scripts runs for random amount of time. range is between 95-115 seconds.
I am not sure where this variable 5-30 seconds are being used and why scrapy is failing to close gracelully after 90 seconds as expected
is this the default and accepted behaviour in scrapy/twisted reactor architecture where this lag is being introduced
or if any setting is there to override this behavior
Thanks
Member
shaneaevans commented on Sep 9, 2011
Previously reported by agtilden on Trac
scrapyd only allows one job to be scheduled per URL invocation. This makes scheduling lots of jobs needlessly time consuming.
I propose adding a file upload option that would contain a json string with the following structure:
[{"project" : {"spider": {"spider_arg_name": "spider_arg_value"}}},
    {"another_project" : {"another_spider": {"spider_arg_name": "spider_arg_value"}}}]
The return value would be a json list of the same length. Elements in the list would be either the jobid assigned by scrapyd or null in case the scheduler encountered an exception.
This can be implemented so that the existing parameter passing continues to work for scheduling one job at a time.
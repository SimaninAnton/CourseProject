akurtovic commented on Jun 2, 2014
I have an issue with JSON output where (seemingly at random) a few entries are corrupt. The script uses several spiders to crawl a list of news websites and pull a headline and link. As you can see below, there is one corrupt JSON entry amid a total of more than 70 entries that worked fine.
...
{"headline": "Rocks Thrown From Festus Overpass Damage Vehicles", "link": "http://stlouis.cbslocal.com/2014/05/29/rocks-thrown-from-festus-overpass-damage-vehicles/"}
r-man-who-robbed-car-wash-shot-employee-261327581.html"}
{"headline": "Police arrest man accused of threatening to kill wife with machete", "link": "http://www.kmov.com/news/crime/Man-accused-of-wielding-machete-threatening-to-kill-wife-261311461.html"}
...
This error is not consistent so I don't how to recreate it. When I re-ran the same project just a minute later, that particular entry was not corrupt anymore. And sometimes the JSON output file is completely clean, while at other times there are 3-4 errors out of 50-70 articles. This has happened on many attempts over the last couple of days. I thought it was a encoding issue or something in the URL field, but the JSON lines sometimes break on the headline field as well.
Below is my pipelines class (the project is here: https://github.com/akurtovic/Scrapy-Projects/tree/master/crimelog)
class JsonWriterPipeline(object):

    def __init__(self):
        self.file = codecs.open('crimelog.json', 'wb', encoding='utf-8')

    def process_item(self, item, spider):
        line = json.dumps(dict(item), ensure_ascii=False) + "\n"
        self.file.write(line)
        return item
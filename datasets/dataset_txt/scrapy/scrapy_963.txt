natoinet commented on Apr 14, 2016
Hello,
I am crawling sometimes websites with an invalid ssl certificate. For example, Scrapy 1.1.0 RC3 fails to open when I do:
scrapy shell https://www.directoriosanitario.com/directorio
or
scrapy shell https://saobinv.5go.cc/top/
and throws the following exception:
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure service_identity.exceptions.VerificationError: VerificationError(errors=[DNSMismatch(mismatched_id=DNS_ID(hostname=b'www.directoriosanitario.com'))])>]
I tried it with Scrapy 1.0.5 on python 2.7 and the spider opens but warns with:
AttributeError: 'NoneType' object has no attribute 'failVerification'
Is there a way to force the spider to open with Scrapy 1.1.0 RC3?
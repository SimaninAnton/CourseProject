trifle commented on Jan 29, 2016
Currently, redirects go wherever they want, ignoring the deny_res and deny_domain patterns set on a LinkExtractor. This means that no matter how one configures the LinkExtractor, denied URLs may end up being downloaded, parsed and stored.
The best way to stop this from happening would be to write a new downloader middleware. It should subclass BaseRedirectMiddleware, load the allow/deny patterns the same way OffsiteMiddleware does and raise IgnoreRequest when redirect_urls match these patterns.
There is already one related, but less generic issue #1042 .
I think I remember some discussion about a desirable refactor of the URL pattern matching logic (which is all over the place), but I can't find it currently.
I'd love to provide a pull request but it's unlikely I find the time to do so and I also don't have any experience writing tests (sorry).
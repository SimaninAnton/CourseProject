jwm commented on Apr 15, 2014
I'm working on a speaker scraper (https://github.com/scrapinghub/pycon-speakers) for JavaOne. To paginate through its results, you load the same URL multiple times, each time receiving the next page of results.
Because of this, that URL can't be cached, but AFAICT the only way to disable caching in scrapy is to disable caching for the entire crawl (i.e., a global scrapy setting).
It looked like a meta flag was added a while ago for this (#19) but it's more suited for internal use, and should probably be replaced by checking for dont_cache in a caching policy.
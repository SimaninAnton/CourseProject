staszek-arsdata commented on Sep 13, 2013
There's na issue with contrib/downloadermiddleware/httpproxy.py.
While I was setting proxy using request.meta['proxy] in my spider for each yield request, the processing was blocked.
Only setting env variable http_proxy didn't block the spider. But this kind of setting limits to one proxy per spider, so it's not as useful as request.meta['proxy'].
After reading the stackoverflow thread;
http://stackoverflow.com/questions/14945873/enabling-httpproxymiddleware-in-scrapyd I come into guess that the problem is somewhere in contrib/downloadermiddleware/httpproxy.py.
I see It raises NotConfigured in init if no env proxy variables are set.
After I commened out the:
    if not self.proxies:
        raise NotConfigured
It started working OK.
I don't know the internals of scrapy well, so don't know whether it's really needed, but for the code of contrib/downloadermiddleware/httpproxy.py it's not needed, as self.proxies stays as empty dict and the rest of the code within the module is OK with that.
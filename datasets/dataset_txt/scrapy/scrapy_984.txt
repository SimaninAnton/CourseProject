Contributor
djunzu commented on Mar 28, 2016
My log have some exceptions like this one:
2016-03-25 20:33:35 [XYZ_SpiderName] WARNING: File (error): Error processing file from <GET http://url_path/xyz_img.jpg> referred in <None>: Image too small (279x560 < 300x300)
Traceback (most recent call last):
  File "/home/me/.local/lib64/python2.7/site-packages/Scrapy-1.0.5-py2.7.egg/scrapy/pipelines/files.py", line 268, in media_downloaded
    checksum = self.file_downloaded(response, request, info)
  File "/home/me/.local/lib64/python2.7/site-packages/Scrapy-1.0.5-py2.7.egg/scrapy/pipelines/images.py", line 60, in file_downloaded
    return self.image_downloaded(response, request, info)
  File "/home/me/.local/lib64/python2.7/site-packages/Scrapy-1.0.5-py2.7.egg/scrapy/pipelines/images.py", line 64, in image_downloaded
    for path, image, buf in self.get_images(response, request, info):
  File "/home/me/.local/lib64/python2.7/site-packages/Scrapy-1.0.5-py2.7.egg/scrapy/pipelines/images.py", line 82, in get_images
    (width, height, self.MIN_WIDTH, self.MIN_HEIGHT))
ImageException: Image too small (279x560 < 300x300)
The exception is raised because the downloaded image is too small. OK!
The exception is caught and the event is logged. OK!
The exception is then reraised. -> Is this right?
I do not expect to see this kind of exception when running a spider. I think the expected behavior is to have the event logged, but not propagated as a uncaught exception.
nieksand commented on 25 Mar 2019
If I hit Tornado with an insanely huge request URL, I get the following log output:
[I 190325 14:37:00 iostream:734] Unsatisfiable read, closing connection: delimiter re.compile(b'\r?\n\r?\n') not found within 65536 bytes
I can reproduce this with Python 3.6.7 on both Tornado 5.1.1 and Tornado 6.0.2.
Curl shows an empty response:
... snip giant GET line...
> Host: localhost:9800
> User-Agent: curl/7.61.0
> Accept: */*
> 
* Empty reply from server
* Connection #0 to host localhost left intact
curl: (52) Empty reply from server
Here is a Python snippet that generates a sufficiently nasty URL:
arg = 'a' * 70000
print(f"curl --verbose 'http://localhost:9800/foo?x={arg}'")
I hit this in the real world. My normally beefy-but-manageable input data of ~1000 bytes had a crazy outlier that triggered this. Of course, I need to fix my code to not throw 70KB of crap in a request URL.
Two thoughts:
The error message should be more intuitive
This should return an http 414 (URI Too Long)
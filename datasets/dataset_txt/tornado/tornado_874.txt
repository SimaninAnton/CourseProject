MysticHLE commented on 23 Nov 2013
I'm not sure if this is by design or not, but from testing and looking at the source code for iostream.py, it seems that Tornado is doing something extremely unexpected when performing read_bytes(), particularly in _try_inline_read().
First, Tornado would try to read from the buffer. If no data is in the buffer, it would proceed to reading from the socket/descriptor into the buffer until an exception occurs or if there is nothing to read from the socket. Strangely, this can potentially fill the buffer completely, irrespective of the number of bytes to read specified in the parameter of read_bytes().
Afterwards, Tornado would try to read from the buffer again, invoke the specified callback (assuming we're not using a streaming callback) in the parameter to read_bytes(), and then call _maybe_add_error_listener(), which potentially (if the stream isn't closed) adds another ioloop.IOLoop.READ event to the IOLoop, eventually triggering another _read_to_buffer() within _handle_read(), and may now fill the buffer and close the stream with an IOException (line 462), preventing any further reads from the stream.
Our use case is using read_bytes() and read_until() to upload a large file using chunk encoding...so it seems strange that reading data from the socket to the buffer would ignore the requested amount of data being read and close the stream prematurely. Is this a bug, or is this by design and we are using the library incorrectly?
Thanks
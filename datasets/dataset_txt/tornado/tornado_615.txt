ghandee commented on 24 Aug 2015
Hi,
I'm using tornado's 4.2.1 AsyncHttpClient to send HEAD requests to couple of urls (client is configured to use CurlAsyncHTTPClient and max_clients is set to 1000) and I have libcurl compiled with c-ares enabled.
Simplified version of code looks pretty much like that
concurrency = 10
sem = tornado.locks.Semaphore(concurrency)

def fun(self, url):
        with (yield sem.acquire()):
            try:
                response = yield self.client.fetch(
                    url, method='HEAD',
                    validate_cert=False,
                    request_timeout=REQUEST_TIMEOUT,
                    connect_timeout=CONNECT_TIMEOUT
                )
Initially, I wasnt using semaphores but without this concurrency primitive code in my case starts throwing lots of errors (same if I increase semaphore lock counter to say 50).
After a while I start getting 599 Network unreachable errors which I cant debug in any reasonable way :/
The code runs in infinite loop, sends head request, and schedules next call using add_timeout. I wanted to be able to ping as many resources as possible and at first I run at "too many open files problem, which was OS configuration limititaiton that I solved". Right now I think I have reasonable setup but I am not able to use tornado's event loop's full potential.
Has someone used AsyncHttpClient in similar case (sending multiple requests) and ran into something similar ?
Any clues / help / ideas will be appreciated
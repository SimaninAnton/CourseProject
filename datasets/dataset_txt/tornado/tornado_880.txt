kernelsauce commented on 7 Nov 2013
Hi.
In Tornado github HEAD you can through some simple juggling force Tornado to exit because there is no more memory to allocate.
Recipe:
Create a random string (128MB - 1B), must not contain double CRLF.
Open sockets towards Tornado.
Send random string on all sockets, never close sockets.
Wait for server to use all memory available.
If the server OS has swapping enabled expect that the server will become severely sluggish.
In the perfect world, a HTTP parser with support for streaming would be used and the parser should continously be updated as bytes become available. This way you could in the least set a max amount of header fields to accept and also discard invalid headers before max buffer limit or CRLF is reached (I think 128MB is a lot).
Also Tornado will accept any valid header containing content-length less than 128MB - 1B any read until all the bytes are accepted. This will occur even if there are no matching request handlers... Maybe for the future Tornado would read these bytes on demand?
If Tornado is forwarded requests via nginx or others I would expect this not to be a issue...
j
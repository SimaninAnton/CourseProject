williame commented on 20 Sep 2014
My webserver keeled over recently due to "to many files open". I poked around, and my limit was 1024. I restarted the server and upped the ulimit, but I still wondered how the webserver had used up 1K of descriptors; its not a busy site.
I am running it as non-root and using an iptable rule to give it traffic from port 80. Standard stuff.
The server has been running a few days now, under very light load; a few browser visits per hour.
I have just run lsof on it and it has loads of TCP connections open! They are in sets of 6, which is how many concurrent sockets a browser normally opens against a site.
I will try and anonymize a bit of lsof output:
python  12448  wil   80u  IPv4 3570570303      0t0        TCP box:3456->ip-123.123.221.221:55550 (ESTABLISHED)
python  12448  wil   81u  IPv4 3570570701      0t0        TCP box:3456->ip-123.123.221.221:55552 (ESTABLISHED)
python  12448  wil   82u  IPv4 3570570713      0t0        TCP box:3456->ip-123.123.221.221:55554 (ESTABLISHED)
python  12448  wil   83u  IPv4 3570570739      0t0        TCP box:3456->ip-123.123.221.221:55556 (ESTABLISHED)
python  12448  wil   84u  IPv4 3570570740      0t0        TCP box:3456->ip-123.123.221.221:55558 (ESTABLISHED)
python  12448  wil   85u  IPv4 3570570741      0t0        TCP box:3456->ip-123.123.221.221:55560 (ESTABLISHED)
I can match up these ip-addresses with my normal webserver logs and see how long ago these were created.
And many of these sockets that are open go back days!
What gives? Why aren't they getting closed? How do you get tornado to close stale sockets?